{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available? device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Box prediction\n",
    "# Trying again!\n",
    "import time\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from skimage import io\n",
    "import math\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mplTransforms\n",
    "from datetime import datetime\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"CUDA available? device: \", device)\n",
    "\n",
    "# ---- Make depth images ------------------------------------\n",
    "# -----------------------------------------------------------\n",
    "IMG_X, IMG_Y = 100, 100\n",
    "# length and width of blocks (fixed for now)\n",
    "block_l, block_w = 10, 15 \n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "\n",
    "# -- Calc rectangle vertices. credit Sparkler, stackoverflow, feb 17\n",
    "def makeRectangle(l, w, theta, offset=(0, 0)):\n",
    "    c, s = math.cos(theta), math.sin(theta)\n",
    "    rectCoords = [(l / 2.0, w / 2.0), (l / 2.0, -w / 2.0),\n",
    "                  (-l / 2.0, -w / 2.0), (-l / 2.0, w / 2.0)]\n",
    "    return [(c * x - s * y + offset[0], s * x + c * y + offset[1]) for (x, y) in rectCoords]\n",
    "    #return np.array([(c * x - s * y + offset[0], s * x + c * y + offset[1]) for (x, y) in rectCoords])\n",
    "\n",
    "\n",
    "# ---- Save to file -------------------\n",
    "def make_dataset(dirname, num_images):\n",
    "    true_coords = []\n",
    "    newpath = \"./\" + dirname\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "        print(newpath)\n",
    "    for i in range(num_images):\n",
    "        # orient = 0 # degrees\n",
    "        img = Image.new(\"RGB\", (IMG_X, IMG_Y), \"black\")\n",
    "\n",
    "        # block_l and _w offset so blocks don't run off edge of image\n",
    "        rand_x = int(np.random.rand() * (IMG_X - 2 * block_l)) + block_l\n",
    "        rand_y = int(np.random.rand() * (IMG_Y - 2 * block_w)) + block_w\n",
    "        orient = int(np.random.rand() * 180)  # .random() is range [0.0, 1.0).\n",
    "        orient = math.radians(orient)  # math.cos takes radians!\n",
    "\n",
    "        rect_vertices = makeRectangle(\n",
    "            block_l, block_w, orient, offset=(rand_x, rand_y))\n",
    "\n",
    "        # true_coords.append(np.array((rand_x, rand_y, math.degrees(orient))))\n",
    "        #true_coords.append(np.array([rand_y, rand_x, np.cos(orient), np.sin(orient)]))\n",
    "        true_coords.append(np.array(rect_vertices).flatten())\n",
    "        \n",
    "        idraw = ImageDraw.Draw(img)\n",
    "        idraw.polygon(rect_vertices, fill=\"white\")\n",
    "\n",
    "        img.save(newpath + \"/rect\" + str(i) + \".png\")\n",
    "    return true_coords\n",
    "\n",
    "\n",
    "# ---- Define dataloader ------------------------------------\n",
    "# -----------------------------------------------------------\n",
    "class RectDepthImgsDataset(Dataset):\n",
    "    \"\"\"Artificially generated depth images dataset\"\"\"\n",
    "\n",
    "    def __init__(self, img_dir, coords, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.true_coords = coords\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # print('true coord len', len(self.true_coords))\n",
    "        return len(self.true_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # image = self.images[idx]\n",
    "        image = io.imread(self.img_dir + '/rect' + str(idx) + '.png')\n",
    "        image = torch.FloatTensor(image).permute(\n",
    "            2, 0, 1)  # PIL and torch expect difft orders\n",
    "        coords = torch.FloatTensor(self.true_coords[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # sample = {'image': image, 'grasp': str(coords[0]) + str(coords[1])}\n",
    "        sample = {'image': image, 'grasp': coords}\n",
    "        sample = image, coords\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "# ---- Define Net ------------------------------------\n",
    "# ----------------------------------------------------\n",
    "class Net(nn.Module):  # CIFAR is 32x32x3, MNIST is 28x28pred_x)\n",
    "    def __init__(self, IMG_X, IMG_Y):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self._imgx = IMG_X\n",
    "        self._imgy = IMG_Y\n",
    "        _pool = 2\n",
    "        _stride = 5\n",
    "        _outputlayers = 16\n",
    "\n",
    "        num_classes = 8\n",
    "\n",
    "        def _calc(val):\n",
    "            layer_size = (val - (_stride - 1)) / _pool\n",
    "            return layer_size\n",
    "\n",
    "        def calcOutputs(numOutputLayers):\n",
    "            # print(self._imgx)\n",
    "            const = _calc(_calc(self._imgx))\n",
    "            const *= _calc(_calc(self._imgy))\n",
    "            const *= numOutputLayers \n",
    "            # print(self._const)\n",
    "            const = int(const)\n",
    "            return const\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 100, _stride).to(device)\n",
    "        self.pool = nn.MaxPool2d(_pool, _pool).to(device)\n",
    "        self.conv2 = nn.Conv2d(100, _outputlayers, _stride).to(device)\n",
    "        self.fc1 = nn.Linear(self._const, 120).to(device)\n",
    "        self.fc2 = nn.Linear(120, 84).to(device)\n",
    "        self.fc3 = nn.Linear(84, num_classes).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.size())\n",
    "        x = x.to(device)\n",
    "        x = x.view(-1, 3, IMG_X, IMG_Y)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self._const)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# -- Utility fxn -------------------------------------\n",
    "# Source: https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/train.py\n",
    "# ---------------------------------------------------\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Keeps track of most recent, average, sum, and count of a metric.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def save_checkpoint(epoch, epochs_since_improvement, regrModel,\n",
    "                    loss_history,\n",
    "                    regrLoss, best_loss, is_best):\n",
    "    # Save checkpoint\n",
    "    \"\"\"\n",
    "    Save model checkpoint.\n",
    "    :param epoch: epoch number\n",
    "    :param epochs_since_improvement: number of epochs since last improvement\n",
    "    :param model: model\n",
    "    :param optimizer: optimizer\n",
    "    :param loss: validation loss in this epoch\n",
    "    :param best_loss: best validation loss achieved so far (not necessarily in this checkpoint)\n",
    "    :param is_best: is this checkpoint the best so far?\n",
    "    \"\"\"\n",
    "    state = {\n",
    "        \"epoch\": epoch,\n",
    "        \"epochs_since_improvement\": epochs_since_improvement,\n",
    "        \"regrModel\": regrModel,\n",
    "        \"regrLoss\": regrLoss,\n",
    "        \"loss_history\": loss_history,\n",
    "        \"best_loss\": best_loss,\n",
    "        \"is_best\": is_best\n",
    "    }\n",
    "\n",
    "    filename = \"checkpoint_attempt2.tar\"\n",
    "    torch.save(state, filename)\n",
    "    # If this checkpoint is the best so far, store a copy so it doesn't get overwritten by a worse checkpoint\n",
    "    if is_best:\n",
    "        torch.save(state, \"BEST_\" + filename)\n",
    "\n",
    "# -- Main Functions --------------------------------------------------\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def run_dataset_creation():\n",
    "    train_truth = make_dataset('data', 10000)\n",
    "    print(len(train_truth))\n",
    "    test_truth = make_dataset('./data/test', 300)\n",
    "    # to things\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"CUDA available? device: \", device)\n",
    "\n",
    "    # Dataset is depth images of rectangular blocks\n",
    "    global train_loader\n",
    "    train_dataset = RectDepthImgsDataset(img_dir='./data', coords=train_truth)\n",
    "    # Data loader\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "\n",
    "    test_dataset = RectDepthImgsDataset(\n",
    "        img_dir='./data/test', coords=test_truth)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
    "                             shuffle=True)\n",
    "\n",
    "    np.save(\"train_truth.npy\", train_truth)\n",
    "    np.save(\"test_truth.npy\", test_truth)\n",
    "\n",
    "\n",
    "def train_dataset():\n",
    "\n",
    "    num_classes = 3  # predicting x,y,orientation\n",
    "    learning_rate = 0.0001\n",
    "    criterion = nn.MSELoss()\n",
    "    num_epochs = 400 \n",
    "\n",
    "    print_freq = 25  # print training or validation status every __ batches\n",
    "    epochs_since_improvement = 0\n",
    "    best_loss = 5000.0  # assume a high loss at first\n",
    "\n",
    "    train_truth = np.load(\"train_truth.npy\")\n",
    "    # loading the training and testing data5\n",
    "    test_truth = np.load(\"test_truth.npy\")\n",
    "\n",
    "    batch_time = AverageMeter()  # forward prop. + back prop. time\n",
    "    data_time = AverageMeter()  # data loading time\n",
    "    loss_avg = AverageMeter()  # loss\n",
    "    loss_history = []\n",
    "\n",
    "    # -- Instantiate CNN -------------------------\n",
    "    regrModel = Net(IMG_X, IMG_Y)\n",
    "    regrModel = regrModel.to(device)\n",
    "    optimizer = torch.optim.Adam(regrModel.parameters(), lr=learning_rate)\n",
    "\n",
    "    regrModel.train()  # enable dropout\n",
    "    print('Training model now...')\n",
    "\n",
    "    # -- Load datasets -------------------------\n",
    "    train_truth = np.load(\"train_truth.npy\")\n",
    "    train_dataset = RectDepthImgsDataset(img_dir='./data', coords=train_truth)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "\n",
    "    # -- Begin training -------------------------\n",
    "    print('Start time: ',  datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        for i_batch, (images, labels) in enumerate(train_loader):\n",
    "            data_time.update(time.time() - start)\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = regrModel(images).to(device)\n",
    "\n",
    "            regrLoss = criterion(outputs, labels)\n",
    "            loss_history.append(regrLoss)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            regrLoss.backward()\n",
    "\n",
    "            # Update Model\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_avg.update(regrLoss.item())\n",
    "\n",
    "            # Print status\n",
    "            batch_time.update(time.time() - start)\n",
    "            start = time.time()\n",
    "\n",
    "            if i_batch % print_freq == 0:\n",
    "                print(\n",
    "                    \"Epoch: [{0}][{1}/{2}]\\t\"\n",
    "                    \"Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"\n",
    "                    \"Loss {loss.val:.4f} (Avg {loss.avg:.4f})\\t\".format(\n",
    "                        epoch,\n",
    "                        i_batch,\n",
    "                        len(train_loader),\n",
    "                        batch_time=batch_time,\n",
    "                        loss=loss_avg,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # One epoch's loss\n",
    "        is_best = loss_avg.avg < best_loss\n",
    "        best_loss = min(loss_avg.avg, best_loss)\n",
    "\n",
    "        if not is_best:\n",
    "            epochs_since_improvement += 1\n",
    "            print(\"\\nEpochs since last improvement: %d, %d loss\\n\" %\n",
    "                  (epochs_since_improvement, loss_avg.avg))\n",
    "\n",
    "        else:\n",
    "            epochs_since_improvement = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        save_checkpoint(epoch, epochs_since_improvement, regrModel,\n",
    "                        loss_history,\n",
    "                        loss_avg.avg, best_loss, is_best)\n",
    "    print('End time: ',  datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "\n",
    "# --- VIEW RESULTS ----------------------------------------\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def view_loss_results():\n",
    "    filename = \"checkpoint_attempt2.tar\"\n",
    "    checkpoint = torch.load(filename)\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    loss_history = checkpoint['loss_history']\n",
    "    regrModel = checkpoint['regrModel']\n",
    "\n",
    "    print('\\nLoaded checkpoint from epoch %d. Best loss so far is %.3f.\\n' %\n",
    "          (start_epoch, best_loss))\n",
    "    test_truth = np.load(\"test_truth.npy\")\n",
    "    test_dataset = RectDepthImgsDataset(\n",
    "        img_dir='./data/test', coords=test_truth)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
    "                             shuffle=True)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        dataiter = iter(test_loader)\n",
    "        images, labels = dataiter.next()\n",
    "\n",
    "        # Move to default device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = regrModel(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Loss\n",
    "        print(\"loss across batch size of \", labels.size()[0], 'is: \\n', loss)\n",
    "\n",
    "        # print(labels)\n",
    "        print('\\n!-- labels size', labels.size())\n",
    "\n",
    "        plt.plot(range(len(loss_history)), loss_history)  # regr loss\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot(range(len(loss_history)), loss_history)  # regr loss\n",
    "        \n",
    "        plt.xlim((4500, 5100))\n",
    "        plt.ylim((0,30))\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        # sns.regplot(x=np.arange(len(loss_history)),\n",
    "        # y=np.array(loss_history)) # regr loss\n",
    "\n",
    "\n",
    "def view_image_results():\n",
    "    filename = \"checkpoint_attempt2.tar\"\n",
    "    checkpoint = torch.load(filename)\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    loss_history = checkpoint['loss_history']\n",
    "    regrModel = checkpoint['regrModel']\n",
    "\n",
    "    print('\\nLoaded checkpoint from epoch %d. Best loss so far is %.3f.\\n' %\n",
    "          (start_epoch, best_loss))\n",
    "\n",
    "    test_truth = np.load(\"test_truth.npy\")\n",
    "    test_dataset = RectDepthImgsDataset(\n",
    "        img_dir='./data/test', coords=test_truth)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
    "                             shuffle=True)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        dataiter = iter(test_loader)\n",
    "        images, coords = dataiter.next()\n",
    "\n",
    "        # Move to default device\n",
    "        images = images.to(device)\n",
    "        coords = coords.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = regrModel(images)\n",
    "\n",
    "        labels = coords.cpu()\n",
    "\n",
    "        plt.rcParams['figure.figsize'] = [50, 10]\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        print('lenlabels', len(labels))\n",
    "        print(block_l, block_w, IMG_X, IMG_Y)\n",
    "\n",
    "        for i in range(len(labels) - 10):\n",
    "            #print('i', i)\n",
    "            #cornerUR, cornerLR, cornerLL, cornerUL = labels[i].numpy()\n",
    "            corners = labels[i].numpy()\n",
    "            pred_corners = outputs[i].cpu().numpy()\n",
    "            print('i', i, 'truth: ', corners, 'pred:', pred_corners) \n",
    "            \n",
    "            unflattened_corners = []\n",
    "            pred_unflattened_corners = []\n",
    "            for j in range(4):\n",
    "                tmpx = corners[2 * j] + (i * IMG_X)\n",
    "                tmpy = corners[(2 * j) + 1]\n",
    "                pred_tmpx = pred_corners[2 * j] + (i * IMG_X)\n",
    "                pred_tmpy = pred_corners[(2 * j) + 1]\n",
    "                unflattened_corners.append((tmpx, tmpy))\n",
    "                pred_unflattened_corners.append((pred_tmpx, pred_tmpy))\n",
    "            unflattened_corners = np.array(unflattened_corners)\n",
    "            pred_unflattened_corners = np.array(pred_unflattened_corners)\n",
    "                \n",
    "\n",
    "                \n",
    "            # -- Plot truth rectangle \n",
    "            truth_rect = patches.Polygon(unflattened_corners, closed=True, fill=True, color='black')\n",
    "            # correct for rotation around LL corner\n",
    "            ax.add_patch(truth_rect)\n",
    "            \n",
    "\n",
    "            # -- Plot prediction\n",
    "            pred_rect = patches.Polygon(pred_unflattened_corners, closed=True, fill=True, color='orange')\n",
    "            # correct for rotation around LL corner\n",
    "            ax.add_patch(pred_rect)\n",
    "            \n",
    "            # -- Plot image border \n",
    "            image_outline = patches.Rectangle((i * IMG_X, 0), 200, 200, angle=0, fill=False, color='black')\n",
    "            ax.add_patch(image_outline)\n",
    "\n",
    "            # Scatter plot of true centers\n",
    "            # TODO: add logic to offset back to center correctly (accounting for theta)\n",
    "            x, y = corners[0], corners[1]\n",
    "            x, y = x - (block_l/2.0), y - (block_w/2.0)\n",
    "            ax.scatter(x + i * IMG_X, y, color='r', marker='x', linewidth='1',\n",
    "                       zorder=100)\n",
    "        ax.set_aspect('equal', 'box')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    print('Creating dataset')\n",
    "    run_dataset_creation()\n",
    "\n",
    "    print('Training model')\n",
    "    train_dataset()\n",
    "\n",
    "    print('View results')\n",
    "\n",
    "    view_loss_results()\n",
    "    view_image_results()\n",
    "\n",
    "    #input('Close all?')\n",
    "    #plt.close('all')\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    #main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset\n",
      "10000\n",
      "CUDA available? device:  cuda:0\n",
      "Training model\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute '_const'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-9870015f151e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'View results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-9870015f151e>\u001b[0m in \u001b[0;36mtrain_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;31m# -- Instantiate CNN -------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     \u001b[0mregrModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0mregrModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregrModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregrModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-9870015f151e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, IMG_X, IMG_Y)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_outputlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_const\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m84\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 518\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Net' object has no attribute '_const'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Calc rectangle vertices. credit Sparkler, stackoverflow, feb 17\n",
    "def makeRectangle(l, w, theta, offset=(0, 0)):\n",
    "    c, s = math.cos(theta), math.sin(theta)\n",
    "    rectCoords = [(l / 2.0, w / 2.0), (l / 2.0, -w / 2.0),\n",
    "                  (-l / 2.0, -w / 2.0), (-l / 2.0, w / 2.0)]\n",
    "    #return np.array([(c * x - s * y + offset[0], s * x + c * y + offset[1]) for (x, y) in rectCoords]).flatten()\n",
    "    return [(c * x - s * y + offset[0], s * x + c * y + offset[1]) for (x, y) in rectCoords]\n",
    "\n",
    "verts = makeRectangle(20,30,0)\n",
    "print('verts', verts)\n",
    "verts = np.array(verts).flatten()\n",
    "unflat = []\n",
    "for i in range(4):\n",
    "    print(i)\n",
    "    tmpx = verts[2 * i]\n",
    "    tmpy = verts[(2 * i) + 1]\n",
    "    unflat.append((tmpx, tmpy))\n",
    "print(unflat)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "poly = patches.Polygon(unflat, fill=True)\n",
    "ax.add_patch(poly)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
