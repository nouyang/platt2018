{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wed 17:10 \n",
    "# Creates rectangle \"depth images\", a CNN, solves, and graphs the losses (by epoch)\n",
    "# as well as the labels against the original image, and the true image (with x's)\n",
    "# nrw\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from skimage import io\n",
    "import math\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "IMG_X, IMG_Y = 400,300\n",
    "# length and width of blocks (fixed for now)\n",
    "block_l, block_w = 25, 25\n",
    "num_images = 1500\n",
    "\n",
    "# img_list = []\n",
    "true_coords = []\n",
    "\n",
    "\n",
    "# Calc rectangle vertices. makeRectangle() credit Sparkler, stackoverflow, feb 17\n",
    "def makeRectangle(l, w, theta, offset=(0, 0)):\n",
    "    c, s = math.cos(theta), math.sin(theta)\n",
    "    rectCoords = [(l/2.0, w/2.0), (l/2.0, -w/2.0), (-l/2.0, -w/2.0), (-l/2.0, w/2.0)]\n",
    "    return [(c*x-s*y+offset[0], s*x+c*y+offset[1]) for (x, y) in rectCoords]\n",
    "\n",
    "\n",
    "# ---- Make depth images ---\n",
    "for i in range(num_images):\n",
    "    orient = 0 # degrees\n",
    "    img = Image.new('RGB', (IMG_X, IMG_Y), 'black')\n",
    "\n",
    "    # block_l and _w offset so blocks don't run off edge of image\n",
    "    rand_x = int(np.random.rand() * (IMG_X-block_l))\n",
    "    rand_y = int(np.random.rand() * (IMG_Y-block_w))\n",
    "\n",
    "    true_coords.append(np.array((rand_x, rand_y)))\n",
    "\n",
    "    rect_vertices = makeRectangle(block_l, block_w, orient, offset=(rand_x,\n",
    "                                                                    rand_y))\n",
    "    idraw = ImageDraw.Draw(img)\n",
    "    idraw.polygon(rect_vertices, fill='white')\n",
    "\n",
    "    # use a truetype font\n",
    "    #font = ImageFont.truetype(\"DejavuSans.ttf\", 15)\n",
    "    #font = ImageFont.truetype(\"Arial.ttf\",14)\n",
    "    #idraw.text((10, 25), '('+ str(rand_x) + ', ' + str(rand_y) +')')\n",
    "\n",
    "\n",
    "    img.save('./data/rect'+str(i)+'.png')\n",
    "\n",
    "\n",
    "    \n",
    "class RectDepthImgsDataset(Dataset):\n",
    "    \"\"\"Artificially generated depth images dataset\"\"\"\n",
    "\n",
    "    def __init__(self, img_dir, coords, transform=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.true_coords = coords\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.true_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # image = self.images[idx]\n",
    "        image = io.imread(self.img_dir + '/rect'+str(idx)+'.png')\n",
    "        image = torch.FloatTensor(image).permute(2, 0, 1) #PIL and torch expect difft orders\n",
    "        coords = torch.FloatTensor(true_coords[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # sample = {'image': image, 'grasp': str(coords[0]) + str(coords[1])}\n",
    "        sample = {'image': image, 'grasp': coords}\n",
    "        sample = image, coords\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 50 \n",
    "num_classes = 2\n",
    "batch_size = 4 \n",
    "learning_rate = 0.001\n",
    "\n",
    "# Dataset is depth images of rectangular blocks\n",
    "train_dataset = RectDepthImgsDataset(img_dir='./data', coords=true_coords)\n",
    "\n",
    "# Data loader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "const = 16*47*47\n",
    "#const = 16*97*72\n",
    "\n",
    "\n",
    "# 300x300\n",
    "#torch.Size([4, 300, 300, 3])\n",
    "#torch.Size([4, 3, 300, 300])\n",
    "#torch.Size([4, 6, 148, 148])\n",
    "#torch.Size([4, 16, 72, 72])\n",
    "\n",
    "\n",
    "# 200x200\n",
    "#const = 16*47*47*4\n",
    "#torch.Size([4, 200, 200, 3])\n",
    "#torch.Size([4, 3, 200, 200])\n",
    "#torch.Size([4, 6, 98, 98])\n",
    "#torch.Size([4, 16, 47, 47])\n",
    "\n",
    "# = 200-4 / 2\n",
    "# where 4 = 5x5 (conv) -1 = area of image after conv without padding = 200->98\n",
    "# = 98-4 / 2\n",
    "# where 4 = 5x5 (conv) -1 = area of image after conv without padding = 98->47\n",
    "# output is 47x47 image, with 16 output channels\n",
    "\n",
    "\n",
    "# 400x300\n",
    "#torch.Size([4, 300, 400, 3])\n",
    "#torch.Size([4, 3, 400, 300])\n",
    "#torch.Size([4, 6, 198, 148])\n",
    "#torch.Size([4, 16, 97, 72])\n",
    "\n",
    "\n",
    "class Net(nn.Module):  # CIFAR is 32x32x3, MNIST is 28x28x1)\n",
    "    def __init__(self, IMG_X, IMG_Y):\n",
    "        super(Net, self).__init__()\n",
    "        self._imgx = IMG_X\n",
    "        self._imgy = IMG_Y\n",
    "        _pool = 2\n",
    "        _stride = 5\n",
    "        _outputlayers = 16\n",
    "        \n",
    "        def _calc(val):\n",
    "            layer_size = (val- (_stride-1)) / _pool\n",
    "            return layer_size \n",
    "        \n",
    "        #print(self._imgx)\n",
    "        self._const = _calc(_calc(self._imgx))\n",
    "        self._const *= _calc(_calc(self._imgy))\n",
    "        self._const *= _outputlayers \n",
    "        #print(self._const)\n",
    "        self._const = int(self._const)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, _stride)\n",
    "        self.pool = nn.MaxPool2d(_pool, _pool)\n",
    "        self.conv2 = nn.Conv2d(6, _outputlayers, _stride)\n",
    "        self.fc1 = nn.Linear(self._const, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        x = x.view(-1, 3, IMG_X, IMG_Y)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self._const)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net(IMG_X, IMG_Y)\n",
    "images = iter(train_loader)\n",
    "outputs = model(images.next()[0])\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model now...\n",
      "Epoch [1/50], Step [1/375], Loss: 52234.1133\n",
      "Epoch [1/50], Step [2/375], Loss: 19984.1602\n",
      "Epoch [1/50], Step [3/375], Loss: 22110.1738\n",
      "Epoch [1/50], Step [4/375], Loss: 16244.5195\n",
      "Epoch [1/50], Step [5/375], Loss: 7527.7583\n",
      "Epoch [1/50], Step [6/375], Loss: 5610.8462\n",
      "Epoch [1/50], Step [7/375], Loss: 44593.1523\n",
      "Epoch [1/50], Step [8/375], Loss: 15119.0801\n",
      "Epoch [1/50], Step [9/375], Loss: 23256.7695\n",
      "Epoch [1/50], Step [10/375], Loss: 12390.0557\n",
      "Epoch [1/50], Step [11/375], Loss: 12360.8604\n",
      "Epoch [1/50], Step [12/375], Loss: 30499.1875\n",
      "Epoch [1/50], Step [13/375], Loss: 3690.3381\n",
      "Epoch [1/50], Step [14/375], Loss: 10630.9932\n",
      "Epoch [1/50], Step [15/375], Loss: 13804.3877\n",
      "Epoch [1/50], Step [16/375], Loss: 7968.5840\n",
      "Epoch [1/50], Step [17/375], Loss: 15270.2881\n",
      "Epoch [1/50], Step [18/375], Loss: 41949.2461\n",
      "Epoch [1/50], Step [19/375], Loss: 25963.5371\n",
      "Epoch [1/50], Step [20/375], Loss: 27096.8223\n",
      "Epoch [1/50], Step [21/375], Loss: 15464.5664\n",
      "Epoch [1/50], Step [22/375], Loss: 7471.5283\n",
      "Epoch [1/50], Step [23/375], Loss: 13257.8682\n",
      "Epoch [1/50], Step [24/375], Loss: 8158.4028\n",
      "Epoch [1/50], Step [25/375], Loss: 14376.7041\n",
      "Epoch [1/50], Step [26/375], Loss: 6241.5093\n",
      "Epoch [1/50], Step [27/375], Loss: 16413.0703\n",
      "Epoch [1/50], Step [28/375], Loss: 5637.1406\n",
      "Epoch [1/50], Step [29/375], Loss: 5370.0996\n",
      "Epoch [1/50], Step [30/375], Loss: 13574.5381\n",
      "Epoch [1/50], Step [31/375], Loss: 15292.4941\n",
      "Epoch [1/50], Step [32/375], Loss: 17394.1348\n",
      "Epoch [1/50], Step [33/375], Loss: 4337.1738\n",
      "Epoch [1/50], Step [34/375], Loss: 12220.3994\n",
      "Epoch [1/50], Step [35/375], Loss: 9321.7021\n",
      "Epoch [1/50], Step [36/375], Loss: 6763.0576\n",
      "Epoch [1/50], Step [37/375], Loss: 11343.5645\n",
      "Epoch [1/50], Step [38/375], Loss: 12213.8184\n",
      "Epoch [1/50], Step [39/375], Loss: 12438.1221\n",
      "Epoch [1/50], Step [40/375], Loss: 8455.0684\n",
      "Epoch [1/50], Step [41/375], Loss: 6233.5962\n",
      "Epoch [1/50], Step [42/375], Loss: 10799.5742\n",
      "Epoch [1/50], Step [43/375], Loss: 26284.8027\n",
      "Epoch [1/50], Step [44/375], Loss: 9340.3984\n",
      "Epoch [1/50], Step [45/375], Loss: 10357.4951\n",
      "Epoch [1/50], Step [46/375], Loss: 12593.0918\n",
      "Epoch [1/50], Step [47/375], Loss: 8913.8838\n",
      "Epoch [1/50], Step [48/375], Loss: 9613.3018\n",
      "Epoch [1/50], Step [49/375], Loss: 4928.3789\n",
      "Epoch [1/50], Step [50/375], Loss: 14437.8779\n",
      "Epoch [1/50], Step [51/375], Loss: 5025.1865\n",
      "Epoch [1/50], Step [52/375], Loss: 9009.4512\n",
      "Epoch [1/50], Step [53/375], Loss: 15900.7178\n",
      "Epoch [1/50], Step [54/375], Loss: 2526.8645\n",
      "Epoch [1/50], Step [55/375], Loss: 26809.7812\n",
      "Epoch [1/50], Step [56/375], Loss: 7341.0684\n",
      "Epoch [1/50], Step [57/375], Loss: 6561.8740\n",
      "Epoch [1/50], Step [58/375], Loss: 7125.8989\n",
      "Epoch [1/50], Step [59/375], Loss: 6374.2065\n",
      "Epoch [1/50], Step [60/375], Loss: 7303.8950\n",
      "Epoch [1/50], Step [61/375], Loss: 5628.5464\n",
      "Epoch [1/50], Step [62/375], Loss: 7487.5815\n",
      "Epoch [1/50], Step [63/375], Loss: 12297.0938\n",
      "Epoch [1/50], Step [64/375], Loss: 13626.9043\n",
      "Epoch [1/50], Step [65/375], Loss: 3461.6340\n",
      "Epoch [1/50], Step [66/375], Loss: 3844.1108\n",
      "Epoch [1/50], Step [67/375], Loss: 4382.0601\n",
      "Epoch [1/50], Step [68/375], Loss: 5852.7974\n",
      "Epoch [1/50], Step [69/375], Loss: 10470.8740\n",
      "Epoch [1/50], Step [70/375], Loss: 4354.9360\n",
      "Epoch [1/50], Step [71/375], Loss: 17927.2090\n",
      "Epoch [1/50], Step [72/375], Loss: 10610.3857\n",
      "Epoch [1/50], Step [73/375], Loss: 9483.7480\n",
      "Epoch [1/50], Step [74/375], Loss: 1290.9587\n",
      "Epoch [1/50], Step [75/375], Loss: 3366.3586\n",
      "Epoch [1/50], Step [76/375], Loss: 9640.9688\n",
      "Epoch [1/50], Step [77/375], Loss: 940.4838\n",
      "Epoch [1/50], Step [78/375], Loss: 1463.9709\n",
      "Epoch [1/50], Step [79/375], Loss: 3678.9375\n",
      "Epoch [1/50], Step [80/375], Loss: 6736.3799\n",
      "Epoch [1/50], Step [81/375], Loss: 8866.8545\n",
      "Epoch [1/50], Step [82/375], Loss: 16814.0820\n",
      "Epoch [1/50], Step [83/375], Loss: 4922.3408\n",
      "Epoch [1/50], Step [84/375], Loss: 12610.9609\n",
      "Epoch [1/50], Step [85/375], Loss: 5813.0244\n",
      "Epoch [1/50], Step [86/375], Loss: 4387.4248\n",
      "Epoch [1/50], Step [87/375], Loss: 7306.7529\n",
      "Epoch [1/50], Step [88/375], Loss: 3159.7339\n",
      "Epoch [1/50], Step [89/375], Loss: 3844.6394\n",
      "Epoch [1/50], Step [90/375], Loss: 9790.1465\n",
      "Epoch [1/50], Step [91/375], Loss: 1876.6869\n",
      "Epoch [1/50], Step [92/375], Loss: 10315.1182\n",
      "Epoch [1/50], Step [93/375], Loss: 4376.3115\n",
      "Epoch [1/50], Step [94/375], Loss: 3746.9883\n",
      "Epoch [1/50], Step [95/375], Loss: 4708.1484\n",
      "Epoch [1/50], Step [96/375], Loss: 9022.0527\n",
      "Epoch [1/50], Step [97/375], Loss: 4479.4136\n",
      "Epoch [1/50], Step [98/375], Loss: 5868.0869\n",
      "Epoch [1/50], Step [99/375], Loss: 6573.5742\n",
      "Epoch [1/50], Step [100/375], Loss: 6579.3867\n",
      "Epoch [1/50], Step [101/375], Loss: 4836.5737\n",
      "Epoch [1/50], Step [102/375], Loss: 9017.2461\n",
      "Epoch [1/50], Step [103/375], Loss: 5206.8955\n",
      "Epoch [1/50], Step [104/375], Loss: 5138.6704\n",
      "Epoch [1/50], Step [105/375], Loss: 5608.5420\n",
      "Epoch [1/50], Step [106/375], Loss: 8169.3018\n",
      "Epoch [1/50], Step [107/375], Loss: 3869.6580\n",
      "Epoch [1/50], Step [108/375], Loss: 9267.8252\n",
      "Epoch [1/50], Step [109/375], Loss: 3378.6606\n",
      "Epoch [1/50], Step [110/375], Loss: 1786.3140\n",
      "Epoch [1/50], Step [111/375], Loss: 3113.0779\n",
      "Epoch [1/50], Step [112/375], Loss: 6941.6455\n",
      "Epoch [1/50], Step [113/375], Loss: 9303.1064\n",
      "Epoch [1/50], Step [114/375], Loss: 6645.6782\n",
      "Epoch [1/50], Step [115/375], Loss: 3893.6152\n",
      "Epoch [1/50], Step [116/375], Loss: 5243.1460\n",
      "Epoch [1/50], Step [117/375], Loss: 3505.5518\n",
      "Epoch [1/50], Step [118/375], Loss: 7241.0142\n",
      "Epoch [1/50], Step [119/375], Loss: 2710.8870\n",
      "Epoch [1/50], Step [120/375], Loss: 8104.8906\n",
      "Epoch [1/50], Step [121/375], Loss: 1658.3687\n",
      "Epoch [1/50], Step [122/375], Loss: 7289.4844\n",
      "Epoch [1/50], Step [123/375], Loss: 4906.4595\n",
      "Epoch [1/50], Step [124/375], Loss: 2049.9319\n",
      "Epoch [1/50], Step [125/375], Loss: 2959.6230\n",
      "Epoch [1/50], Step [126/375], Loss: 3814.4521\n",
      "Epoch [1/50], Step [127/375], Loss: 2145.0642\n",
      "Epoch [1/50], Step [128/375], Loss: 11518.9131\n",
      "Epoch [1/50], Step [129/375], Loss: 6151.6494\n",
      "Epoch [1/50], Step [130/375], Loss: 8476.3164\n",
      "Epoch [1/50], Step [131/375], Loss: 1632.0167\n",
      "Epoch [1/50], Step [132/375], Loss: 4939.0117\n",
      "Epoch [1/50], Step [133/375], Loss: 9119.6387\n",
      "Epoch [1/50], Step [134/375], Loss: 4432.0986\n",
      "Epoch [1/50], Step [135/375], Loss: 3952.2993\n",
      "Epoch [1/50], Step [136/375], Loss: 5068.9404\n",
      "Epoch [1/50], Step [137/375], Loss: 1518.5551\n",
      "Epoch [1/50], Step [138/375], Loss: 4038.4529\n",
      "Epoch [1/50], Step [139/375], Loss: 8049.7388\n",
      "Epoch [1/50], Step [140/375], Loss: 11861.1562\n",
      "Epoch [1/50], Step [141/375], Loss: 12186.7959\n",
      "Epoch [1/50], Step [142/375], Loss: 3654.8118\n",
      "Epoch [1/50], Step [143/375], Loss: 10175.4609\n",
      "Epoch [1/50], Step [144/375], Loss: 5656.4106\n",
      "Epoch [1/50], Step [145/375], Loss: 8674.2725\n",
      "Epoch [1/50], Step [146/375], Loss: 5514.1509\n",
      "Epoch [1/50], Step [147/375], Loss: 8206.4980\n",
      "Epoch [1/50], Step [148/375], Loss: 7927.4976\n",
      "Epoch [1/50], Step [149/375], Loss: 3565.3030\n",
      "Epoch [1/50], Step [150/375], Loss: 4165.5254\n",
      "Epoch [1/50], Step [151/375], Loss: 8607.8145\n",
      "Epoch [1/50], Step [152/375], Loss: 2199.3196\n",
      "Epoch [1/50], Step [153/375], Loss: 2229.1672\n",
      "Epoch [1/50], Step [154/375], Loss: 8034.1055\n",
      "Epoch [1/50], Step [155/375], Loss: 7464.7285\n",
      "Epoch [1/50], Step [156/375], Loss: 4305.9668\n",
      "Epoch [1/50], Step [157/375], Loss: 3924.7681\n",
      "Epoch [1/50], Step [158/375], Loss: 4883.7505\n",
      "Epoch [1/50], Step [159/375], Loss: 9434.8145\n",
      "Epoch [1/50], Step [160/375], Loss: 10617.9746\n",
      "Epoch [1/50], Step [161/375], Loss: 4562.3848\n",
      "Epoch [1/50], Step [162/375], Loss: 9213.7627\n",
      "Epoch [1/50], Step [163/375], Loss: 2735.0840\n",
      "Epoch [1/50], Step [164/375], Loss: 2285.6621\n",
      "Epoch [1/50], Step [165/375], Loss: 5044.9336\n",
      "Epoch [1/50], Step [166/375], Loss: 4910.0015\n",
      "Epoch [1/50], Step [167/375], Loss: 1545.9272\n",
      "Epoch [1/50], Step [168/375], Loss: 824.6813\n",
      "Epoch [1/50], Step [169/375], Loss: 5846.9951\n",
      "Epoch [1/50], Step [170/375], Loss: 7656.6616\n",
      "Epoch [1/50], Step [171/375], Loss: 3530.7664\n",
      "Epoch [1/50], Step [172/375], Loss: 12620.6904\n",
      "Epoch [1/50], Step [173/375], Loss: 4585.0376\n",
      "Epoch [1/50], Step [174/375], Loss: 7121.1675\n",
      "Epoch [1/50], Step [175/375], Loss: 3990.9026\n",
      "Epoch [1/50], Step [176/375], Loss: 8751.8516\n",
      "Epoch [1/50], Step [177/375], Loss: 6141.5391\n",
      "Epoch [1/50], Step [178/375], Loss: 6453.3257\n",
      "Epoch [1/50], Step [179/375], Loss: 8329.0645\n",
      "Epoch [1/50], Step [180/375], Loss: 2793.9263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [181/375], Loss: 6078.9692\n",
      "Epoch [1/50], Step [182/375], Loss: 7690.0483\n",
      "Epoch [1/50], Step [183/375], Loss: 8498.9717\n",
      "Epoch [1/50], Step [184/375], Loss: 10774.4990\n",
      "Epoch [1/50], Step [185/375], Loss: 5250.1016\n",
      "Epoch [1/50], Step [186/375], Loss: 5597.1860\n",
      "Epoch [1/50], Step [187/375], Loss: 6868.5830\n",
      "Epoch [1/50], Step [188/375], Loss: 7371.2456\n",
      "Epoch [1/50], Step [189/375], Loss: 1560.0724\n",
      "Epoch [1/50], Step [190/375], Loss: 6739.6270\n",
      "Epoch [1/50], Step [191/375], Loss: 1634.0278\n",
      "Epoch [1/50], Step [192/375], Loss: 2716.3025\n",
      "Epoch [1/50], Step [193/375], Loss: 4871.0093\n",
      "Epoch [1/50], Step [194/375], Loss: 6763.3110\n",
      "Epoch [1/50], Step [195/375], Loss: 1857.4230\n",
      "Epoch [1/50], Step [196/375], Loss: 7994.8701\n",
      "Epoch [1/50], Step [197/375], Loss: 1385.5677\n",
      "Epoch [1/50], Step [198/375], Loss: 5667.6362\n",
      "Epoch [1/50], Step [199/375], Loss: 6237.8159\n",
      "Epoch [1/50], Step [200/375], Loss: 6258.0469\n",
      "Epoch [1/50], Step [201/375], Loss: 2089.6096\n",
      "Epoch [1/50], Step [202/375], Loss: 1934.6141\n",
      "Epoch [1/50], Step [203/375], Loss: 5604.0654\n",
      "Epoch [1/50], Step [204/375], Loss: 9391.3496\n",
      "Epoch [1/50], Step [205/375], Loss: 6740.8184\n",
      "Epoch [1/50], Step [206/375], Loss: 3779.3948\n",
      "Epoch [1/50], Step [207/375], Loss: 7173.0132\n",
      "Epoch [1/50], Step [208/375], Loss: 8892.8174\n",
      "Epoch [1/50], Step [209/375], Loss: 4435.1387\n",
      "Epoch [1/50], Step [210/375], Loss: 6359.4614\n",
      "Epoch [1/50], Step [211/375], Loss: 3546.7456\n",
      "Epoch [1/50], Step [212/375], Loss: 2298.1597\n",
      "Epoch [1/50], Step [213/375], Loss: 7119.5112\n",
      "Epoch [1/50], Step [214/375], Loss: 11465.3535\n",
      "Epoch [1/50], Step [215/375], Loss: 5492.8765\n",
      "Epoch [1/50], Step [216/375], Loss: 7033.2715\n",
      "Epoch [1/50], Step [217/375], Loss: 4111.8008\n",
      "Epoch [1/50], Step [218/375], Loss: 6886.7417\n",
      "Epoch [1/50], Step [219/375], Loss: 7687.2686\n",
      "Epoch [1/50], Step [220/375], Loss: 5827.6450\n",
      "Epoch [1/50], Step [221/375], Loss: 3494.7366\n",
      "Epoch [1/50], Step [222/375], Loss: 3992.1394\n",
      "Epoch [1/50], Step [223/375], Loss: 7895.5151\n",
      "Epoch [1/50], Step [224/375], Loss: 7488.0542\n",
      "Epoch [1/50], Step [225/375], Loss: 3265.3481\n",
      "Epoch [1/50], Step [226/375], Loss: 5286.3413\n",
      "Epoch [1/50], Step [227/375], Loss: 3384.0208\n",
      "Epoch [1/50], Step [228/375], Loss: 4465.9531\n",
      "Epoch [1/50], Step [229/375], Loss: 3462.5500\n",
      "Epoch [1/50], Step [230/375], Loss: 6401.4917\n",
      "Epoch [1/50], Step [231/375], Loss: 4483.8115\n",
      "Epoch [1/50], Step [232/375], Loss: 1193.9395\n",
      "Epoch [1/50], Step [233/375], Loss: 4005.0649\n",
      "Epoch [1/50], Step [234/375], Loss: 3879.9226\n",
      "Epoch [1/50], Step [235/375], Loss: 8484.1543\n",
      "Epoch [1/50], Step [236/375], Loss: 8265.3213\n",
      "Epoch [1/50], Step [237/375], Loss: 8853.9922\n",
      "Epoch [1/50], Step [238/375], Loss: 6192.9668\n",
      "Epoch [1/50], Step [239/375], Loss: 6516.3242\n",
      "Epoch [1/50], Step [240/375], Loss: 3478.3499\n",
      "Epoch [1/50], Step [241/375], Loss: 6345.5493\n",
      "Epoch [1/50], Step [242/375], Loss: 3527.3887\n",
      "Epoch [1/50], Step [243/375], Loss: 1520.8883\n",
      "Epoch [1/50], Step [244/375], Loss: 5834.4165\n",
      "Epoch [1/50], Step [245/375], Loss: 8464.5088\n",
      "Epoch [1/50], Step [246/375], Loss: 2494.2551\n",
      "Epoch [1/50], Step [247/375], Loss: 6979.2056\n",
      "Epoch [1/50], Step [248/375], Loss: 11827.9590\n",
      "Epoch [1/50], Step [249/375], Loss: 7286.7622\n",
      "Epoch [1/50], Step [250/375], Loss: 5047.6460\n",
      "Epoch [1/50], Step [251/375], Loss: 8263.6348\n",
      "Epoch [1/50], Step [252/375], Loss: 5270.7739\n",
      "Epoch [1/50], Step [253/375], Loss: 12898.1699\n",
      "Epoch [1/50], Step [254/375], Loss: 4133.5737\n",
      "Epoch [1/50], Step [255/375], Loss: 10496.9785\n",
      "Epoch [1/50], Step [256/375], Loss: 4262.2051\n",
      "Epoch [1/50], Step [257/375], Loss: 6024.6479\n",
      "Epoch [1/50], Step [258/375], Loss: 12684.3154\n",
      "Epoch [1/50], Step [259/375], Loss: 7563.4390\n",
      "Epoch [1/50], Step [260/375], Loss: 10562.8496\n",
      "Epoch [1/50], Step [261/375], Loss: 6782.7861\n",
      "Epoch [1/50], Step [262/375], Loss: 7789.0571\n",
      "Epoch [1/50], Step [263/375], Loss: 5670.1445\n",
      "Epoch [1/50], Step [264/375], Loss: 3665.4336\n",
      "Epoch [1/50], Step [265/375], Loss: 5915.5635\n",
      "Epoch [1/50], Step [266/375], Loss: 3116.7500\n",
      "Epoch [1/50], Step [267/375], Loss: 3241.2397\n",
      "Epoch [1/50], Step [268/375], Loss: 6184.7695\n",
      "Epoch [1/50], Step [269/375], Loss: 6002.5957\n",
      "Epoch [1/50], Step [270/375], Loss: 7643.8110\n",
      "Epoch [1/50], Step [271/375], Loss: 9356.7305\n",
      "Epoch [1/50], Step [272/375], Loss: 7941.8232\n",
      "Epoch [1/50], Step [273/375], Loss: 4592.8711\n",
      "Epoch [1/50], Step [274/375], Loss: 5207.2222\n",
      "Epoch [1/50], Step [275/375], Loss: 9104.2402\n",
      "Epoch [1/50], Step [276/375], Loss: 8848.3574\n",
      "Epoch [1/50], Step [277/375], Loss: 8931.4404\n",
      "Epoch [1/50], Step [278/375], Loss: 11906.2236\n",
      "Epoch [1/50], Step [279/375], Loss: 7229.9287\n",
      "Epoch [1/50], Step [280/375], Loss: 6294.4619\n",
      "Epoch [1/50], Step [281/375], Loss: 2721.4663\n",
      "Epoch [1/50], Step [282/375], Loss: 4115.5420\n",
      "Epoch [1/50], Step [283/375], Loss: 5842.4829\n",
      "Epoch [1/50], Step [284/375], Loss: 7469.6421\n",
      "Epoch [1/50], Step [285/375], Loss: 3970.0317\n",
      "Epoch [1/50], Step [286/375], Loss: 10338.3574\n",
      "Epoch [1/50], Step [287/375], Loss: 10387.6348\n",
      "Epoch [1/50], Step [288/375], Loss: 3430.0491\n",
      "Epoch [1/50], Step [289/375], Loss: 5148.2227\n",
      "Epoch [1/50], Step [290/375], Loss: 5309.7886\n",
      "Epoch [1/50], Step [291/375], Loss: 5079.1230\n",
      "Epoch [1/50], Step [292/375], Loss: 7805.1787\n",
      "Epoch [1/50], Step [293/375], Loss: 4482.8135\n",
      "Epoch [1/50], Step [294/375], Loss: 8895.6738\n",
      "Epoch [1/50], Step [295/375], Loss: 7408.8633\n",
      "Epoch [1/50], Step [296/375], Loss: 9393.9531\n",
      "Epoch [1/50], Step [297/375], Loss: 10658.7178\n",
      "Epoch [1/50], Step [298/375], Loss: 6102.7412\n",
      "Epoch [1/50], Step [299/375], Loss: 10103.0215\n",
      "Epoch [1/50], Step [300/375], Loss: 7124.3037\n",
      "Epoch [1/50], Step [301/375], Loss: 5159.3921\n",
      "Epoch [1/50], Step [302/375], Loss: 4776.9121\n",
      "Epoch [1/50], Step [303/375], Loss: 4146.3096\n",
      "Epoch [1/50], Step [304/375], Loss: 4973.0742\n",
      "Epoch [1/50], Step [305/375], Loss: 7168.4878\n",
      "Epoch [1/50], Step [306/375], Loss: 5862.4912\n",
      "Epoch [1/50], Step [307/375], Loss: 8518.5498\n",
      "Epoch [1/50], Step [308/375], Loss: 10992.0957\n",
      "Epoch [1/50], Step [309/375], Loss: 5318.1021\n",
      "Epoch [1/50], Step [310/375], Loss: 3120.2783\n",
      "Epoch [1/50], Step [311/375], Loss: 8922.9854\n",
      "Epoch [1/50], Step [312/375], Loss: 6164.2275\n",
      "Epoch [1/50], Step [313/375], Loss: 7444.4609\n",
      "Epoch [1/50], Step [314/375], Loss: 4530.3291\n",
      "Epoch [1/50], Step [315/375], Loss: 8388.4199\n",
      "Epoch [1/50], Step [316/375], Loss: 4251.9873\n",
      "Epoch [1/50], Step [317/375], Loss: 9708.4160\n",
      "Epoch [1/50], Step [318/375], Loss: 11923.7559\n",
      "Epoch [1/50], Step [319/375], Loss: 8138.4668\n",
      "Epoch [1/50], Step [320/375], Loss: 2696.1074\n",
      "Epoch [1/50], Step [321/375], Loss: 8367.7246\n",
      "Epoch [1/50], Step [322/375], Loss: 9903.8271\n",
      "Epoch [1/50], Step [323/375], Loss: 4184.8940\n",
      "Epoch [1/50], Step [324/375], Loss: 6109.2192\n",
      "Epoch [1/50], Step [325/375], Loss: 2622.4336\n",
      "Epoch [1/50], Step [326/375], Loss: 4183.0679\n",
      "Epoch [1/50], Step [327/375], Loss: 7976.2217\n",
      "Epoch [1/50], Step [328/375], Loss: 3499.8462\n",
      "Epoch [1/50], Step [329/375], Loss: 6357.1865\n",
      "Epoch [1/50], Step [330/375], Loss: 13124.9434\n",
      "Epoch [1/50], Step [331/375], Loss: 6194.3853\n",
      "Epoch [1/50], Step [332/375], Loss: 4326.2275\n",
      "Epoch [1/50], Step [333/375], Loss: 5064.3687\n",
      "Epoch [1/50], Step [334/375], Loss: 8250.2617\n",
      "Epoch [1/50], Step [335/375], Loss: 6542.2080\n",
      "Epoch [1/50], Step [336/375], Loss: 4940.2959\n",
      "Epoch [1/50], Step [337/375], Loss: 12045.6875\n",
      "Epoch [1/50], Step [338/375], Loss: 8378.7422\n",
      "Epoch [1/50], Step [339/375], Loss: 7863.7715\n",
      "Epoch [1/50], Step [340/375], Loss: 4817.0366\n",
      "Epoch [1/50], Step [341/375], Loss: 6896.4775\n",
      "Epoch [1/50], Step [342/375], Loss: 11048.7441\n",
      "Epoch [1/50], Step [343/375], Loss: 3515.8950\n",
      "Epoch [1/50], Step [344/375], Loss: 3244.6677\n",
      "Epoch [1/50], Step [345/375], Loss: 6117.8774\n",
      "Epoch [1/50], Step [346/375], Loss: 4338.7578\n",
      "Epoch [1/50], Step [347/375], Loss: 5336.0361\n",
      "Epoch [1/50], Step [348/375], Loss: 8092.8979\n",
      "Epoch [1/50], Step [349/375], Loss: 5534.3516\n",
      "Epoch [1/50], Step [350/375], Loss: 5919.1504\n",
      "Epoch [1/50], Step [351/375], Loss: 5454.2944\n",
      "Epoch [1/50], Step [352/375], Loss: 9705.1406\n",
      "Epoch [1/50], Step [353/375], Loss: 5550.1021\n",
      "Epoch [1/50], Step [354/375], Loss: 2354.7722\n",
      "Epoch [1/50], Step [355/375], Loss: 4632.6934\n",
      "Epoch [1/50], Step [356/375], Loss: 7827.6895\n",
      "Epoch [1/50], Step [357/375], Loss: 8081.5405\n",
      "Epoch [1/50], Step [358/375], Loss: 6074.3491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [359/375], Loss: 7903.2666\n",
      "Epoch [1/50], Step [360/375], Loss: 4100.9961\n",
      "Epoch [1/50], Step [361/375], Loss: 7670.7969\n",
      "Epoch [1/50], Step [362/375], Loss: 6008.6909\n",
      "Epoch [1/50], Step [363/375], Loss: 10513.2725\n",
      "Epoch [1/50], Step [364/375], Loss: 7117.0562\n",
      "Epoch [1/50], Step [365/375], Loss: 9298.4678\n",
      "Epoch [1/50], Step [366/375], Loss: 4316.3442\n",
      "Epoch [1/50], Step [367/375], Loss: 2588.3147\n",
      "Epoch [1/50], Step [368/375], Loss: 4523.0483\n",
      "Epoch [1/50], Step [369/375], Loss: 13003.1738\n",
      "Epoch [1/50], Step [370/375], Loss: 3681.2712\n",
      "Epoch [1/50], Step [371/375], Loss: 7388.8281\n",
      "Epoch [1/50], Step [372/375], Loss: 12293.6621\n",
      "Epoch [1/50], Step [373/375], Loss: 8175.7041\n",
      "Epoch [1/50], Step [374/375], Loss: 14953.7314\n",
      "Epoch [1/50], Step [375/375], Loss: 3519.2703\n",
      "Epoch [2/50], Step [1/375], Loss: 8668.6709\n",
      "Epoch [2/50], Step [2/375], Loss: 4071.4028\n",
      "Epoch [2/50], Step [3/375], Loss: 3575.3765\n",
      "Epoch [2/50], Step [4/375], Loss: 4599.8350\n",
      "Epoch [2/50], Step [5/375], Loss: 8287.0332\n",
      "Epoch [2/50], Step [6/375], Loss: 4539.9854\n",
      "Epoch [2/50], Step [7/375], Loss: 4404.7354\n",
      "Epoch [2/50], Step [8/375], Loss: 5952.5522\n",
      "Epoch [2/50], Step [9/375], Loss: 1438.6659\n",
      "Epoch [2/50], Step [10/375], Loss: 7782.6460\n",
      "Epoch [2/50], Step [11/375], Loss: 2459.3821\n",
      "Epoch [2/50], Step [12/375], Loss: 4288.8735\n",
      "Epoch [2/50], Step [13/375], Loss: 6008.1274\n",
      "Epoch [2/50], Step [14/375], Loss: 4516.2529\n",
      "Epoch [2/50], Step [15/375], Loss: 1743.0647\n",
      "Epoch [2/50], Step [16/375], Loss: 3470.0171\n",
      "Epoch [2/50], Step [17/375], Loss: 2264.1299\n",
      "Epoch [2/50], Step [18/375], Loss: 4771.0171\n",
      "Epoch [2/50], Step [19/375], Loss: 3568.1794\n",
      "Epoch [2/50], Step [20/375], Loss: 3138.5374\n",
      "Epoch [2/50], Step [21/375], Loss: 4657.3125\n",
      "Epoch [2/50], Step [22/375], Loss: 7448.2832\n",
      "Epoch [2/50], Step [23/375], Loss: 4557.1694\n",
      "Epoch [2/50], Step [24/375], Loss: 3608.3445\n",
      "Epoch [2/50], Step [25/375], Loss: 4309.5850\n",
      "Epoch [2/50], Step [26/375], Loss: 7045.1162\n",
      "Epoch [2/50], Step [27/375], Loss: 1898.1106\n",
      "Epoch [2/50], Step [28/375], Loss: 6077.2593\n",
      "Epoch [2/50], Step [29/375], Loss: 4827.8145\n",
      "Epoch [2/50], Step [30/375], Loss: 4458.8018\n",
      "Epoch [2/50], Step [31/375], Loss: 5139.7583\n",
      "Epoch [2/50], Step [32/375], Loss: 3527.3347\n",
      "Epoch [2/50], Step [33/375], Loss: 11123.8105\n",
      "Epoch [2/50], Step [34/375], Loss: 6526.0190\n",
      "Epoch [2/50], Step [35/375], Loss: 2651.6746\n",
      "Epoch [2/50], Step [36/375], Loss: 2307.8169\n",
      "Epoch [2/50], Step [37/375], Loss: 6589.4102\n",
      "Epoch [2/50], Step [38/375], Loss: 7436.9370\n",
      "Epoch [2/50], Step [39/375], Loss: 6182.2261\n",
      "Epoch [2/50], Step [40/375], Loss: 6350.5688\n",
      "Epoch [2/50], Step [41/375], Loss: 2387.8518\n",
      "Epoch [2/50], Step [42/375], Loss: 6502.2969\n",
      "Epoch [2/50], Step [43/375], Loss: 4306.9639\n",
      "Epoch [2/50], Step [44/375], Loss: 2528.3896\n",
      "Epoch [2/50], Step [45/375], Loss: 3267.3357\n",
      "Epoch [2/50], Step [46/375], Loss: 2780.6074\n",
      "Epoch [2/50], Step [47/375], Loss: 5112.7793\n",
      "Epoch [2/50], Step [48/375], Loss: 4884.0557\n",
      "Epoch [2/50], Step [49/375], Loss: 3641.0798\n",
      "Epoch [2/50], Step [50/375], Loss: 2438.1028\n",
      "Epoch [2/50], Step [51/375], Loss: 805.6545\n",
      "Epoch [2/50], Step [52/375], Loss: 5056.8354\n",
      "Epoch [2/50], Step [53/375], Loss: 6562.0576\n",
      "Epoch [2/50], Step [54/375], Loss: 2928.3997\n",
      "Epoch [2/50], Step [55/375], Loss: 7668.2412\n",
      "Epoch [2/50], Step [56/375], Loss: 6776.9443\n",
      "Epoch [2/50], Step [57/375], Loss: 3816.1460\n",
      "Epoch [2/50], Step [58/375], Loss: 2864.4353\n",
      "Epoch [2/50], Step [59/375], Loss: 2945.2056\n",
      "Epoch [2/50], Step [60/375], Loss: 3613.9646\n",
      "Epoch [2/50], Step [61/375], Loss: 3516.8691\n",
      "Epoch [2/50], Step [62/375], Loss: 9357.0049\n",
      "Epoch [2/50], Step [63/375], Loss: 5314.8696\n",
      "Epoch [2/50], Step [64/375], Loss: 3412.8259\n",
      "Epoch [2/50], Step [65/375], Loss: 3535.1221\n",
      "Epoch [2/50], Step [66/375], Loss: 3875.5320\n",
      "Epoch [2/50], Step [67/375], Loss: 2778.1702\n",
      "Epoch [2/50], Step [68/375], Loss: 3571.4348\n",
      "Epoch [2/50], Step [69/375], Loss: 2215.1868\n",
      "Epoch [2/50], Step [70/375], Loss: 4932.4229\n",
      "Epoch [2/50], Step [71/375], Loss: 5199.7524\n",
      "Epoch [2/50], Step [72/375], Loss: 4511.1538\n",
      "Epoch [2/50], Step [73/375], Loss: 7881.6523\n",
      "Epoch [2/50], Step [74/375], Loss: 3424.4788\n",
      "Epoch [2/50], Step [75/375], Loss: 4841.3667\n",
      "Epoch [2/50], Step [76/375], Loss: 6010.7891\n",
      "Epoch [2/50], Step [77/375], Loss: 6713.0884\n",
      "Epoch [2/50], Step [78/375], Loss: 4122.6196\n",
      "Epoch [2/50], Step [79/375], Loss: 4673.0127\n",
      "Epoch [2/50], Step [80/375], Loss: 278.7497\n",
      "Epoch [2/50], Step [81/375], Loss: 4278.8018\n",
      "Epoch [2/50], Step [82/375], Loss: 5863.0479\n",
      "Epoch [2/50], Step [83/375], Loss: 3650.1643\n",
      "Epoch [2/50], Step [84/375], Loss: 3820.5852\n",
      "Epoch [2/50], Step [85/375], Loss: 2518.6196\n",
      "Epoch [2/50], Step [86/375], Loss: 4588.9946\n",
      "Epoch [2/50], Step [87/375], Loss: 4048.3271\n",
      "Epoch [2/50], Step [88/375], Loss: 5213.9775\n",
      "Epoch [2/50], Step [89/375], Loss: 7051.8623\n",
      "Epoch [2/50], Step [90/375], Loss: 4405.7100\n",
      "Epoch [2/50], Step [91/375], Loss: 4525.3730\n",
      "Epoch [2/50], Step [92/375], Loss: 4817.5073\n",
      "Epoch [2/50], Step [93/375], Loss: 5697.8823\n",
      "Epoch [2/50], Step [94/375], Loss: 5469.9482\n",
      "Epoch [2/50], Step [95/375], Loss: 4052.7817\n",
      "Epoch [2/50], Step [96/375], Loss: 4174.0864\n",
      "Epoch [2/50], Step [97/375], Loss: 3270.9297\n",
      "Epoch [2/50], Step [98/375], Loss: 1570.7484\n",
      "Epoch [2/50], Step [99/375], Loss: 4120.5498\n",
      "Epoch [2/50], Step [100/375], Loss: 5342.6733\n",
      "Epoch [2/50], Step [101/375], Loss: 4238.6685\n",
      "Epoch [2/50], Step [102/375], Loss: 2738.0266\n",
      "Epoch [2/50], Step [103/375], Loss: 7843.8740\n",
      "Epoch [2/50], Step [104/375], Loss: 2279.0288\n",
      "Epoch [2/50], Step [105/375], Loss: 3290.9907\n",
      "Epoch [2/50], Step [106/375], Loss: 2850.2996\n",
      "Epoch [2/50], Step [107/375], Loss: 2011.9229\n",
      "Epoch [2/50], Step [108/375], Loss: 5456.0146\n",
      "Epoch [2/50], Step [109/375], Loss: 4116.4771\n",
      "Epoch [2/50], Step [110/375], Loss: 2628.6758\n",
      "Epoch [2/50], Step [111/375], Loss: 3647.9324\n",
      "Epoch [2/50], Step [112/375], Loss: 2838.6062\n",
      "Epoch [2/50], Step [113/375], Loss: 6126.4243\n",
      "Epoch [2/50], Step [114/375], Loss: 2779.7659\n",
      "Epoch [2/50], Step [115/375], Loss: 6268.3662\n",
      "Epoch [2/50], Step [116/375], Loss: 3558.2268\n",
      "Epoch [2/50], Step [117/375], Loss: 4508.4473\n",
      "Epoch [2/50], Step [118/375], Loss: 6161.8901\n",
      "Epoch [2/50], Step [119/375], Loss: 6278.9814\n",
      "Epoch [2/50], Step [120/375], Loss: 2405.1787\n",
      "Epoch [2/50], Step [121/375], Loss: 2613.7117\n",
      "Epoch [2/50], Step [122/375], Loss: 5454.3979\n",
      "Epoch [2/50], Step [123/375], Loss: 7110.2812\n",
      "Epoch [2/50], Step [124/375], Loss: 6662.3423\n",
      "Epoch [2/50], Step [125/375], Loss: 5928.8120\n",
      "Epoch [2/50], Step [126/375], Loss: 3790.2617\n",
      "Epoch [2/50], Step [127/375], Loss: 4621.6411\n",
      "Epoch [2/50], Step [128/375], Loss: 7216.3208\n",
      "Epoch [2/50], Step [129/375], Loss: 5414.7759\n",
      "Epoch [2/50], Step [130/375], Loss: 2470.2981\n",
      "Epoch [2/50], Step [131/375], Loss: 4071.2778\n",
      "Epoch [2/50], Step [132/375], Loss: 2910.7744\n",
      "Epoch [2/50], Step [133/375], Loss: 3499.0691\n",
      "Epoch [2/50], Step [134/375], Loss: 4487.4644\n",
      "Epoch [2/50], Step [135/375], Loss: 1021.9658\n",
      "Epoch [2/50], Step [136/375], Loss: 4606.5508\n",
      "Epoch [2/50], Step [137/375], Loss: 3112.5369\n",
      "Epoch [2/50], Step [138/375], Loss: 1775.2252\n",
      "Epoch [2/50], Step [139/375], Loss: 4077.6475\n",
      "Epoch [2/50], Step [140/375], Loss: 3244.3376\n",
      "Epoch [2/50], Step [141/375], Loss: 4252.4863\n",
      "Epoch [2/50], Step [142/375], Loss: 3661.7871\n",
      "Epoch [2/50], Step [143/375], Loss: 2685.0901\n",
      "Epoch [2/50], Step [144/375], Loss: 3818.9133\n",
      "Epoch [2/50], Step [145/375], Loss: 5289.0610\n",
      "Epoch [2/50], Step [146/375], Loss: 7528.6860\n",
      "Epoch [2/50], Step [147/375], Loss: 3827.2490\n",
      "Epoch [2/50], Step [148/375], Loss: 4005.5161\n",
      "Epoch [2/50], Step [149/375], Loss: 7118.6216\n",
      "Epoch [2/50], Step [150/375], Loss: 5871.5688\n",
      "Epoch [2/50], Step [151/375], Loss: 7595.6279\n",
      "Epoch [2/50], Step [152/375], Loss: 3673.4568\n",
      "Epoch [2/50], Step [153/375], Loss: 4692.7969\n",
      "Epoch [2/50], Step [154/375], Loss: 6867.0806\n",
      "Epoch [2/50], Step [155/375], Loss: 5998.7915\n",
      "Epoch [2/50], Step [156/375], Loss: 2380.6484\n",
      "Epoch [2/50], Step [157/375], Loss: 4245.9580\n",
      "Epoch [2/50], Step [158/375], Loss: 4176.3643\n",
      "Epoch [2/50], Step [159/375], Loss: 3492.8489\n",
      "Epoch [2/50], Step [160/375], Loss: 3828.9387\n",
      "Epoch [2/50], Step [161/375], Loss: 11608.1250\n",
      "Epoch [2/50], Step [162/375], Loss: 3218.8137\n",
      "Epoch [2/50], Step [163/375], Loss: 5724.4766\n",
      "Epoch [2/50], Step [164/375], Loss: 4496.3325\n",
      "Epoch [2/50], Step [165/375], Loss: 3295.9724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Step [166/375], Loss: 2472.8000\n",
      "Epoch [2/50], Step [167/375], Loss: 5523.2026\n",
      "Epoch [2/50], Step [168/375], Loss: 5454.5923\n",
      "Epoch [2/50], Step [169/375], Loss: 4378.1230\n",
      "Epoch [2/50], Step [170/375], Loss: 8133.5732\n",
      "Epoch [2/50], Step [171/375], Loss: 2207.1880\n",
      "Epoch [2/50], Step [172/375], Loss: 5228.5596\n",
      "Epoch [2/50], Step [173/375], Loss: 4979.1494\n",
      "Epoch [2/50], Step [174/375], Loss: 2485.0310\n",
      "Epoch [2/50], Step [175/375], Loss: 5228.2812\n",
      "Epoch [2/50], Step [176/375], Loss: 4851.5225\n",
      "Epoch [2/50], Step [177/375], Loss: 3736.1882\n",
      "Epoch [2/50], Step [178/375], Loss: 7289.9834\n",
      "Epoch [2/50], Step [179/375], Loss: 2790.8867\n",
      "Epoch [2/50], Step [180/375], Loss: 2768.8286\n",
      "Epoch [2/50], Step [181/375], Loss: 3769.9182\n",
      "Epoch [2/50], Step [182/375], Loss: 3846.4614\n",
      "Epoch [2/50], Step [183/375], Loss: 6446.9434\n",
      "Epoch [2/50], Step [184/375], Loss: 2841.7585\n",
      "Epoch [2/50], Step [185/375], Loss: 1010.3520\n",
      "Epoch [2/50], Step [186/375], Loss: 3843.8831\n",
      "Epoch [2/50], Step [187/375], Loss: 898.6280\n",
      "Epoch [2/50], Step [188/375], Loss: 4213.7827\n",
      "Epoch [2/50], Step [189/375], Loss: 1096.9675\n",
      "Epoch [2/50], Step [190/375], Loss: 5044.3418\n",
      "Epoch [2/50], Step [191/375], Loss: 5014.1582\n",
      "Epoch [2/50], Step [192/375], Loss: 8807.0693\n",
      "Epoch [2/50], Step [193/375], Loss: 5011.6313\n",
      "Epoch [2/50], Step [194/375], Loss: 5953.6562\n",
      "Epoch [2/50], Step [195/375], Loss: 3731.3625\n",
      "Epoch [2/50], Step [196/375], Loss: 2061.5938\n",
      "Epoch [2/50], Step [197/375], Loss: 7814.7158\n",
      "Epoch [2/50], Step [198/375], Loss: 644.7102\n",
      "Epoch [2/50], Step [199/375], Loss: 5464.5688\n",
      "Epoch [2/50], Step [200/375], Loss: 3859.6824\n",
      "Epoch [2/50], Step [201/375], Loss: 6591.2305\n",
      "Epoch [2/50], Step [202/375], Loss: 1396.4897\n",
      "Epoch [2/50], Step [203/375], Loss: 12033.4365\n",
      "Epoch [2/50], Step [204/375], Loss: 4453.7178\n",
      "Epoch [2/50], Step [205/375], Loss: 2979.9316\n",
      "Epoch [2/50], Step [206/375], Loss: 4328.3604\n",
      "Epoch [2/50], Step [207/375], Loss: 4205.9507\n",
      "Epoch [2/50], Step [208/375], Loss: 3521.4282\n",
      "Epoch [2/50], Step [209/375], Loss: 3967.3704\n",
      "Epoch [2/50], Step [210/375], Loss: 3584.5347\n",
      "Epoch [2/50], Step [211/375], Loss: 6610.4253\n",
      "Epoch [2/50], Step [212/375], Loss: 11888.9209\n",
      "Epoch [2/50], Step [213/375], Loss: 2824.8953\n",
      "Epoch [2/50], Step [214/375], Loss: 3652.5752\n",
      "Epoch [2/50], Step [215/375], Loss: 9451.6631\n",
      "Epoch [2/50], Step [216/375], Loss: 4389.8228\n",
      "Epoch [2/50], Step [217/375], Loss: 3393.0876\n",
      "Epoch [2/50], Step [218/375], Loss: 1523.1685\n",
      "Epoch [2/50], Step [219/375], Loss: 4022.3582\n",
      "Epoch [2/50], Step [220/375], Loss: 2060.1194\n",
      "Epoch [2/50], Step [221/375], Loss: 5052.3555\n",
      "Epoch [2/50], Step [222/375], Loss: 4832.3159\n",
      "Epoch [2/50], Step [223/375], Loss: 3340.0720\n",
      "Epoch [2/50], Step [224/375], Loss: 3531.1699\n",
      "Epoch [2/50], Step [225/375], Loss: 3415.5188\n",
      "Epoch [2/50], Step [226/375], Loss: 3412.1948\n",
      "Epoch [2/50], Step [227/375], Loss: 7729.5913\n",
      "Epoch [2/50], Step [228/375], Loss: 4092.7585\n",
      "Epoch [2/50], Step [229/375], Loss: 9859.5264\n",
      "Epoch [2/50], Step [230/375], Loss: 4099.9448\n",
      "Epoch [2/50], Step [231/375], Loss: 2882.5825\n",
      "Epoch [2/50], Step [232/375], Loss: 1558.0349\n",
      "Epoch [2/50], Step [233/375], Loss: 5848.0747\n",
      "Epoch [2/50], Step [234/375], Loss: 2642.0132\n",
      "Epoch [2/50], Step [235/375], Loss: 3414.3445\n",
      "Epoch [2/50], Step [236/375], Loss: 2561.7024\n",
      "Epoch [2/50], Step [237/375], Loss: 4515.5811\n",
      "Epoch [2/50], Step [238/375], Loss: 3230.9802\n",
      "Epoch [2/50], Step [239/375], Loss: 1639.5620\n",
      "Epoch [2/50], Step [240/375], Loss: 3035.4783\n",
      "Epoch [2/50], Step [241/375], Loss: 2147.0698\n",
      "Epoch [2/50], Step [242/375], Loss: 6706.1445\n",
      "Epoch [2/50], Step [243/375], Loss: 7177.1025\n",
      "Epoch [2/50], Step [244/375], Loss: 3343.4766\n",
      "Epoch [2/50], Step [245/375], Loss: 3754.0098\n",
      "Epoch [2/50], Step [246/375], Loss: 3310.5574\n",
      "Epoch [2/50], Step [247/375], Loss: 4934.5386\n",
      "Epoch [2/50], Step [248/375], Loss: 6837.7979\n",
      "Epoch [2/50], Step [249/375], Loss: 1180.1373\n",
      "Epoch [2/50], Step [250/375], Loss: 1423.7146\n",
      "Epoch [2/50], Step [251/375], Loss: 3377.0813\n",
      "Epoch [2/50], Step [252/375], Loss: 3692.8296\n",
      "Epoch [2/50], Step [253/375], Loss: 7478.5576\n",
      "Epoch [2/50], Step [254/375], Loss: 3835.5425\n",
      "Epoch [2/50], Step [255/375], Loss: 1459.3813\n",
      "Epoch [2/50], Step [256/375], Loss: 3077.4866\n",
      "Epoch [2/50], Step [257/375], Loss: 2500.9524\n",
      "Epoch [2/50], Step [258/375], Loss: 5764.8618\n",
      "Epoch [2/50], Step [259/375], Loss: 2917.3022\n",
      "Epoch [2/50], Step [260/375], Loss: 6390.7134\n",
      "Epoch [2/50], Step [261/375], Loss: 4854.4204\n",
      "Epoch [2/50], Step [262/375], Loss: 4553.7261\n",
      "Epoch [2/50], Step [263/375], Loss: 1963.6492\n",
      "Epoch [2/50], Step [264/375], Loss: 2978.2505\n",
      "Epoch [2/50], Step [265/375], Loss: 4069.3745\n",
      "Epoch [2/50], Step [266/375], Loss: 10446.8027\n",
      "Epoch [2/50], Step [267/375], Loss: 2533.3372\n",
      "Epoch [2/50], Step [268/375], Loss: 3436.2212\n",
      "Epoch [2/50], Step [269/375], Loss: 5472.9614\n",
      "Epoch [2/50], Step [270/375], Loss: 6275.3018\n",
      "Epoch [2/50], Step [271/375], Loss: 1767.4691\n",
      "Epoch [2/50], Step [272/375], Loss: 7822.1602\n",
      "Epoch [2/50], Step [273/375], Loss: 2064.3052\n",
      "Epoch [2/50], Step [274/375], Loss: 4544.7104\n",
      "Epoch [2/50], Step [275/375], Loss: 4853.9458\n",
      "Epoch [2/50], Step [276/375], Loss: 3470.2300\n",
      "Epoch [2/50], Step [277/375], Loss: 4726.3091\n",
      "Epoch [2/50], Step [278/375], Loss: 3198.4089\n",
      "Epoch [2/50], Step [279/375], Loss: 5403.8657\n",
      "Epoch [2/50], Step [280/375], Loss: 3981.9854\n",
      "Epoch [2/50], Step [281/375], Loss: 2185.6313\n",
      "Epoch [2/50], Step [282/375], Loss: 370.7280\n",
      "Epoch [2/50], Step [283/375], Loss: 3023.0474\n",
      "Epoch [2/50], Step [284/375], Loss: 5603.2227\n",
      "Epoch [2/50], Step [285/375], Loss: 1602.1094\n",
      "Epoch [2/50], Step [286/375], Loss: 4291.2607\n",
      "Epoch [2/50], Step [287/375], Loss: 3094.6265\n",
      "Epoch [2/50], Step [288/375], Loss: 1654.9171\n",
      "Epoch [2/50], Step [289/375], Loss: 3758.3574\n",
      "Epoch [2/50], Step [290/375], Loss: 2540.0859\n",
      "Epoch [2/50], Step [291/375], Loss: 7976.8262\n",
      "Epoch [2/50], Step [292/375], Loss: 1628.3109\n",
      "Epoch [2/50], Step [293/375], Loss: 5664.1826\n",
      "Epoch [2/50], Step [294/375], Loss: 3510.1648\n",
      "Epoch [2/50], Step [295/375], Loss: 6015.7563\n",
      "Epoch [2/50], Step [296/375], Loss: 5752.0298\n",
      "Epoch [2/50], Step [297/375], Loss: 2929.1521\n",
      "Epoch [2/50], Step [298/375], Loss: 6628.2935\n",
      "Epoch [2/50], Step [299/375], Loss: 4964.9551\n",
      "Epoch [2/50], Step [300/375], Loss: 9681.5195\n",
      "Epoch [2/50], Step [301/375], Loss: 3500.0127\n",
      "Epoch [2/50], Step [302/375], Loss: 2812.8994\n",
      "Epoch [2/50], Step [303/375], Loss: 5536.8779\n",
      "Epoch [2/50], Step [304/375], Loss: 5073.3477\n",
      "Epoch [2/50], Step [305/375], Loss: 3581.1160\n",
      "Epoch [2/50], Step [306/375], Loss: 1294.4810\n",
      "Epoch [2/50], Step [307/375], Loss: 5889.8730\n",
      "Epoch [2/50], Step [308/375], Loss: 9181.2598\n",
      "Epoch [2/50], Step [309/375], Loss: 1355.3721\n",
      "Epoch [2/50], Step [310/375], Loss: 2130.9355\n",
      "Epoch [2/50], Step [311/375], Loss: 2563.2979\n",
      "Epoch [2/50], Step [312/375], Loss: 8071.6904\n",
      "Epoch [2/50], Step [313/375], Loss: 2586.6790\n",
      "Epoch [2/50], Step [314/375], Loss: 2510.9167\n",
      "Epoch [2/50], Step [315/375], Loss: 2475.0540\n",
      "Epoch [2/50], Step [316/375], Loss: 2680.4434\n",
      "Epoch [2/50], Step [317/375], Loss: 3865.0913\n",
      "Epoch [2/50], Step [318/375], Loss: 4800.7349\n",
      "Epoch [2/50], Step [319/375], Loss: 4257.8438\n",
      "Epoch [2/50], Step [320/375], Loss: 3125.8579\n",
      "Epoch [2/50], Step [321/375], Loss: 2554.2578\n",
      "Epoch [2/50], Step [322/375], Loss: 1948.4703\n",
      "Epoch [2/50], Step [323/375], Loss: 4385.6899\n",
      "Epoch [2/50], Step [324/375], Loss: 4533.3174\n",
      "Epoch [2/50], Step [325/375], Loss: 1178.4556\n",
      "Epoch [2/50], Step [326/375], Loss: 4384.1777\n",
      "Epoch [2/50], Step [327/375], Loss: 2542.9011\n",
      "Epoch [2/50], Step [328/375], Loss: 4107.2754\n",
      "Epoch [2/50], Step [329/375], Loss: 2507.9912\n",
      "Epoch [2/50], Step [330/375], Loss: 3632.5991\n",
      "Epoch [2/50], Step [331/375], Loss: 4607.0181\n",
      "Epoch [2/50], Step [332/375], Loss: 4362.4424\n",
      "Epoch [2/50], Step [333/375], Loss: 4421.7197\n",
      "Epoch [2/50], Step [334/375], Loss: 5478.7964\n",
      "Epoch [2/50], Step [335/375], Loss: 5266.9658\n",
      "Epoch [2/50], Step [336/375], Loss: 2497.6252\n",
      "Epoch [2/50], Step [337/375], Loss: 5136.8794\n",
      "Epoch [2/50], Step [338/375], Loss: 7475.7075\n",
      "Epoch [2/50], Step [339/375], Loss: 7134.7739\n",
      "Epoch [2/50], Step [340/375], Loss: 1492.2909\n",
      "Epoch [2/50], Step [341/375], Loss: 9938.7402\n",
      "Epoch [2/50], Step [342/375], Loss: 6213.3916\n",
      "Epoch [2/50], Step [343/375], Loss: 3057.2351\n",
      "Epoch [2/50], Step [344/375], Loss: 2029.3743\n",
      "Epoch [2/50], Step [345/375], Loss: 7177.2368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Step [346/375], Loss: 3598.3057\n",
      "Epoch [2/50], Step [347/375], Loss: 1865.8590\n",
      "Epoch [2/50], Step [348/375], Loss: 2554.5625\n",
      "Epoch [2/50], Step [349/375], Loss: 5502.9331\n",
      "Epoch [2/50], Step [350/375], Loss: 5218.9307\n",
      "Epoch [2/50], Step [351/375], Loss: 2773.1475\n",
      "Epoch [2/50], Step [352/375], Loss: 2185.9585\n",
      "Epoch [2/50], Step [353/375], Loss: 5667.9883\n",
      "Epoch [2/50], Step [354/375], Loss: 1620.7308\n",
      "Epoch [2/50], Step [355/375], Loss: 4957.9956\n",
      "Epoch [2/50], Step [356/375], Loss: 2725.2249\n",
      "Epoch [2/50], Step [357/375], Loss: 2344.1211\n",
      "Epoch [2/50], Step [358/375], Loss: 4552.4185\n",
      "Epoch [2/50], Step [359/375], Loss: 4501.3535\n",
      "Epoch [2/50], Step [360/375], Loss: 3553.4075\n",
      "Epoch [2/50], Step [361/375], Loss: 2956.6658\n",
      "Epoch [2/50], Step [362/375], Loss: 4895.9023\n",
      "Epoch [2/50], Step [363/375], Loss: 4726.7510\n",
      "Epoch [2/50], Step [364/375], Loss: 3854.8416\n",
      "Epoch [2/50], Step [365/375], Loss: 4731.6270\n",
      "Epoch [2/50], Step [366/375], Loss: 1919.2802\n",
      "Epoch [2/50], Step [367/375], Loss: 2740.5342\n",
      "Epoch [2/50], Step [368/375], Loss: 3844.1838\n",
      "Epoch [2/50], Step [369/375], Loss: 4255.6011\n",
      "Epoch [2/50], Step [370/375], Loss: 2029.2990\n",
      "Epoch [2/50], Step [371/375], Loss: 8431.1504\n",
      "Epoch [2/50], Step [372/375], Loss: 4743.5186\n",
      "Epoch [2/50], Step [373/375], Loss: 3453.6958\n",
      "Epoch [2/50], Step [374/375], Loss: 5843.8481\n",
      "Epoch [2/50], Step [375/375], Loss: 5201.6040\n",
      "Epoch [3/50], Step [1/375], Loss: 1372.4163\n",
      "Epoch [3/50], Step [2/375], Loss: 6443.9819\n",
      "Epoch [3/50], Step [3/375], Loss: 4428.6460\n",
      "Epoch [3/50], Step [4/375], Loss: 2186.3508\n",
      "Epoch [3/50], Step [5/375], Loss: 2348.0554\n",
      "Epoch [3/50], Step [6/375], Loss: 7947.8633\n",
      "Epoch [3/50], Step [7/375], Loss: 2826.7368\n",
      "Epoch [3/50], Step [8/375], Loss: 1969.4487\n",
      "Epoch [3/50], Step [9/375], Loss: 5131.4497\n",
      "Epoch [3/50], Step [10/375], Loss: 1305.1647\n",
      "Epoch [3/50], Step [11/375], Loss: 2502.2354\n",
      "Epoch [3/50], Step [12/375], Loss: 658.4362\n",
      "Epoch [3/50], Step [13/375], Loss: 944.6103\n",
      "Epoch [3/50], Step [14/375], Loss: 313.3683\n",
      "Epoch [3/50], Step [15/375], Loss: 2257.2188\n",
      "Epoch [3/50], Step [16/375], Loss: 3447.5386\n",
      "Epoch [3/50], Step [17/375], Loss: 1896.1451\n",
      "Epoch [3/50], Step [18/375], Loss: 3088.0750\n",
      "Epoch [3/50], Step [19/375], Loss: 1976.5679\n",
      "Epoch [3/50], Step [20/375], Loss: 3040.6267\n",
      "Epoch [3/50], Step [21/375], Loss: 4435.7666\n",
      "Epoch [3/50], Step [22/375], Loss: 703.7139\n",
      "Epoch [3/50], Step [23/375], Loss: 1242.5159\n",
      "Epoch [3/50], Step [24/375], Loss: 1669.6608\n",
      "Epoch [3/50], Step [25/375], Loss: 1574.9857\n",
      "Epoch [3/50], Step [26/375], Loss: 896.9373\n",
      "Epoch [3/50], Step [27/375], Loss: 1599.7107\n",
      "Epoch [3/50], Step [28/375], Loss: 3683.4253\n",
      "Epoch [3/50], Step [29/375], Loss: 6581.1426\n",
      "Epoch [3/50], Step [30/375], Loss: 2266.5972\n",
      "Epoch [3/50], Step [31/375], Loss: 1503.0892\n",
      "Epoch [3/50], Step [32/375], Loss: 1185.8273\n",
      "Epoch [3/50], Step [33/375], Loss: 1626.2206\n",
      "Epoch [3/50], Step [34/375], Loss: 3026.8647\n",
      "Epoch [3/50], Step [35/375], Loss: 3284.0747\n",
      "Epoch [3/50], Step [36/375], Loss: 2557.9272\n",
      "Epoch [3/50], Step [37/375], Loss: 626.0263\n",
      "Epoch [3/50], Step [38/375], Loss: 2059.2698\n",
      "Epoch [3/50], Step [39/375], Loss: 481.6481\n",
      "Epoch [3/50], Step [40/375], Loss: 2499.5964\n",
      "Epoch [3/50], Step [41/375], Loss: 1470.8219\n",
      "Epoch [3/50], Step [42/375], Loss: 1222.6401\n",
      "Epoch [3/50], Step [43/375], Loss: 420.9786\n",
      "Epoch [3/50], Step [44/375], Loss: 2409.7620\n",
      "Epoch [3/50], Step [45/375], Loss: 6168.9307\n",
      "Epoch [3/50], Step [46/375], Loss: 1326.8146\n",
      "Epoch [3/50], Step [47/375], Loss: 2226.5652\n",
      "Epoch [3/50], Step [48/375], Loss: 1485.5370\n",
      "Epoch [3/50], Step [49/375], Loss: 2634.3794\n",
      "Epoch [3/50], Step [50/375], Loss: 4396.2769\n",
      "Epoch [3/50], Step [51/375], Loss: 3514.8115\n",
      "Epoch [3/50], Step [52/375], Loss: 1803.3114\n",
      "Epoch [3/50], Step [53/375], Loss: 2982.3228\n",
      "Epoch [3/50], Step [54/375], Loss: 1805.2355\n",
      "Epoch [3/50], Step [55/375], Loss: 1145.4888\n",
      "Epoch [3/50], Step [56/375], Loss: 2283.8188\n",
      "Epoch [3/50], Step [57/375], Loss: 1493.3718\n",
      "Epoch [3/50], Step [58/375], Loss: 1984.5946\n",
      "Epoch [3/50], Step [59/375], Loss: 4821.8130\n",
      "Epoch [3/50], Step [60/375], Loss: 3348.0686\n",
      "Epoch [3/50], Step [61/375], Loss: 3076.7471\n",
      "Epoch [3/50], Step [62/375], Loss: 4238.5396\n",
      "Epoch [3/50], Step [63/375], Loss: 1194.7944\n",
      "Epoch [3/50], Step [64/375], Loss: 674.4740\n",
      "Epoch [3/50], Step [65/375], Loss: 2415.4993\n",
      "Epoch [3/50], Step [66/375], Loss: 843.5927\n",
      "Epoch [3/50], Step [67/375], Loss: 1570.5684\n",
      "Epoch [3/50], Step [68/375], Loss: 554.4633\n",
      "Epoch [3/50], Step [69/375], Loss: 1802.4414\n",
      "Epoch [3/50], Step [70/375], Loss: 1151.4645\n",
      "Epoch [3/50], Step [71/375], Loss: 1072.7853\n",
      "Epoch [3/50], Step [72/375], Loss: 589.1137\n",
      "Epoch [3/50], Step [73/375], Loss: 1058.5912\n",
      "Epoch [3/50], Step [74/375], Loss: 5118.7295\n",
      "Epoch [3/50], Step [75/375], Loss: 1670.3263\n",
      "Epoch [3/50], Step [76/375], Loss: 1627.1102\n",
      "Epoch [3/50], Step [77/375], Loss: 3070.5984\n",
      "Epoch [3/50], Step [78/375], Loss: 1447.3459\n",
      "Epoch [3/50], Step [79/375], Loss: 1327.8984\n",
      "Epoch [3/50], Step [80/375], Loss: 2244.0789\n",
      "Epoch [3/50], Step [81/375], Loss: 1829.9777\n",
      "Epoch [3/50], Step [82/375], Loss: 1388.9797\n",
      "Epoch [3/50], Step [83/375], Loss: 974.7468\n",
      "Epoch [3/50], Step [84/375], Loss: 1493.4714\n",
      "Epoch [3/50], Step [85/375], Loss: 824.1420\n",
      "Epoch [3/50], Step [86/375], Loss: 2658.2876\n",
      "Epoch [3/50], Step [87/375], Loss: 6139.0376\n",
      "Epoch [3/50], Step [88/375], Loss: 1651.5885\n",
      "Epoch [3/50], Step [89/375], Loss: 2169.9053\n",
      "Epoch [3/50], Step [90/375], Loss: 5429.6948\n",
      "Epoch [3/50], Step [91/375], Loss: 1362.3087\n",
      "Epoch [3/50], Step [92/375], Loss: 2112.6987\n",
      "Epoch [3/50], Step [93/375], Loss: 1038.4030\n",
      "Epoch [3/50], Step [94/375], Loss: 850.4351\n",
      "Epoch [3/50], Step [95/375], Loss: 6226.0835\n",
      "Epoch [3/50], Step [96/375], Loss: 468.3013\n",
      "Epoch [3/50], Step [97/375], Loss: 969.0427\n",
      "Epoch [3/50], Step [98/375], Loss: 5007.4546\n",
      "Epoch [3/50], Step [99/375], Loss: 1619.2213\n",
      "Epoch [3/50], Step [100/375], Loss: 2153.4636\n",
      "Epoch [3/50], Step [101/375], Loss: 1560.5029\n",
      "Epoch [3/50], Step [102/375], Loss: 3479.7681\n",
      "Epoch [3/50], Step [103/375], Loss: 4072.4290\n",
      "Epoch [3/50], Step [104/375], Loss: 894.5941\n",
      "Epoch [3/50], Step [105/375], Loss: 2632.5664\n",
      "Epoch [3/50], Step [106/375], Loss: 1090.7606\n",
      "Epoch [3/50], Step [107/375], Loss: 2682.8279\n",
      "Epoch [3/50], Step [108/375], Loss: 5673.3960\n",
      "Epoch [3/50], Step [109/375], Loss: 4152.4785\n",
      "Epoch [3/50], Step [110/375], Loss: 5221.5874\n",
      "Epoch [3/50], Step [111/375], Loss: 2261.8069\n",
      "Epoch [3/50], Step [112/375], Loss: 2617.5911\n",
      "Epoch [3/50], Step [113/375], Loss: 1853.4893\n",
      "Epoch [3/50], Step [114/375], Loss: 1701.2561\n",
      "Epoch [3/50], Step [115/375], Loss: 1184.0085\n",
      "Epoch [3/50], Step [116/375], Loss: 1762.9749\n",
      "Epoch [3/50], Step [117/375], Loss: 2390.0073\n",
      "Epoch [3/50], Step [118/375], Loss: 1257.9857\n",
      "Epoch [3/50], Step [119/375], Loss: 1794.7898\n",
      "Epoch [3/50], Step [120/375], Loss: 5633.9497\n",
      "Epoch [3/50], Step [121/375], Loss: 3951.8015\n",
      "Epoch [3/50], Step [122/375], Loss: 1014.6883\n",
      "Epoch [3/50], Step [123/375], Loss: 2066.9226\n",
      "Epoch [3/50], Step [124/375], Loss: 966.7319\n",
      "Epoch [3/50], Step [125/375], Loss: 2066.5371\n",
      "Epoch [3/50], Step [126/375], Loss: 1241.8330\n",
      "Epoch [3/50], Step [127/375], Loss: 2813.7329\n",
      "Epoch [3/50], Step [128/375], Loss: 1753.8933\n",
      "Epoch [3/50], Step [129/375], Loss: 3558.3665\n",
      "Epoch [3/50], Step [130/375], Loss: 1020.6030\n",
      "Epoch [3/50], Step [131/375], Loss: 3487.0439\n",
      "Epoch [3/50], Step [132/375], Loss: 130.3147\n",
      "Epoch [3/50], Step [133/375], Loss: 1453.9746\n",
      "Epoch [3/50], Step [134/375], Loss: 586.0865\n",
      "Epoch [3/50], Step [135/375], Loss: 673.9698\n",
      "Epoch [3/50], Step [136/375], Loss: 2307.2092\n",
      "Epoch [3/50], Step [137/375], Loss: 5337.9136\n",
      "Epoch [3/50], Step [138/375], Loss: 950.6685\n",
      "Epoch [3/50], Step [139/375], Loss: 5541.7744\n",
      "Epoch [3/50], Step [140/375], Loss: 1701.0846\n",
      "Epoch [3/50], Step [141/375], Loss: 1718.6469\n",
      "Epoch [3/50], Step [142/375], Loss: 2228.8403\n",
      "Epoch [3/50], Step [143/375], Loss: 3516.5051\n",
      "Epoch [3/50], Step [144/375], Loss: 2720.9763\n",
      "Epoch [3/50], Step [145/375], Loss: 1550.2864\n",
      "Epoch [3/50], Step [146/375], Loss: 1848.0414\n",
      "Epoch [3/50], Step [147/375], Loss: 1043.5463\n",
      "Epoch [3/50], Step [148/375], Loss: 1834.3997\n",
      "Epoch [3/50], Step [149/375], Loss: 2116.6550\n",
      "Epoch [3/50], Step [150/375], Loss: 3309.1550\n",
      "Epoch [3/50], Step [151/375], Loss: 4579.3340\n",
      "Epoch [3/50], Step [152/375], Loss: 2727.1289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Step [153/375], Loss: 2244.7808\n",
      "Epoch [3/50], Step [154/375], Loss: 2351.2351\n",
      "Epoch [3/50], Step [155/375], Loss: 2529.0632\n",
      "Epoch [3/50], Step [156/375], Loss: 1787.5590\n",
      "Epoch [3/50], Step [157/375], Loss: 1455.6115\n",
      "Epoch [3/50], Step [158/375], Loss: 1732.3876\n",
      "Epoch [3/50], Step [159/375], Loss: 5309.4028\n",
      "Epoch [3/50], Step [160/375], Loss: 6497.8735\n",
      "Epoch [3/50], Step [161/375], Loss: 1606.2976\n",
      "Epoch [3/50], Step [162/375], Loss: 1649.2542\n",
      "Epoch [3/50], Step [163/375], Loss: 2438.0488\n",
      "Epoch [3/50], Step [164/375], Loss: 2211.1272\n",
      "Epoch [3/50], Step [165/375], Loss: 1699.4506\n",
      "Epoch [3/50], Step [166/375], Loss: 7512.4268\n",
      "Epoch [3/50], Step [167/375], Loss: 1747.9604\n",
      "Epoch [3/50], Step [168/375], Loss: 3737.1279\n",
      "Epoch [3/50], Step [169/375], Loss: 673.6597\n",
      "Epoch [3/50], Step [170/375], Loss: 1082.9980\n",
      "Epoch [3/50], Step [171/375], Loss: 380.5278\n",
      "Epoch [3/50], Step [172/375], Loss: 3044.2004\n",
      "Epoch [3/50], Step [173/375], Loss: 5790.9502\n",
      "Epoch [3/50], Step [174/375], Loss: 5812.5249\n",
      "Epoch [3/50], Step [175/375], Loss: 6136.1738\n",
      "Epoch [3/50], Step [176/375], Loss: 1059.5059\n",
      "Epoch [3/50], Step [177/375], Loss: 3738.4495\n",
      "Epoch [3/50], Step [178/375], Loss: 1850.7551\n",
      "Epoch [3/50], Step [179/375], Loss: 500.1247\n",
      "Epoch [3/50], Step [180/375], Loss: 1929.3523\n",
      "Epoch [3/50], Step [181/375], Loss: 5254.5669\n",
      "Epoch [3/50], Step [182/375], Loss: 3121.1584\n",
      "Epoch [3/50], Step [183/375], Loss: 1596.4559\n",
      "Epoch [3/50], Step [184/375], Loss: 3740.6360\n",
      "Epoch [3/50], Step [185/375], Loss: 282.0044\n",
      "Epoch [3/50], Step [186/375], Loss: 1936.5363\n",
      "Epoch [3/50], Step [187/375], Loss: 1267.0482\n",
      "Epoch [3/50], Step [188/375], Loss: 1205.0082\n",
      "Epoch [3/50], Step [189/375], Loss: 1477.3445\n",
      "Epoch [3/50], Step [190/375], Loss: 1650.0134\n",
      "Epoch [3/50], Step [191/375], Loss: 1710.8915\n",
      "Epoch [3/50], Step [192/375], Loss: 2018.2710\n",
      "Epoch [3/50], Step [193/375], Loss: 504.7755\n",
      "Epoch [3/50], Step [194/375], Loss: 4499.0439\n",
      "Epoch [3/50], Step [195/375], Loss: 4413.9819\n",
      "Epoch [3/50], Step [196/375], Loss: 3410.8499\n",
      "Epoch [3/50], Step [197/375], Loss: 1472.1580\n",
      "Epoch [3/50], Step [198/375], Loss: 1215.0939\n",
      "Epoch [3/50], Step [199/375], Loss: 2809.4104\n",
      "Epoch [3/50], Step [200/375], Loss: 3928.5090\n",
      "Epoch [3/50], Step [201/375], Loss: 2059.6455\n",
      "Epoch [3/50], Step [202/375], Loss: 2065.1204\n",
      "Epoch [3/50], Step [203/375], Loss: 1188.1860\n",
      "Epoch [3/50], Step [204/375], Loss: 8163.6201\n",
      "Epoch [3/50], Step [205/375], Loss: 4594.5713\n",
      "Epoch [3/50], Step [206/375], Loss: 2485.1421\n",
      "Epoch [3/50], Step [207/375], Loss: 2277.5884\n",
      "Epoch [3/50], Step [208/375], Loss: 1607.9279\n",
      "Epoch [3/50], Step [209/375], Loss: 1115.3815\n",
      "Epoch [3/50], Step [210/375], Loss: 3151.9919\n",
      "Epoch [3/50], Step [211/375], Loss: 2824.7212\n",
      "Epoch [3/50], Step [212/375], Loss: 1804.8427\n",
      "Epoch [3/50], Step [213/375], Loss: 1859.6617\n",
      "Epoch [3/50], Step [214/375], Loss: 1640.3971\n",
      "Epoch [3/50], Step [215/375], Loss: 1030.6743\n",
      "Epoch [3/50], Step [216/375], Loss: 3203.9675\n",
      "Epoch [3/50], Step [217/375], Loss: 3087.8179\n",
      "Epoch [3/50], Step [218/375], Loss: 3389.2827\n",
      "Epoch [3/50], Step [219/375], Loss: 6130.6260\n",
      "Epoch [3/50], Step [220/375], Loss: 2274.0571\n",
      "Epoch [3/50], Step [221/375], Loss: 1305.1958\n",
      "Epoch [3/50], Step [222/375], Loss: 2007.0217\n",
      "Epoch [3/50], Step [223/375], Loss: 3054.5222\n",
      "Epoch [3/50], Step [224/375], Loss: 1582.9298\n",
      "Epoch [3/50], Step [225/375], Loss: 1810.3666\n",
      "Epoch [3/50], Step [226/375], Loss: 2122.5359\n",
      "Epoch [3/50], Step [227/375], Loss: 1862.2965\n",
      "Epoch [3/50], Step [228/375], Loss: 2760.2354\n",
      "Epoch [3/50], Step [229/375], Loss: 5952.2407\n",
      "Epoch [3/50], Step [230/375], Loss: 3022.4797\n",
      "Epoch [3/50], Step [231/375], Loss: 6197.4800\n",
      "Epoch [3/50], Step [232/375], Loss: 5062.9966\n",
      "Epoch [3/50], Step [233/375], Loss: 2046.9473\n",
      "Epoch [3/50], Step [234/375], Loss: 4464.1968\n",
      "Epoch [3/50], Step [235/375], Loss: 2033.1642\n",
      "Epoch [3/50], Step [236/375], Loss: 276.9085\n",
      "Epoch [3/50], Step [237/375], Loss: 4666.7456\n",
      "Epoch [3/50], Step [238/375], Loss: 1533.3464\n",
      "Epoch [3/50], Step [239/375], Loss: 797.3527\n",
      "Epoch [3/50], Step [240/375], Loss: 2244.1111\n",
      "Epoch [3/50], Step [241/375], Loss: 5395.1675\n",
      "Epoch [3/50], Step [242/375], Loss: 4897.9487\n",
      "Epoch [3/50], Step [243/375], Loss: 6533.1968\n",
      "Epoch [3/50], Step [244/375], Loss: 3765.9575\n",
      "Epoch [3/50], Step [245/375], Loss: 5802.0093\n",
      "Epoch [3/50], Step [246/375], Loss: 2452.3364\n",
      "Epoch [3/50], Step [247/375], Loss: 3956.8296\n",
      "Epoch [3/50], Step [248/375], Loss: 863.1147\n",
      "Epoch [3/50], Step [249/375], Loss: 4934.0522\n",
      "Epoch [3/50], Step [250/375], Loss: 4868.3867\n",
      "Epoch [3/50], Step [251/375], Loss: 1885.2729\n",
      "Epoch [3/50], Step [252/375], Loss: 2910.6985\n",
      "Epoch [3/50], Step [253/375], Loss: 1194.0660\n",
      "Epoch [3/50], Step [254/375], Loss: 3221.6340\n",
      "Epoch [3/50], Step [255/375], Loss: 3390.4355\n",
      "Epoch [3/50], Step [256/375], Loss: 1233.5659\n",
      "Epoch [3/50], Step [257/375], Loss: 1258.4985\n",
      "Epoch [3/50], Step [258/375], Loss: 3429.3535\n",
      "Epoch [3/50], Step [259/375], Loss: 4414.6816\n",
      "Epoch [3/50], Step [260/375], Loss: 1653.8997\n",
      "Epoch [3/50], Step [261/375], Loss: 2776.1897\n",
      "Epoch [3/50], Step [262/375], Loss: 3964.7976\n",
      "Epoch [3/50], Step [263/375], Loss: 1255.1063\n",
      "Epoch [3/50], Step [264/375], Loss: 3195.1938\n",
      "Epoch [3/50], Step [265/375], Loss: 1117.4347\n",
      "Epoch [3/50], Step [266/375], Loss: 3429.0042\n",
      "Epoch [3/50], Step [267/375], Loss: 1553.9106\n",
      "Epoch [3/50], Step [268/375], Loss: 1887.2632\n",
      "Epoch [3/50], Step [269/375], Loss: 2159.8345\n",
      "Epoch [3/50], Step [270/375], Loss: 1302.9429\n",
      "Epoch [3/50], Step [271/375], Loss: 2084.6570\n",
      "Epoch [3/50], Step [272/375], Loss: 1284.5706\n",
      "Epoch [3/50], Step [273/375], Loss: 3587.1216\n",
      "Epoch [3/50], Step [274/375], Loss: 908.2785\n",
      "Epoch [3/50], Step [275/375], Loss: 2182.0547\n",
      "Epoch [3/50], Step [276/375], Loss: 1894.9396\n",
      "Epoch [3/50], Step [277/375], Loss: 1432.3887\n",
      "Epoch [3/50], Step [278/375], Loss: 2356.9751\n",
      "Epoch [3/50], Step [279/375], Loss: 6445.5391\n",
      "Epoch [3/50], Step [280/375], Loss: 4413.8457\n",
      "Epoch [3/50], Step [281/375], Loss: 1588.6542\n",
      "Epoch [3/50], Step [282/375], Loss: 4058.1208\n",
      "Epoch [3/50], Step [283/375], Loss: 3322.6392\n",
      "Epoch [3/50], Step [284/375], Loss: 1588.2174\n",
      "Epoch [3/50], Step [285/375], Loss: 2567.6855\n",
      "Epoch [3/50], Step [286/375], Loss: 838.9584\n",
      "Epoch [3/50], Step [287/375], Loss: 5172.0566\n",
      "Epoch [3/50], Step [288/375], Loss: 4655.3301\n",
      "Epoch [3/50], Step [289/375], Loss: 3810.2854\n",
      "Epoch [3/50], Step [290/375], Loss: 4013.8611\n",
      "Epoch [3/50], Step [291/375], Loss: 1461.1826\n",
      "Epoch [3/50], Step [292/375], Loss: 4631.7466\n",
      "Epoch [3/50], Step [293/375], Loss: 1679.1909\n",
      "Epoch [3/50], Step [294/375], Loss: 1265.3467\n",
      "Epoch [3/50], Step [295/375], Loss: 1095.0548\n",
      "Epoch [3/50], Step [296/375], Loss: 2695.5234\n",
      "Epoch [3/50], Step [297/375], Loss: 2461.1167\n",
      "Epoch [3/50], Step [298/375], Loss: 3363.7471\n",
      "Epoch [3/50], Step [299/375], Loss: 1432.1074\n",
      "Epoch [3/50], Step [300/375], Loss: 6162.1704\n",
      "Epoch [3/50], Step [301/375], Loss: 2041.0623\n",
      "Epoch [3/50], Step [302/375], Loss: 2240.2222\n",
      "Epoch [3/50], Step [303/375], Loss: 1131.2722\n",
      "Epoch [3/50], Step [304/375], Loss: 3347.7415\n",
      "Epoch [3/50], Step [305/375], Loss: 778.0812\n",
      "Epoch [3/50], Step [306/375], Loss: 4990.1265\n",
      "Epoch [3/50], Step [307/375], Loss: 2202.8831\n",
      "Epoch [3/50], Step [308/375], Loss: 1456.7196\n",
      "Epoch [3/50], Step [309/375], Loss: 1945.5018\n",
      "Epoch [3/50], Step [310/375], Loss: 4196.9019\n",
      "Epoch [3/50], Step [311/375], Loss: 2562.4563\n",
      "Epoch [3/50], Step [312/375], Loss: 1668.2249\n",
      "Epoch [3/50], Step [313/375], Loss: 923.0764\n",
      "Epoch [3/50], Step [314/375], Loss: 631.1777\n",
      "Epoch [3/50], Step [315/375], Loss: 832.0987\n",
      "Epoch [3/50], Step [316/375], Loss: 673.3521\n",
      "Epoch [3/50], Step [317/375], Loss: 843.5728\n",
      "Epoch [3/50], Step [318/375], Loss: 3655.7915\n",
      "Epoch [3/50], Step [319/375], Loss: 1585.4701\n",
      "Epoch [3/50], Step [320/375], Loss: 2255.1079\n",
      "Epoch [3/50], Step [321/375], Loss: 2814.1355\n",
      "Epoch [3/50], Step [322/375], Loss: 486.3102\n",
      "Epoch [3/50], Step [323/375], Loss: 2105.1531\n",
      "Epoch [3/50], Step [324/375], Loss: 4212.6182\n",
      "Epoch [3/50], Step [325/375], Loss: 1128.0011\n",
      "Epoch [3/50], Step [326/375], Loss: 1733.2052\n",
      "Epoch [3/50], Step [327/375], Loss: 1190.2841\n",
      "Epoch [3/50], Step [328/375], Loss: 1132.6620\n",
      "Epoch [3/50], Step [329/375], Loss: 1098.2955\n",
      "Epoch [3/50], Step [330/375], Loss: 624.2556\n",
      "Epoch [3/50], Step [331/375], Loss: 1992.4901\n",
      "Epoch [3/50], Step [332/375], Loss: 729.3507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Step [333/375], Loss: 2185.8335\n",
      "Epoch [3/50], Step [334/375], Loss: 2254.2693\n",
      "Epoch [3/50], Step [335/375], Loss: 2931.7913\n",
      "Epoch [3/50], Step [336/375], Loss: 1660.8732\n",
      "Epoch [3/50], Step [337/375], Loss: 1658.9429\n",
      "Epoch [3/50], Step [338/375], Loss: 662.5910\n",
      "Epoch [3/50], Step [339/375], Loss: 1489.2577\n",
      "Epoch [3/50], Step [340/375], Loss: 3403.0776\n",
      "Epoch [3/50], Step [341/375], Loss: 1133.1039\n",
      "Epoch [3/50], Step [342/375], Loss: 1020.8512\n",
      "Epoch [3/50], Step [343/375], Loss: 1538.3984\n",
      "Epoch [3/50], Step [344/375], Loss: 1039.1923\n",
      "Epoch [3/50], Step [345/375], Loss: 3776.6050\n",
      "Epoch [3/50], Step [346/375], Loss: 1387.5771\n",
      "Epoch [3/50], Step [347/375], Loss: 3094.5994\n",
      "Epoch [3/50], Step [348/375], Loss: 1977.5586\n",
      "Epoch [3/50], Step [349/375], Loss: 1364.6720\n",
      "Epoch [3/50], Step [350/375], Loss: 3478.3635\n",
      "Epoch [3/50], Step [351/375], Loss: 5667.3281\n",
      "Epoch [3/50], Step [352/375], Loss: 4909.6548\n",
      "Epoch [3/50], Step [353/375], Loss: 3055.4048\n",
      "Epoch [3/50], Step [354/375], Loss: 4677.3911\n",
      "Epoch [3/50], Step [355/375], Loss: 8056.9229\n",
      "Epoch [3/50], Step [356/375], Loss: 3490.7251\n",
      "Epoch [3/50], Step [357/375], Loss: 1792.1873\n",
      "Epoch [3/50], Step [358/375], Loss: 3725.5325\n",
      "Epoch [3/50], Step [359/375], Loss: 2661.6267\n",
      "Epoch [3/50], Step [360/375], Loss: 1228.4611\n",
      "Epoch [3/50], Step [361/375], Loss: 4091.5061\n",
      "Epoch [3/50], Step [362/375], Loss: 5380.2598\n",
      "Epoch [3/50], Step [363/375], Loss: 4191.1221\n",
      "Epoch [3/50], Step [364/375], Loss: 2640.0164\n",
      "Epoch [3/50], Step [365/375], Loss: 3199.3494\n",
      "Epoch [3/50], Step [366/375], Loss: 834.1997\n",
      "Epoch [3/50], Step [367/375], Loss: 4879.7451\n",
      "Epoch [3/50], Step [368/375], Loss: 1993.0375\n",
      "Epoch [3/50], Step [369/375], Loss: 3113.4585\n",
      "Epoch [3/50], Step [370/375], Loss: 8625.8877\n",
      "Epoch [3/50], Step [371/375], Loss: 1668.1360\n",
      "Epoch [3/50], Step [372/375], Loss: 7121.9312\n",
      "Epoch [3/50], Step [373/375], Loss: 2999.2952\n",
      "Epoch [3/50], Step [374/375], Loss: 977.7019\n",
      "Epoch [3/50], Step [375/375], Loss: 2957.6487\n",
      "Epoch [4/50], Step [1/375], Loss: 1354.1399\n",
      "Epoch [4/50], Step [2/375], Loss: 1621.9552\n",
      "Epoch [4/50], Step [3/375], Loss: 3022.6892\n",
      "Epoch [4/50], Step [4/375], Loss: 3477.1299\n",
      "Epoch [4/50], Step [5/375], Loss: 3883.0862\n",
      "Epoch [4/50], Step [6/375], Loss: 1358.3851\n",
      "Epoch [4/50], Step [7/375], Loss: 1252.2565\n",
      "Epoch [4/50], Step [8/375], Loss: 737.9225\n",
      "Epoch [4/50], Step [9/375], Loss: 590.1433\n",
      "Epoch [4/50], Step [10/375], Loss: 2056.0310\n",
      "Epoch [4/50], Step [11/375], Loss: 1384.5408\n",
      "Epoch [4/50], Step [12/375], Loss: 1056.4231\n",
      "Epoch [4/50], Step [13/375], Loss: 606.3914\n",
      "Epoch [4/50], Step [14/375], Loss: 1699.7241\n",
      "Epoch [4/50], Step [15/375], Loss: 1764.6349\n",
      "Epoch [4/50], Step [16/375], Loss: 1045.7856\n",
      "Epoch [4/50], Step [17/375], Loss: 661.5249\n",
      "Epoch [4/50], Step [18/375], Loss: 1148.2501\n",
      "Epoch [4/50], Step [19/375], Loss: 91.1418\n",
      "Epoch [4/50], Step [20/375], Loss: 1938.9211\n",
      "Epoch [4/50], Step [21/375], Loss: 3946.0847\n",
      "Epoch [4/50], Step [22/375], Loss: 1400.0383\n",
      "Epoch [4/50], Step [23/375], Loss: 651.4343\n",
      "Epoch [4/50], Step [24/375], Loss: 1781.2545\n",
      "Epoch [4/50], Step [25/375], Loss: 487.3997\n",
      "Epoch [4/50], Step [26/375], Loss: 927.1044\n",
      "Epoch [4/50], Step [27/375], Loss: 982.8647\n",
      "Epoch [4/50], Step [28/375], Loss: 1577.0861\n",
      "Epoch [4/50], Step [29/375], Loss: 354.7840\n",
      "Epoch [4/50], Step [30/375], Loss: 2313.9753\n",
      "Epoch [4/50], Step [31/375], Loss: 2074.9336\n",
      "Epoch [4/50], Step [32/375], Loss: 693.7471\n",
      "Epoch [4/50], Step [33/375], Loss: 378.5349\n",
      "Epoch [4/50], Step [34/375], Loss: 2014.3759\n",
      "Epoch [4/50], Step [35/375], Loss: 857.3513\n",
      "Epoch [4/50], Step [36/375], Loss: 2646.5989\n",
      "Epoch [4/50], Step [37/375], Loss: 1496.3452\n",
      "Epoch [4/50], Step [38/375], Loss: 890.4819\n",
      "Epoch [4/50], Step [39/375], Loss: 1411.4546\n",
      "Epoch [4/50], Step [40/375], Loss: 255.4615\n",
      "Epoch [4/50], Step [41/375], Loss: 310.0201\n",
      "Epoch [4/50], Step [42/375], Loss: 605.8215\n",
      "Epoch [4/50], Step [43/375], Loss: 1746.9464\n",
      "Epoch [4/50], Step [44/375], Loss: 882.0963\n",
      "Epoch [4/50], Step [45/375], Loss: 1957.9054\n",
      "Epoch [4/50], Step [46/375], Loss: 958.3127\n",
      "Epoch [4/50], Step [47/375], Loss: 824.9645\n",
      "Epoch [4/50], Step [48/375], Loss: 1483.4985\n",
      "Epoch [4/50], Step [49/375], Loss: 306.1503\n",
      "Epoch [4/50], Step [50/375], Loss: 672.9112\n",
      "Epoch [4/50], Step [51/375], Loss: 2205.3171\n",
      "Epoch [4/50], Step [52/375], Loss: 1526.4158\n",
      "Epoch [4/50], Step [53/375], Loss: 327.5830\n",
      "Epoch [4/50], Step [54/375], Loss: 2257.8545\n",
      "Epoch [4/50], Step [55/375], Loss: 432.0085\n",
      "Epoch [4/50], Step [56/375], Loss: 1062.1697\n",
      "Epoch [4/50], Step [57/375], Loss: 1672.3138\n",
      "Epoch [4/50], Step [58/375], Loss: 742.5201\n",
      "Epoch [4/50], Step [59/375], Loss: 881.2416\n",
      "Epoch [4/50], Step [60/375], Loss: 1724.4238\n",
      "Epoch [4/50], Step [61/375], Loss: 772.0731\n",
      "Epoch [4/50], Step [62/375], Loss: 802.1280\n",
      "Epoch [4/50], Step [63/375], Loss: 736.1817\n",
      "Epoch [4/50], Step [64/375], Loss: 1386.6620\n",
      "Epoch [4/50], Step [65/375], Loss: 504.7909\n",
      "Epoch [4/50], Step [66/375], Loss: 392.2211\n",
      "Epoch [4/50], Step [67/375], Loss: 881.7568\n",
      "Epoch [4/50], Step [68/375], Loss: 439.0265\n",
      "Epoch [4/50], Step [69/375], Loss: 3760.9185\n",
      "Epoch [4/50], Step [70/375], Loss: 579.8193\n",
      "Epoch [4/50], Step [71/375], Loss: 4469.6250\n",
      "Epoch [4/50], Step [72/375], Loss: 1152.1655\n",
      "Epoch [4/50], Step [73/375], Loss: 752.7123\n",
      "Epoch [4/50], Step [74/375], Loss: 1083.0590\n",
      "Epoch [4/50], Step [75/375], Loss: 685.1841\n",
      "Epoch [4/50], Step [76/375], Loss: 970.4742\n",
      "Epoch [4/50], Step [77/375], Loss: 485.6670\n",
      "Epoch [4/50], Step [78/375], Loss: 1359.6726\n",
      "Epoch [4/50], Step [79/375], Loss: 285.0760\n",
      "Epoch [4/50], Step [80/375], Loss: 444.8734\n",
      "Epoch [4/50], Step [81/375], Loss: 1744.7938\n",
      "Epoch [4/50], Step [82/375], Loss: 545.2068\n",
      "Epoch [4/50], Step [83/375], Loss: 1496.3379\n",
      "Epoch [4/50], Step [84/375], Loss: 1108.0826\n",
      "Epoch [4/50], Step [85/375], Loss: 816.3733\n",
      "Epoch [4/50], Step [86/375], Loss: 441.6605\n",
      "Epoch [4/50], Step [87/375], Loss: 443.9193\n",
      "Epoch [4/50], Step [88/375], Loss: 3561.0374\n",
      "Epoch [4/50], Step [89/375], Loss: 1738.8745\n",
      "Epoch [4/50], Step [90/375], Loss: 910.1726\n",
      "Epoch [4/50], Step [91/375], Loss: 561.5029\n",
      "Epoch [4/50], Step [92/375], Loss: 549.8890\n",
      "Epoch [4/50], Step [93/375], Loss: 199.0105\n",
      "Epoch [4/50], Step [94/375], Loss: 1164.8348\n",
      "Epoch [4/50], Step [95/375], Loss: 2454.0391\n",
      "Epoch [4/50], Step [96/375], Loss: 2875.6956\n",
      "Epoch [4/50], Step [97/375], Loss: 255.0177\n",
      "Epoch [4/50], Step [98/375], Loss: 1999.4963\n",
      "Epoch [4/50], Step [99/375], Loss: 982.2470\n",
      "Epoch [4/50], Step [100/375], Loss: 1592.6879\n",
      "Epoch [4/50], Step [101/375], Loss: 684.1700\n",
      "Epoch [4/50], Step [102/375], Loss: 1698.2743\n",
      "Epoch [4/50], Step [103/375], Loss: 1713.3947\n",
      "Epoch [4/50], Step [104/375], Loss: 284.2303\n",
      "Epoch [4/50], Step [105/375], Loss: 184.2138\n",
      "Epoch [4/50], Step [106/375], Loss: 1023.4654\n",
      "Epoch [4/50], Step [107/375], Loss: 181.9805\n",
      "Epoch [4/50], Step [108/375], Loss: 848.5138\n",
      "Epoch [4/50], Step [109/375], Loss: 1004.8421\n",
      "Epoch [4/50], Step [110/375], Loss: 1498.7482\n",
      "Epoch [4/50], Step [111/375], Loss: 1343.5494\n",
      "Epoch [4/50], Step [112/375], Loss: 554.8140\n",
      "Epoch [4/50], Step [113/375], Loss: 1032.3855\n",
      "Epoch [4/50], Step [114/375], Loss: 350.3157\n",
      "Epoch [4/50], Step [115/375], Loss: 592.7624\n",
      "Epoch [4/50], Step [116/375], Loss: 663.8414\n",
      "Epoch [4/50], Step [117/375], Loss: 842.8332\n",
      "Epoch [4/50], Step [118/375], Loss: 907.5588\n",
      "Epoch [4/50], Step [119/375], Loss: 251.5811\n",
      "Epoch [4/50], Step [120/375], Loss: 606.0471\n",
      "Epoch [4/50], Step [121/375], Loss: 936.1054\n",
      "Epoch [4/50], Step [122/375], Loss: 1156.7916\n",
      "Epoch [4/50], Step [123/375], Loss: 2393.7830\n",
      "Epoch [4/50], Step [124/375], Loss: 891.1078\n",
      "Epoch [4/50], Step [125/375], Loss: 961.1053\n",
      "Epoch [4/50], Step [126/375], Loss: 364.7473\n",
      "Epoch [4/50], Step [127/375], Loss: 1333.4674\n",
      "Epoch [4/50], Step [128/375], Loss: 2913.0081\n",
      "Epoch [4/50], Step [129/375], Loss: 572.9742\n",
      "Epoch [4/50], Step [130/375], Loss: 431.2658\n",
      "Epoch [4/50], Step [131/375], Loss: 619.4790\n",
      "Epoch [4/50], Step [132/375], Loss: 1069.7124\n",
      "Epoch [4/50], Step [133/375], Loss: 1285.3608\n",
      "Epoch [4/50], Step [134/375], Loss: 2156.2339\n",
      "Epoch [4/50], Step [135/375], Loss: 1565.5266\n",
      "Epoch [4/50], Step [136/375], Loss: 323.0061\n",
      "Epoch [4/50], Step [137/375], Loss: 1152.5662\n",
      "Epoch [4/50], Step [138/375], Loss: 1722.0607\n",
      "Epoch [4/50], Step [139/375], Loss: 1253.8495\n",
      "Epoch [4/50], Step [140/375], Loss: 1319.7145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Step [141/375], Loss: 507.3004\n",
      "Epoch [4/50], Step [142/375], Loss: 2036.5254\n",
      "Epoch [4/50], Step [143/375], Loss: 1368.9346\n",
      "Epoch [4/50], Step [144/375], Loss: 1369.0459\n",
      "Epoch [4/50], Step [145/375], Loss: 1584.9005\n",
      "Epoch [4/50], Step [146/375], Loss: 1417.3010\n",
      "Epoch [4/50], Step [147/375], Loss: 2851.1245\n",
      "Epoch [4/50], Step [148/375], Loss: 822.6086\n",
      "Epoch [4/50], Step [149/375], Loss: 1473.3252\n",
      "Epoch [4/50], Step [150/375], Loss: 1684.1733\n",
      "Epoch [4/50], Step [151/375], Loss: 3406.8149\n",
      "Epoch [4/50], Step [152/375], Loss: 253.7112\n",
      "Epoch [4/50], Step [153/375], Loss: 1056.4252\n",
      "Epoch [4/50], Step [154/375], Loss: 693.7974\n",
      "Epoch [4/50], Step [155/375], Loss: 603.1117\n",
      "Epoch [4/50], Step [156/375], Loss: 1870.9757\n",
      "Epoch [4/50], Step [157/375], Loss: 1192.5756\n",
      "Epoch [4/50], Step [158/375], Loss: 1316.5913\n",
      "Epoch [4/50], Step [159/375], Loss: 325.3700\n",
      "Epoch [4/50], Step [160/375], Loss: 1002.0502\n",
      "Epoch [4/50], Step [161/375], Loss: 1107.5355\n",
      "Epoch [4/50], Step [162/375], Loss: 1455.3270\n",
      "Epoch [4/50], Step [163/375], Loss: 1532.0264\n",
      "Epoch [4/50], Step [164/375], Loss: 709.3956\n",
      "Epoch [4/50], Step [165/375], Loss: 206.1229\n",
      "Epoch [4/50], Step [166/375], Loss: 247.9724\n",
      "Epoch [4/50], Step [167/375], Loss: 1388.6747\n",
      "Epoch [4/50], Step [168/375], Loss: 858.7171\n",
      "Epoch [4/50], Step [169/375], Loss: 1533.0527\n",
      "Epoch [4/50], Step [170/375], Loss: 1066.1289\n",
      "Epoch [4/50], Step [171/375], Loss: 637.3464\n",
      "Epoch [4/50], Step [172/375], Loss: 407.7418\n",
      "Epoch [4/50], Step [173/375], Loss: 732.5944\n",
      "Epoch [4/50], Step [174/375], Loss: 1574.5730\n",
      "Epoch [4/50], Step [175/375], Loss: 3362.6006\n",
      "Epoch [4/50], Step [176/375], Loss: 1431.1436\n",
      "Epoch [4/50], Step [177/375], Loss: 1229.9805\n",
      "Epoch [4/50], Step [178/375], Loss: 1413.5823\n",
      "Epoch [4/50], Step [179/375], Loss: 733.6920\n",
      "Epoch [4/50], Step [180/375], Loss: 923.6934\n",
      "Epoch [4/50], Step [181/375], Loss: 825.8302\n",
      "Epoch [4/50], Step [182/375], Loss: 1055.8916\n",
      "Epoch [4/50], Step [183/375], Loss: 1029.3855\n",
      "Epoch [4/50], Step [184/375], Loss: 188.3374\n",
      "Epoch [4/50], Step [185/375], Loss: 950.3914\n",
      "Epoch [4/50], Step [186/375], Loss: 693.9152\n",
      "Epoch [4/50], Step [187/375], Loss: 1751.5559\n",
      "Epoch [4/50], Step [188/375], Loss: 326.6317\n",
      "Epoch [4/50], Step [189/375], Loss: 411.6932\n",
      "Epoch [4/50], Step [190/375], Loss: 1328.1017\n",
      "Epoch [4/50], Step [191/375], Loss: 2474.6589\n",
      "Epoch [4/50], Step [192/375], Loss: 287.2828\n",
      "Epoch [4/50], Step [193/375], Loss: 588.8524\n",
      "Epoch [4/50], Step [194/375], Loss: 401.5278\n",
      "Epoch [4/50], Step [195/375], Loss: 337.1026\n",
      "Epoch [4/50], Step [196/375], Loss: 232.8272\n",
      "Epoch [4/50], Step [197/375], Loss: 263.8791\n",
      "Epoch [4/50], Step [198/375], Loss: 1178.8121\n",
      "Epoch [4/50], Step [199/375], Loss: 2435.1138\n",
      "Epoch [4/50], Step [200/375], Loss: 1410.9133\n",
      "Epoch [4/50], Step [201/375], Loss: 1856.0421\n",
      "Epoch [4/50], Step [202/375], Loss: 372.4062\n",
      "Epoch [4/50], Step [203/375], Loss: 1489.7196\n",
      "Epoch [4/50], Step [204/375], Loss: 677.9825\n",
      "Epoch [4/50], Step [205/375], Loss: 310.8575\n",
      "Epoch [4/50], Step [206/375], Loss: 301.5630\n",
      "Epoch [4/50], Step [207/375], Loss: 1737.5363\n",
      "Epoch [4/50], Step [208/375], Loss: 2291.3665\n",
      "Epoch [4/50], Step [209/375], Loss: 1064.6970\n",
      "Epoch [4/50], Step [210/375], Loss: 500.1026\n",
      "Epoch [4/50], Step [211/375], Loss: 1071.0881\n",
      "Epoch [4/50], Step [212/375], Loss: 1058.1545\n",
      "Epoch [4/50], Step [213/375], Loss: 315.6125\n",
      "Epoch [4/50], Step [214/375], Loss: 1281.6565\n",
      "Epoch [4/50], Step [215/375], Loss: 1405.6838\n",
      "Epoch [4/50], Step [216/375], Loss: 221.2428\n",
      "Epoch [4/50], Step [217/375], Loss: 444.1686\n",
      "Epoch [4/50], Step [218/375], Loss: 730.0359\n",
      "Epoch [4/50], Step [219/375], Loss: 198.2364\n",
      "Epoch [4/50], Step [220/375], Loss: 244.4911\n",
      "Epoch [4/50], Step [221/375], Loss: 1780.7241\n",
      "Epoch [4/50], Step [222/375], Loss: 316.0939\n",
      "Epoch [4/50], Step [223/375], Loss: 126.3176\n",
      "Epoch [4/50], Step [224/375], Loss: 626.9435\n",
      "Epoch [4/50], Step [225/375], Loss: 761.0234\n",
      "Epoch [4/50], Step [226/375], Loss: 903.2910\n",
      "Epoch [4/50], Step [227/375], Loss: 333.8095\n",
      "Epoch [4/50], Step [228/375], Loss: 1470.1696\n",
      "Epoch [4/50], Step [229/375], Loss: 1302.9780\n",
      "Epoch [4/50], Step [230/375], Loss: 1860.2271\n",
      "Epoch [4/50], Step [231/375], Loss: 876.0434\n",
      "Epoch [4/50], Step [232/375], Loss: 1541.8167\n",
      "Epoch [4/50], Step [233/375], Loss: 1078.7510\n",
      "Epoch [4/50], Step [234/375], Loss: 2189.1995\n",
      "Epoch [4/50], Step [235/375], Loss: 328.8868\n",
      "Epoch [4/50], Step [236/375], Loss: 1700.4164\n",
      "Epoch [4/50], Step [237/375], Loss: 2025.1799\n",
      "Epoch [4/50], Step [238/375], Loss: 1758.6764\n",
      "Epoch [4/50], Step [239/375], Loss: 1447.8735\n",
      "Epoch [4/50], Step [240/375], Loss: 603.9662\n",
      "Epoch [4/50], Step [241/375], Loss: 938.9159\n",
      "Epoch [4/50], Step [242/375], Loss: 1329.0435\n",
      "Epoch [4/50], Step [243/375], Loss: 1588.0167\n",
      "Epoch [4/50], Step [244/375], Loss: 377.1030\n",
      "Epoch [4/50], Step [245/375], Loss: 1761.7581\n",
      "Epoch [4/50], Step [246/375], Loss: 1333.5508\n",
      "Epoch [4/50], Step [247/375], Loss: 703.8676\n",
      "Epoch [4/50], Step [248/375], Loss: 809.8586\n",
      "Epoch [4/50], Step [249/375], Loss: 1115.2013\n",
      "Epoch [4/50], Step [250/375], Loss: 1938.5604\n",
      "Epoch [4/50], Step [251/375], Loss: 287.6306\n",
      "Epoch [4/50], Step [252/375], Loss: 703.8164\n",
      "Epoch [4/50], Step [253/375], Loss: 609.2301\n",
      "Epoch [4/50], Step [254/375], Loss: 3116.3118\n",
      "Epoch [4/50], Step [255/375], Loss: 1380.7189\n",
      "Epoch [4/50], Step [256/375], Loss: 2039.8009\n",
      "Epoch [4/50], Step [257/375], Loss: 430.0360\n",
      "Epoch [4/50], Step [258/375], Loss: 1069.7395\n",
      "Epoch [4/50], Step [259/375], Loss: 2503.9695\n",
      "Epoch [4/50], Step [260/375], Loss: 472.7174\n",
      "Epoch [4/50], Step [261/375], Loss: 619.7994\n",
      "Epoch [4/50], Step [262/375], Loss: 953.9014\n",
      "Epoch [4/50], Step [263/375], Loss: 460.6768\n",
      "Epoch [4/50], Step [264/375], Loss: 995.6357\n",
      "Epoch [4/50], Step [265/375], Loss: 941.9183\n",
      "Epoch [4/50], Step [266/375], Loss: 1954.3124\n",
      "Epoch [4/50], Step [267/375], Loss: 680.8713\n",
      "Epoch [4/50], Step [268/375], Loss: 1217.0460\n",
      "Epoch [4/50], Step [269/375], Loss: 1841.9832\n",
      "Epoch [4/50], Step [270/375], Loss: 689.3719\n",
      "Epoch [4/50], Step [271/375], Loss: 140.4146\n",
      "Epoch [4/50], Step [272/375], Loss: 456.1069\n",
      "Epoch [4/50], Step [273/375], Loss: 339.2412\n",
      "Epoch [4/50], Step [274/375], Loss: 3489.3862\n",
      "Epoch [4/50], Step [275/375], Loss: 826.9563\n",
      "Epoch [4/50], Step [276/375], Loss: 255.4079\n",
      "Epoch [4/50], Step [277/375], Loss: 297.7159\n",
      "Epoch [4/50], Step [278/375], Loss: 435.5811\n",
      "Epoch [4/50], Step [279/375], Loss: 324.4377\n",
      "Epoch [4/50], Step [280/375], Loss: 1648.1595\n",
      "Epoch [4/50], Step [281/375], Loss: 920.9161\n",
      "Epoch [4/50], Step [282/375], Loss: 900.0975\n",
      "Epoch [4/50], Step [283/375], Loss: 3362.0349\n",
      "Epoch [4/50], Step [284/375], Loss: 487.4111\n",
      "Epoch [4/50], Step [285/375], Loss: 585.6130\n",
      "Epoch [4/50], Step [286/375], Loss: 2022.8406\n",
      "Epoch [4/50], Step [287/375], Loss: 378.9234\n",
      "Epoch [4/50], Step [288/375], Loss: 1811.3441\n",
      "Epoch [4/50], Step [289/375], Loss: 2175.9087\n",
      "Epoch [4/50], Step [290/375], Loss: 1493.3837\n",
      "Epoch [4/50], Step [291/375], Loss: 281.8894\n",
      "Epoch [4/50], Step [292/375], Loss: 890.6263\n",
      "Epoch [4/50], Step [293/375], Loss: 921.9258\n",
      "Epoch [4/50], Step [294/375], Loss: 1997.8347\n",
      "Epoch [4/50], Step [295/375], Loss: 1092.0101\n",
      "Epoch [4/50], Step [296/375], Loss: 3954.2893\n",
      "Epoch [4/50], Step [297/375], Loss: 573.5884\n",
      "Epoch [4/50], Step [298/375], Loss: 712.3659\n",
      "Epoch [4/50], Step [299/375], Loss: 831.4836\n",
      "Epoch [4/50], Step [300/375], Loss: 698.4375\n",
      "Epoch [4/50], Step [301/375], Loss: 2509.7073\n",
      "Epoch [4/50], Step [302/375], Loss: 3514.1482\n",
      "Epoch [4/50], Step [303/375], Loss: 1642.4418\n",
      "Epoch [4/50], Step [304/375], Loss: 1046.3524\n",
      "Epoch [4/50], Step [305/375], Loss: 337.8172\n",
      "Epoch [4/50], Step [306/375], Loss: 366.4266\n",
      "Epoch [4/50], Step [307/375], Loss: 926.9541\n",
      "Epoch [4/50], Step [308/375], Loss: 1280.4769\n",
      "Epoch [4/50], Step [309/375], Loss: 2329.4285\n",
      "Epoch [4/50], Step [310/375], Loss: 1617.6178\n",
      "Epoch [4/50], Step [311/375], Loss: 1534.0857\n",
      "Epoch [4/50], Step [312/375], Loss: 2295.8708\n",
      "Epoch [4/50], Step [313/375], Loss: 1841.3055\n",
      "Epoch [4/50], Step [314/375], Loss: 659.5186\n",
      "Epoch [4/50], Step [315/375], Loss: 2590.5708\n",
      "Epoch [4/50], Step [316/375], Loss: 1035.2755\n",
      "Epoch [4/50], Step [317/375], Loss: 1339.0410\n",
      "Epoch [4/50], Step [318/375], Loss: 1046.3774\n",
      "Epoch [4/50], Step [319/375], Loss: 421.4859\n",
      "Epoch [4/50], Step [320/375], Loss: 2520.7322\n",
      "Epoch [4/50], Step [321/375], Loss: 1943.0745\n",
      "Epoch [4/50], Step [322/375], Loss: 773.0590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Step [323/375], Loss: 1375.6428\n",
      "Epoch [4/50], Step [324/375], Loss: 830.8058\n",
      "Epoch [4/50], Step [325/375], Loss: 719.9750\n",
      "Epoch [4/50], Step [326/375], Loss: 451.2329\n",
      "Epoch [4/50], Step [327/375], Loss: 2307.1909\n",
      "Epoch [4/50], Step [328/375], Loss: 1217.9360\n",
      "Epoch [4/50], Step [329/375], Loss: 278.8081\n",
      "Epoch [4/50], Step [330/375], Loss: 980.8730\n",
      "Epoch [4/50], Step [331/375], Loss: 1013.5474\n",
      "Epoch [4/50], Step [332/375], Loss: 504.0211\n",
      "Epoch [4/50], Step [333/375], Loss: 1035.7882\n",
      "Epoch [4/50], Step [334/375], Loss: 1736.3629\n",
      "Epoch [4/50], Step [335/375], Loss: 1758.1569\n",
      "Epoch [4/50], Step [336/375], Loss: 186.1565\n",
      "Epoch [4/50], Step [337/375], Loss: 1151.7313\n",
      "Epoch [4/50], Step [338/375], Loss: 825.2887\n",
      "Epoch [4/50], Step [339/375], Loss: 553.8921\n",
      "Epoch [4/50], Step [340/375], Loss: 1446.1283\n",
      "Epoch [4/50], Step [341/375], Loss: 1461.9148\n",
      "Epoch [4/50], Step [342/375], Loss: 1870.4327\n",
      "Epoch [4/50], Step [343/375], Loss: 268.6685\n",
      "Epoch [4/50], Step [344/375], Loss: 872.6697\n",
      "Epoch [4/50], Step [345/375], Loss: 948.5604\n",
      "Epoch [4/50], Step [346/375], Loss: 521.6152\n",
      "Epoch [4/50], Step [347/375], Loss: 1144.0702\n",
      "Epoch [4/50], Step [348/375], Loss: 1987.6088\n",
      "Epoch [4/50], Step [349/375], Loss: 896.5862\n",
      "Epoch [4/50], Step [350/375], Loss: 816.3242\n",
      "Epoch [4/50], Step [351/375], Loss: 661.1495\n",
      "Epoch [4/50], Step [352/375], Loss: 833.0864\n",
      "Epoch [4/50], Step [353/375], Loss: 2359.7002\n",
      "Epoch [4/50], Step [354/375], Loss: 259.7653\n",
      "Epoch [4/50], Step [355/375], Loss: 960.2586\n",
      "Epoch [4/50], Step [356/375], Loss: 603.5594\n",
      "Epoch [4/50], Step [357/375], Loss: 4027.2031\n",
      "Epoch [4/50], Step [358/375], Loss: 2689.7192\n",
      "Epoch [4/50], Step [359/375], Loss: 1056.7816\n",
      "Epoch [4/50], Step [360/375], Loss: 1074.7551\n",
      "Epoch [4/50], Step [361/375], Loss: 237.8483\n",
      "Epoch [4/50], Step [362/375], Loss: 1544.0850\n",
      "Epoch [4/50], Step [363/375], Loss: 524.6564\n",
      "Epoch [4/50], Step [364/375], Loss: 881.3083\n",
      "Epoch [4/50], Step [365/375], Loss: 1387.2048\n",
      "Epoch [4/50], Step [366/375], Loss: 1850.4078\n",
      "Epoch [4/50], Step [367/375], Loss: 421.6530\n",
      "Epoch [4/50], Step [368/375], Loss: 575.5559\n",
      "Epoch [4/50], Step [369/375], Loss: 377.2623\n",
      "Epoch [4/50], Step [370/375], Loss: 1306.9418\n",
      "Epoch [4/50], Step [371/375], Loss: 1348.6254\n",
      "Epoch [4/50], Step [372/375], Loss: 681.4884\n",
      "Epoch [4/50], Step [373/375], Loss: 2026.5798\n",
      "Epoch [4/50], Step [374/375], Loss: 2679.5842\n",
      "Epoch [4/50], Step [375/375], Loss: 755.2046\n",
      "Epoch [5/50], Step [1/375], Loss: 1579.2277\n",
      "Epoch [5/50], Step [2/375], Loss: 1969.2186\n",
      "Epoch [5/50], Step [3/375], Loss: 543.0871\n",
      "Epoch [5/50], Step [4/375], Loss: 620.6480\n",
      "Epoch [5/50], Step [5/375], Loss: 540.1317\n",
      "Epoch [5/50], Step [6/375], Loss: 589.6576\n",
      "Epoch [5/50], Step [7/375], Loss: 1204.9960\n",
      "Epoch [5/50], Step [8/375], Loss: 532.6110\n",
      "Epoch [5/50], Step [9/375], Loss: 1195.6786\n",
      "Epoch [5/50], Step [10/375], Loss: 497.6866\n",
      "Epoch [5/50], Step [11/375], Loss: 267.5508\n",
      "Epoch [5/50], Step [12/375], Loss: 1558.1049\n",
      "Epoch [5/50], Step [13/375], Loss: 541.7249\n",
      "Epoch [5/50], Step [14/375], Loss: 662.9016\n",
      "Epoch [5/50], Step [15/375], Loss: 642.0941\n",
      "Epoch [5/50], Step [16/375], Loss: 233.5866\n",
      "Epoch [5/50], Step [17/375], Loss: 321.3350\n",
      "Epoch [5/50], Step [18/375], Loss: 297.9884\n",
      "Epoch [5/50], Step [19/375], Loss: 586.2039\n",
      "Epoch [5/50], Step [20/375], Loss: 883.4384\n",
      "Epoch [5/50], Step [21/375], Loss: 657.1716\n",
      "Epoch [5/50], Step [22/375], Loss: 334.8894\n",
      "Epoch [5/50], Step [23/375], Loss: 373.7185\n",
      "Epoch [5/50], Step [24/375], Loss: 982.9861\n",
      "Epoch [5/50], Step [25/375], Loss: 661.3366\n",
      "Epoch [5/50], Step [26/375], Loss: 393.6777\n",
      "Epoch [5/50], Step [27/375], Loss: 576.8065\n",
      "Epoch [5/50], Step [28/375], Loss: 1581.9210\n",
      "Epoch [5/50], Step [29/375], Loss: 446.1208\n",
      "Epoch [5/50], Step [30/375], Loss: 1389.6592\n",
      "Epoch [5/50], Step [31/375], Loss: 341.9315\n",
      "Epoch [5/50], Step [32/375], Loss: 1149.6642\n",
      "Epoch [5/50], Step [33/375], Loss: 170.8123\n",
      "Epoch [5/50], Step [34/375], Loss: 232.4253\n",
      "Epoch [5/50], Step [35/375], Loss: 606.5794\n",
      "Epoch [5/50], Step [36/375], Loss: 527.7551\n",
      "Epoch [5/50], Step [37/375], Loss: 262.0667\n",
      "Epoch [5/50], Step [38/375], Loss: 1110.2073\n",
      "Epoch [5/50], Step [39/375], Loss: 194.2750\n",
      "Epoch [5/50], Step [40/375], Loss: 50.0173\n",
      "Epoch [5/50], Step [41/375], Loss: 997.3348\n",
      "Epoch [5/50], Step [42/375], Loss: 699.7968\n",
      "Epoch [5/50], Step [43/375], Loss: 301.7451\n",
      "Epoch [5/50], Step [44/375], Loss: 430.9403\n",
      "Epoch [5/50], Step [45/375], Loss: 398.0103\n",
      "Epoch [5/50], Step [46/375], Loss: 403.7774\n",
      "Epoch [5/50], Step [47/375], Loss: 967.6263\n",
      "Epoch [5/50], Step [48/375], Loss: 1113.5681\n",
      "Epoch [5/50], Step [49/375], Loss: 1321.1497\n",
      "Epoch [5/50], Step [50/375], Loss: 1151.2944\n",
      "Epoch [5/50], Step [51/375], Loss: 378.1484\n",
      "Epoch [5/50], Step [52/375], Loss: 519.0364\n",
      "Epoch [5/50], Step [53/375], Loss: 329.4503\n",
      "Epoch [5/50], Step [54/375], Loss: 320.6068\n",
      "Epoch [5/50], Step [55/375], Loss: 626.1874\n",
      "Epoch [5/50], Step [56/375], Loss: 77.3857\n",
      "Epoch [5/50], Step [57/375], Loss: 615.7277\n",
      "Epoch [5/50], Step [58/375], Loss: 1237.7267\n",
      "Epoch [5/50], Step [59/375], Loss: 655.9310\n",
      "Epoch [5/50], Step [60/375], Loss: 1250.2175\n",
      "Epoch [5/50], Step [61/375], Loss: 432.1826\n",
      "Epoch [5/50], Step [62/375], Loss: 445.1303\n",
      "Epoch [5/50], Step [63/375], Loss: 723.9419\n",
      "Epoch [5/50], Step [64/375], Loss: 463.6362\n",
      "Epoch [5/50], Step [65/375], Loss: 696.5473\n",
      "Epoch [5/50], Step [66/375], Loss: 499.2633\n",
      "Epoch [5/50], Step [67/375], Loss: 176.2777\n",
      "Epoch [5/50], Step [68/375], Loss: 119.0156\n",
      "Epoch [5/50], Step [69/375], Loss: 559.2479\n",
      "Epoch [5/50], Step [70/375], Loss: 1215.4968\n",
      "Epoch [5/50], Step [71/375], Loss: 334.6279\n",
      "Epoch [5/50], Step [72/375], Loss: 206.3942\n",
      "Epoch [5/50], Step [73/375], Loss: 914.1506\n",
      "Epoch [5/50], Step [74/375], Loss: 163.1596\n",
      "Epoch [5/50], Step [75/375], Loss: 558.8825\n",
      "Epoch [5/50], Step [76/375], Loss: 1185.7935\n",
      "Epoch [5/50], Step [77/375], Loss: 331.9790\n",
      "Epoch [5/50], Step [78/375], Loss: 392.5175\n",
      "Epoch [5/50], Step [79/375], Loss: 456.0542\n",
      "Epoch [5/50], Step [80/375], Loss: 157.9190\n",
      "Epoch [5/50], Step [81/375], Loss: 199.6905\n",
      "Epoch [5/50], Step [82/375], Loss: 310.5097\n",
      "Epoch [5/50], Step [83/375], Loss: 662.2483\n",
      "Epoch [5/50], Step [84/375], Loss: 718.6270\n",
      "Epoch [5/50], Step [85/375], Loss: 608.8737\n",
      "Epoch [5/50], Step [86/375], Loss: 392.1728\n",
      "Epoch [5/50], Step [87/375], Loss: 850.7415\n",
      "Epoch [5/50], Step [88/375], Loss: 160.1947\n",
      "Epoch [5/50], Step [89/375], Loss: 326.9484\n",
      "Epoch [5/50], Step [90/375], Loss: 335.9062\n",
      "Epoch [5/50], Step [91/375], Loss: 192.8656\n",
      "Epoch [5/50], Step [92/375], Loss: 284.0252\n",
      "Epoch [5/50], Step [93/375], Loss: 177.5704\n",
      "Epoch [5/50], Step [94/375], Loss: 382.2820\n",
      "Epoch [5/50], Step [95/375], Loss: 409.8760\n",
      "Epoch [5/50], Step [96/375], Loss: 713.3976\n",
      "Epoch [5/50], Step [97/375], Loss: 718.5896\n",
      "Epoch [5/50], Step [98/375], Loss: 358.0083\n",
      "Epoch [5/50], Step [99/375], Loss: 954.0327\n",
      "Epoch [5/50], Step [100/375], Loss: 577.2048\n",
      "Epoch [5/50], Step [101/375], Loss: 260.3153\n",
      "Epoch [5/50], Step [102/375], Loss: 496.3592\n",
      "Epoch [5/50], Step [103/375], Loss: 430.5029\n",
      "Epoch [5/50], Step [104/375], Loss: 151.8642\n",
      "Epoch [5/50], Step [105/375], Loss: 628.0285\n",
      "Epoch [5/50], Step [106/375], Loss: 1113.6609\n",
      "Epoch [5/50], Step [107/375], Loss: 1162.9086\n",
      "Epoch [5/50], Step [108/375], Loss: 322.4380\n",
      "Epoch [5/50], Step [109/375], Loss: 907.4097\n",
      "Epoch [5/50], Step [110/375], Loss: 1263.8883\n",
      "Epoch [5/50], Step [111/375], Loss: 268.4409\n",
      "Epoch [5/50], Step [112/375], Loss: 1347.9275\n",
      "Epoch [5/50], Step [113/375], Loss: 1438.5930\n",
      "Epoch [5/50], Step [114/375], Loss: 154.8320\n",
      "Epoch [5/50], Step [115/375], Loss: 641.6666\n",
      "Epoch [5/50], Step [116/375], Loss: 389.7093\n",
      "Epoch [5/50], Step [117/375], Loss: 1251.5168\n",
      "Epoch [5/50], Step [118/375], Loss: 774.8025\n",
      "Epoch [5/50], Step [119/375], Loss: 797.7502\n",
      "Epoch [5/50], Step [120/375], Loss: 543.9051\n",
      "Epoch [5/50], Step [121/375], Loss: 520.3688\n",
      "Epoch [5/50], Step [122/375], Loss: 711.2293\n",
      "Epoch [5/50], Step [123/375], Loss: 216.3473\n",
      "Epoch [5/50], Step [124/375], Loss: 1470.4574\n",
      "Epoch [5/50], Step [125/375], Loss: 362.2276\n",
      "Epoch [5/50], Step [126/375], Loss: 582.8985\n",
      "Epoch [5/50], Step [127/375], Loss: 696.6298\n",
      "Epoch [5/50], Step [128/375], Loss: 332.1655\n",
      "Epoch [5/50], Step [129/375], Loss: 407.8451\n",
      "Epoch [5/50], Step [130/375], Loss: 243.3000\n",
      "Epoch [5/50], Step [131/375], Loss: 984.0067\n",
      "Epoch [5/50], Step [132/375], Loss: 647.2262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Step [133/375], Loss: 291.0418\n",
      "Epoch [5/50], Step [134/375], Loss: 895.5205\n",
      "Epoch [5/50], Step [135/375], Loss: 854.7452\n",
      "Epoch [5/50], Step [136/375], Loss: 200.5273\n",
      "Epoch [5/50], Step [137/375], Loss: 1168.8644\n",
      "Epoch [5/50], Step [138/375], Loss: 1291.4303\n",
      "Epoch [5/50], Step [139/375], Loss: 243.0426\n",
      "Epoch [5/50], Step [140/375], Loss: 356.7267\n",
      "Epoch [5/50], Step [141/375], Loss: 415.8865\n",
      "Epoch [5/50], Step [142/375], Loss: 902.1750\n",
      "Epoch [5/50], Step [143/375], Loss: 903.4130\n",
      "Epoch [5/50], Step [144/375], Loss: 664.9444\n",
      "Epoch [5/50], Step [145/375], Loss: 1442.7932\n",
      "Epoch [5/50], Step [146/375], Loss: 513.1320\n",
      "Epoch [5/50], Step [147/375], Loss: 872.1293\n",
      "Epoch [5/50], Step [148/375], Loss: 1275.9763\n",
      "Epoch [5/50], Step [149/375], Loss: 603.4524\n",
      "Epoch [5/50], Step [150/375], Loss: 584.3364\n",
      "Epoch [5/50], Step [151/375], Loss: 298.5821\n",
      "Epoch [5/50], Step [152/375], Loss: 702.5954\n",
      "Epoch [5/50], Step [153/375], Loss: 434.3623\n",
      "Epoch [5/50], Step [154/375], Loss: 965.4919\n",
      "Epoch [5/50], Step [155/375], Loss: 342.6640\n",
      "Epoch [5/50], Step [156/375], Loss: 142.6407\n",
      "Epoch [5/50], Step [157/375], Loss: 333.6394\n",
      "Epoch [5/50], Step [158/375], Loss: 344.4228\n",
      "Epoch [5/50], Step [159/375], Loss: 163.4619\n",
      "Epoch [5/50], Step [160/375], Loss: 178.9626\n",
      "Epoch [5/50], Step [161/375], Loss: 606.0814\n",
      "Epoch [5/50], Step [162/375], Loss: 294.9439\n",
      "Epoch [5/50], Step [163/375], Loss: 112.6999\n",
      "Epoch [5/50], Step [164/375], Loss: 755.1595\n",
      "Epoch [5/50], Step [165/375], Loss: 1411.4852\n",
      "Epoch [5/50], Step [166/375], Loss: 180.6773\n",
      "Epoch [5/50], Step [167/375], Loss: 199.3322\n",
      "Epoch [5/50], Step [168/375], Loss: 252.5220\n",
      "Epoch [5/50], Step [169/375], Loss: 283.8751\n",
      "Epoch [5/50], Step [170/375], Loss: 155.1361\n",
      "Epoch [5/50], Step [171/375], Loss: 249.9499\n",
      "Epoch [5/50], Step [172/375], Loss: 529.7225\n",
      "Epoch [5/50], Step [173/375], Loss: 934.3535\n",
      "Epoch [5/50], Step [174/375], Loss: 1110.3422\n",
      "Epoch [5/50], Step [175/375], Loss: 274.9499\n",
      "Epoch [5/50], Step [176/375], Loss: 1216.0756\n",
      "Epoch [5/50], Step [177/375], Loss: 556.3632\n",
      "Epoch [5/50], Step [178/375], Loss: 364.7190\n",
      "Epoch [5/50], Step [179/375], Loss: 78.8045\n",
      "Epoch [5/50], Step [180/375], Loss: 1757.5491\n",
      "Epoch [5/50], Step [181/375], Loss: 631.0438\n",
      "Epoch [5/50], Step [182/375], Loss: 223.0834\n",
      "Epoch [5/50], Step [183/375], Loss: 736.7226\n",
      "Epoch [5/50], Step [184/375], Loss: 639.1235\n",
      "Epoch [5/50], Step [185/375], Loss: 195.3985\n",
      "Epoch [5/50], Step [186/375], Loss: 222.8572\n",
      "Epoch [5/50], Step [187/375], Loss: 690.6967\n",
      "Epoch [5/50], Step [188/375], Loss: 249.4277\n",
      "Epoch [5/50], Step [189/375], Loss: 215.1548\n",
      "Epoch [5/50], Step [190/375], Loss: 298.3630\n",
      "Epoch [5/50], Step [191/375], Loss: 817.0963\n",
      "Epoch [5/50], Step [192/375], Loss: 219.7914\n",
      "Epoch [5/50], Step [193/375], Loss: 165.0227\n",
      "Epoch [5/50], Step [194/375], Loss: 362.7039\n",
      "Epoch [5/50], Step [195/375], Loss: 483.8849\n",
      "Epoch [5/50], Step [196/375], Loss: 1036.0806\n",
      "Epoch [5/50], Step [197/375], Loss: 331.8112\n",
      "Epoch [5/50], Step [198/375], Loss: 741.4614\n",
      "Epoch [5/50], Step [199/375], Loss: 399.5720\n",
      "Epoch [5/50], Step [200/375], Loss: 558.0886\n",
      "Epoch [5/50], Step [201/375], Loss: 623.9896\n",
      "Epoch [5/50], Step [202/375], Loss: 121.1093\n",
      "Epoch [5/50], Step [203/375], Loss: 661.3433\n",
      "Epoch [5/50], Step [204/375], Loss: 621.5822\n",
      "Epoch [5/50], Step [205/375], Loss: 271.5097\n",
      "Epoch [5/50], Step [206/375], Loss: 409.6930\n",
      "Epoch [5/50], Step [207/375], Loss: 190.1668\n",
      "Epoch [5/50], Step [208/375], Loss: 400.9570\n",
      "Epoch [5/50], Step [209/375], Loss: 2198.6602\n",
      "Epoch [5/50], Step [210/375], Loss: 749.8469\n",
      "Epoch [5/50], Step [211/375], Loss: 257.2790\n",
      "Epoch [5/50], Step [212/375], Loss: 566.1498\n",
      "Epoch [5/50], Step [213/375], Loss: 179.2808\n",
      "Epoch [5/50], Step [214/375], Loss: 921.9322\n",
      "Epoch [5/50], Step [215/375], Loss: 309.3486\n",
      "Epoch [5/50], Step [216/375], Loss: 99.7248\n",
      "Epoch [5/50], Step [217/375], Loss: 472.7313\n",
      "Epoch [5/50], Step [218/375], Loss: 414.3394\n",
      "Epoch [5/50], Step [219/375], Loss: 1313.7618\n",
      "Epoch [5/50], Step [220/375], Loss: 195.0918\n",
      "Epoch [5/50], Step [221/375], Loss: 946.6401\n",
      "Epoch [5/50], Step [222/375], Loss: 825.4831\n",
      "Epoch [5/50], Step [223/375], Loss: 99.7887\n",
      "Epoch [5/50], Step [224/375], Loss: 1559.6199\n",
      "Epoch [5/50], Step [225/375], Loss: 341.1019\n",
      "Epoch [5/50], Step [226/375], Loss: 597.5151\n",
      "Epoch [5/50], Step [227/375], Loss: 1964.9506\n",
      "Epoch [5/50], Step [228/375], Loss: 572.1699\n",
      "Epoch [5/50], Step [229/375], Loss: 88.8428\n",
      "Epoch [5/50], Step [230/375], Loss: 194.0270\n",
      "Epoch [5/50], Step [231/375], Loss: 763.2156\n",
      "Epoch [5/50], Step [232/375], Loss: 477.6191\n",
      "Epoch [5/50], Step [233/375], Loss: 207.2393\n",
      "Epoch [5/50], Step [234/375], Loss: 184.8602\n",
      "Epoch [5/50], Step [235/375], Loss: 841.8719\n",
      "Epoch [5/50], Step [236/375], Loss: 252.6837\n",
      "Epoch [5/50], Step [237/375], Loss: 767.0642\n",
      "Epoch [5/50], Step [238/375], Loss: 378.2495\n",
      "Epoch [5/50], Step [239/375], Loss: 159.3163\n",
      "Epoch [5/50], Step [240/375], Loss: 707.4823\n",
      "Epoch [5/50], Step [241/375], Loss: 446.5892\n",
      "Epoch [5/50], Step [242/375], Loss: 270.3999\n",
      "Epoch [5/50], Step [243/375], Loss: 265.9248\n",
      "Epoch [5/50], Step [244/375], Loss: 240.0896\n",
      "Epoch [5/50], Step [245/375], Loss: 104.5146\n",
      "Epoch [5/50], Step [246/375], Loss: 425.0580\n",
      "Epoch [5/50], Step [247/375], Loss: 138.5410\n",
      "Epoch [5/50], Step [248/375], Loss: 137.1054\n",
      "Epoch [5/50], Step [249/375], Loss: 537.7656\n",
      "Epoch [5/50], Step [250/375], Loss: 672.4957\n",
      "Epoch [5/50], Step [251/375], Loss: 391.7854\n",
      "Epoch [5/50], Step [252/375], Loss: 175.4541\n",
      "Epoch [5/50], Step [253/375], Loss: 402.3727\n",
      "Epoch [5/50], Step [254/375], Loss: 459.9197\n",
      "Epoch [5/50], Step [255/375], Loss: 599.3595\n",
      "Epoch [5/50], Step [256/375], Loss: 559.1993\n",
      "Epoch [5/50], Step [257/375], Loss: 441.0255\n",
      "Epoch [5/50], Step [258/375], Loss: 729.8967\n",
      "Epoch [5/50], Step [259/375], Loss: 405.6368\n",
      "Epoch [5/50], Step [260/375], Loss: 735.3760\n",
      "Epoch [5/50], Step [261/375], Loss: 260.3895\n",
      "Epoch [5/50], Step [262/375], Loss: 333.5908\n",
      "Epoch [5/50], Step [263/375], Loss: 1094.7144\n",
      "Epoch [5/50], Step [264/375], Loss: 828.7609\n",
      "Epoch [5/50], Step [265/375], Loss: 684.8379\n",
      "Epoch [5/50], Step [266/375], Loss: 963.1492\n",
      "Epoch [5/50], Step [267/375], Loss: 1104.5612\n",
      "Epoch [5/50], Step [268/375], Loss: 795.2858\n",
      "Epoch [5/50], Step [269/375], Loss: 166.3512\n",
      "Epoch [5/50], Step [270/375], Loss: 737.3398\n",
      "Epoch [5/50], Step [271/375], Loss: 357.6852\n",
      "Epoch [5/50], Step [272/375], Loss: 220.7096\n",
      "Epoch [5/50], Step [273/375], Loss: 281.4710\n",
      "Epoch [5/50], Step [274/375], Loss: 266.9778\n",
      "Epoch [5/50], Step [275/375], Loss: 138.4088\n",
      "Epoch [5/50], Step [276/375], Loss: 627.2091\n",
      "Epoch [5/50], Step [277/375], Loss: 901.9125\n",
      "Epoch [5/50], Step [278/375], Loss: 918.8317\n",
      "Epoch [5/50], Step [279/375], Loss: 655.4954\n",
      "Epoch [5/50], Step [280/375], Loss: 817.0073\n",
      "Epoch [5/50], Step [281/375], Loss: 1407.5817\n",
      "Epoch [5/50], Step [282/375], Loss: 378.4764\n",
      "Epoch [5/50], Step [283/375], Loss: 576.0406\n",
      "Epoch [5/50], Step [284/375], Loss: 775.4250\n",
      "Epoch [5/50], Step [285/375], Loss: 1004.8071\n",
      "Epoch [5/50], Step [286/375], Loss: 409.5714\n",
      "Epoch [5/50], Step [287/375], Loss: 373.9390\n",
      "Epoch [5/50], Step [288/375], Loss: 386.2563\n",
      "Epoch [5/50], Step [289/375], Loss: 584.7116\n",
      "Epoch [5/50], Step [290/375], Loss: 550.8914\n",
      "Epoch [5/50], Step [291/375], Loss: 659.0112\n",
      "Epoch [5/50], Step [292/375], Loss: 297.7282\n",
      "Epoch [5/50], Step [293/375], Loss: 711.1446\n",
      "Epoch [5/50], Step [294/375], Loss: 1238.8710\n",
      "Epoch [5/50], Step [295/375], Loss: 304.7893\n",
      "Epoch [5/50], Step [296/375], Loss: 1045.5874\n",
      "Epoch [5/50], Step [297/375], Loss: 959.8867\n",
      "Epoch [5/50], Step [298/375], Loss: 350.9448\n",
      "Epoch [5/50], Step [299/375], Loss: 571.7373\n",
      "Epoch [5/50], Step [300/375], Loss: 185.7026\n",
      "Epoch [5/50], Step [301/375], Loss: 498.6971\n",
      "Epoch [5/50], Step [302/375], Loss: 665.5795\n",
      "Epoch [5/50], Step [303/375], Loss: 341.1134\n",
      "Epoch [5/50], Step [304/375], Loss: 1273.8834\n",
      "Epoch [5/50], Step [305/375], Loss: 199.5500\n",
      "Epoch [5/50], Step [306/375], Loss: 937.0157\n",
      "Epoch [5/50], Step [307/375], Loss: 1003.7419\n",
      "Epoch [5/50], Step [308/375], Loss: 947.3341\n",
      "Epoch [5/50], Step [309/375], Loss: 591.8018\n",
      "Epoch [5/50], Step [310/375], Loss: 1092.1755\n",
      "Epoch [5/50], Step [311/375], Loss: 622.0037\n",
      "Epoch [5/50], Step [312/375], Loss: 1476.1271\n",
      "Epoch [5/50], Step [313/375], Loss: 322.6975\n",
      "Epoch [5/50], Step [314/375], Loss: 2543.2185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Step [315/375], Loss: 371.7722\n",
      "Epoch [5/50], Step [316/375], Loss: 439.6635\n",
      "Epoch [5/50], Step [317/375], Loss: 733.4745\n",
      "Epoch [5/50], Step [318/375], Loss: 827.7115\n",
      "Epoch [5/50], Step [319/375], Loss: 766.2334\n",
      "Epoch [5/50], Step [320/375], Loss: 816.2375\n",
      "Epoch [5/50], Step [321/375], Loss: 1033.0165\n",
      "Epoch [5/50], Step [322/375], Loss: 1142.4774\n",
      "Epoch [5/50], Step [323/375], Loss: 357.7401\n",
      "Epoch [5/50], Step [324/375], Loss: 515.6860\n",
      "Epoch [5/50], Step [325/375], Loss: 352.5821\n",
      "Epoch [5/50], Step [326/375], Loss: 811.0623\n",
      "Epoch [5/50], Step [327/375], Loss: 439.7506\n",
      "Epoch [5/50], Step [328/375], Loss: 271.9757\n",
      "Epoch [5/50], Step [329/375], Loss: 2042.4174\n",
      "Epoch [5/50], Step [330/375], Loss: 169.2188\n",
      "Epoch [5/50], Step [331/375], Loss: 725.6898\n",
      "Epoch [5/50], Step [332/375], Loss: 161.3185\n",
      "Epoch [5/50], Step [333/375], Loss: 488.6317\n",
      "Epoch [5/50], Step [334/375], Loss: 382.8658\n",
      "Epoch [5/50], Step [335/375], Loss: 1310.9154\n",
      "Epoch [5/50], Step [336/375], Loss: 774.9569\n",
      "Epoch [5/50], Step [337/375], Loss: 572.0945\n",
      "Epoch [5/50], Step [338/375], Loss: 527.3908\n",
      "Epoch [5/50], Step [339/375], Loss: 320.1214\n",
      "Epoch [5/50], Step [340/375], Loss: 153.8945\n",
      "Epoch [5/50], Step [341/375], Loss: 420.4599\n",
      "Epoch [5/50], Step [342/375], Loss: 1334.7471\n",
      "Epoch [5/50], Step [343/375], Loss: 455.3813\n",
      "Epoch [5/50], Step [344/375], Loss: 108.5565\n",
      "Epoch [5/50], Step [345/375], Loss: 511.8653\n",
      "Epoch [5/50], Step [346/375], Loss: 313.2626\n",
      "Epoch [5/50], Step [347/375], Loss: 206.0114\n",
      "Epoch [5/50], Step [348/375], Loss: 202.4902\n",
      "Epoch [5/50], Step [349/375], Loss: 1698.7268\n",
      "Epoch [5/50], Step [350/375], Loss: 228.8890\n",
      "Epoch [5/50], Step [351/375], Loss: 317.6729\n",
      "Epoch [5/50], Step [352/375], Loss: 1100.4174\n",
      "Epoch [5/50], Step [353/375], Loss: 129.3733\n",
      "Epoch [5/50], Step [354/375], Loss: 900.6685\n",
      "Epoch [5/50], Step [355/375], Loss: 260.6133\n",
      "Epoch [5/50], Step [356/375], Loss: 788.6434\n",
      "Epoch [5/50], Step [357/375], Loss: 568.2116\n",
      "Epoch [5/50], Step [358/375], Loss: 757.9968\n",
      "Epoch [5/50], Step [359/375], Loss: 460.1585\n",
      "Epoch [5/50], Step [360/375], Loss: 1021.4298\n",
      "Epoch [5/50], Step [361/375], Loss: 151.6324\n",
      "Epoch [5/50], Step [362/375], Loss: 1112.2268\n",
      "Epoch [5/50], Step [363/375], Loss: 484.8722\n",
      "Epoch [5/50], Step [364/375], Loss: 456.9794\n",
      "Epoch [5/50], Step [365/375], Loss: 593.4495\n",
      "Epoch [5/50], Step [366/375], Loss: 386.3681\n",
      "Epoch [5/50], Step [367/375], Loss: 505.0080\n",
      "Epoch [5/50], Step [368/375], Loss: 120.7008\n",
      "Epoch [5/50], Step [369/375], Loss: 162.2519\n",
      "Epoch [5/50], Step [370/375], Loss: 2331.2063\n",
      "Epoch [5/50], Step [371/375], Loss: 1079.2914\n",
      "Epoch [5/50], Step [372/375], Loss: 343.4486\n",
      "Epoch [5/50], Step [373/375], Loss: 417.1688\n",
      "Epoch [5/50], Step [374/375], Loss: 192.6847\n",
      "Epoch [5/50], Step [375/375], Loss: 401.2943\n",
      "Epoch [6/50], Step [1/375], Loss: 1314.1211\n",
      "Epoch [6/50], Step [2/375], Loss: 317.1536\n",
      "Epoch [6/50], Step [3/375], Loss: 316.2785\n",
      "Epoch [6/50], Step [4/375], Loss: 251.6860\n",
      "Epoch [6/50], Step [5/375], Loss: 158.0279\n",
      "Epoch [6/50], Step [6/375], Loss: 115.4051\n",
      "Epoch [6/50], Step [7/375], Loss: 75.8298\n",
      "Epoch [6/50], Step [8/375], Loss: 602.8074\n",
      "Epoch [6/50], Step [9/375], Loss: 639.0405\n",
      "Epoch [6/50], Step [10/375], Loss: 330.4315\n",
      "Epoch [6/50], Step [11/375], Loss: 629.0529\n",
      "Epoch [6/50], Step [12/375], Loss: 450.5313\n",
      "Epoch [6/50], Step [13/375], Loss: 180.1762\n",
      "Epoch [6/50], Step [14/375], Loss: 383.2555\n",
      "Epoch [6/50], Step [15/375], Loss: 221.3342\n",
      "Epoch [6/50], Step [16/375], Loss: 610.1115\n",
      "Epoch [6/50], Step [17/375], Loss: 117.7393\n",
      "Epoch [6/50], Step [18/375], Loss: 596.7683\n",
      "Epoch [6/50], Step [19/375], Loss: 259.2284\n",
      "Epoch [6/50], Step [20/375], Loss: 329.0689\n",
      "Epoch [6/50], Step [21/375], Loss: 360.8748\n",
      "Epoch [6/50], Step [22/375], Loss: 609.8240\n",
      "Epoch [6/50], Step [23/375], Loss: 648.0244\n",
      "Epoch [6/50], Step [24/375], Loss: 521.3282\n",
      "Epoch [6/50], Step [25/375], Loss: 1743.2854\n",
      "Epoch [6/50], Step [26/375], Loss: 321.0078\n",
      "Epoch [6/50], Step [27/375], Loss: 175.3599\n",
      "Epoch [6/50], Step [28/375], Loss: 696.8644\n",
      "Epoch [6/50], Step [29/375], Loss: 343.4516\n",
      "Epoch [6/50], Step [30/375], Loss: 495.0926\n",
      "Epoch [6/50], Step [31/375], Loss: 576.1567\n",
      "Epoch [6/50], Step [32/375], Loss: 330.2080\n",
      "Epoch [6/50], Step [33/375], Loss: 172.0378\n",
      "Epoch [6/50], Step [34/375], Loss: 181.6594\n",
      "Epoch [6/50], Step [35/375], Loss: 612.2501\n",
      "Epoch [6/50], Step [36/375], Loss: 1097.3898\n",
      "Epoch [6/50], Step [37/375], Loss: 147.3437\n",
      "Epoch [6/50], Step [38/375], Loss: 651.2872\n",
      "Epoch [6/50], Step [39/375], Loss: 94.5152\n",
      "Epoch [6/50], Step [40/375], Loss: 593.2672\n",
      "Epoch [6/50], Step [41/375], Loss: 582.1105\n",
      "Epoch [6/50], Step [42/375], Loss: 64.2162\n",
      "Epoch [6/50], Step [43/375], Loss: 396.5807\n",
      "Epoch [6/50], Step [44/375], Loss: 439.3475\n",
      "Epoch [6/50], Step [45/375], Loss: 150.5811\n",
      "Epoch [6/50], Step [46/375], Loss: 239.1550\n",
      "Epoch [6/50], Step [47/375], Loss: 577.2690\n",
      "Epoch [6/50], Step [48/375], Loss: 700.8824\n",
      "Epoch [6/50], Step [49/375], Loss: 501.1774\n",
      "Epoch [6/50], Step [50/375], Loss: 202.6507\n",
      "Epoch [6/50], Step [51/375], Loss: 303.2577\n",
      "Epoch [6/50], Step [52/375], Loss: 396.3073\n",
      "Epoch [6/50], Step [53/375], Loss: 304.9681\n",
      "Epoch [6/50], Step [54/375], Loss: 454.6828\n",
      "Epoch [6/50], Step [55/375], Loss: 110.7649\n",
      "Epoch [6/50], Step [56/375], Loss: 288.6574\n",
      "Epoch [6/50], Step [57/375], Loss: 159.3297\n",
      "Epoch [6/50], Step [58/375], Loss: 548.4468\n",
      "Epoch [6/50], Step [59/375], Loss: 201.3656\n",
      "Epoch [6/50], Step [60/375], Loss: 213.9601\n",
      "Epoch [6/50], Step [61/375], Loss: 1541.4205\n",
      "Epoch [6/50], Step [62/375], Loss: 232.9301\n",
      "Epoch [6/50], Step [63/375], Loss: 577.2789\n",
      "Epoch [6/50], Step [64/375], Loss: 625.4440\n",
      "Epoch [6/50], Step [65/375], Loss: 245.0445\n",
      "Epoch [6/50], Step [66/375], Loss: 191.1734\n",
      "Epoch [6/50], Step [67/375], Loss: 175.8748\n",
      "Epoch [6/50], Step [68/375], Loss: 488.6476\n",
      "Epoch [6/50], Step [69/375], Loss: 208.0646\n",
      "Epoch [6/50], Step [70/375], Loss: 218.6185\n",
      "Epoch [6/50], Step [71/375], Loss: 265.0653\n",
      "Epoch [6/50], Step [72/375], Loss: 68.3582\n",
      "Epoch [6/50], Step [73/375], Loss: 812.2117\n",
      "Epoch [6/50], Step [74/375], Loss: 287.3684\n",
      "Epoch [6/50], Step [75/375], Loss: 539.1645\n",
      "Epoch [6/50], Step [76/375], Loss: 455.5580\n",
      "Epoch [6/50], Step [77/375], Loss: 142.0761\n",
      "Epoch [6/50], Step [78/375], Loss: 344.3423\n",
      "Epoch [6/50], Step [79/375], Loss: 191.9122\n",
      "Epoch [6/50], Step [80/375], Loss: 177.1998\n",
      "Epoch [6/50], Step [81/375], Loss: 292.6693\n",
      "Epoch [6/50], Step [82/375], Loss: 282.5060\n",
      "Epoch [6/50], Step [83/375], Loss: 404.4674\n",
      "Epoch [6/50], Step [84/375], Loss: 418.5611\n",
      "Epoch [6/50], Step [85/375], Loss: 107.4275\n",
      "Epoch [6/50], Step [86/375], Loss: 398.9875\n",
      "Epoch [6/50], Step [87/375], Loss: 863.6968\n",
      "Epoch [6/50], Step [88/375], Loss: 185.6560\n",
      "Epoch [6/50], Step [89/375], Loss: 202.9723\n",
      "Epoch [6/50], Step [90/375], Loss: 325.4630\n",
      "Epoch [6/50], Step [91/375], Loss: 626.4621\n",
      "Epoch [6/50], Step [92/375], Loss: 278.2147\n",
      "Epoch [6/50], Step [93/375], Loss: 239.0785\n",
      "Epoch [6/50], Step [94/375], Loss: 538.7947\n",
      "Epoch [6/50], Step [95/375], Loss: 1671.0034\n",
      "Epoch [6/50], Step [96/375], Loss: 492.7602\n",
      "Epoch [6/50], Step [97/375], Loss: 170.0243\n",
      "Epoch [6/50], Step [98/375], Loss: 491.8644\n",
      "Epoch [6/50], Step [99/375], Loss: 456.6740\n",
      "Epoch [6/50], Step [100/375], Loss: 900.8924\n",
      "Epoch [6/50], Step [101/375], Loss: 521.9890\n",
      "Epoch [6/50], Step [102/375], Loss: 121.7944\n",
      "Epoch [6/50], Step [103/375], Loss: 148.5509\n",
      "Epoch [6/50], Step [104/375], Loss: 604.2678\n",
      "Epoch [6/50], Step [105/375], Loss: 308.2150\n",
      "Epoch [6/50], Step [106/375], Loss: 92.0840\n",
      "Epoch [6/50], Step [107/375], Loss: 281.7697\n",
      "Epoch [6/50], Step [108/375], Loss: 381.8107\n",
      "Epoch [6/50], Step [109/375], Loss: 297.1463\n",
      "Epoch [6/50], Step [110/375], Loss: 180.4580\n",
      "Epoch [6/50], Step [111/375], Loss: 38.5729\n",
      "Epoch [6/50], Step [112/375], Loss: 340.1537\n",
      "Epoch [6/50], Step [113/375], Loss: 176.6142\n",
      "Epoch [6/50], Step [114/375], Loss: 134.0684\n",
      "Epoch [6/50], Step [115/375], Loss: 136.0205\n",
      "Epoch [6/50], Step [116/375], Loss: 750.4866\n",
      "Epoch [6/50], Step [117/375], Loss: 978.3257\n",
      "Epoch [6/50], Step [118/375], Loss: 152.4383\n",
      "Epoch [6/50], Step [119/375], Loss: 270.3271\n",
      "Epoch [6/50], Step [120/375], Loss: 521.6018\n",
      "Epoch [6/50], Step [121/375], Loss: 647.8897\n",
      "Epoch [6/50], Step [122/375], Loss: 320.4283\n",
      "Epoch [6/50], Step [123/375], Loss: 37.6893\n",
      "Epoch [6/50], Step [124/375], Loss: 393.1812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Step [125/375], Loss: 396.1413\n",
      "Epoch [6/50], Step [126/375], Loss: 192.2263\n",
      "Epoch [6/50], Step [127/375], Loss: 178.2067\n",
      "Epoch [6/50], Step [128/375], Loss: 83.6793\n",
      "Epoch [6/50], Step [129/375], Loss: 229.0657\n",
      "Epoch [6/50], Step [130/375], Loss: 577.8209\n",
      "Epoch [6/50], Step [131/375], Loss: 289.2885\n",
      "Epoch [6/50], Step [132/375], Loss: 107.9350\n",
      "Epoch [6/50], Step [133/375], Loss: 823.0717\n",
      "Epoch [6/50], Step [134/375], Loss: 62.2097\n",
      "Epoch [6/50], Step [135/375], Loss: 771.3649\n",
      "Epoch [6/50], Step [136/375], Loss: 152.2507\n",
      "Epoch [6/50], Step [137/375], Loss: 699.3933\n",
      "Epoch [6/50], Step [138/375], Loss: 58.2596\n",
      "Epoch [6/50], Step [139/375], Loss: 1107.0358\n",
      "Epoch [6/50], Step [140/375], Loss: 686.8383\n",
      "Epoch [6/50], Step [141/375], Loss: 179.5259\n",
      "Epoch [6/50], Step [142/375], Loss: 180.9678\n",
      "Epoch [6/50], Step [143/375], Loss: 278.3525\n",
      "Epoch [6/50], Step [144/375], Loss: 465.4451\n",
      "Epoch [6/50], Step [145/375], Loss: 472.9464\n",
      "Epoch [6/50], Step [146/375], Loss: 88.0320\n",
      "Epoch [6/50], Step [147/375], Loss: 633.3967\n",
      "Epoch [6/50], Step [148/375], Loss: 638.8785\n",
      "Epoch [6/50], Step [149/375], Loss: 755.8690\n",
      "Epoch [6/50], Step [150/375], Loss: 1454.0195\n",
      "Epoch [6/50], Step [151/375], Loss: 53.4151\n",
      "Epoch [6/50], Step [152/375], Loss: 173.7684\n",
      "Epoch [6/50], Step [153/375], Loss: 544.2990\n",
      "Epoch [6/50], Step [154/375], Loss: 124.0608\n",
      "Epoch [6/50], Step [155/375], Loss: 440.2043\n",
      "Epoch [6/50], Step [156/375], Loss: 240.3992\n",
      "Epoch [6/50], Step [157/375], Loss: 408.4005\n",
      "Epoch [6/50], Step [158/375], Loss: 196.3160\n",
      "Epoch [6/50], Step [159/375], Loss: 608.3362\n",
      "Epoch [6/50], Step [160/375], Loss: 275.6692\n",
      "Epoch [6/50], Step [161/375], Loss: 542.9869\n",
      "Epoch [6/50], Step [162/375], Loss: 298.8010\n",
      "Epoch [6/50], Step [163/375], Loss: 240.8543\n",
      "Epoch [6/50], Step [164/375], Loss: 377.0137\n",
      "Epoch [6/50], Step [165/375], Loss: 284.7161\n",
      "Epoch [6/50], Step [166/375], Loss: 250.6033\n",
      "Epoch [6/50], Step [167/375], Loss: 311.3867\n",
      "Epoch [6/50], Step [168/375], Loss: 500.1774\n",
      "Epoch [6/50], Step [169/375], Loss: 285.5946\n",
      "Epoch [6/50], Step [170/375], Loss: 592.4377\n",
      "Epoch [6/50], Step [171/375], Loss: 265.5836\n",
      "Epoch [6/50], Step [172/375], Loss: 381.3261\n",
      "Epoch [6/50], Step [173/375], Loss: 922.1815\n",
      "Epoch [6/50], Step [174/375], Loss: 571.3156\n",
      "Epoch [6/50], Step [175/375], Loss: 378.5154\n",
      "Epoch [6/50], Step [176/375], Loss: 392.3289\n",
      "Epoch [6/50], Step [177/375], Loss: 319.6837\n",
      "Epoch [6/50], Step [178/375], Loss: 449.5946\n",
      "Epoch [6/50], Step [179/375], Loss: 295.7014\n",
      "Epoch [6/50], Step [180/375], Loss: 400.2775\n",
      "Epoch [6/50], Step [181/375], Loss: 701.5938\n",
      "Epoch [6/50], Step [182/375], Loss: 689.9630\n",
      "Epoch [6/50], Step [183/375], Loss: 60.6647\n",
      "Epoch [6/50], Step [184/375], Loss: 302.9337\n",
      "Epoch [6/50], Step [185/375], Loss: 413.7504\n",
      "Epoch [6/50], Step [186/375], Loss: 128.4205\n",
      "Epoch [6/50], Step [187/375], Loss: 563.8295\n",
      "Epoch [6/50], Step [188/375], Loss: 1029.8832\n",
      "Epoch [6/50], Step [189/375], Loss: 74.0252\n",
      "Epoch [6/50], Step [190/375], Loss: 925.7092\n",
      "Epoch [6/50], Step [191/375], Loss: 395.6463\n",
      "Epoch [6/50], Step [192/375], Loss: 317.2351\n",
      "Epoch [6/50], Step [193/375], Loss: 381.4688\n",
      "Epoch [6/50], Step [194/375], Loss: 1191.3688\n",
      "Epoch [6/50], Step [195/375], Loss: 82.4150\n",
      "Epoch [6/50], Step [196/375], Loss: 187.3326\n",
      "Epoch [6/50], Step [197/375], Loss: 282.8988\n",
      "Epoch [6/50], Step [198/375], Loss: 977.9276\n",
      "Epoch [6/50], Step [199/375], Loss: 84.9186\n",
      "Epoch [6/50], Step [200/375], Loss: 507.9249\n",
      "Epoch [6/50], Step [201/375], Loss: 527.0660\n",
      "Epoch [6/50], Step [202/375], Loss: 285.9973\n",
      "Epoch [6/50], Step [203/375], Loss: 244.2386\n",
      "Epoch [6/50], Step [204/375], Loss: 391.8517\n",
      "Epoch [6/50], Step [205/375], Loss: 918.9709\n",
      "Epoch [6/50], Step [206/375], Loss: 468.0240\n",
      "Epoch [6/50], Step [207/375], Loss: 216.3394\n",
      "Epoch [6/50], Step [208/375], Loss: 538.0266\n",
      "Epoch [6/50], Step [209/375], Loss: 81.1280\n",
      "Epoch [6/50], Step [210/375], Loss: 307.7777\n",
      "Epoch [6/50], Step [211/375], Loss: 194.3044\n",
      "Epoch [6/50], Step [212/375], Loss: 1462.8451\n",
      "Epoch [6/50], Step [213/375], Loss: 676.0109\n",
      "Epoch [6/50], Step [214/375], Loss: 409.0283\n",
      "Epoch [6/50], Step [215/375], Loss: 344.2271\n",
      "Epoch [6/50], Step [216/375], Loss: 740.7507\n",
      "Epoch [6/50], Step [217/375], Loss: 250.0297\n",
      "Epoch [6/50], Step [218/375], Loss: 418.8398\n",
      "Epoch [6/50], Step [219/375], Loss: 941.5495\n",
      "Epoch [6/50], Step [220/375], Loss: 192.4986\n",
      "Epoch [6/50], Step [221/375], Loss: 237.0760\n",
      "Epoch [6/50], Step [222/375], Loss: 184.8292\n",
      "Epoch [6/50], Step [223/375], Loss: 316.4349\n",
      "Epoch [6/50], Step [224/375], Loss: 337.2568\n",
      "Epoch [6/50], Step [225/375], Loss: 154.4918\n",
      "Epoch [6/50], Step [226/375], Loss: 182.7464\n",
      "Epoch [6/50], Step [227/375], Loss: 267.0111\n",
      "Epoch [6/50], Step [228/375], Loss: 599.6621\n",
      "Epoch [6/50], Step [229/375], Loss: 213.3069\n",
      "Epoch [6/50], Step [230/375], Loss: 182.3495\n",
      "Epoch [6/50], Step [231/375], Loss: 808.4395\n",
      "Epoch [6/50], Step [232/375], Loss: 442.5437\n",
      "Epoch [6/50], Step [233/375], Loss: 457.1438\n",
      "Epoch [6/50], Step [234/375], Loss: 528.6279\n",
      "Epoch [6/50], Step [235/375], Loss: 291.0421\n",
      "Epoch [6/50], Step [236/375], Loss: 192.7868\n",
      "Epoch [6/50], Step [237/375], Loss: 284.5584\n",
      "Epoch [6/50], Step [238/375], Loss: 658.6007\n",
      "Epoch [6/50], Step [239/375], Loss: 1001.8505\n",
      "Epoch [6/50], Step [240/375], Loss: 498.8206\n",
      "Epoch [6/50], Step [241/375], Loss: 1461.7892\n",
      "Epoch [6/50], Step [242/375], Loss: 313.5519\n",
      "Epoch [6/50], Step [243/375], Loss: 1472.4695\n",
      "Epoch [6/50], Step [244/375], Loss: 1783.6438\n",
      "Epoch [6/50], Step [245/375], Loss: 331.8030\n",
      "Epoch [6/50], Step [246/375], Loss: 417.9852\n",
      "Epoch [6/50], Step [247/375], Loss: 245.1938\n",
      "Epoch [6/50], Step [248/375], Loss: 159.4042\n",
      "Epoch [6/50], Step [249/375], Loss: 458.6049\n",
      "Epoch [6/50], Step [250/375], Loss: 680.4534\n",
      "Epoch [6/50], Step [251/375], Loss: 169.6268\n",
      "Epoch [6/50], Step [252/375], Loss: 12.9262\n",
      "Epoch [6/50], Step [253/375], Loss: 196.5153\n",
      "Epoch [6/50], Step [254/375], Loss: 221.3475\n",
      "Epoch [6/50], Step [255/375], Loss: 601.8376\n",
      "Epoch [6/50], Step [256/375], Loss: 285.5971\n",
      "Epoch [6/50], Step [257/375], Loss: 125.4516\n",
      "Epoch [6/50], Step [258/375], Loss: 905.4966\n",
      "Epoch [6/50], Step [259/375], Loss: 222.8925\n",
      "Epoch [6/50], Step [260/375], Loss: 168.7722\n",
      "Epoch [6/50], Step [261/375], Loss: 353.5548\n",
      "Epoch [6/50], Step [262/375], Loss: 715.8497\n",
      "Epoch [6/50], Step [263/375], Loss: 366.1835\n",
      "Epoch [6/50], Step [264/375], Loss: 389.5979\n",
      "Epoch [6/50], Step [265/375], Loss: 135.7874\n",
      "Epoch [6/50], Step [266/375], Loss: 167.1544\n",
      "Epoch [6/50], Step [267/375], Loss: 516.6670\n",
      "Epoch [6/50], Step [268/375], Loss: 351.9782\n",
      "Epoch [6/50], Step [269/375], Loss: 315.0516\n",
      "Epoch [6/50], Step [270/375], Loss: 44.8320\n",
      "Epoch [6/50], Step [271/375], Loss: 513.7423\n",
      "Epoch [6/50], Step [272/375], Loss: 136.0494\n",
      "Epoch [6/50], Step [273/375], Loss: 213.2166\n",
      "Epoch [6/50], Step [274/375], Loss: 609.8047\n",
      "Epoch [6/50], Step [275/375], Loss: 359.8909\n",
      "Epoch [6/50], Step [276/375], Loss: 289.4808\n",
      "Epoch [6/50], Step [277/375], Loss: 87.6691\n",
      "Epoch [6/50], Step [278/375], Loss: 510.1430\n",
      "Epoch [6/50], Step [279/375], Loss: 166.9423\n",
      "Epoch [6/50], Step [280/375], Loss: 847.7377\n",
      "Epoch [6/50], Step [281/375], Loss: 226.2632\n",
      "Epoch [6/50], Step [282/375], Loss: 191.9261\n",
      "Epoch [6/50], Step [283/375], Loss: 170.7576\n",
      "Epoch [6/50], Step [284/375], Loss: 183.1981\n",
      "Epoch [6/50], Step [285/375], Loss: 304.7989\n",
      "Epoch [6/50], Step [286/375], Loss: 167.6918\n",
      "Epoch [6/50], Step [287/375], Loss: 316.7349\n",
      "Epoch [6/50], Step [288/375], Loss: 158.2817\n",
      "Epoch [6/50], Step [289/375], Loss: 168.1411\n",
      "Epoch [6/50], Step [290/375], Loss: 927.1862\n",
      "Epoch [6/50], Step [291/375], Loss: 158.3614\n",
      "Epoch [6/50], Step [292/375], Loss: 719.0864\n",
      "Epoch [6/50], Step [293/375], Loss: 149.3191\n",
      "Epoch [6/50], Step [294/375], Loss: 316.1340\n",
      "Epoch [6/50], Step [295/375], Loss: 89.0355\n",
      "Epoch [6/50], Step [296/375], Loss: 142.4258\n",
      "Epoch [6/50], Step [297/375], Loss: 218.3699\n",
      "Epoch [6/50], Step [298/375], Loss: 203.2104\n",
      "Epoch [6/50], Step [299/375], Loss: 217.9184\n",
      "Epoch [6/50], Step [300/375], Loss: 142.4327\n",
      "Epoch [6/50], Step [301/375], Loss: 535.5165\n",
      "Epoch [6/50], Step [302/375], Loss: 324.0206\n",
      "Epoch [6/50], Step [303/375], Loss: 173.4609\n",
      "Epoch [6/50], Step [304/375], Loss: 931.6033\n",
      "Epoch [6/50], Step [305/375], Loss: 1010.3427\n",
      "Epoch [6/50], Step [306/375], Loss: 571.2263\n",
      "Epoch [6/50], Step [307/375], Loss: 350.2096\n",
      "Epoch [6/50], Step [308/375], Loss: 513.0958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Step [309/375], Loss: 107.3865\n",
      "Epoch [6/50], Step [310/375], Loss: 511.5005\n",
      "Epoch [6/50], Step [311/375], Loss: 247.5462\n",
      "Epoch [6/50], Step [312/375], Loss: 975.3859\n",
      "Epoch [6/50], Step [313/375], Loss: 486.7133\n",
      "Epoch [6/50], Step [314/375], Loss: 1025.0842\n",
      "Epoch [6/50], Step [315/375], Loss: 457.8015\n",
      "Epoch [6/50], Step [316/375], Loss: 902.8281\n",
      "Epoch [6/50], Step [317/375], Loss: 543.7512\n",
      "Epoch [6/50], Step [318/375], Loss: 224.0290\n",
      "Epoch [6/50], Step [319/375], Loss: 1064.3833\n",
      "Epoch [6/50], Step [320/375], Loss: 536.6981\n",
      "Epoch [6/50], Step [321/375], Loss: 174.7224\n",
      "Epoch [6/50], Step [322/375], Loss: 738.2281\n",
      "Epoch [6/50], Step [323/375], Loss: 259.4663\n",
      "Epoch [6/50], Step [324/375], Loss: 217.8930\n",
      "Epoch [6/50], Step [325/375], Loss: 69.1371\n",
      "Epoch [6/50], Step [326/375], Loss: 690.8245\n",
      "Epoch [6/50], Step [327/375], Loss: 635.9495\n",
      "Epoch [6/50], Step [328/375], Loss: 316.4460\n",
      "Epoch [6/50], Step [329/375], Loss: 817.5868\n",
      "Epoch [6/50], Step [330/375], Loss: 607.6472\n",
      "Epoch [6/50], Step [331/375], Loss: 370.6024\n",
      "Epoch [6/50], Step [332/375], Loss: 432.5469\n",
      "Epoch [6/50], Step [333/375], Loss: 180.9406\n",
      "Epoch [6/50], Step [334/375], Loss: 321.9798\n",
      "Epoch [6/50], Step [335/375], Loss: 512.4753\n",
      "Epoch [6/50], Step [336/375], Loss: 149.2079\n",
      "Epoch [6/50], Step [337/375], Loss: 615.6637\n",
      "Epoch [6/50], Step [338/375], Loss: 416.2405\n",
      "Epoch [6/50], Step [339/375], Loss: 519.2763\n",
      "Epoch [6/50], Step [340/375], Loss: 100.6522\n",
      "Epoch [6/50], Step [341/375], Loss: 170.3755\n",
      "Epoch [6/50], Step [342/375], Loss: 179.2118\n",
      "Epoch [6/50], Step [343/375], Loss: 1188.2693\n",
      "Epoch [6/50], Step [344/375], Loss: 494.1735\n",
      "Epoch [6/50], Step [345/375], Loss: 237.4765\n",
      "Epoch [6/50], Step [346/375], Loss: 279.1596\n",
      "Epoch [6/50], Step [347/375], Loss: 215.3339\n",
      "Epoch [6/50], Step [348/375], Loss: 328.6436\n",
      "Epoch [6/50], Step [349/375], Loss: 1154.9631\n",
      "Epoch [6/50], Step [350/375], Loss: 412.3176\n",
      "Epoch [6/50], Step [351/375], Loss: 223.6626\n",
      "Epoch [6/50], Step [352/375], Loss: 146.6433\n",
      "Epoch [6/50], Step [353/375], Loss: 543.3478\n",
      "Epoch [6/50], Step [354/375], Loss: 258.7772\n",
      "Epoch [6/50], Step [355/375], Loss: 754.7915\n",
      "Epoch [6/50], Step [356/375], Loss: 97.4050\n",
      "Epoch [6/50], Step [357/375], Loss: 250.3721\n",
      "Epoch [6/50], Step [358/375], Loss: 548.6691\n",
      "Epoch [6/50], Step [359/375], Loss: 199.2919\n",
      "Epoch [6/50], Step [360/375], Loss: 765.3576\n",
      "Epoch [6/50], Step [361/375], Loss: 575.4293\n",
      "Epoch [6/50], Step [362/375], Loss: 340.5361\n",
      "Epoch [6/50], Step [363/375], Loss: 452.7314\n",
      "Epoch [6/50], Step [364/375], Loss: 298.3199\n",
      "Epoch [6/50], Step [365/375], Loss: 206.1825\n",
      "Epoch [6/50], Step [366/375], Loss: 406.4413\n",
      "Epoch [6/50], Step [367/375], Loss: 1356.3430\n",
      "Epoch [6/50], Step [368/375], Loss: 995.9424\n",
      "Epoch [6/50], Step [369/375], Loss: 662.3132\n",
      "Epoch [6/50], Step [370/375], Loss: 274.3562\n",
      "Epoch [6/50], Step [371/375], Loss: 89.8892\n",
      "Epoch [6/50], Step [372/375], Loss: 1053.6027\n",
      "Epoch [6/50], Step [373/375], Loss: 332.1196\n",
      "Epoch [6/50], Step [374/375], Loss: 1809.1229\n",
      "Epoch [6/50], Step [375/375], Loss: 302.3307\n",
      "Epoch [7/50], Step [1/375], Loss: 243.7829\n",
      "Epoch [7/50], Step [2/375], Loss: 543.1575\n",
      "Epoch [7/50], Step [3/375], Loss: 675.3486\n",
      "Epoch [7/50], Step [4/375], Loss: 314.1331\n",
      "Epoch [7/50], Step [5/375], Loss: 294.4138\n",
      "Epoch [7/50], Step [6/375], Loss: 686.4850\n",
      "Epoch [7/50], Step [7/375], Loss: 376.5633\n",
      "Epoch [7/50], Step [8/375], Loss: 216.9719\n",
      "Epoch [7/50], Step [9/375], Loss: 743.5586\n",
      "Epoch [7/50], Step [10/375], Loss: 203.9976\n",
      "Epoch [7/50], Step [11/375], Loss: 459.9917\n",
      "Epoch [7/50], Step [12/375], Loss: 182.4939\n",
      "Epoch [7/50], Step [13/375], Loss: 78.3448\n",
      "Epoch [7/50], Step [14/375], Loss: 477.4258\n",
      "Epoch [7/50], Step [15/375], Loss: 443.2265\n",
      "Epoch [7/50], Step [16/375], Loss: 313.9492\n",
      "Epoch [7/50], Step [17/375], Loss: 86.8727\n",
      "Epoch [7/50], Step [18/375], Loss: 449.0764\n",
      "Epoch [7/50], Step [19/375], Loss: 113.1152\n",
      "Epoch [7/50], Step [20/375], Loss: 882.5432\n",
      "Epoch [7/50], Step [21/375], Loss: 127.0192\n",
      "Epoch [7/50], Step [22/375], Loss: 177.2955\n",
      "Epoch [7/50], Step [23/375], Loss: 294.0571\n",
      "Epoch [7/50], Step [24/375], Loss: 478.3328\n",
      "Epoch [7/50], Step [25/375], Loss: 121.6680\n",
      "Epoch [7/50], Step [26/375], Loss: 593.9938\n",
      "Epoch [7/50], Step [27/375], Loss: 342.3067\n",
      "Epoch [7/50], Step [28/375], Loss: 368.8620\n",
      "Epoch [7/50], Step [29/375], Loss: 233.3833\n",
      "Epoch [7/50], Step [30/375], Loss: 282.8376\n",
      "Epoch [7/50], Step [31/375], Loss: 1062.0939\n",
      "Epoch [7/50], Step [32/375], Loss: 92.5226\n",
      "Epoch [7/50], Step [33/375], Loss: 298.8432\n",
      "Epoch [7/50], Step [34/375], Loss: 317.0100\n",
      "Epoch [7/50], Step [35/375], Loss: 904.7204\n",
      "Epoch [7/50], Step [36/375], Loss: 356.3766\n",
      "Epoch [7/50], Step [37/375], Loss: 55.0745\n",
      "Epoch [7/50], Step [38/375], Loss: 1185.2545\n",
      "Epoch [7/50], Step [39/375], Loss: 178.1730\n",
      "Epoch [7/50], Step [40/375], Loss: 236.8146\n",
      "Epoch [7/50], Step [41/375], Loss: 105.3247\n",
      "Epoch [7/50], Step [42/375], Loss: 255.8188\n",
      "Epoch [7/50], Step [43/375], Loss: 151.0219\n",
      "Epoch [7/50], Step [44/375], Loss: 220.9460\n",
      "Epoch [7/50], Step [45/375], Loss: 284.2787\n",
      "Epoch [7/50], Step [46/375], Loss: 101.5681\n",
      "Epoch [7/50], Step [47/375], Loss: 162.7545\n",
      "Epoch [7/50], Step [48/375], Loss: 291.5908\n",
      "Epoch [7/50], Step [49/375], Loss: 136.8010\n",
      "Epoch [7/50], Step [50/375], Loss: 224.4506\n",
      "Epoch [7/50], Step [51/375], Loss: 446.9890\n",
      "Epoch [7/50], Step [52/375], Loss: 63.7954\n",
      "Epoch [7/50], Step [53/375], Loss: 431.1902\n",
      "Epoch [7/50], Step [54/375], Loss: 789.1885\n",
      "Epoch [7/50], Step [55/375], Loss: 330.6073\n",
      "Epoch [7/50], Step [56/375], Loss: 425.9906\n",
      "Epoch [7/50], Step [57/375], Loss: 1051.5420\n",
      "Epoch [7/50], Step [58/375], Loss: 126.2938\n",
      "Epoch [7/50], Step [59/375], Loss: 94.8357\n",
      "Epoch [7/50], Step [60/375], Loss: 242.1889\n",
      "Epoch [7/50], Step [61/375], Loss: 91.3838\n",
      "Epoch [7/50], Step [62/375], Loss: 309.8580\n",
      "Epoch [7/50], Step [63/375], Loss: 377.5791\n",
      "Epoch [7/50], Step [64/375], Loss: 166.0364\n",
      "Epoch [7/50], Step [65/375], Loss: 118.9048\n",
      "Epoch [7/50], Step [66/375], Loss: 594.6545\n",
      "Epoch [7/50], Step [67/375], Loss: 313.5057\n",
      "Epoch [7/50], Step [68/375], Loss: 106.9486\n",
      "Epoch [7/50], Step [69/375], Loss: 359.5192\n",
      "Epoch [7/50], Step [70/375], Loss: 184.0069\n",
      "Epoch [7/50], Step [71/375], Loss: 127.9809\n",
      "Epoch [7/50], Step [72/375], Loss: 53.5335\n",
      "Epoch [7/50], Step [73/375], Loss: 195.2928\n",
      "Epoch [7/50], Step [74/375], Loss: 489.9590\n",
      "Epoch [7/50], Step [75/375], Loss: 105.2653\n",
      "Epoch [7/50], Step [76/375], Loss: 204.2316\n",
      "Epoch [7/50], Step [77/375], Loss: 773.4003\n",
      "Epoch [7/50], Step [78/375], Loss: 187.2240\n",
      "Epoch [7/50], Step [79/375], Loss: 178.0558\n",
      "Epoch [7/50], Step [80/375], Loss: 174.0215\n",
      "Epoch [7/50], Step [81/375], Loss: 194.2923\n",
      "Epoch [7/50], Step [82/375], Loss: 227.0762\n",
      "Epoch [7/50], Step [83/375], Loss: 248.7232\n",
      "Epoch [7/50], Step [84/375], Loss: 234.1183\n",
      "Epoch [7/50], Step [85/375], Loss: 383.6921\n",
      "Epoch [7/50], Step [86/375], Loss: 148.6633\n",
      "Epoch [7/50], Step [87/375], Loss: 319.4168\n",
      "Epoch [7/50], Step [88/375], Loss: 133.6648\n",
      "Epoch [7/50], Step [89/375], Loss: 345.9503\n",
      "Epoch [7/50], Step [90/375], Loss: 536.2368\n",
      "Epoch [7/50], Step [91/375], Loss: 109.7028\n",
      "Epoch [7/50], Step [92/375], Loss: 152.6168\n",
      "Epoch [7/50], Step [93/375], Loss: 373.0253\n",
      "Epoch [7/50], Step [94/375], Loss: 371.8014\n",
      "Epoch [7/50], Step [95/375], Loss: 347.9493\n",
      "Epoch [7/50], Step [96/375], Loss: 223.6781\n",
      "Epoch [7/50], Step [97/375], Loss: 274.8219\n",
      "Epoch [7/50], Step [98/375], Loss: 278.5704\n",
      "Epoch [7/50], Step [99/375], Loss: 204.7651\n",
      "Epoch [7/50], Step [100/375], Loss: 313.0572\n",
      "Epoch [7/50], Step [101/375], Loss: 439.1918\n",
      "Epoch [7/50], Step [102/375], Loss: 356.8052\n",
      "Epoch [7/50], Step [103/375], Loss: 442.5775\n",
      "Epoch [7/50], Step [104/375], Loss: 218.1804\n",
      "Epoch [7/50], Step [105/375], Loss: 190.3040\n",
      "Epoch [7/50], Step [106/375], Loss: 25.5195\n",
      "Epoch [7/50], Step [107/375], Loss: 224.8463\n",
      "Epoch [7/50], Step [108/375], Loss: 904.3699\n",
      "Epoch [7/50], Step [109/375], Loss: 324.3126\n",
      "Epoch [7/50], Step [110/375], Loss: 146.1522\n",
      "Epoch [7/50], Step [111/375], Loss: 288.7968\n",
      "Epoch [7/50], Step [112/375], Loss: 297.1916\n",
      "Epoch [7/50], Step [113/375], Loss: 131.4068\n",
      "Epoch [7/50], Step [114/375], Loss: 352.7340\n",
      "Epoch [7/50], Step [115/375], Loss: 153.8316\n",
      "Epoch [7/50], Step [116/375], Loss: 740.0051\n",
      "Epoch [7/50], Step [117/375], Loss: 266.3119\n",
      "Epoch [7/50], Step [118/375], Loss: 921.3396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Step [119/375], Loss: 292.3405\n",
      "Epoch [7/50], Step [120/375], Loss: 197.1644\n",
      "Epoch [7/50], Step [121/375], Loss: 214.9511\n",
      "Epoch [7/50], Step [122/375], Loss: 213.9549\n",
      "Epoch [7/50], Step [123/375], Loss: 71.6400\n",
      "Epoch [7/50], Step [124/375], Loss: 413.1750\n",
      "Epoch [7/50], Step [125/375], Loss: 121.0482\n",
      "Epoch [7/50], Step [126/375], Loss: 897.6967\n",
      "Epoch [7/50], Step [127/375], Loss: 669.1193\n",
      "Epoch [7/50], Step [128/375], Loss: 313.4447\n",
      "Epoch [7/50], Step [129/375], Loss: 117.8798\n",
      "Epoch [7/50], Step [130/375], Loss: 124.6176\n",
      "Epoch [7/50], Step [131/375], Loss: 299.9961\n",
      "Epoch [7/50], Step [132/375], Loss: 211.9083\n",
      "Epoch [7/50], Step [133/375], Loss: 123.7250\n",
      "Epoch [7/50], Step [134/375], Loss: 134.9000\n",
      "Epoch [7/50], Step [135/375], Loss: 704.3141\n",
      "Epoch [7/50], Step [136/375], Loss: 271.5929\n",
      "Epoch [7/50], Step [137/375], Loss: 98.5826\n",
      "Epoch [7/50], Step [138/375], Loss: 294.0125\n",
      "Epoch [7/50], Step [139/375], Loss: 681.8959\n",
      "Epoch [7/50], Step [140/375], Loss: 253.7552\n",
      "Epoch [7/50], Step [141/375], Loss: 372.5217\n",
      "Epoch [7/50], Step [142/375], Loss: 260.0960\n",
      "Epoch [7/50], Step [143/375], Loss: 383.3658\n",
      "Epoch [7/50], Step [144/375], Loss: 329.8814\n",
      "Epoch [7/50], Step [145/375], Loss: 301.7575\n",
      "Epoch [7/50], Step [146/375], Loss: 542.6375\n",
      "Epoch [7/50], Step [147/375], Loss: 493.2912\n",
      "Epoch [7/50], Step [148/375], Loss: 591.1207\n",
      "Epoch [7/50], Step [149/375], Loss: 637.6575\n",
      "Epoch [7/50], Step [150/375], Loss: 447.3958\n",
      "Epoch [7/50], Step [151/375], Loss: 127.4731\n",
      "Epoch [7/50], Step [152/375], Loss: 94.7493\n",
      "Epoch [7/50], Step [153/375], Loss: 1767.1179\n",
      "Epoch [7/50], Step [154/375], Loss: 253.5059\n",
      "Epoch [7/50], Step [155/375], Loss: 200.7809\n",
      "Epoch [7/50], Step [156/375], Loss: 147.3459\n",
      "Epoch [7/50], Step [157/375], Loss: 589.2155\n",
      "Epoch [7/50], Step [158/375], Loss: 338.4244\n",
      "Epoch [7/50], Step [159/375], Loss: 202.2614\n",
      "Epoch [7/50], Step [160/375], Loss: 185.1250\n",
      "Epoch [7/50], Step [161/375], Loss: 334.2634\n",
      "Epoch [7/50], Step [162/375], Loss: 191.9621\n",
      "Epoch [7/50], Step [163/375], Loss: 86.9354\n",
      "Epoch [7/50], Step [164/375], Loss: 160.9541\n",
      "Epoch [7/50], Step [165/375], Loss: 171.6203\n",
      "Epoch [7/50], Step [166/375], Loss: 262.0094\n",
      "Epoch [7/50], Step [167/375], Loss: 83.5981\n",
      "Epoch [7/50], Step [168/375], Loss: 836.9650\n",
      "Epoch [7/50], Step [169/375], Loss: 111.5447\n",
      "Epoch [7/50], Step [170/375], Loss: 177.8820\n",
      "Epoch [7/50], Step [171/375], Loss: 44.4816\n",
      "Epoch [7/50], Step [172/375], Loss: 485.1528\n",
      "Epoch [7/50], Step [173/375], Loss: 698.1747\n",
      "Epoch [7/50], Step [174/375], Loss: 809.7352\n",
      "Epoch [7/50], Step [175/375], Loss: 421.6781\n",
      "Epoch [7/50], Step [176/375], Loss: 524.2815\n",
      "Epoch [7/50], Step [177/375], Loss: 222.7263\n",
      "Epoch [7/50], Step [178/375], Loss: 117.9703\n",
      "Epoch [7/50], Step [179/375], Loss: 444.4661\n",
      "Epoch [7/50], Step [180/375], Loss: 937.0215\n",
      "Epoch [7/50], Step [181/375], Loss: 200.2751\n",
      "Epoch [7/50], Step [182/375], Loss: 300.1319\n",
      "Epoch [7/50], Step [183/375], Loss: 79.3397\n",
      "Epoch [7/50], Step [184/375], Loss: 59.3941\n",
      "Epoch [7/50], Step [185/375], Loss: 82.6034\n",
      "Epoch [7/50], Step [186/375], Loss: 337.0595\n",
      "Epoch [7/50], Step [187/375], Loss: 186.2992\n",
      "Epoch [7/50], Step [188/375], Loss: 360.5501\n",
      "Epoch [7/50], Step [189/375], Loss: 485.4249\n",
      "Epoch [7/50], Step [190/375], Loss: 537.0584\n",
      "Epoch [7/50], Step [191/375], Loss: 240.5748\n",
      "Epoch [7/50], Step [192/375], Loss: 124.9091\n",
      "Epoch [7/50], Step [193/375], Loss: 162.4336\n",
      "Epoch [7/50], Step [194/375], Loss: 225.3543\n",
      "Epoch [7/50], Step [195/375], Loss: 407.4984\n",
      "Epoch [7/50], Step [196/375], Loss: 146.8607\n",
      "Epoch [7/50], Step [197/375], Loss: 216.6777\n",
      "Epoch [7/50], Step [198/375], Loss: 726.3889\n",
      "Epoch [7/50], Step [199/375], Loss: 74.8339\n",
      "Epoch [7/50], Step [200/375], Loss: 223.1004\n",
      "Epoch [7/50], Step [201/375], Loss: 665.9211\n",
      "Epoch [7/50], Step [202/375], Loss: 161.8068\n",
      "Epoch [7/50], Step [203/375], Loss: 280.8922\n",
      "Epoch [7/50], Step [204/375], Loss: 102.9231\n",
      "Epoch [7/50], Step [205/375], Loss: 358.0520\n",
      "Epoch [7/50], Step [206/375], Loss: 52.3111\n",
      "Epoch [7/50], Step [207/375], Loss: 224.8453\n",
      "Epoch [7/50], Step [208/375], Loss: 272.1168\n",
      "Epoch [7/50], Step [209/375], Loss: 111.3949\n",
      "Epoch [7/50], Step [210/375], Loss: 200.4594\n",
      "Epoch [7/50], Step [211/375], Loss: 480.6279\n",
      "Epoch [7/50], Step [212/375], Loss: 317.0121\n",
      "Epoch [7/50], Step [213/375], Loss: 213.4906\n",
      "Epoch [7/50], Step [214/375], Loss: 229.9424\n",
      "Epoch [7/50], Step [215/375], Loss: 189.1544\n",
      "Epoch [7/50], Step [216/375], Loss: 478.6487\n",
      "Epoch [7/50], Step [217/375], Loss: 316.6049\n",
      "Epoch [7/50], Step [218/375], Loss: 773.5237\n",
      "Epoch [7/50], Step [219/375], Loss: 216.0717\n",
      "Epoch [7/50], Step [220/375], Loss: 389.9603\n",
      "Epoch [7/50], Step [221/375], Loss: 300.2357\n",
      "Epoch [7/50], Step [222/375], Loss: 63.6737\n",
      "Epoch [7/50], Step [223/375], Loss: 41.2096\n",
      "Epoch [7/50], Step [224/375], Loss: 273.1717\n",
      "Epoch [7/50], Step [225/375], Loss: 152.6256\n",
      "Epoch [7/50], Step [226/375], Loss: 129.5702\n",
      "Epoch [7/50], Step [227/375], Loss: 454.3132\n",
      "Epoch [7/50], Step [228/375], Loss: 1093.3718\n",
      "Epoch [7/50], Step [229/375], Loss: 491.9474\n",
      "Epoch [7/50], Step [230/375], Loss: 200.8866\n",
      "Epoch [7/50], Step [231/375], Loss: 98.5636\n",
      "Epoch [7/50], Step [232/375], Loss: 406.7162\n",
      "Epoch [7/50], Step [233/375], Loss: 265.1692\n",
      "Epoch [7/50], Step [234/375], Loss: 279.7253\n",
      "Epoch [7/50], Step [235/375], Loss: 116.2158\n",
      "Epoch [7/50], Step [236/375], Loss: 119.4800\n",
      "Epoch [7/50], Step [237/375], Loss: 351.4162\n",
      "Epoch [7/50], Step [238/375], Loss: 424.9708\n",
      "Epoch [7/50], Step [239/375], Loss: 362.5537\n",
      "Epoch [7/50], Step [240/375], Loss: 124.9300\n",
      "Epoch [7/50], Step [241/375], Loss: 474.6246\n",
      "Epoch [7/50], Step [242/375], Loss: 997.2519\n",
      "Epoch [7/50], Step [243/375], Loss: 274.4481\n",
      "Epoch [7/50], Step [244/375], Loss: 143.4406\n",
      "Epoch [7/50], Step [245/375], Loss: 220.1980\n",
      "Epoch [7/50], Step [246/375], Loss: 454.2932\n",
      "Epoch [7/50], Step [247/375], Loss: 193.2430\n",
      "Epoch [7/50], Step [248/375], Loss: 723.5906\n",
      "Epoch [7/50], Step [249/375], Loss: 580.5657\n",
      "Epoch [7/50], Step [250/375], Loss: 200.0379\n",
      "Epoch [7/50], Step [251/375], Loss: 115.4224\n",
      "Epoch [7/50], Step [252/375], Loss: 419.6767\n",
      "Epoch [7/50], Step [253/375], Loss: 206.6393\n",
      "Epoch [7/50], Step [254/375], Loss: 716.0103\n",
      "Epoch [7/50], Step [255/375], Loss: 416.7530\n",
      "Epoch [7/50], Step [256/375], Loss: 205.2663\n",
      "Epoch [7/50], Step [257/375], Loss: 73.9046\n",
      "Epoch [7/50], Step [258/375], Loss: 197.8547\n",
      "Epoch [7/50], Step [259/375], Loss: 515.7738\n",
      "Epoch [7/50], Step [260/375], Loss: 78.6590\n",
      "Epoch [7/50], Step [261/375], Loss: 148.2671\n",
      "Epoch [7/50], Step [262/375], Loss: 171.9872\n",
      "Epoch [7/50], Step [263/375], Loss: 65.2878\n",
      "Epoch [7/50], Step [264/375], Loss: 153.9341\n",
      "Epoch [7/50], Step [265/375], Loss: 180.6536\n",
      "Epoch [7/50], Step [266/375], Loss: 763.5063\n",
      "Epoch [7/50], Step [267/375], Loss: 285.6278\n",
      "Epoch [7/50], Step [268/375], Loss: 584.0685\n",
      "Epoch [7/50], Step [269/375], Loss: 346.0700\n",
      "Epoch [7/50], Step [270/375], Loss: 349.2447\n",
      "Epoch [7/50], Step [271/375], Loss: 110.4058\n",
      "Epoch [7/50], Step [272/375], Loss: 111.9335\n",
      "Epoch [7/50], Step [273/375], Loss: 80.3997\n",
      "Epoch [7/50], Step [274/375], Loss: 253.1818\n",
      "Epoch [7/50], Step [275/375], Loss: 126.4741\n",
      "Epoch [7/50], Step [276/375], Loss: 308.4846\n",
      "Epoch [7/50], Step [277/375], Loss: 160.4573\n",
      "Epoch [7/50], Step [278/375], Loss: 696.9438\n",
      "Epoch [7/50], Step [279/375], Loss: 156.2596\n",
      "Epoch [7/50], Step [280/375], Loss: 186.5955\n",
      "Epoch [7/50], Step [281/375], Loss: 244.6657\n",
      "Epoch [7/50], Step [282/375], Loss: 192.7775\n",
      "Epoch [7/50], Step [283/375], Loss: 479.2797\n",
      "Epoch [7/50], Step [284/375], Loss: 277.5410\n",
      "Epoch [7/50], Step [285/375], Loss: 109.6310\n",
      "Epoch [7/50], Step [286/375], Loss: 1633.6633\n",
      "Epoch [7/50], Step [287/375], Loss: 310.5855\n",
      "Epoch [7/50], Step [288/375], Loss: 91.2540\n",
      "Epoch [7/50], Step [289/375], Loss: 119.7825\n",
      "Epoch [7/50], Step [290/375], Loss: 36.2620\n",
      "Epoch [7/50], Step [291/375], Loss: 165.2009\n",
      "Epoch [7/50], Step [292/375], Loss: 403.7381\n",
      "Epoch [7/50], Step [293/375], Loss: 779.0346\n",
      "Epoch [7/50], Step [294/375], Loss: 179.7591\n",
      "Epoch [7/50], Step [295/375], Loss: 309.5494\n",
      "Epoch [7/50], Step [296/375], Loss: 875.0093\n",
      "Epoch [7/50], Step [297/375], Loss: 312.0958\n",
      "Epoch [7/50], Step [298/375], Loss: 542.7689\n",
      "Epoch [7/50], Step [299/375], Loss: 262.2737\n",
      "Epoch [7/50], Step [300/375], Loss: 57.1294\n",
      "Epoch [7/50], Step [301/375], Loss: 99.2863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Step [302/375], Loss: 51.9696\n",
      "Epoch [7/50], Step [303/375], Loss: 53.4698\n",
      "Epoch [7/50], Step [304/375], Loss: 92.2447\n",
      "Epoch [7/50], Step [305/375], Loss: 178.5842\n",
      "Epoch [7/50], Step [306/375], Loss: 448.7451\n",
      "Epoch [7/50], Step [307/375], Loss: 159.5281\n",
      "Epoch [7/50], Step [308/375], Loss: 300.8189\n",
      "Epoch [7/50], Step [309/375], Loss: 206.7794\n",
      "Epoch [7/50], Step [310/375], Loss: 673.3740\n",
      "Epoch [7/50], Step [311/375], Loss: 230.9084\n",
      "Epoch [7/50], Step [312/375], Loss: 361.5803\n",
      "Epoch [7/50], Step [313/375], Loss: 351.0154\n",
      "Epoch [7/50], Step [314/375], Loss: 237.9431\n",
      "Epoch [7/50], Step [315/375], Loss: 139.9273\n",
      "Epoch [7/50], Step [316/375], Loss: 319.8869\n",
      "Epoch [7/50], Step [317/375], Loss: 274.1342\n",
      "Epoch [7/50], Step [318/375], Loss: 150.9972\n",
      "Epoch [7/50], Step [319/375], Loss: 141.3335\n",
      "Epoch [7/50], Step [320/375], Loss: 1001.2253\n",
      "Epoch [7/50], Step [321/375], Loss: 54.2195\n",
      "Epoch [7/50], Step [322/375], Loss: 148.7921\n",
      "Epoch [7/50], Step [323/375], Loss: 214.0174\n",
      "Epoch [7/50], Step [324/375], Loss: 363.4224\n",
      "Epoch [7/50], Step [325/375], Loss: 329.6868\n",
      "Epoch [7/50], Step [326/375], Loss: 647.5197\n",
      "Epoch [7/50], Step [327/375], Loss: 1773.9799\n",
      "Epoch [7/50], Step [328/375], Loss: 436.7054\n",
      "Epoch [7/50], Step [329/375], Loss: 340.6996\n",
      "Epoch [7/50], Step [330/375], Loss: 263.4669\n",
      "Epoch [7/50], Step [331/375], Loss: 867.6901\n",
      "Epoch [7/50], Step [332/375], Loss: 667.5041\n",
      "Epoch [7/50], Step [333/375], Loss: 477.9782\n",
      "Epoch [7/50], Step [334/375], Loss: 621.4688\n",
      "Epoch [7/50], Step [335/375], Loss: 384.5020\n",
      "Epoch [7/50], Step [336/375], Loss: 529.2585\n",
      "Epoch [7/50], Step [337/375], Loss: 130.2312\n",
      "Epoch [7/50], Step [338/375], Loss: 342.6066\n",
      "Epoch [7/50], Step [339/375], Loss: 220.1749\n",
      "Epoch [7/50], Step [340/375], Loss: 277.8936\n",
      "Epoch [7/50], Step [341/375], Loss: 196.4933\n",
      "Epoch [7/50], Step [342/375], Loss: 135.9343\n",
      "Epoch [7/50], Step [343/375], Loss: 240.1570\n",
      "Epoch [7/50], Step [344/375], Loss: 468.6254\n",
      "Epoch [7/50], Step [345/375], Loss: 68.1786\n",
      "Epoch [7/50], Step [346/375], Loss: 80.8168\n",
      "Epoch [7/50], Step [347/375], Loss: 403.3227\n",
      "Epoch [7/50], Step [348/375], Loss: 433.7604\n",
      "Epoch [7/50], Step [349/375], Loss: 352.8525\n",
      "Epoch [7/50], Step [350/375], Loss: 473.9221\n",
      "Epoch [7/50], Step [351/375], Loss: 434.6608\n",
      "Epoch [7/50], Step [352/375], Loss: 89.0648\n",
      "Epoch [7/50], Step [353/375], Loss: 284.8415\n",
      "Epoch [7/50], Step [354/375], Loss: 61.4345\n",
      "Epoch [7/50], Step [355/375], Loss: 188.4249\n",
      "Epoch [7/50], Step [356/375], Loss: 73.5738\n",
      "Epoch [7/50], Step [357/375], Loss: 384.4875\n",
      "Epoch [7/50], Step [358/375], Loss: 32.8082\n",
      "Epoch [7/50], Step [359/375], Loss: 512.5720\n",
      "Epoch [7/50], Step [360/375], Loss: 345.4213\n",
      "Epoch [7/50], Step [361/375], Loss: 76.9393\n",
      "Epoch [7/50], Step [362/375], Loss: 695.6836\n",
      "Epoch [7/50], Step [363/375], Loss: 98.9605\n",
      "Epoch [7/50], Step [364/375], Loss: 394.2312\n",
      "Epoch [7/50], Step [365/375], Loss: 550.2764\n",
      "Epoch [7/50], Step [366/375], Loss: 107.4439\n",
      "Epoch [7/50], Step [367/375], Loss: 367.7556\n",
      "Epoch [7/50], Step [368/375], Loss: 567.8147\n",
      "Epoch [7/50], Step [369/375], Loss: 713.5795\n",
      "Epoch [7/50], Step [370/375], Loss: 363.0623\n",
      "Epoch [7/50], Step [371/375], Loss: 840.3590\n",
      "Epoch [7/50], Step [372/375], Loss: 386.8068\n",
      "Epoch [7/50], Step [373/375], Loss: 479.4774\n",
      "Epoch [7/50], Step [374/375], Loss: 171.5024\n",
      "Epoch [7/50], Step [375/375], Loss: 534.3882\n",
      "Epoch [8/50], Step [1/375], Loss: 514.1185\n",
      "Epoch [8/50], Step [2/375], Loss: 96.8249\n",
      "Epoch [8/50], Step [3/375], Loss: 342.0592\n",
      "Epoch [8/50], Step [4/375], Loss: 170.7702\n",
      "Epoch [8/50], Step [5/375], Loss: 129.5332\n",
      "Epoch [8/50], Step [6/375], Loss: 722.8131\n",
      "Epoch [8/50], Step [7/375], Loss: 596.6463\n",
      "Epoch [8/50], Step [8/375], Loss: 191.9983\n",
      "Epoch [8/50], Step [9/375], Loss: 162.6078\n",
      "Epoch [8/50], Step [10/375], Loss: 187.0281\n",
      "Epoch [8/50], Step [11/375], Loss: 240.2609\n",
      "Epoch [8/50], Step [12/375], Loss: 116.2270\n",
      "Epoch [8/50], Step [13/375], Loss: 201.8512\n",
      "Epoch [8/50], Step [14/375], Loss: 117.5119\n",
      "Epoch [8/50], Step [15/375], Loss: 147.0171\n",
      "Epoch [8/50], Step [16/375], Loss: 425.5748\n",
      "Epoch [8/50], Step [17/375], Loss: 219.4914\n",
      "Epoch [8/50], Step [18/375], Loss: 248.1275\n",
      "Epoch [8/50], Step [19/375], Loss: 199.0226\n",
      "Epoch [8/50], Step [20/375], Loss: 297.1707\n",
      "Epoch [8/50], Step [21/375], Loss: 367.8614\n",
      "Epoch [8/50], Step [22/375], Loss: 220.3961\n",
      "Epoch [8/50], Step [23/375], Loss: 174.2494\n",
      "Epoch [8/50], Step [24/375], Loss: 286.4997\n",
      "Epoch [8/50], Step [25/375], Loss: 134.6240\n",
      "Epoch [8/50], Step [26/375], Loss: 676.0055\n",
      "Epoch [8/50], Step [27/375], Loss: 386.2444\n",
      "Epoch [8/50], Step [28/375], Loss: 90.6317\n",
      "Epoch [8/50], Step [29/375], Loss: 140.1927\n",
      "Epoch [8/50], Step [30/375], Loss: 154.2637\n",
      "Epoch [8/50], Step [31/375], Loss: 136.4656\n",
      "Epoch [8/50], Step [32/375], Loss: 644.2613\n",
      "Epoch [8/50], Step [33/375], Loss: 908.6337\n",
      "Epoch [8/50], Step [34/375], Loss: 161.4661\n",
      "Epoch [8/50], Step [35/375], Loss: 105.6162\n",
      "Epoch [8/50], Step [36/375], Loss: 285.2406\n",
      "Epoch [8/50], Step [37/375], Loss: 413.2555\n",
      "Epoch [8/50], Step [38/375], Loss: 211.7293\n",
      "Epoch [8/50], Step [39/375], Loss: 271.5265\n",
      "Epoch [8/50], Step [40/375], Loss: 234.1931\n",
      "Epoch [8/50], Step [41/375], Loss: 252.0197\n",
      "Epoch [8/50], Step [42/375], Loss: 215.6976\n",
      "Epoch [8/50], Step [43/375], Loss: 185.6929\n",
      "Epoch [8/50], Step [44/375], Loss: 361.2850\n",
      "Epoch [8/50], Step [45/375], Loss: 336.3371\n",
      "Epoch [8/50], Step [46/375], Loss: 222.5247\n",
      "Epoch [8/50], Step [47/375], Loss: 214.7716\n",
      "Epoch [8/50], Step [48/375], Loss: 83.6152\n",
      "Epoch [8/50], Step [49/375], Loss: 211.1211\n",
      "Epoch [8/50], Step [50/375], Loss: 492.9809\n",
      "Epoch [8/50], Step [51/375], Loss: 133.3959\n",
      "Epoch [8/50], Step [52/375], Loss: 158.6366\n",
      "Epoch [8/50], Step [53/375], Loss: 25.8443\n",
      "Epoch [8/50], Step [54/375], Loss: 100.9166\n",
      "Epoch [8/50], Step [55/375], Loss: 132.9167\n",
      "Epoch [8/50], Step [56/375], Loss: 416.6990\n",
      "Epoch [8/50], Step [57/375], Loss: 226.2398\n",
      "Epoch [8/50], Step [58/375], Loss: 893.2872\n",
      "Epoch [8/50], Step [59/375], Loss: 223.6066\n",
      "Epoch [8/50], Step [60/375], Loss: 40.9419\n",
      "Epoch [8/50], Step [61/375], Loss: 200.9902\n",
      "Epoch [8/50], Step [62/375], Loss: 491.7763\n",
      "Epoch [8/50], Step [63/375], Loss: 119.9976\n",
      "Epoch [8/50], Step [64/375], Loss: 425.5556\n",
      "Epoch [8/50], Step [65/375], Loss: 71.8816\n",
      "Epoch [8/50], Step [66/375], Loss: 439.6120\n",
      "Epoch [8/50], Step [67/375], Loss: 502.7985\n",
      "Epoch [8/50], Step [68/375], Loss: 171.1928\n",
      "Epoch [8/50], Step [69/375], Loss: 401.5067\n",
      "Epoch [8/50], Step [70/375], Loss: 20.7025\n",
      "Epoch [8/50], Step [71/375], Loss: 570.1929\n",
      "Epoch [8/50], Step [72/375], Loss: 374.7418\n",
      "Epoch [8/50], Step [73/375], Loss: 316.6604\n",
      "Epoch [8/50], Step [74/375], Loss: 374.9973\n",
      "Epoch [8/50], Step [75/375], Loss: 666.9458\n",
      "Epoch [8/50], Step [76/375], Loss: 1174.4917\n",
      "Epoch [8/50], Step [77/375], Loss: 773.8214\n",
      "Epoch [8/50], Step [78/375], Loss: 658.6763\n",
      "Epoch [8/50], Step [79/375], Loss: 256.0311\n",
      "Epoch [8/50], Step [80/375], Loss: 690.0997\n",
      "Epoch [8/50], Step [81/375], Loss: 258.8051\n",
      "Epoch [8/50], Step [82/375], Loss: 1409.1926\n",
      "Epoch [8/50], Step [83/375], Loss: 587.7819\n",
      "Epoch [8/50], Step [84/375], Loss: 451.0846\n",
      "Epoch [8/50], Step [85/375], Loss: 140.3732\n",
      "Epoch [8/50], Step [86/375], Loss: 1014.6575\n",
      "Epoch [8/50], Step [87/375], Loss: 188.1974\n",
      "Epoch [8/50], Step [88/375], Loss: 400.9258\n",
      "Epoch [8/50], Step [89/375], Loss: 605.5544\n",
      "Epoch [8/50], Step [90/375], Loss: 82.3233\n",
      "Epoch [8/50], Step [91/375], Loss: 178.8454\n",
      "Epoch [8/50], Step [92/375], Loss: 461.3890\n",
      "Epoch [8/50], Step [93/375], Loss: 364.1814\n",
      "Epoch [8/50], Step [94/375], Loss: 505.8444\n",
      "Epoch [8/50], Step [95/375], Loss: 655.9113\n",
      "Epoch [8/50], Step [96/375], Loss: 876.3542\n",
      "Epoch [8/50], Step [97/375], Loss: 132.9377\n",
      "Epoch [8/50], Step [98/375], Loss: 665.2050\n",
      "Epoch [8/50], Step [99/375], Loss: 389.7247\n",
      "Epoch [8/50], Step [100/375], Loss: 299.1079\n",
      "Epoch [8/50], Step [101/375], Loss: 727.5413\n",
      "Epoch [8/50], Step [102/375], Loss: 23.3979\n",
      "Epoch [8/50], Step [103/375], Loss: 70.4314\n",
      "Epoch [8/50], Step [104/375], Loss: 201.0962\n",
      "Epoch [8/50], Step [105/375], Loss: 133.1519\n",
      "Epoch [8/50], Step [106/375], Loss: 207.0138\n",
      "Epoch [8/50], Step [107/375], Loss: 260.9536\n",
      "Epoch [8/50], Step [108/375], Loss: 128.7933\n",
      "Epoch [8/50], Step [109/375], Loss: 126.3209\n",
      "Epoch [8/50], Step [110/375], Loss: 403.7876\n",
      "Epoch [8/50], Step [111/375], Loss: 566.0931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Step [112/375], Loss: 110.9245\n",
      "Epoch [8/50], Step [113/375], Loss: 141.7860\n",
      "Epoch [8/50], Step [114/375], Loss: 152.3967\n",
      "Epoch [8/50], Step [115/375], Loss: 222.4730\n",
      "Epoch [8/50], Step [116/375], Loss: 392.2863\n",
      "Epoch [8/50], Step [117/375], Loss: 74.6806\n",
      "Epoch [8/50], Step [118/375], Loss: 208.4967\n",
      "Epoch [8/50], Step [119/375], Loss: 309.3675\n",
      "Epoch [8/50], Step [120/375], Loss: 416.5945\n",
      "Epoch [8/50], Step [121/375], Loss: 86.6415\n",
      "Epoch [8/50], Step [122/375], Loss: 167.2000\n",
      "Epoch [8/50], Step [123/375], Loss: 97.8281\n",
      "Epoch [8/50], Step [124/375], Loss: 615.8004\n",
      "Epoch [8/50], Step [125/375], Loss: 540.8915\n",
      "Epoch [8/50], Step [126/375], Loss: 1194.9222\n",
      "Epoch [8/50], Step [127/375], Loss: 434.7356\n",
      "Epoch [8/50], Step [128/375], Loss: 1140.6600\n",
      "Epoch [8/50], Step [129/375], Loss: 434.4286\n",
      "Epoch [8/50], Step [130/375], Loss: 441.7146\n",
      "Epoch [8/50], Step [131/375], Loss: 619.1586\n",
      "Epoch [8/50], Step [132/375], Loss: 175.1384\n",
      "Epoch [8/50], Step [133/375], Loss: 383.6584\n",
      "Epoch [8/50], Step [134/375], Loss: 99.9894\n",
      "Epoch [8/50], Step [135/375], Loss: 124.6012\n",
      "Epoch [8/50], Step [136/375], Loss: 310.7956\n",
      "Epoch [8/50], Step [137/375], Loss: 98.1291\n",
      "Epoch [8/50], Step [138/375], Loss: 200.4131\n",
      "Epoch [8/50], Step [139/375], Loss: 475.2726\n",
      "Epoch [8/50], Step [140/375], Loss: 164.1436\n",
      "Epoch [8/50], Step [141/375], Loss: 213.0802\n",
      "Epoch [8/50], Step [142/375], Loss: 190.7802\n",
      "Epoch [8/50], Step [143/375], Loss: 49.3882\n",
      "Epoch [8/50], Step [144/375], Loss: 519.2938\n",
      "Epoch [8/50], Step [145/375], Loss: 244.2434\n",
      "Epoch [8/50], Step [146/375], Loss: 203.3523\n",
      "Epoch [8/50], Step [147/375], Loss: 99.2150\n",
      "Epoch [8/50], Step [148/375], Loss: 279.5097\n",
      "Epoch [8/50], Step [149/375], Loss: 80.0991\n",
      "Epoch [8/50], Step [150/375], Loss: 229.3494\n",
      "Epoch [8/50], Step [151/375], Loss: 399.7497\n",
      "Epoch [8/50], Step [152/375], Loss: 89.5744\n",
      "Epoch [8/50], Step [153/375], Loss: 54.1140\n",
      "Epoch [8/50], Step [154/375], Loss: 182.0189\n",
      "Epoch [8/50], Step [155/375], Loss: 140.5347\n",
      "Epoch [8/50], Step [156/375], Loss: 1186.6630\n",
      "Epoch [8/50], Step [157/375], Loss: 326.7221\n",
      "Epoch [8/50], Step [158/375], Loss: 141.6317\n",
      "Epoch [8/50], Step [159/375], Loss: 115.2249\n",
      "Epoch [8/50], Step [160/375], Loss: 116.9979\n",
      "Epoch [8/50], Step [161/375], Loss: 269.3065\n",
      "Epoch [8/50], Step [162/375], Loss: 540.9598\n",
      "Epoch [8/50], Step [163/375], Loss: 23.1675\n",
      "Epoch [8/50], Step [164/375], Loss: 106.0766\n",
      "Epoch [8/50], Step [165/375], Loss: 420.9778\n",
      "Epoch [8/50], Step [166/375], Loss: 391.4724\n",
      "Epoch [8/50], Step [167/375], Loss: 203.6138\n",
      "Epoch [8/50], Step [168/375], Loss: 199.1296\n",
      "Epoch [8/50], Step [169/375], Loss: 236.2749\n",
      "Epoch [8/50], Step [170/375], Loss: 159.7409\n",
      "Epoch [8/50], Step [171/375], Loss: 102.6983\n",
      "Epoch [8/50], Step [172/375], Loss: 429.1630\n",
      "Epoch [8/50], Step [173/375], Loss: 379.2321\n",
      "Epoch [8/50], Step [174/375], Loss: 168.2370\n",
      "Epoch [8/50], Step [175/375], Loss: 379.4827\n",
      "Epoch [8/50], Step [176/375], Loss: 165.1903\n",
      "Epoch [8/50], Step [177/375], Loss: 158.1574\n",
      "Epoch [8/50], Step [178/375], Loss: 68.3727\n",
      "Epoch [8/50], Step [179/375], Loss: 275.6353\n",
      "Epoch [8/50], Step [180/375], Loss: 93.5621\n",
      "Epoch [8/50], Step [181/375], Loss: 114.6507\n",
      "Epoch [8/50], Step [182/375], Loss: 269.9262\n",
      "Epoch [8/50], Step [183/375], Loss: 178.4963\n",
      "Epoch [8/50], Step [184/375], Loss: 216.2805\n",
      "Epoch [8/50], Step [185/375], Loss: 312.2644\n",
      "Epoch [8/50], Step [186/375], Loss: 381.8824\n",
      "Epoch [8/50], Step [187/375], Loss: 470.2909\n",
      "Epoch [8/50], Step [188/375], Loss: 497.7310\n",
      "Epoch [8/50], Step [189/375], Loss: 200.4807\n",
      "Epoch [8/50], Step [190/375], Loss: 149.3115\n",
      "Epoch [8/50], Step [191/375], Loss: 285.1930\n",
      "Epoch [8/50], Step [192/375], Loss: 321.6743\n",
      "Epoch [8/50], Step [193/375], Loss: 64.9823\n",
      "Epoch [8/50], Step [194/375], Loss: 50.2963\n",
      "Epoch [8/50], Step [195/375], Loss: 149.7797\n",
      "Epoch [8/50], Step [196/375], Loss: 407.0700\n",
      "Epoch [8/50], Step [197/375], Loss: 38.6991\n",
      "Epoch [8/50], Step [198/375], Loss: 79.0544\n",
      "Epoch [8/50], Step [199/375], Loss: 1105.0964\n",
      "Epoch [8/50], Step [200/375], Loss: 57.6743\n",
      "Epoch [8/50], Step [201/375], Loss: 736.3887\n",
      "Epoch [8/50], Step [202/375], Loss: 192.6598\n",
      "Epoch [8/50], Step [203/375], Loss: 349.0954\n",
      "Epoch [8/50], Step [204/375], Loss: 166.6536\n",
      "Epoch [8/50], Step [205/375], Loss: 1229.3890\n",
      "Epoch [8/50], Step [206/375], Loss: 96.3296\n",
      "Epoch [8/50], Step [207/375], Loss: 86.5468\n",
      "Epoch [8/50], Step [208/375], Loss: 189.0547\n",
      "Epoch [8/50], Step [209/375], Loss: 391.1120\n",
      "Epoch [8/50], Step [210/375], Loss: 166.9528\n",
      "Epoch [8/50], Step [211/375], Loss: 126.1785\n",
      "Epoch [8/50], Step [212/375], Loss: 52.4827\n",
      "Epoch [8/50], Step [213/375], Loss: 96.8510\n",
      "Epoch [8/50], Step [214/375], Loss: 219.2267\n",
      "Epoch [8/50], Step [215/375], Loss: 345.5349\n",
      "Epoch [8/50], Step [216/375], Loss: 165.8981\n",
      "Epoch [8/50], Step [217/375], Loss: 408.3485\n",
      "Epoch [8/50], Step [218/375], Loss: 233.7375\n",
      "Epoch [8/50], Step [219/375], Loss: 86.7176\n",
      "Epoch [8/50], Step [220/375], Loss: 530.9719\n",
      "Epoch [8/50], Step [221/375], Loss: 98.2169\n",
      "Epoch [8/50], Step [222/375], Loss: 157.0720\n",
      "Epoch [8/50], Step [223/375], Loss: 301.7137\n",
      "Epoch [8/50], Step [224/375], Loss: 203.4064\n",
      "Epoch [8/50], Step [225/375], Loss: 287.9390\n",
      "Epoch [8/50], Step [226/375], Loss: 92.5641\n",
      "Epoch [8/50], Step [227/375], Loss: 227.6879\n",
      "Epoch [8/50], Step [228/375], Loss: 426.9159\n",
      "Epoch [8/50], Step [229/375], Loss: 340.3417\n",
      "Epoch [8/50], Step [230/375], Loss: 393.9674\n",
      "Epoch [8/50], Step [231/375], Loss: 455.2516\n",
      "Epoch [8/50], Step [232/375], Loss: 574.2201\n",
      "Epoch [8/50], Step [233/375], Loss: 83.6451\n",
      "Epoch [8/50], Step [234/375], Loss: 392.8696\n",
      "Epoch [8/50], Step [235/375], Loss: 98.1826\n",
      "Epoch [8/50], Step [236/375], Loss: 236.9985\n",
      "Epoch [8/50], Step [237/375], Loss: 26.4378\n",
      "Epoch [8/50], Step [238/375], Loss: 540.2262\n",
      "Epoch [8/50], Step [239/375], Loss: 88.5261\n",
      "Epoch [8/50], Step [240/375], Loss: 404.9635\n",
      "Epoch [8/50], Step [241/375], Loss: 145.1856\n",
      "Epoch [8/50], Step [242/375], Loss: 75.1508\n",
      "Epoch [8/50], Step [243/375], Loss: 765.4581\n",
      "Epoch [8/50], Step [244/375], Loss: 357.7860\n",
      "Epoch [8/50], Step [245/375], Loss: 73.5697\n",
      "Epoch [8/50], Step [246/375], Loss: 375.9112\n",
      "Epoch [8/50], Step [247/375], Loss: 326.4782\n",
      "Epoch [8/50], Step [248/375], Loss: 382.3516\n",
      "Epoch [8/50], Step [249/375], Loss: 532.8510\n",
      "Epoch [8/50], Step [250/375], Loss: 350.7539\n",
      "Epoch [8/50], Step [251/375], Loss: 143.4437\n",
      "Epoch [8/50], Step [252/375], Loss: 54.2915\n",
      "Epoch [8/50], Step [253/375], Loss: 171.0514\n",
      "Epoch [8/50], Step [254/375], Loss: 877.1978\n",
      "Epoch [8/50], Step [255/375], Loss: 167.1192\n",
      "Epoch [8/50], Step [256/375], Loss: 53.0615\n",
      "Epoch [8/50], Step [257/375], Loss: 254.5170\n",
      "Epoch [8/50], Step [258/375], Loss: 350.5437\n",
      "Epoch [8/50], Step [259/375], Loss: 451.2322\n",
      "Epoch [8/50], Step [260/375], Loss: 275.1870\n",
      "Epoch [8/50], Step [261/375], Loss: 432.2828\n",
      "Epoch [8/50], Step [262/375], Loss: 326.0773\n",
      "Epoch [8/50], Step [263/375], Loss: 699.1402\n",
      "Epoch [8/50], Step [264/375], Loss: 118.8362\n",
      "Epoch [8/50], Step [265/375], Loss: 88.4433\n",
      "Epoch [8/50], Step [266/375], Loss: 357.1925\n",
      "Epoch [8/50], Step [267/375], Loss: 194.2803\n",
      "Epoch [8/50], Step [268/375], Loss: 139.9662\n",
      "Epoch [8/50], Step [269/375], Loss: 494.9995\n",
      "Epoch [8/50], Step [270/375], Loss: 147.1687\n",
      "Epoch [8/50], Step [271/375], Loss: 284.3140\n",
      "Epoch [8/50], Step [272/375], Loss: 272.8333\n",
      "Epoch [8/50], Step [273/375], Loss: 882.0027\n",
      "Epoch [8/50], Step [274/375], Loss: 875.7645\n",
      "Epoch [8/50], Step [275/375], Loss: 160.3701\n",
      "Epoch [8/50], Step [276/375], Loss: 168.6761\n",
      "Epoch [8/50], Step [277/375], Loss: 99.6746\n",
      "Epoch [8/50], Step [278/375], Loss: 524.4473\n",
      "Epoch [8/50], Step [279/375], Loss: 183.3382\n",
      "Epoch [8/50], Step [280/375], Loss: 358.8523\n",
      "Epoch [8/50], Step [281/375], Loss: 758.8215\n",
      "Epoch [8/50], Step [282/375], Loss: 435.7055\n",
      "Epoch [8/50], Step [283/375], Loss: 192.1881\n",
      "Epoch [8/50], Step [284/375], Loss: 544.7277\n",
      "Epoch [8/50], Step [285/375], Loss: 610.9597\n",
      "Epoch [8/50], Step [286/375], Loss: 171.6964\n",
      "Epoch [8/50], Step [287/375], Loss: 393.6038\n",
      "Epoch [8/50], Step [288/375], Loss: 95.3226\n",
      "Epoch [8/50], Step [289/375], Loss: 92.4859\n",
      "Epoch [8/50], Step [290/375], Loss: 118.8916\n",
      "Epoch [8/50], Step [291/375], Loss: 540.1043\n",
      "Epoch [8/50], Step [292/375], Loss: 762.6295\n",
      "Epoch [8/50], Step [293/375], Loss: 206.4893\n",
      "Epoch [8/50], Step [294/375], Loss: 222.5451\n",
      "Epoch [8/50], Step [295/375], Loss: 71.3732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Step [296/375], Loss: 34.5749\n",
      "Epoch [8/50], Step [297/375], Loss: 705.0886\n",
      "Epoch [8/50], Step [298/375], Loss: 223.2375\n",
      "Epoch [8/50], Step [299/375], Loss: 224.5280\n",
      "Epoch [8/50], Step [300/375], Loss: 37.4303\n",
      "Epoch [8/50], Step [301/375], Loss: 107.0306\n",
      "Epoch [8/50], Step [302/375], Loss: 177.2496\n",
      "Epoch [8/50], Step [303/375], Loss: 115.8932\n",
      "Epoch [8/50], Step [304/375], Loss: 127.4817\n",
      "Epoch [8/50], Step [305/375], Loss: 397.0278\n",
      "Epoch [8/50], Step [306/375], Loss: 229.8356\n",
      "Epoch [8/50], Step [307/375], Loss: 271.1283\n",
      "Epoch [8/50], Step [308/375], Loss: 132.6828\n",
      "Epoch [8/50], Step [309/375], Loss: 212.3669\n",
      "Epoch [8/50], Step [310/375], Loss: 258.2011\n",
      "Epoch [8/50], Step [311/375], Loss: 74.3116\n",
      "Epoch [8/50], Step [312/375], Loss: 344.5788\n",
      "Epoch [8/50], Step [313/375], Loss: 797.3037\n",
      "Epoch [8/50], Step [314/375], Loss: 239.8291\n",
      "Epoch [8/50], Step [315/375], Loss: 155.0201\n",
      "Epoch [8/50], Step [316/375], Loss: 465.7018\n",
      "Epoch [8/50], Step [317/375], Loss: 106.2796\n",
      "Epoch [8/50], Step [318/375], Loss: 456.6382\n",
      "Epoch [8/50], Step [319/375], Loss: 304.8316\n",
      "Epoch [8/50], Step [320/375], Loss: 133.4569\n",
      "Epoch [8/50], Step [321/375], Loss: 183.8418\n",
      "Epoch [8/50], Step [322/375], Loss: 175.4316\n",
      "Epoch [8/50], Step [323/375], Loss: 304.0531\n",
      "Epoch [8/50], Step [324/375], Loss: 192.8409\n",
      "Epoch [8/50], Step [325/375], Loss: 368.8219\n",
      "Epoch [8/50], Step [326/375], Loss: 84.0275\n",
      "Epoch [8/50], Step [327/375], Loss: 227.1562\n",
      "Epoch [8/50], Step [328/375], Loss: 497.0427\n",
      "Epoch [8/50], Step [329/375], Loss: 68.6134\n",
      "Epoch [8/50], Step [330/375], Loss: 174.1238\n",
      "Epoch [8/50], Step [331/375], Loss: 345.0874\n",
      "Epoch [8/50], Step [332/375], Loss: 227.9251\n",
      "Epoch [8/50], Step [333/375], Loss: 205.2146\n",
      "Epoch [8/50], Step [334/375], Loss: 177.1485\n",
      "Epoch [8/50], Step [335/375], Loss: 175.4839\n",
      "Epoch [8/50], Step [336/375], Loss: 89.7038\n",
      "Epoch [8/50], Step [337/375], Loss: 20.9994\n",
      "Epoch [8/50], Step [338/375], Loss: 140.9411\n",
      "Epoch [8/50], Step [339/375], Loss: 192.6089\n",
      "Epoch [8/50], Step [340/375], Loss: 271.8295\n",
      "Epoch [8/50], Step [341/375], Loss: 295.5377\n",
      "Epoch [8/50], Step [342/375], Loss: 205.6247\n",
      "Epoch [8/50], Step [343/375], Loss: 112.1730\n",
      "Epoch [8/50], Step [344/375], Loss: 409.4001\n",
      "Epoch [8/50], Step [345/375], Loss: 155.0545\n",
      "Epoch [8/50], Step [346/375], Loss: 606.5262\n",
      "Epoch [8/50], Step [347/375], Loss: 66.8028\n",
      "Epoch [8/50], Step [348/375], Loss: 413.9163\n",
      "Epoch [8/50], Step [349/375], Loss: 261.0303\n",
      "Epoch [8/50], Step [350/375], Loss: 855.9117\n",
      "Epoch [8/50], Step [351/375], Loss: 50.7440\n",
      "Epoch [8/50], Step [352/375], Loss: 37.3219\n",
      "Epoch [8/50], Step [353/375], Loss: 361.9261\n",
      "Epoch [8/50], Step [354/375], Loss: 168.8284\n",
      "Epoch [8/50], Step [355/375], Loss: 74.7785\n",
      "Epoch [8/50], Step [356/375], Loss: 114.6955\n",
      "Epoch [8/50], Step [357/375], Loss: 242.9771\n",
      "Epoch [8/50], Step [358/375], Loss: 98.1517\n",
      "Epoch [8/50], Step [359/375], Loss: 612.2855\n",
      "Epoch [8/50], Step [360/375], Loss: 52.9629\n",
      "Epoch [8/50], Step [361/375], Loss: 241.1030\n",
      "Epoch [8/50], Step [362/375], Loss: 463.5705\n",
      "Epoch [8/50], Step [363/375], Loss: 331.8312\n",
      "Epoch [8/50], Step [364/375], Loss: 456.3516\n",
      "Epoch [8/50], Step [365/375], Loss: 105.9248\n",
      "Epoch [8/50], Step [366/375], Loss: 274.2882\n",
      "Epoch [8/50], Step [367/375], Loss: 1065.0739\n",
      "Epoch [8/50], Step [368/375], Loss: 355.3813\n",
      "Epoch [8/50], Step [369/375], Loss: 217.7170\n",
      "Epoch [8/50], Step [370/375], Loss: 975.3925\n",
      "Epoch [8/50], Step [371/375], Loss: 499.6117\n",
      "Epoch [8/50], Step [372/375], Loss: 606.3707\n",
      "Epoch [8/50], Step [373/375], Loss: 165.1532\n",
      "Epoch [8/50], Step [374/375], Loss: 460.0254\n",
      "Epoch [8/50], Step [375/375], Loss: 194.7761\n",
      "Epoch [9/50], Step [1/375], Loss: 200.6402\n",
      "Epoch [9/50], Step [2/375], Loss: 354.0543\n",
      "Epoch [9/50], Step [3/375], Loss: 60.4955\n",
      "Epoch [9/50], Step [4/375], Loss: 151.2539\n",
      "Epoch [9/50], Step [5/375], Loss: 165.0343\n",
      "Epoch [9/50], Step [6/375], Loss: 126.2195\n",
      "Epoch [9/50], Step [7/375], Loss: 408.1515\n",
      "Epoch [9/50], Step [8/375], Loss: 218.2378\n",
      "Epoch [9/50], Step [9/375], Loss: 178.2282\n",
      "Epoch [9/50], Step [10/375], Loss: 147.4739\n",
      "Epoch [9/50], Step [11/375], Loss: 321.7769\n",
      "Epoch [9/50], Step [12/375], Loss: 166.1914\n",
      "Epoch [9/50], Step [13/375], Loss: 518.0082\n",
      "Epoch [9/50], Step [14/375], Loss: 490.9819\n",
      "Epoch [9/50], Step [15/375], Loss: 231.4582\n",
      "Epoch [9/50], Step [16/375], Loss: 104.7883\n",
      "Epoch [9/50], Step [17/375], Loss: 54.9775\n",
      "Epoch [9/50], Step [18/375], Loss: 365.7656\n",
      "Epoch [9/50], Step [19/375], Loss: 754.7195\n",
      "Epoch [9/50], Step [20/375], Loss: 411.1588\n",
      "Epoch [9/50], Step [21/375], Loss: 683.9370\n",
      "Epoch [9/50], Step [22/375], Loss: 342.3882\n",
      "Epoch [9/50], Step [23/375], Loss: 384.9063\n",
      "Epoch [9/50], Step [24/375], Loss: 53.5493\n",
      "Epoch [9/50], Step [25/375], Loss: 407.2726\n",
      "Epoch [9/50], Step [26/375], Loss: 225.4151\n",
      "Epoch [9/50], Step [27/375], Loss: 338.6604\n",
      "Epoch [9/50], Step [28/375], Loss: 98.0323\n",
      "Epoch [9/50], Step [29/375], Loss: 704.8459\n",
      "Epoch [9/50], Step [30/375], Loss: 291.2280\n",
      "Epoch [9/50], Step [31/375], Loss: 179.3950\n",
      "Epoch [9/50], Step [32/375], Loss: 2185.5271\n",
      "Epoch [9/50], Step [33/375], Loss: 332.0864\n",
      "Epoch [9/50], Step [34/375], Loss: 142.8070\n",
      "Epoch [9/50], Step [35/375], Loss: 702.8114\n",
      "Epoch [9/50], Step [36/375], Loss: 148.0999\n",
      "Epoch [9/50], Step [37/375], Loss: 142.9404\n",
      "Epoch [9/50], Step [38/375], Loss: 573.7459\n",
      "Epoch [9/50], Step [39/375], Loss: 78.3076\n",
      "Epoch [9/50], Step [40/375], Loss: 141.5498\n",
      "Epoch [9/50], Step [41/375], Loss: 194.1479\n",
      "Epoch [9/50], Step [42/375], Loss: 58.5303\n",
      "Epoch [9/50], Step [43/375], Loss: 469.6500\n",
      "Epoch [9/50], Step [44/375], Loss: 472.3572\n",
      "Epoch [9/50], Step [45/375], Loss: 337.3249\n",
      "Epoch [9/50], Step [46/375], Loss: 103.1526\n",
      "Epoch [9/50], Step [47/375], Loss: 105.9103\n",
      "Epoch [9/50], Step [48/375], Loss: 343.7503\n",
      "Epoch [9/50], Step [49/375], Loss: 443.4902\n",
      "Epoch [9/50], Step [50/375], Loss: 1175.4531\n",
      "Epoch [9/50], Step [51/375], Loss: 281.5163\n",
      "Epoch [9/50], Step [52/375], Loss: 80.3645\n",
      "Epoch [9/50], Step [53/375], Loss: 267.4274\n",
      "Epoch [9/50], Step [54/375], Loss: 377.5284\n",
      "Epoch [9/50], Step [55/375], Loss: 267.1344\n",
      "Epoch [9/50], Step [56/375], Loss: 87.0135\n",
      "Epoch [9/50], Step [57/375], Loss: 467.1686\n",
      "Epoch [9/50], Step [58/375], Loss: 141.6055\n",
      "Epoch [9/50], Step [59/375], Loss: 345.7401\n",
      "Epoch [9/50], Step [60/375], Loss: 153.1313\n",
      "Epoch [9/50], Step [61/375], Loss: 143.6303\n",
      "Epoch [9/50], Step [62/375], Loss: 282.9158\n",
      "Epoch [9/50], Step [63/375], Loss: 698.1788\n",
      "Epoch [9/50], Step [64/375], Loss: 86.5733\n",
      "Epoch [9/50], Step [65/375], Loss: 316.3584\n",
      "Epoch [9/50], Step [66/375], Loss: 326.8094\n",
      "Epoch [9/50], Step [67/375], Loss: 739.8132\n",
      "Epoch [9/50], Step [68/375], Loss: 466.9091\n",
      "Epoch [9/50], Step [69/375], Loss: 353.3531\n",
      "Epoch [9/50], Step [70/375], Loss: 476.0572\n",
      "Epoch [9/50], Step [71/375], Loss: 484.0557\n",
      "Epoch [9/50], Step [72/375], Loss: 328.4255\n",
      "Epoch [9/50], Step [73/375], Loss: 588.8827\n",
      "Epoch [9/50], Step [74/375], Loss: 253.3570\n",
      "Epoch [9/50], Step [75/375], Loss: 411.7796\n",
      "Epoch [9/50], Step [76/375], Loss: 228.1710\n",
      "Epoch [9/50], Step [77/375], Loss: 76.3298\n",
      "Epoch [9/50], Step [78/375], Loss: 154.2747\n",
      "Epoch [9/50], Step [79/375], Loss: 26.0973\n",
      "Epoch [9/50], Step [80/375], Loss: 227.0328\n",
      "Epoch [9/50], Step [81/375], Loss: 176.4803\n",
      "Epoch [9/50], Step [82/375], Loss: 759.1876\n",
      "Epoch [9/50], Step [83/375], Loss: 1029.4598\n",
      "Epoch [9/50], Step [84/375], Loss: 382.8307\n",
      "Epoch [9/50], Step [85/375], Loss: 268.5570\n",
      "Epoch [9/50], Step [86/375], Loss: 329.5930\n",
      "Epoch [9/50], Step [87/375], Loss: 94.7662\n",
      "Epoch [9/50], Step [88/375], Loss: 97.1023\n",
      "Epoch [9/50], Step [89/375], Loss: 122.6184\n",
      "Epoch [9/50], Step [90/375], Loss: 329.2943\n",
      "Epoch [9/50], Step [91/375], Loss: 142.9256\n",
      "Epoch [9/50], Step [92/375], Loss: 182.5574\n",
      "Epoch [9/50], Step [93/375], Loss: 661.4144\n",
      "Epoch [9/50], Step [94/375], Loss: 154.0300\n",
      "Epoch [9/50], Step [95/375], Loss: 97.2823\n",
      "Epoch [9/50], Step [96/375], Loss: 54.4097\n",
      "Epoch [9/50], Step [97/375], Loss: 719.3422\n",
      "Epoch [9/50], Step [98/375], Loss: 187.5010\n",
      "Epoch [9/50], Step [99/375], Loss: 352.5711\n",
      "Epoch [9/50], Step [100/375], Loss: 217.6914\n",
      "Epoch [9/50], Step [101/375], Loss: 650.3947\n",
      "Epoch [9/50], Step [102/375], Loss: 115.5393\n",
      "Epoch [9/50], Step [103/375], Loss: 157.4030\n",
      "Epoch [9/50], Step [104/375], Loss: 124.7244\n",
      "Epoch [9/50], Step [105/375], Loss: 174.1633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Step [106/375], Loss: 390.7432\n",
      "Epoch [9/50], Step [107/375], Loss: 57.5750\n",
      "Epoch [9/50], Step [108/375], Loss: 397.0170\n",
      "Epoch [9/50], Step [109/375], Loss: 333.8103\n",
      "Epoch [9/50], Step [110/375], Loss: 62.2461\n",
      "Epoch [9/50], Step [111/375], Loss: 724.2366\n",
      "Epoch [9/50], Step [112/375], Loss: 158.7722\n",
      "Epoch [9/50], Step [113/375], Loss: 264.6479\n",
      "Epoch [9/50], Step [114/375], Loss: 131.1438\n",
      "Epoch [9/50], Step [115/375], Loss: 62.7322\n",
      "Epoch [9/50], Step [116/375], Loss: 174.6615\n",
      "Epoch [9/50], Step [117/375], Loss: 230.7427\n",
      "Epoch [9/50], Step [118/375], Loss: 186.4683\n",
      "Epoch [9/50], Step [119/375], Loss: 89.5075\n",
      "Epoch [9/50], Step [120/375], Loss: 306.7967\n",
      "Epoch [9/50], Step [121/375], Loss: 438.5555\n",
      "Epoch [9/50], Step [122/375], Loss: 15.6919\n",
      "Epoch [9/50], Step [123/375], Loss: 63.1192\n",
      "Epoch [9/50], Step [124/375], Loss: 418.4706\n",
      "Epoch [9/50], Step [125/375], Loss: 152.8796\n",
      "Epoch [9/50], Step [126/375], Loss: 600.6061\n",
      "Epoch [9/50], Step [127/375], Loss: 1125.7490\n",
      "Epoch [9/50], Step [128/375], Loss: 494.7976\n",
      "Epoch [9/50], Step [129/375], Loss: 45.6739\n",
      "Epoch [9/50], Step [130/375], Loss: 582.5761\n",
      "Epoch [9/50], Step [131/375], Loss: 591.4476\n",
      "Epoch [9/50], Step [132/375], Loss: 481.0332\n",
      "Epoch [9/50], Step [133/375], Loss: 222.8668\n",
      "Epoch [9/50], Step [134/375], Loss: 139.9746\n",
      "Epoch [9/50], Step [135/375], Loss: 281.9508\n",
      "Epoch [9/50], Step [136/375], Loss: 520.2268\n",
      "Epoch [9/50], Step [137/375], Loss: 220.2708\n",
      "Epoch [9/50], Step [138/375], Loss: 111.8586\n",
      "Epoch [9/50], Step [139/375], Loss: 90.2800\n",
      "Epoch [9/50], Step [140/375], Loss: 401.1245\n",
      "Epoch [9/50], Step [141/375], Loss: 277.7871\n",
      "Epoch [9/50], Step [142/375], Loss: 655.6408\n",
      "Epoch [9/50], Step [143/375], Loss: 511.1922\n",
      "Epoch [9/50], Step [144/375], Loss: 577.8459\n",
      "Epoch [9/50], Step [145/375], Loss: 968.8868\n",
      "Epoch [9/50], Step [146/375], Loss: 789.3779\n",
      "Epoch [9/50], Step [147/375], Loss: 265.0045\n",
      "Epoch [9/50], Step [148/375], Loss: 98.9140\n",
      "Epoch [9/50], Step [149/375], Loss: 727.8764\n",
      "Epoch [9/50], Step [150/375], Loss: 129.3238\n",
      "Epoch [9/50], Step [151/375], Loss: 132.7380\n",
      "Epoch [9/50], Step [152/375], Loss: 294.4055\n",
      "Epoch [9/50], Step [153/375], Loss: 140.1141\n",
      "Epoch [9/50], Step [154/375], Loss: 118.8159\n",
      "Epoch [9/50], Step [155/375], Loss: 523.0414\n",
      "Epoch [9/50], Step [156/375], Loss: 222.2843\n",
      "Epoch [9/50], Step [157/375], Loss: 228.8647\n",
      "Epoch [9/50], Step [158/375], Loss: 113.9847\n",
      "Epoch [9/50], Step [159/375], Loss: 306.6739\n",
      "Epoch [9/50], Step [160/375], Loss: 179.5809\n",
      "Epoch [9/50], Step [161/375], Loss: 405.9464\n",
      "Epoch [9/50], Step [162/375], Loss: 723.8098\n",
      "Epoch [9/50], Step [163/375], Loss: 208.1412\n",
      "Epoch [9/50], Step [164/375], Loss: 225.3312\n",
      "Epoch [9/50], Step [165/375], Loss: 103.3107\n",
      "Epoch [9/50], Step [166/375], Loss: 305.1850\n",
      "Epoch [9/50], Step [167/375], Loss: 309.0531\n",
      "Epoch [9/50], Step [168/375], Loss: 88.1158\n",
      "Epoch [9/50], Step [169/375], Loss: 273.0673\n",
      "Epoch [9/50], Step [170/375], Loss: 180.4286\n",
      "Epoch [9/50], Step [171/375], Loss: 379.8139\n",
      "Epoch [9/50], Step [172/375], Loss: 391.4984\n",
      "Epoch [9/50], Step [173/375], Loss: 314.4353\n",
      "Epoch [9/50], Step [174/375], Loss: 353.7612\n",
      "Epoch [9/50], Step [175/375], Loss: 285.3736\n",
      "Epoch [9/50], Step [176/375], Loss: 108.7405\n",
      "Epoch [9/50], Step [177/375], Loss: 191.8569\n",
      "Epoch [9/50], Step [178/375], Loss: 288.5207\n",
      "Epoch [9/50], Step [179/375], Loss: 814.3309\n",
      "Epoch [9/50], Step [180/375], Loss: 383.7993\n",
      "Epoch [9/50], Step [181/375], Loss: 244.0390\n",
      "Epoch [9/50], Step [182/375], Loss: 266.9422\n",
      "Epoch [9/50], Step [183/375], Loss: 168.3545\n",
      "Epoch [9/50], Step [184/375], Loss: 57.5010\n",
      "Epoch [9/50], Step [185/375], Loss: 225.0100\n",
      "Epoch [9/50], Step [186/375], Loss: 325.3403\n",
      "Epoch [9/50], Step [187/375], Loss: 254.0310\n",
      "Epoch [9/50], Step [188/375], Loss: 193.8345\n",
      "Epoch [9/50], Step [189/375], Loss: 53.4596\n",
      "Epoch [9/50], Step [190/375], Loss: 271.6099\n",
      "Epoch [9/50], Step [191/375], Loss: 97.7985\n",
      "Epoch [9/50], Step [192/375], Loss: 180.2734\n",
      "Epoch [9/50], Step [193/375], Loss: 747.5598\n",
      "Epoch [9/50], Step [194/375], Loss: 122.5064\n",
      "Epoch [9/50], Step [195/375], Loss: 479.9588\n",
      "Epoch [9/50], Step [196/375], Loss: 284.3622\n",
      "Epoch [9/50], Step [197/375], Loss: 164.1967\n",
      "Epoch [9/50], Step [198/375], Loss: 81.8244\n",
      "Epoch [9/50], Step [199/375], Loss: 352.0441\n",
      "Epoch [9/50], Step [200/375], Loss: 342.5814\n",
      "Epoch [9/50], Step [201/375], Loss: 380.6597\n",
      "Epoch [9/50], Step [202/375], Loss: 142.8748\n",
      "Epoch [9/50], Step [203/375], Loss: 179.6616\n",
      "Epoch [9/50], Step [204/375], Loss: 86.6292\n",
      "Epoch [9/50], Step [205/375], Loss: 135.1796\n",
      "Epoch [9/50], Step [206/375], Loss: 510.8619\n",
      "Epoch [9/50], Step [207/375], Loss: 297.9579\n",
      "Epoch [9/50], Step [208/375], Loss: 306.7498\n",
      "Epoch [9/50], Step [209/375], Loss: 148.9215\n",
      "Epoch [9/50], Step [210/375], Loss: 116.7665\n",
      "Epoch [9/50], Step [211/375], Loss: 352.1631\n",
      "Epoch [9/50], Step [212/375], Loss: 509.8548\n",
      "Epoch [9/50], Step [213/375], Loss: 232.3280\n",
      "Epoch [9/50], Step [214/375], Loss: 532.1980\n",
      "Epoch [9/50], Step [215/375], Loss: 351.3354\n",
      "Epoch [9/50], Step [216/375], Loss: 644.7856\n",
      "Epoch [9/50], Step [217/375], Loss: 548.1631\n",
      "Epoch [9/50], Step [218/375], Loss: 393.1875\n",
      "Epoch [9/50], Step [219/375], Loss: 253.6935\n",
      "Epoch [9/50], Step [220/375], Loss: 933.3674\n",
      "Epoch [9/50], Step [221/375], Loss: 718.1857\n",
      "Epoch [9/50], Step [222/375], Loss: 136.3363\n",
      "Epoch [9/50], Step [223/375], Loss: 435.2690\n",
      "Epoch [9/50], Step [224/375], Loss: 338.4529\n",
      "Epoch [9/50], Step [225/375], Loss: 451.9914\n",
      "Epoch [9/50], Step [226/375], Loss: 324.5404\n",
      "Epoch [9/50], Step [227/375], Loss: 153.4583\n",
      "Epoch [9/50], Step [228/375], Loss: 47.1845\n",
      "Epoch [9/50], Step [229/375], Loss: 171.0926\n",
      "Epoch [9/50], Step [230/375], Loss: 349.0509\n",
      "Epoch [9/50], Step [231/375], Loss: 1054.1798\n",
      "Epoch [9/50], Step [232/375], Loss: 156.3960\n",
      "Epoch [9/50], Step [233/375], Loss: 405.8139\n",
      "Epoch [9/50], Step [234/375], Loss: 354.9193\n",
      "Epoch [9/50], Step [235/375], Loss: 300.5804\n",
      "Epoch [9/50], Step [236/375], Loss: 134.8269\n",
      "Epoch [9/50], Step [237/375], Loss: 125.3757\n",
      "Epoch [9/50], Step [238/375], Loss: 193.4324\n",
      "Epoch [9/50], Step [239/375], Loss: 226.4908\n",
      "Epoch [9/50], Step [240/375], Loss: 123.5271\n",
      "Epoch [9/50], Step [241/375], Loss: 295.1733\n",
      "Epoch [9/50], Step [242/375], Loss: 85.1133\n",
      "Epoch [9/50], Step [243/375], Loss: 479.5277\n",
      "Epoch [9/50], Step [244/375], Loss: 1130.1621\n",
      "Epoch [9/50], Step [245/375], Loss: 402.0329\n",
      "Epoch [9/50], Step [246/375], Loss: 1065.2188\n",
      "Epoch [9/50], Step [247/375], Loss: 223.5125\n",
      "Epoch [9/50], Step [248/375], Loss: 835.9529\n",
      "Epoch [9/50], Step [249/375], Loss: 596.6917\n",
      "Epoch [9/50], Step [250/375], Loss: 1542.2769\n",
      "Epoch [9/50], Step [251/375], Loss: 467.9346\n",
      "Epoch [9/50], Step [252/375], Loss: 312.8974\n",
      "Epoch [9/50], Step [253/375], Loss: 109.4557\n",
      "Epoch [9/50], Step [254/375], Loss: 542.4423\n",
      "Epoch [9/50], Step [255/375], Loss: 468.9211\n",
      "Epoch [9/50], Step [256/375], Loss: 841.9985\n",
      "Epoch [9/50], Step [257/375], Loss: 426.4552\n",
      "Epoch [9/50], Step [258/375], Loss: 111.5296\n",
      "Epoch [9/50], Step [259/375], Loss: 426.6780\n",
      "Epoch [9/50], Step [260/375], Loss: 103.1485\n",
      "Epoch [9/50], Step [261/375], Loss: 68.9073\n",
      "Epoch [9/50], Step [262/375], Loss: 318.2135\n",
      "Epoch [9/50], Step [263/375], Loss: 481.5223\n",
      "Epoch [9/50], Step [264/375], Loss: 258.4362\n",
      "Epoch [9/50], Step [265/375], Loss: 240.1823\n",
      "Epoch [9/50], Step [266/375], Loss: 170.9515\n",
      "Epoch [9/50], Step [267/375], Loss: 623.4279\n",
      "Epoch [9/50], Step [268/375], Loss: 126.9412\n",
      "Epoch [9/50], Step [269/375], Loss: 364.7918\n",
      "Epoch [9/50], Step [270/375], Loss: 599.8534\n",
      "Epoch [9/50], Step [271/375], Loss: 103.6532\n",
      "Epoch [9/50], Step [272/375], Loss: 255.2272\n",
      "Epoch [9/50], Step [273/375], Loss: 70.4868\n",
      "Epoch [9/50], Step [274/375], Loss: 278.5895\n",
      "Epoch [9/50], Step [275/375], Loss: 282.0172\n",
      "Epoch [9/50], Step [276/375], Loss: 224.7356\n",
      "Epoch [9/50], Step [277/375], Loss: 514.1769\n",
      "Epoch [9/50], Step [278/375], Loss: 108.3805\n",
      "Epoch [9/50], Step [279/375], Loss: 617.1546\n",
      "Epoch [9/50], Step [280/375], Loss: 176.9054\n",
      "Epoch [9/50], Step [281/375], Loss: 478.9338\n",
      "Epoch [9/50], Step [282/375], Loss: 82.7353\n",
      "Epoch [9/50], Step [283/375], Loss: 480.7495\n",
      "Epoch [9/50], Step [284/375], Loss: 444.6472\n",
      "Epoch [9/50], Step [285/375], Loss: 40.2935\n",
      "Epoch [9/50], Step [286/375], Loss: 109.6632\n",
      "Epoch [9/50], Step [287/375], Loss: 55.7578\n",
      "Epoch [9/50], Step [288/375], Loss: 572.0748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Step [289/375], Loss: 576.3943\n",
      "Epoch [9/50], Step [290/375], Loss: 71.0589\n",
      "Epoch [9/50], Step [291/375], Loss: 275.2910\n",
      "Epoch [9/50], Step [292/375], Loss: 329.5810\n",
      "Epoch [9/50], Step [293/375], Loss: 108.3926\n",
      "Epoch [9/50], Step [294/375], Loss: 318.7663\n",
      "Epoch [9/50], Step [295/375], Loss: 441.5792\n",
      "Epoch [9/50], Step [296/375], Loss: 65.7524\n",
      "Epoch [9/50], Step [297/375], Loss: 246.3896\n",
      "Epoch [9/50], Step [298/375], Loss: 270.9596\n",
      "Epoch [9/50], Step [299/375], Loss: 348.9077\n",
      "Epoch [9/50], Step [300/375], Loss: 203.6235\n",
      "Epoch [9/50], Step [301/375], Loss: 674.4431\n",
      "Epoch [9/50], Step [302/375], Loss: 235.3997\n",
      "Epoch [9/50], Step [303/375], Loss: 329.3999\n",
      "Epoch [9/50], Step [304/375], Loss: 442.9438\n",
      "Epoch [9/50], Step [305/375], Loss: 527.6542\n",
      "Epoch [9/50], Step [306/375], Loss: 354.9608\n",
      "Epoch [9/50], Step [307/375], Loss: 108.8315\n",
      "Epoch [9/50], Step [308/375], Loss: 633.9041\n",
      "Epoch [9/50], Step [309/375], Loss: 353.9238\n",
      "Epoch [9/50], Step [310/375], Loss: 372.5369\n",
      "Epoch [9/50], Step [311/375], Loss: 532.8001\n",
      "Epoch [9/50], Step [312/375], Loss: 232.1607\n",
      "Epoch [9/50], Step [313/375], Loss: 372.2240\n",
      "Epoch [9/50], Step [314/375], Loss: 499.5359\n",
      "Epoch [9/50], Step [315/375], Loss: 238.1737\n",
      "Epoch [9/50], Step [316/375], Loss: 390.4510\n",
      "Epoch [9/50], Step [317/375], Loss: 92.3060\n",
      "Epoch [9/50], Step [318/375], Loss: 321.3318\n",
      "Epoch [9/50], Step [319/375], Loss: 267.6919\n",
      "Epoch [9/50], Step [320/375], Loss: 270.2023\n",
      "Epoch [9/50], Step [321/375], Loss: 629.8500\n",
      "Epoch [9/50], Step [322/375], Loss: 905.1387\n",
      "Epoch [9/50], Step [323/375], Loss: 401.9355\n",
      "Epoch [9/50], Step [324/375], Loss: 71.7942\n",
      "Epoch [9/50], Step [325/375], Loss: 257.2500\n",
      "Epoch [9/50], Step [326/375], Loss: 196.0795\n",
      "Epoch [9/50], Step [327/375], Loss: 80.0513\n",
      "Epoch [9/50], Step [328/375], Loss: 76.0954\n",
      "Epoch [9/50], Step [329/375], Loss: 996.9470\n",
      "Epoch [9/50], Step [330/375], Loss: 73.5365\n",
      "Epoch [9/50], Step [331/375], Loss: 225.8806\n",
      "Epoch [9/50], Step [332/375], Loss: 589.7239\n",
      "Epoch [9/50], Step [333/375], Loss: 415.4745\n",
      "Epoch [9/50], Step [334/375], Loss: 370.3981\n",
      "Epoch [9/50], Step [335/375], Loss: 222.7091\n",
      "Epoch [9/50], Step [336/375], Loss: 209.4942\n",
      "Epoch [9/50], Step [337/375], Loss: 154.5683\n",
      "Epoch [9/50], Step [338/375], Loss: 95.5966\n",
      "Epoch [9/50], Step [339/375], Loss: 171.3547\n",
      "Epoch [9/50], Step [340/375], Loss: 37.8408\n",
      "Epoch [9/50], Step [341/375], Loss: 209.9434\n",
      "Epoch [9/50], Step [342/375], Loss: 356.9435\n",
      "Epoch [9/50], Step [343/375], Loss: 578.0482\n",
      "Epoch [9/50], Step [344/375], Loss: 85.1620\n",
      "Epoch [9/50], Step [345/375], Loss: 120.4953\n",
      "Epoch [9/50], Step [346/375], Loss: 252.3412\n",
      "Epoch [9/50], Step [347/375], Loss: 271.2343\n",
      "Epoch [9/50], Step [348/375], Loss: 107.8436\n",
      "Epoch [9/50], Step [349/375], Loss: 161.9124\n",
      "Epoch [9/50], Step [350/375], Loss: 528.7707\n",
      "Epoch [9/50], Step [351/375], Loss: 133.2496\n",
      "Epoch [9/50], Step [352/375], Loss: 47.8018\n",
      "Epoch [9/50], Step [353/375], Loss: 265.0006\n",
      "Epoch [9/50], Step [354/375], Loss: 237.5463\n",
      "Epoch [9/50], Step [355/375], Loss: 343.0561\n",
      "Epoch [9/50], Step [356/375], Loss: 303.0792\n",
      "Epoch [9/50], Step [357/375], Loss: 333.6382\n",
      "Epoch [9/50], Step [358/375], Loss: 348.6813\n",
      "Epoch [9/50], Step [359/375], Loss: 181.8339\n",
      "Epoch [9/50], Step [360/375], Loss: 165.0426\n",
      "Epoch [9/50], Step [361/375], Loss: 274.7115\n",
      "Epoch [9/50], Step [362/375], Loss: 418.5033\n",
      "Epoch [9/50], Step [363/375], Loss: 480.3473\n",
      "Epoch [9/50], Step [364/375], Loss: 91.0553\n",
      "Epoch [9/50], Step [365/375], Loss: 34.2974\n",
      "Epoch [9/50], Step [366/375], Loss: 252.1351\n",
      "Epoch [9/50], Step [367/375], Loss: 180.5946\n",
      "Epoch [9/50], Step [368/375], Loss: 139.4692\n",
      "Epoch [9/50], Step [369/375], Loss: 837.6837\n",
      "Epoch [9/50], Step [370/375], Loss: 179.9469\n",
      "Epoch [9/50], Step [371/375], Loss: 115.1313\n",
      "Epoch [9/50], Step [372/375], Loss: 34.0858\n",
      "Epoch [9/50], Step [373/375], Loss: 173.8677\n",
      "Epoch [9/50], Step [374/375], Loss: 287.3294\n",
      "Epoch [9/50], Step [375/375], Loss: 189.7292\n",
      "Epoch [10/50], Step [1/375], Loss: 660.7745\n",
      "Epoch [10/50], Step [2/375], Loss: 396.6504\n",
      "Epoch [10/50], Step [3/375], Loss: 417.2352\n",
      "Epoch [10/50], Step [4/375], Loss: 632.0333\n",
      "Epoch [10/50], Step [5/375], Loss: 90.3151\n",
      "Epoch [10/50], Step [6/375], Loss: 169.2707\n",
      "Epoch [10/50], Step [7/375], Loss: 174.2843\n",
      "Epoch [10/50], Step [8/375], Loss: 185.4165\n",
      "Epoch [10/50], Step [9/375], Loss: 930.3735\n",
      "Epoch [10/50], Step [10/375], Loss: 453.4639\n",
      "Epoch [10/50], Step [11/375], Loss: 149.6761\n",
      "Epoch [10/50], Step [12/375], Loss: 273.5846\n",
      "Epoch [10/50], Step [13/375], Loss: 423.8687\n",
      "Epoch [10/50], Step [14/375], Loss: 28.2938\n",
      "Epoch [10/50], Step [15/375], Loss: 303.2564\n",
      "Epoch [10/50], Step [16/375], Loss: 450.2871\n",
      "Epoch [10/50], Step [17/375], Loss: 222.2887\n",
      "Epoch [10/50], Step [18/375], Loss: 409.2899\n",
      "Epoch [10/50], Step [19/375], Loss: 1090.9028\n",
      "Epoch [10/50], Step [20/375], Loss: 572.7065\n",
      "Epoch [10/50], Step [21/375], Loss: 625.1366\n",
      "Epoch [10/50], Step [22/375], Loss: 155.2840\n",
      "Epoch [10/50], Step [23/375], Loss: 235.8187\n",
      "Epoch [10/50], Step [24/375], Loss: 85.7057\n",
      "Epoch [10/50], Step [25/375], Loss: 88.1302\n",
      "Epoch [10/50], Step [26/375], Loss: 734.8250\n",
      "Epoch [10/50], Step [27/375], Loss: 477.3140\n",
      "Epoch [10/50], Step [28/375], Loss: 350.4589\n",
      "Epoch [10/50], Step [29/375], Loss: 258.4086\n",
      "Epoch [10/50], Step [30/375], Loss: 53.2604\n",
      "Epoch [10/50], Step [31/375], Loss: 160.2929\n",
      "Epoch [10/50], Step [32/375], Loss: 671.7666\n",
      "Epoch [10/50], Step [33/375], Loss: 208.1723\n",
      "Epoch [10/50], Step [34/375], Loss: 216.2018\n",
      "Epoch [10/50], Step [35/375], Loss: 547.8657\n",
      "Epoch [10/50], Step [36/375], Loss: 178.3354\n",
      "Epoch [10/50], Step [37/375], Loss: 473.2527\n",
      "Epoch [10/50], Step [38/375], Loss: 151.5719\n",
      "Epoch [10/50], Step [39/375], Loss: 668.8572\n",
      "Epoch [10/50], Step [40/375], Loss: 660.3790\n",
      "Epoch [10/50], Step [41/375], Loss: 520.7874\n",
      "Epoch [10/50], Step [42/375], Loss: 94.0220\n",
      "Epoch [10/50], Step [43/375], Loss: 418.7553\n",
      "Epoch [10/50], Step [44/375], Loss: 674.1098\n",
      "Epoch [10/50], Step [45/375], Loss: 79.2059\n",
      "Epoch [10/50], Step [46/375], Loss: 159.4480\n",
      "Epoch [10/50], Step [47/375], Loss: 71.4632\n",
      "Epoch [10/50], Step [48/375], Loss: 455.2824\n",
      "Epoch [10/50], Step [49/375], Loss: 214.5410\n",
      "Epoch [10/50], Step [50/375], Loss: 115.3324\n",
      "Epoch [10/50], Step [51/375], Loss: 504.6246\n",
      "Epoch [10/50], Step [52/375], Loss: 425.3900\n",
      "Epoch [10/50], Step [53/375], Loss: 158.0023\n",
      "Epoch [10/50], Step [54/375], Loss: 218.2568\n",
      "Epoch [10/50], Step [55/375], Loss: 131.8717\n",
      "Epoch [10/50], Step [56/375], Loss: 539.8642\n",
      "Epoch [10/50], Step [57/375], Loss: 192.9879\n",
      "Epoch [10/50], Step [58/375], Loss: 171.7286\n",
      "Epoch [10/50], Step [59/375], Loss: 195.0903\n",
      "Epoch [10/50], Step [60/375], Loss: 238.8310\n",
      "Epoch [10/50], Step [61/375], Loss: 104.0580\n",
      "Epoch [10/50], Step [62/375], Loss: 483.7238\n",
      "Epoch [10/50], Step [63/375], Loss: 87.1197\n",
      "Epoch [10/50], Step [64/375], Loss: 111.2685\n",
      "Epoch [10/50], Step [65/375], Loss: 443.4606\n",
      "Epoch [10/50], Step [66/375], Loss: 111.1830\n",
      "Epoch [10/50], Step [67/375], Loss: 433.6436\n",
      "Epoch [10/50], Step [68/375], Loss: 51.9102\n",
      "Epoch [10/50], Step [69/375], Loss: 238.2289\n",
      "Epoch [10/50], Step [70/375], Loss: 396.8762\n",
      "Epoch [10/50], Step [71/375], Loss: 625.8593\n",
      "Epoch [10/50], Step [72/375], Loss: 244.1601\n",
      "Epoch [10/50], Step [73/375], Loss: 395.8852\n",
      "Epoch [10/50], Step [74/375], Loss: 481.8920\n",
      "Epoch [10/50], Step [75/375], Loss: 248.6409\n",
      "Epoch [10/50], Step [76/375], Loss: 1240.3727\n",
      "Epoch [10/50], Step [77/375], Loss: 690.1498\n",
      "Epoch [10/50], Step [78/375], Loss: 407.3721\n",
      "Epoch [10/50], Step [79/375], Loss: 102.2947\n",
      "Epoch [10/50], Step [80/375], Loss: 539.7024\n",
      "Epoch [10/50], Step [81/375], Loss: 361.7471\n",
      "Epoch [10/50], Step [82/375], Loss: 94.3839\n",
      "Epoch [10/50], Step [83/375], Loss: 438.7420\n",
      "Epoch [10/50], Step [84/375], Loss: 824.9528\n",
      "Epoch [10/50], Step [85/375], Loss: 213.4881\n",
      "Epoch [10/50], Step [86/375], Loss: 84.4239\n",
      "Epoch [10/50], Step [87/375], Loss: 220.8873\n",
      "Epoch [10/50], Step [88/375], Loss: 602.4084\n",
      "Epoch [10/50], Step [89/375], Loss: 131.8000\n",
      "Epoch [10/50], Step [90/375], Loss: 82.1132\n",
      "Epoch [10/50], Step [91/375], Loss: 331.0355\n",
      "Epoch [10/50], Step [92/375], Loss: 84.1785\n",
      "Epoch [10/50], Step [93/375], Loss: 313.6206\n",
      "Epoch [10/50], Step [94/375], Loss: 784.9449\n",
      "Epoch [10/50], Step [95/375], Loss: 401.6868\n",
      "Epoch [10/50], Step [96/375], Loss: 228.8707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [97/375], Loss: 905.0061\n",
      "Epoch [10/50], Step [98/375], Loss: 302.7169\n",
      "Epoch [10/50], Step [99/375], Loss: 155.8321\n",
      "Epoch [10/50], Step [100/375], Loss: 132.8013\n",
      "Epoch [10/50], Step [101/375], Loss: 477.5134\n",
      "Epoch [10/50], Step [102/375], Loss: 164.8356\n",
      "Epoch [10/50], Step [103/375], Loss: 217.9168\n",
      "Epoch [10/50], Step [104/375], Loss: 435.2779\n",
      "Epoch [10/50], Step [105/375], Loss: 199.1374\n",
      "Epoch [10/50], Step [106/375], Loss: 97.5664\n",
      "Epoch [10/50], Step [107/375], Loss: 215.4558\n",
      "Epoch [10/50], Step [108/375], Loss: 555.1829\n",
      "Epoch [10/50], Step [109/375], Loss: 195.8154\n",
      "Epoch [10/50], Step [110/375], Loss: 53.6013\n",
      "Epoch [10/50], Step [111/375], Loss: 572.6911\n",
      "Epoch [10/50], Step [112/375], Loss: 363.5424\n",
      "Epoch [10/50], Step [113/375], Loss: 346.8384\n",
      "Epoch [10/50], Step [114/375], Loss: 427.3124\n",
      "Epoch [10/50], Step [115/375], Loss: 311.4222\n",
      "Epoch [10/50], Step [116/375], Loss: 140.9984\n",
      "Epoch [10/50], Step [117/375], Loss: 372.7830\n",
      "Epoch [10/50], Step [118/375], Loss: 86.2681\n",
      "Epoch [10/50], Step [119/375], Loss: 209.1161\n",
      "Epoch [10/50], Step [120/375], Loss: 645.7732\n",
      "Epoch [10/50], Step [121/375], Loss: 79.1078\n",
      "Epoch [10/50], Step [122/375], Loss: 203.6215\n",
      "Epoch [10/50], Step [123/375], Loss: 115.0163\n",
      "Epoch [10/50], Step [124/375], Loss: 119.6338\n",
      "Epoch [10/50], Step [125/375], Loss: 664.4614\n",
      "Epoch [10/50], Step [126/375], Loss: 96.4097\n",
      "Epoch [10/50], Step [127/375], Loss: 248.3606\n",
      "Epoch [10/50], Step [128/375], Loss: 145.3043\n",
      "Epoch [10/50], Step [129/375], Loss: 63.1845\n",
      "Epoch [10/50], Step [130/375], Loss: 368.9627\n",
      "Epoch [10/50], Step [131/375], Loss: 294.9080\n",
      "Epoch [10/50], Step [132/375], Loss: 515.4830\n",
      "Epoch [10/50], Step [133/375], Loss: 118.6681\n",
      "Epoch [10/50], Step [134/375], Loss: 221.5125\n",
      "Epoch [10/50], Step [135/375], Loss: 15.4877\n",
      "Epoch [10/50], Step [136/375], Loss: 37.8324\n",
      "Epoch [10/50], Step [137/375], Loss: 278.3260\n",
      "Epoch [10/50], Step [138/375], Loss: 148.8031\n",
      "Epoch [10/50], Step [139/375], Loss: 162.9202\n",
      "Epoch [10/50], Step [140/375], Loss: 603.4342\n",
      "Epoch [10/50], Step [141/375], Loss: 1393.4240\n",
      "Epoch [10/50], Step [142/375], Loss: 50.8014\n",
      "Epoch [10/50], Step [143/375], Loss: 696.8871\n",
      "Epoch [10/50], Step [144/375], Loss: 196.5704\n",
      "Epoch [10/50], Step [145/375], Loss: 236.5935\n",
      "Epoch [10/50], Step [146/375], Loss: 70.4570\n",
      "Epoch [10/50], Step [147/375], Loss: 303.4602\n",
      "Epoch [10/50], Step [148/375], Loss: 216.2860\n",
      "Epoch [10/50], Step [149/375], Loss: 229.4450\n",
      "Epoch [10/50], Step [150/375], Loss: 210.1913\n",
      "Epoch [10/50], Step [151/375], Loss: 167.0882\n",
      "Epoch [10/50], Step [152/375], Loss: 29.0362\n",
      "Epoch [10/50], Step [153/375], Loss: 400.6942\n",
      "Epoch [10/50], Step [154/375], Loss: 32.8728\n",
      "Epoch [10/50], Step [155/375], Loss: 207.9993\n",
      "Epoch [10/50], Step [156/375], Loss: 605.7651\n",
      "Epoch [10/50], Step [157/375], Loss: 308.6886\n",
      "Epoch [10/50], Step [158/375], Loss: 257.8381\n",
      "Epoch [10/50], Step [159/375], Loss: 115.0753\n",
      "Epoch [10/50], Step [160/375], Loss: 252.8682\n",
      "Epoch [10/50], Step [161/375], Loss: 157.8033\n",
      "Epoch [10/50], Step [162/375], Loss: 215.4404\n",
      "Epoch [10/50], Step [163/375], Loss: 477.1731\n",
      "Epoch [10/50], Step [164/375], Loss: 116.4499\n",
      "Epoch [10/50], Step [165/375], Loss: 402.0491\n",
      "Epoch [10/50], Step [166/375], Loss: 183.9758\n",
      "Epoch [10/50], Step [167/375], Loss: 171.8887\n",
      "Epoch [10/50], Step [168/375], Loss: 88.0093\n",
      "Epoch [10/50], Step [169/375], Loss: 211.9269\n",
      "Epoch [10/50], Step [170/375], Loss: 809.5322\n",
      "Epoch [10/50], Step [171/375], Loss: 213.3089\n",
      "Epoch [10/50], Step [172/375], Loss: 204.9067\n",
      "Epoch [10/50], Step [173/375], Loss: 87.6025\n",
      "Epoch [10/50], Step [174/375], Loss: 179.3317\n",
      "Epoch [10/50], Step [175/375], Loss: 485.0499\n",
      "Epoch [10/50], Step [176/375], Loss: 78.7074\n",
      "Epoch [10/50], Step [177/375], Loss: 172.2097\n",
      "Epoch [10/50], Step [178/375], Loss: 502.5910\n",
      "Epoch [10/50], Step [179/375], Loss: 562.0253\n",
      "Epoch [10/50], Step [180/375], Loss: 200.3673\n",
      "Epoch [10/50], Step [181/375], Loss: 129.1246\n",
      "Epoch [10/50], Step [182/375], Loss: 421.2351\n",
      "Epoch [10/50], Step [183/375], Loss: 127.3092\n",
      "Epoch [10/50], Step [184/375], Loss: 371.3419\n",
      "Epoch [10/50], Step [185/375], Loss: 146.5616\n",
      "Epoch [10/50], Step [186/375], Loss: 361.0595\n",
      "Epoch [10/50], Step [187/375], Loss: 43.5940\n",
      "Epoch [10/50], Step [188/375], Loss: 1513.9067\n",
      "Epoch [10/50], Step [189/375], Loss: 265.6683\n",
      "Epoch [10/50], Step [190/375], Loss: 285.1196\n",
      "Epoch [10/50], Step [191/375], Loss: 104.2428\n",
      "Epoch [10/50], Step [192/375], Loss: 78.7584\n",
      "Epoch [10/50], Step [193/375], Loss: 137.9646\n",
      "Epoch [10/50], Step [194/375], Loss: 184.5780\n",
      "Epoch [10/50], Step [195/375], Loss: 988.7656\n",
      "Epoch [10/50], Step [196/375], Loss: 872.0771\n",
      "Epoch [10/50], Step [197/375], Loss: 551.1656\n",
      "Epoch [10/50], Step [198/375], Loss: 142.5412\n",
      "Epoch [10/50], Step [199/375], Loss: 210.6982\n",
      "Epoch [10/50], Step [200/375], Loss: 329.6643\n",
      "Epoch [10/50], Step [201/375], Loss: 350.2456\n",
      "Epoch [10/50], Step [202/375], Loss: 396.9255\n",
      "Epoch [10/50], Step [203/375], Loss: 187.0896\n",
      "Epoch [10/50], Step [204/375], Loss: 62.0533\n",
      "Epoch [10/50], Step [205/375], Loss: 224.4138\n",
      "Epoch [10/50], Step [206/375], Loss: 120.9895\n",
      "Epoch [10/50], Step [207/375], Loss: 153.9312\n",
      "Epoch [10/50], Step [208/375], Loss: 283.7719\n",
      "Epoch [10/50], Step [209/375], Loss: 98.7791\n",
      "Epoch [10/50], Step [210/375], Loss: 294.5947\n",
      "Epoch [10/50], Step [211/375], Loss: 10.4810\n",
      "Epoch [10/50], Step [212/375], Loss: 227.9991\n",
      "Epoch [10/50], Step [213/375], Loss: 107.6207\n",
      "Epoch [10/50], Step [214/375], Loss: 255.3339\n",
      "Epoch [10/50], Step [215/375], Loss: 141.7939\n",
      "Epoch [10/50], Step [216/375], Loss: 67.8747\n",
      "Epoch [10/50], Step [217/375], Loss: 307.6019\n",
      "Epoch [10/50], Step [218/375], Loss: 288.8743\n",
      "Epoch [10/50], Step [219/375], Loss: 304.6312\n",
      "Epoch [10/50], Step [220/375], Loss: 247.7646\n",
      "Epoch [10/50], Step [221/375], Loss: 358.7285\n",
      "Epoch [10/50], Step [222/375], Loss: 321.9991\n",
      "Epoch [10/50], Step [223/375], Loss: 230.7096\n",
      "Epoch [10/50], Step [224/375], Loss: 219.9655\n",
      "Epoch [10/50], Step [225/375], Loss: 161.1017\n",
      "Epoch [10/50], Step [226/375], Loss: 385.2484\n",
      "Epoch [10/50], Step [227/375], Loss: 210.2141\n",
      "Epoch [10/50], Step [228/375], Loss: 120.1410\n",
      "Epoch [10/50], Step [229/375], Loss: 820.4930\n",
      "Epoch [10/50], Step [230/375], Loss: 219.5313\n",
      "Epoch [10/50], Step [231/375], Loss: 286.2546\n",
      "Epoch [10/50], Step [232/375], Loss: 920.5578\n",
      "Epoch [10/50], Step [233/375], Loss: 180.1603\n",
      "Epoch [10/50], Step [234/375], Loss: 299.9758\n",
      "Epoch [10/50], Step [235/375], Loss: 500.6808\n",
      "Epoch [10/50], Step [236/375], Loss: 154.7275\n",
      "Epoch [10/50], Step [237/375], Loss: 360.7383\n",
      "Epoch [10/50], Step [238/375], Loss: 232.2209\n",
      "Epoch [10/50], Step [239/375], Loss: 125.9766\n",
      "Epoch [10/50], Step [240/375], Loss: 700.9078\n",
      "Epoch [10/50], Step [241/375], Loss: 178.5931\n",
      "Epoch [10/50], Step [242/375], Loss: 208.9878\n",
      "Epoch [10/50], Step [243/375], Loss: 101.9707\n",
      "Epoch [10/50], Step [244/375], Loss: 260.9099\n",
      "Epoch [10/50], Step [245/375], Loss: 1133.5320\n",
      "Epoch [10/50], Step [246/375], Loss: 187.5581\n",
      "Epoch [10/50], Step [247/375], Loss: 253.8860\n",
      "Epoch [10/50], Step [248/375], Loss: 153.4142\n",
      "Epoch [10/50], Step [249/375], Loss: 389.0478\n",
      "Epoch [10/50], Step [250/375], Loss: 634.1799\n",
      "Epoch [10/50], Step [251/375], Loss: 1609.4353\n",
      "Epoch [10/50], Step [252/375], Loss: 246.1424\n",
      "Epoch [10/50], Step [253/375], Loss: 290.7347\n",
      "Epoch [10/50], Step [254/375], Loss: 219.4632\n",
      "Epoch [10/50], Step [255/375], Loss: 199.0079\n",
      "Epoch [10/50], Step [256/375], Loss: 1107.4507\n",
      "Epoch [10/50], Step [257/375], Loss: 350.1715\n",
      "Epoch [10/50], Step [258/375], Loss: 638.6539\n",
      "Epoch [10/50], Step [259/375], Loss: 366.8763\n",
      "Epoch [10/50], Step [260/375], Loss: 180.6257\n",
      "Epoch [10/50], Step [261/375], Loss: 615.3901\n",
      "Epoch [10/50], Step [262/375], Loss: 171.1192\n",
      "Epoch [10/50], Step [263/375], Loss: 320.7790\n",
      "Epoch [10/50], Step [264/375], Loss: 819.2217\n",
      "Epoch [10/50], Step [265/375], Loss: 281.2838\n",
      "Epoch [10/50], Step [266/375], Loss: 230.3132\n",
      "Epoch [10/50], Step [267/375], Loss: 107.3564\n",
      "Epoch [10/50], Step [268/375], Loss: 195.5108\n",
      "Epoch [10/50], Step [269/375], Loss: 121.5347\n",
      "Epoch [10/50], Step [270/375], Loss: 68.1298\n",
      "Epoch [10/50], Step [271/375], Loss: 153.7787\n",
      "Epoch [10/50], Step [272/375], Loss: 384.1655\n",
      "Epoch [10/50], Step [273/375], Loss: 708.3022\n",
      "Epoch [10/50], Step [274/375], Loss: 470.1763\n",
      "Epoch [10/50], Step [275/375], Loss: 399.0219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [276/375], Loss: 561.5078\n",
      "Epoch [10/50], Step [277/375], Loss: 69.8435\n",
      "Epoch [10/50], Step [278/375], Loss: 485.5443\n",
      "Epoch [10/50], Step [279/375], Loss: 194.0294\n",
      "Epoch [10/50], Step [280/375], Loss: 128.6839\n",
      "Epoch [10/50], Step [281/375], Loss: 180.9920\n",
      "Epoch [10/50], Step [282/375], Loss: 1099.3781\n",
      "Epoch [10/50], Step [283/375], Loss: 164.1377\n",
      "Epoch [10/50], Step [284/375], Loss: 137.9154\n",
      "Epoch [10/50], Step [285/375], Loss: 509.5755\n",
      "Epoch [10/50], Step [286/375], Loss: 755.7412\n",
      "Epoch [10/50], Step [287/375], Loss: 657.6324\n",
      "Epoch [10/50], Step [288/375], Loss: 574.4731\n",
      "Epoch [10/50], Step [289/375], Loss: 327.6023\n",
      "Epoch [10/50], Step [290/375], Loss: 314.7544\n",
      "Epoch [10/50], Step [291/375], Loss: 166.5984\n",
      "Epoch [10/50], Step [292/375], Loss: 174.3405\n",
      "Epoch [10/50], Step [293/375], Loss: 139.4468\n",
      "Epoch [10/50], Step [294/375], Loss: 615.9415\n",
      "Epoch [10/50], Step [295/375], Loss: 43.0486\n",
      "Epoch [10/50], Step [296/375], Loss: 342.5482\n",
      "Epoch [10/50], Step [297/375], Loss: 203.1743\n",
      "Epoch [10/50], Step [298/375], Loss: 615.8348\n",
      "Epoch [10/50], Step [299/375], Loss: 360.3134\n",
      "Epoch [10/50], Step [300/375], Loss: 337.0239\n",
      "Epoch [10/50], Step [301/375], Loss: 241.9669\n",
      "Epoch [10/50], Step [302/375], Loss: 320.9668\n",
      "Epoch [10/50], Step [303/375], Loss: 482.8982\n",
      "Epoch [10/50], Step [304/375], Loss: 426.4810\n",
      "Epoch [10/50], Step [305/375], Loss: 317.6386\n",
      "Epoch [10/50], Step [306/375], Loss: 192.9903\n",
      "Epoch [10/50], Step [307/375], Loss: 1764.8710\n",
      "Epoch [10/50], Step [308/375], Loss: 118.0619\n",
      "Epoch [10/50], Step [309/375], Loss: 293.3170\n",
      "Epoch [10/50], Step [310/375], Loss: 2338.0869\n",
      "Epoch [10/50], Step [311/375], Loss: 458.2439\n",
      "Epoch [10/50], Step [312/375], Loss: 814.9446\n",
      "Epoch [10/50], Step [313/375], Loss: 383.9444\n",
      "Epoch [10/50], Step [314/375], Loss: 1019.9296\n",
      "Epoch [10/50], Step [315/375], Loss: 1120.9614\n",
      "Epoch [10/50], Step [316/375], Loss: 195.2090\n",
      "Epoch [10/50], Step [317/375], Loss: 544.8282\n",
      "Epoch [10/50], Step [318/375], Loss: 425.3496\n",
      "Epoch [10/50], Step [319/375], Loss: 509.2148\n",
      "Epoch [10/50], Step [320/375], Loss: 658.6110\n",
      "Epoch [10/50], Step [321/375], Loss: 445.6668\n",
      "Epoch [10/50], Step [322/375], Loss: 162.5403\n",
      "Epoch [10/50], Step [323/375], Loss: 260.8589\n",
      "Epoch [10/50], Step [324/375], Loss: 219.4351\n",
      "Epoch [10/50], Step [325/375], Loss: 285.3913\n",
      "Epoch [10/50], Step [326/375], Loss: 446.2111\n",
      "Epoch [10/50], Step [327/375], Loss: 394.9418\n",
      "Epoch [10/50], Step [328/375], Loss: 271.5177\n",
      "Epoch [10/50], Step [329/375], Loss: 841.2327\n",
      "Epoch [10/50], Step [330/375], Loss: 158.2269\n",
      "Epoch [10/50], Step [331/375], Loss: 389.5767\n",
      "Epoch [10/50], Step [332/375], Loss: 584.8395\n",
      "Epoch [10/50], Step [333/375], Loss: 341.4116\n",
      "Epoch [10/50], Step [334/375], Loss: 376.1742\n",
      "Epoch [10/50], Step [335/375], Loss: 127.9011\n",
      "Epoch [10/50], Step [336/375], Loss: 737.1269\n",
      "Epoch [10/50], Step [337/375], Loss: 86.8955\n",
      "Epoch [10/50], Step [338/375], Loss: 210.8522\n",
      "Epoch [10/50], Step [339/375], Loss: 319.9625\n",
      "Epoch [10/50], Step [340/375], Loss: 618.2365\n",
      "Epoch [10/50], Step [341/375], Loss: 731.5699\n",
      "Epoch [10/50], Step [342/375], Loss: 448.7962\n",
      "Epoch [10/50], Step [343/375], Loss: 651.8868\n",
      "Epoch [10/50], Step [344/375], Loss: 290.0058\n",
      "Epoch [10/50], Step [345/375], Loss: 672.1460\n",
      "Epoch [10/50], Step [346/375], Loss: 489.6635\n",
      "Epoch [10/50], Step [347/375], Loss: 236.3940\n",
      "Epoch [10/50], Step [348/375], Loss: 84.0138\n",
      "Epoch [10/50], Step [349/375], Loss: 479.5781\n",
      "Epoch [10/50], Step [350/375], Loss: 159.9618\n",
      "Epoch [10/50], Step [351/375], Loss: 1209.7778\n",
      "Epoch [10/50], Step [352/375], Loss: 1206.4401\n",
      "Epoch [10/50], Step [353/375], Loss: 242.6031\n",
      "Epoch [10/50], Step [354/375], Loss: 135.6489\n",
      "Epoch [10/50], Step [355/375], Loss: 407.3855\n",
      "Epoch [10/50], Step [356/375], Loss: 189.0698\n",
      "Epoch [10/50], Step [357/375], Loss: 849.2252\n",
      "Epoch [10/50], Step [358/375], Loss: 551.0266\n",
      "Epoch [10/50], Step [359/375], Loss: 464.8976\n",
      "Epoch [10/50], Step [360/375], Loss: 615.4860\n",
      "Epoch [10/50], Step [361/375], Loss: 249.6808\n",
      "Epoch [10/50], Step [362/375], Loss: 74.0240\n",
      "Epoch [10/50], Step [363/375], Loss: 994.2420\n",
      "Epoch [10/50], Step [364/375], Loss: 157.8678\n",
      "Epoch [10/50], Step [365/375], Loss: 104.2525\n",
      "Epoch [10/50], Step [366/375], Loss: 560.1978\n",
      "Epoch [10/50], Step [367/375], Loss: 232.8329\n",
      "Epoch [10/50], Step [368/375], Loss: 318.8317\n",
      "Epoch [10/50], Step [369/375], Loss: 1063.1508\n",
      "Epoch [10/50], Step [370/375], Loss: 295.0259\n",
      "Epoch [10/50], Step [371/375], Loss: 123.9567\n",
      "Epoch [10/50], Step [372/375], Loss: 460.9865\n",
      "Epoch [10/50], Step [373/375], Loss: 193.2872\n",
      "Epoch [10/50], Step [374/375], Loss: 890.6201\n",
      "Epoch [10/50], Step [375/375], Loss: 204.8888\n",
      "Epoch [11/50], Step [1/375], Loss: 553.6758\n",
      "Epoch [11/50], Step [2/375], Loss: 329.0037\n",
      "Epoch [11/50], Step [3/375], Loss: 161.3609\n",
      "Epoch [11/50], Step [4/375], Loss: 380.5778\n",
      "Epoch [11/50], Step [5/375], Loss: 296.1357\n",
      "Epoch [11/50], Step [6/375], Loss: 372.3250\n",
      "Epoch [11/50], Step [7/375], Loss: 131.9943\n",
      "Epoch [11/50], Step [8/375], Loss: 59.3038\n",
      "Epoch [11/50], Step [9/375], Loss: 111.1448\n",
      "Epoch [11/50], Step [10/375], Loss: 496.2074\n",
      "Epoch [11/50], Step [11/375], Loss: 77.6151\n",
      "Epoch [11/50], Step [12/375], Loss: 197.9618\n",
      "Epoch [11/50], Step [13/375], Loss: 442.7686\n",
      "Epoch [11/50], Step [14/375], Loss: 455.8709\n",
      "Epoch [11/50], Step [15/375], Loss: 147.3851\n",
      "Epoch [11/50], Step [16/375], Loss: 182.7199\n",
      "Epoch [11/50], Step [17/375], Loss: 53.9994\n",
      "Epoch [11/50], Step [18/375], Loss: 626.8240\n",
      "Epoch [11/50], Step [19/375], Loss: 408.8769\n",
      "Epoch [11/50], Step [20/375], Loss: 251.8188\n",
      "Epoch [11/50], Step [21/375], Loss: 183.1990\n",
      "Epoch [11/50], Step [22/375], Loss: 326.7637\n",
      "Epoch [11/50], Step [23/375], Loss: 322.6481\n",
      "Epoch [11/50], Step [24/375], Loss: 1187.5188\n",
      "Epoch [11/50], Step [25/375], Loss: 256.8965\n",
      "Epoch [11/50], Step [26/375], Loss: 424.2960\n",
      "Epoch [11/50], Step [27/375], Loss: 230.6937\n",
      "Epoch [11/50], Step [28/375], Loss: 747.1189\n",
      "Epoch [11/50], Step [29/375], Loss: 150.4554\n",
      "Epoch [11/50], Step [30/375], Loss: 406.9044\n",
      "Epoch [11/50], Step [31/375], Loss: 155.6892\n",
      "Epoch [11/50], Step [32/375], Loss: 189.9174\n",
      "Epoch [11/50], Step [33/375], Loss: 472.9807\n",
      "Epoch [11/50], Step [34/375], Loss: 167.0141\n",
      "Epoch [11/50], Step [35/375], Loss: 1226.3943\n",
      "Epoch [11/50], Step [36/375], Loss: 403.0486\n",
      "Epoch [11/50], Step [37/375], Loss: 493.9985\n",
      "Epoch [11/50], Step [38/375], Loss: 869.2765\n",
      "Epoch [11/50], Step [39/375], Loss: 1775.3118\n",
      "Epoch [11/50], Step [40/375], Loss: 957.4606\n",
      "Epoch [11/50], Step [41/375], Loss: 406.3833\n",
      "Epoch [11/50], Step [42/375], Loss: 172.3199\n",
      "Epoch [11/50], Step [43/375], Loss: 336.7415\n",
      "Epoch [11/50], Step [44/375], Loss: 179.8191\n",
      "Epoch [11/50], Step [45/375], Loss: 549.8973\n",
      "Epoch [11/50], Step [46/375], Loss: 393.0789\n",
      "Epoch [11/50], Step [47/375], Loss: 438.8737\n",
      "Epoch [11/50], Step [48/375], Loss: 245.4798\n",
      "Epoch [11/50], Step [49/375], Loss: 230.9972\n",
      "Epoch [11/50], Step [50/375], Loss: 507.2667\n",
      "Epoch [11/50], Step [51/375], Loss: 561.9402\n",
      "Epoch [11/50], Step [52/375], Loss: 603.6393\n",
      "Epoch [11/50], Step [53/375], Loss: 521.7923\n",
      "Epoch [11/50], Step [54/375], Loss: 210.1992\n",
      "Epoch [11/50], Step [55/375], Loss: 418.1677\n",
      "Epoch [11/50], Step [56/375], Loss: 560.8846\n",
      "Epoch [11/50], Step [57/375], Loss: 999.6373\n",
      "Epoch [11/50], Step [58/375], Loss: 624.2422\n",
      "Epoch [11/50], Step [59/375], Loss: 495.9919\n",
      "Epoch [11/50], Step [60/375], Loss: 897.2050\n",
      "Epoch [11/50], Step [61/375], Loss: 236.5435\n",
      "Epoch [11/50], Step [62/375], Loss: 107.1861\n",
      "Epoch [11/50], Step [63/375], Loss: 66.7084\n",
      "Epoch [11/50], Step [64/375], Loss: 332.2939\n",
      "Epoch [11/50], Step [65/375], Loss: 294.9211\n",
      "Epoch [11/50], Step [66/375], Loss: 857.8747\n",
      "Epoch [11/50], Step [67/375], Loss: 987.4459\n",
      "Epoch [11/50], Step [68/375], Loss: 1362.2137\n",
      "Epoch [11/50], Step [69/375], Loss: 474.6712\n",
      "Epoch [11/50], Step [70/375], Loss: 665.5950\n",
      "Epoch [11/50], Step [71/375], Loss: 274.9920\n",
      "Epoch [11/50], Step [72/375], Loss: 659.6562\n",
      "Epoch [11/50], Step [73/375], Loss: 1699.3824\n",
      "Epoch [11/50], Step [74/375], Loss: 793.5005\n",
      "Epoch [11/50], Step [75/375], Loss: 524.8256\n",
      "Epoch [11/50], Step [76/375], Loss: 202.8250\n",
      "Epoch [11/50], Step [77/375], Loss: 307.8192\n",
      "Epoch [11/50], Step [78/375], Loss: 130.1059\n",
      "Epoch [11/50], Step [79/375], Loss: 297.2195\n",
      "Epoch [11/50], Step [80/375], Loss: 1177.2725\n",
      "Epoch [11/50], Step [81/375], Loss: 930.2742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Step [82/375], Loss: 703.9904\n",
      "Epoch [11/50], Step [83/375], Loss: 966.2780\n",
      "Epoch [11/50], Step [84/375], Loss: 209.6275\n",
      "Epoch [11/50], Step [85/375], Loss: 705.8029\n",
      "Epoch [11/50], Step [86/375], Loss: 1407.5332\n",
      "Epoch [11/50], Step [87/375], Loss: 1250.3094\n",
      "Epoch [11/50], Step [88/375], Loss: 1863.3851\n",
      "Epoch [11/50], Step [89/375], Loss: 1641.2739\n",
      "Epoch [11/50], Step [90/375], Loss: 92.1379\n",
      "Epoch [11/50], Step [91/375], Loss: 42.6635\n",
      "Epoch [11/50], Step [92/375], Loss: 998.7099\n",
      "Epoch [11/50], Step [93/375], Loss: 939.3417\n",
      "Epoch [11/50], Step [94/375], Loss: 692.8993\n",
      "Epoch [11/50], Step [95/375], Loss: 1431.0416\n",
      "Epoch [11/50], Step [96/375], Loss: 760.0054\n",
      "Epoch [11/50], Step [97/375], Loss: 229.5663\n",
      "Epoch [11/50], Step [98/375], Loss: 76.7210\n",
      "Epoch [11/50], Step [99/375], Loss: 462.9601\n",
      "Epoch [11/50], Step [100/375], Loss: 332.5035\n",
      "Epoch [11/50], Step [101/375], Loss: 232.9635\n",
      "Epoch [11/50], Step [102/375], Loss: 621.5132\n",
      "Epoch [11/50], Step [103/375], Loss: 291.1852\n",
      "Epoch [11/50], Step [104/375], Loss: 245.9807\n",
      "Epoch [11/50], Step [105/375], Loss: 791.1219\n",
      "Epoch [11/50], Step [106/375], Loss: 116.7843\n",
      "Epoch [11/50], Step [107/375], Loss: 539.7456\n",
      "Epoch [11/50], Step [108/375], Loss: 265.9897\n",
      "Epoch [11/50], Step [109/375], Loss: 1740.5571\n",
      "Epoch [11/50], Step [110/375], Loss: 275.8259\n",
      "Epoch [11/50], Step [111/375], Loss: 170.4402\n",
      "Epoch [11/50], Step [112/375], Loss: 593.2932\n",
      "Epoch [11/50], Step [113/375], Loss: 519.3567\n",
      "Epoch [11/50], Step [114/375], Loss: 312.7538\n",
      "Epoch [11/50], Step [115/375], Loss: 1079.5746\n",
      "Epoch [11/50], Step [116/375], Loss: 904.0828\n",
      "Epoch [11/50], Step [117/375], Loss: 1614.6299\n",
      "Epoch [11/50], Step [118/375], Loss: 1131.4099\n",
      "Epoch [11/50], Step [119/375], Loss: 507.2404\n",
      "Epoch [11/50], Step [120/375], Loss: 282.3580\n",
      "Epoch [11/50], Step [121/375], Loss: 582.3037\n",
      "Epoch [11/50], Step [122/375], Loss: 669.5968\n",
      "Epoch [11/50], Step [123/375], Loss: 743.5283\n",
      "Epoch [11/50], Step [124/375], Loss: 492.2856\n",
      "Epoch [11/50], Step [125/375], Loss: 203.3083\n",
      "Epoch [11/50], Step [126/375], Loss: 378.0818\n",
      "Epoch [11/50], Step [127/375], Loss: 663.4719\n",
      "Epoch [11/50], Step [128/375], Loss: 48.0418\n",
      "Epoch [11/50], Step [129/375], Loss: 509.1325\n",
      "Epoch [11/50], Step [130/375], Loss: 70.1341\n",
      "Epoch [11/50], Step [131/375], Loss: 947.9208\n",
      "Epoch [11/50], Step [132/375], Loss: 97.7650\n",
      "Epoch [11/50], Step [133/375], Loss: 490.0607\n",
      "Epoch [11/50], Step [134/375], Loss: 192.9026\n",
      "Epoch [11/50], Step [135/375], Loss: 172.6970\n",
      "Epoch [11/50], Step [136/375], Loss: 126.6159\n",
      "Epoch [11/50], Step [137/375], Loss: 1179.8571\n",
      "Epoch [11/50], Step [138/375], Loss: 425.7570\n",
      "Epoch [11/50], Step [139/375], Loss: 151.1928\n",
      "Epoch [11/50], Step [140/375], Loss: 313.8639\n",
      "Epoch [11/50], Step [141/375], Loss: 552.3674\n",
      "Epoch [11/50], Step [142/375], Loss: 342.4858\n",
      "Epoch [11/50], Step [143/375], Loss: 336.7137\n",
      "Epoch [11/50], Step [144/375], Loss: 117.8868\n",
      "Epoch [11/50], Step [145/375], Loss: 461.7037\n",
      "Epoch [11/50], Step [146/375], Loss: 455.4462\n",
      "Epoch [11/50], Step [147/375], Loss: 1553.7649\n",
      "Epoch [11/50], Step [148/375], Loss: 276.0603\n",
      "Epoch [11/50], Step [149/375], Loss: 305.1038\n",
      "Epoch [11/50], Step [150/375], Loss: 206.4768\n",
      "Epoch [11/50], Step [151/375], Loss: 521.8663\n",
      "Epoch [11/50], Step [152/375], Loss: 380.0413\n",
      "Epoch [11/50], Step [153/375], Loss: 315.5913\n",
      "Epoch [11/50], Step [154/375], Loss: 225.9719\n",
      "Epoch [11/50], Step [155/375], Loss: 604.0653\n",
      "Epoch [11/50], Step [156/375], Loss: 409.6656\n",
      "Epoch [11/50], Step [157/375], Loss: 239.7557\n",
      "Epoch [11/50], Step [158/375], Loss: 82.2310\n",
      "Epoch [11/50], Step [159/375], Loss: 303.7411\n",
      "Epoch [11/50], Step [160/375], Loss: 625.9021\n",
      "Epoch [11/50], Step [161/375], Loss: 292.0859\n",
      "Epoch [11/50], Step [162/375], Loss: 71.6819\n",
      "Epoch [11/50], Step [163/375], Loss: 903.0295\n",
      "Epoch [11/50], Step [164/375], Loss: 212.2905\n",
      "Epoch [11/50], Step [165/375], Loss: 44.4814\n",
      "Epoch [11/50], Step [166/375], Loss: 154.6747\n",
      "Epoch [11/50], Step [167/375], Loss: 115.6969\n",
      "Epoch [11/50], Step [168/375], Loss: 156.4646\n",
      "Epoch [11/50], Step [169/375], Loss: 454.4007\n",
      "Epoch [11/50], Step [170/375], Loss: 506.1547\n",
      "Epoch [11/50], Step [171/375], Loss: 146.0693\n",
      "Epoch [11/50], Step [172/375], Loss: 331.2341\n",
      "Epoch [11/50], Step [173/375], Loss: 1062.5009\n",
      "Epoch [11/50], Step [174/375], Loss: 425.4929\n",
      "Epoch [11/50], Step [175/375], Loss: 196.6492\n",
      "Epoch [11/50], Step [176/375], Loss: 124.8277\n",
      "Epoch [11/50], Step [177/375], Loss: 444.4496\n",
      "Epoch [11/50], Step [178/375], Loss: 699.6200\n",
      "Epoch [11/50], Step [179/375], Loss: 145.0719\n",
      "Epoch [11/50], Step [180/375], Loss: 139.4803\n",
      "Epoch [11/50], Step [181/375], Loss: 120.5918\n",
      "Epoch [11/50], Step [182/375], Loss: 335.8112\n",
      "Epoch [11/50], Step [183/375], Loss: 189.8727\n",
      "Epoch [11/50], Step [184/375], Loss: 342.5861\n",
      "Epoch [11/50], Step [185/375], Loss: 206.6016\n",
      "Epoch [11/50], Step [186/375], Loss: 342.2370\n",
      "Epoch [11/50], Step [187/375], Loss: 214.7815\n",
      "Epoch [11/50], Step [188/375], Loss: 344.1821\n",
      "Epoch [11/50], Step [189/375], Loss: 1813.6621\n",
      "Epoch [11/50], Step [190/375], Loss: 281.3462\n",
      "Epoch [11/50], Step [191/375], Loss: 289.5768\n",
      "Epoch [11/50], Step [192/375], Loss: 590.5596\n",
      "Epoch [11/50], Step [193/375], Loss: 434.3524\n",
      "Epoch [11/50], Step [194/375], Loss: 93.9854\n",
      "Epoch [11/50], Step [195/375], Loss: 1133.6818\n",
      "Epoch [11/50], Step [196/375], Loss: 77.7684\n",
      "Epoch [11/50], Step [197/375], Loss: 185.5807\n",
      "Epoch [11/50], Step [198/375], Loss: 399.8599\n",
      "Epoch [11/50], Step [199/375], Loss: 468.7113\n",
      "Epoch [11/50], Step [200/375], Loss: 319.6843\n",
      "Epoch [11/50], Step [201/375], Loss: 314.3925\n",
      "Epoch [11/50], Step [202/375], Loss: 128.4314\n",
      "Epoch [11/50], Step [203/375], Loss: 104.0723\n",
      "Epoch [11/50], Step [204/375], Loss: 385.6743\n",
      "Epoch [11/50], Step [205/375], Loss: 145.3328\n",
      "Epoch [11/50], Step [206/375], Loss: 348.1348\n",
      "Epoch [11/50], Step [207/375], Loss: 285.3392\n",
      "Epoch [11/50], Step [208/375], Loss: 42.9929\n",
      "Epoch [11/50], Step [209/375], Loss: 486.4047\n",
      "Epoch [11/50], Step [210/375], Loss: 169.6713\n",
      "Epoch [11/50], Step [211/375], Loss: 273.8641\n",
      "Epoch [11/50], Step [212/375], Loss: 180.5723\n",
      "Epoch [11/50], Step [213/375], Loss: 428.8715\n",
      "Epoch [11/50], Step [214/375], Loss: 159.3268\n",
      "Epoch [11/50], Step [215/375], Loss: 225.4356\n",
      "Epoch [11/50], Step [216/375], Loss: 180.2396\n",
      "Epoch [11/50], Step [217/375], Loss: 768.5006\n",
      "Epoch [11/50], Step [218/375], Loss: 488.8201\n",
      "Epoch [11/50], Step [219/375], Loss: 209.5850\n",
      "Epoch [11/50], Step [220/375], Loss: 831.5347\n",
      "Epoch [11/50], Step [221/375], Loss: 313.1934\n",
      "Epoch [11/50], Step [222/375], Loss: 840.2524\n",
      "Epoch [11/50], Step [223/375], Loss: 60.2284\n",
      "Epoch [11/50], Step [224/375], Loss: 479.9747\n",
      "Epoch [11/50], Step [225/375], Loss: 827.0029\n",
      "Epoch [11/50], Step [226/375], Loss: 671.8452\n",
      "Epoch [11/50], Step [227/375], Loss: 1510.5942\n",
      "Epoch [11/50], Step [228/375], Loss: 131.6656\n",
      "Epoch [11/50], Step [229/375], Loss: 546.6566\n",
      "Epoch [11/50], Step [230/375], Loss: 520.8793\n",
      "Epoch [11/50], Step [231/375], Loss: 656.6277\n",
      "Epoch [11/50], Step [232/375], Loss: 685.9657\n",
      "Epoch [11/50], Step [233/375], Loss: 832.7838\n",
      "Epoch [11/50], Step [234/375], Loss: 1264.9954\n",
      "Epoch [11/50], Step [235/375], Loss: 402.0876\n",
      "Epoch [11/50], Step [236/375], Loss: 532.9156\n",
      "Epoch [11/50], Step [237/375], Loss: 130.8594\n",
      "Epoch [11/50], Step [238/375], Loss: 157.2208\n",
      "Epoch [11/50], Step [239/375], Loss: 849.7162\n",
      "Epoch [11/50], Step [240/375], Loss: 1596.0138\n",
      "Epoch [11/50], Step [241/375], Loss: 513.8563\n",
      "Epoch [11/50], Step [242/375], Loss: 511.1261\n",
      "Epoch [11/50], Step [243/375], Loss: 620.7578\n",
      "Epoch [11/50], Step [244/375], Loss: 132.5037\n",
      "Epoch [11/50], Step [245/375], Loss: 748.2275\n",
      "Epoch [11/50], Step [246/375], Loss: 312.2201\n",
      "Epoch [11/50], Step [247/375], Loss: 147.1475\n",
      "Epoch [11/50], Step [248/375], Loss: 143.0785\n",
      "Epoch [11/50], Step [249/375], Loss: 1122.0687\n",
      "Epoch [11/50], Step [250/375], Loss: 362.5031\n",
      "Epoch [11/50], Step [251/375], Loss: 713.0619\n",
      "Epoch [11/50], Step [252/375], Loss: 733.3623\n",
      "Epoch [11/50], Step [253/375], Loss: 380.4478\n",
      "Epoch [11/50], Step [254/375], Loss: 1233.0101\n",
      "Epoch [11/50], Step [255/375], Loss: 2289.8015\n",
      "Epoch [11/50], Step [256/375], Loss: 266.6516\n",
      "Epoch [11/50], Step [257/375], Loss: 872.6030\n",
      "Epoch [11/50], Step [258/375], Loss: 670.1159\n",
      "Epoch [11/50], Step [259/375], Loss: 180.4282\n",
      "Epoch [11/50], Step [260/375], Loss: 666.2861\n",
      "Epoch [11/50], Step [261/375], Loss: 313.5565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Step [262/375], Loss: 968.1425\n",
      "Epoch [11/50], Step [263/375], Loss: 294.8168\n",
      "Epoch [11/50], Step [264/375], Loss: 928.6346\n",
      "Epoch [11/50], Step [265/375], Loss: 489.9063\n",
      "Epoch [11/50], Step [266/375], Loss: 538.2960\n",
      "Epoch [11/50], Step [267/375], Loss: 367.2756\n",
      "Epoch [11/50], Step [268/375], Loss: 164.7632\n",
      "Epoch [11/50], Step [269/375], Loss: 783.0475\n",
      "Epoch [11/50], Step [270/375], Loss: 79.2141\n",
      "Epoch [11/50], Step [271/375], Loss: 1157.5122\n",
      "Epoch [11/50], Step [272/375], Loss: 345.8337\n",
      "Epoch [11/50], Step [273/375], Loss: 569.2805\n",
      "Epoch [11/50], Step [274/375], Loss: 64.3384\n",
      "Epoch [11/50], Step [275/375], Loss: 814.9254\n",
      "Epoch [11/50], Step [276/375], Loss: 530.4289\n",
      "Epoch [11/50], Step [277/375], Loss: 672.1422\n",
      "Epoch [11/50], Step [278/375], Loss: 511.4276\n",
      "Epoch [11/50], Step [279/375], Loss: 1118.6128\n",
      "Epoch [11/50], Step [280/375], Loss: 313.0852\n",
      "Epoch [11/50], Step [281/375], Loss: 263.9372\n",
      "Epoch [11/50], Step [282/375], Loss: 325.5650\n",
      "Epoch [11/50], Step [283/375], Loss: 459.8318\n",
      "Epoch [11/50], Step [284/375], Loss: 606.9940\n",
      "Epoch [11/50], Step [285/375], Loss: 662.5557\n",
      "Epoch [11/50], Step [286/375], Loss: 283.2727\n",
      "Epoch [11/50], Step [287/375], Loss: 191.8273\n",
      "Epoch [11/50], Step [288/375], Loss: 300.3160\n",
      "Epoch [11/50], Step [289/375], Loss: 404.4860\n",
      "Epoch [11/50], Step [290/375], Loss: 300.6320\n",
      "Epoch [11/50], Step [291/375], Loss: 438.5975\n",
      "Epoch [11/50], Step [292/375], Loss: 314.1426\n",
      "Epoch [11/50], Step [293/375], Loss: 294.0964\n",
      "Epoch [11/50], Step [294/375], Loss: 345.6077\n",
      "Epoch [11/50], Step [295/375], Loss: 231.6564\n",
      "Epoch [11/50], Step [296/375], Loss: 204.9109\n",
      "Epoch [11/50], Step [297/375], Loss: 270.7147\n",
      "Epoch [11/50], Step [298/375], Loss: 584.0639\n",
      "Epoch [11/50], Step [299/375], Loss: 284.0922\n",
      "Epoch [11/50], Step [300/375], Loss: 141.4047\n",
      "Epoch [11/50], Step [301/375], Loss: 434.2871\n",
      "Epoch [11/50], Step [302/375], Loss: 499.2096\n",
      "Epoch [11/50], Step [303/375], Loss: 20.0153\n",
      "Epoch [11/50], Step [304/375], Loss: 424.5573\n",
      "Epoch [11/50], Step [305/375], Loss: 151.3423\n",
      "Epoch [11/50], Step [306/375], Loss: 137.6588\n",
      "Epoch [11/50], Step [307/375], Loss: 609.7140\n",
      "Epoch [11/50], Step [308/375], Loss: 399.6971\n",
      "Epoch [11/50], Step [309/375], Loss: 98.0864\n",
      "Epoch [11/50], Step [310/375], Loss: 1119.7306\n",
      "Epoch [11/50], Step [311/375], Loss: 268.8958\n",
      "Epoch [11/50], Step [312/375], Loss: 99.0030\n",
      "Epoch [11/50], Step [313/375], Loss: 731.9534\n",
      "Epoch [11/50], Step [314/375], Loss: 266.9277\n",
      "Epoch [11/50], Step [315/375], Loss: 378.8611\n",
      "Epoch [11/50], Step [316/375], Loss: 709.3986\n",
      "Epoch [11/50], Step [317/375], Loss: 1115.2125\n",
      "Epoch [11/50], Step [318/375], Loss: 499.9865\n",
      "Epoch [11/50], Step [319/375], Loss: 438.7731\n",
      "Epoch [11/50], Step [320/375], Loss: 212.2968\n",
      "Epoch [11/50], Step [321/375], Loss: 587.1899\n",
      "Epoch [11/50], Step [322/375], Loss: 161.8798\n",
      "Epoch [11/50], Step [323/375], Loss: 198.6983\n",
      "Epoch [11/50], Step [324/375], Loss: 432.6852\n",
      "Epoch [11/50], Step [325/375], Loss: 331.5232\n",
      "Epoch [11/50], Step [326/375], Loss: 347.5087\n",
      "Epoch [11/50], Step [327/375], Loss: 249.8714\n",
      "Epoch [11/50], Step [328/375], Loss: 189.0671\n",
      "Epoch [11/50], Step [329/375], Loss: 383.6944\n",
      "Epoch [11/50], Step [330/375], Loss: 179.0954\n",
      "Epoch [11/50], Step [331/375], Loss: 630.9714\n",
      "Epoch [11/50], Step [332/375], Loss: 865.7247\n",
      "Epoch [11/50], Step [333/375], Loss: 611.5750\n",
      "Epoch [11/50], Step [334/375], Loss: 426.1046\n",
      "Epoch [11/50], Step [335/375], Loss: 279.7724\n",
      "Epoch [11/50], Step [336/375], Loss: 677.4596\n",
      "Epoch [11/50], Step [337/375], Loss: 153.6158\n",
      "Epoch [11/50], Step [338/375], Loss: 298.5850\n",
      "Epoch [11/50], Step [339/375], Loss: 234.1068\n",
      "Epoch [11/50], Step [340/375], Loss: 423.1620\n",
      "Epoch [11/50], Step [341/375], Loss: 285.4045\n",
      "Epoch [11/50], Step [342/375], Loss: 273.9208\n",
      "Epoch [11/50], Step [343/375], Loss: 327.7905\n",
      "Epoch [11/50], Step [344/375], Loss: 473.4897\n",
      "Epoch [11/50], Step [345/375], Loss: 28.8521\n",
      "Epoch [11/50], Step [346/375], Loss: 348.1208\n",
      "Epoch [11/50], Step [347/375], Loss: 165.2061\n",
      "Epoch [11/50], Step [348/375], Loss: 467.6530\n",
      "Epoch [11/50], Step [349/375], Loss: 852.9054\n",
      "Epoch [11/50], Step [350/375], Loss: 144.8591\n",
      "Epoch [11/50], Step [351/375], Loss: 1138.8918\n",
      "Epoch [11/50], Step [352/375], Loss: 429.2871\n",
      "Epoch [11/50], Step [353/375], Loss: 212.6987\n",
      "Epoch [11/50], Step [354/375], Loss: 293.9682\n",
      "Epoch [11/50], Step [355/375], Loss: 491.6169\n",
      "Epoch [11/50], Step [356/375], Loss: 469.5946\n",
      "Epoch [11/50], Step [357/375], Loss: 227.1876\n",
      "Epoch [11/50], Step [358/375], Loss: 238.4246\n",
      "Epoch [11/50], Step [359/375], Loss: 376.5473\n",
      "Epoch [11/50], Step [360/375], Loss: 292.2246\n",
      "Epoch [11/50], Step [361/375], Loss: 532.3860\n",
      "Epoch [11/50], Step [362/375], Loss: 382.8535\n",
      "Epoch [11/50], Step [363/375], Loss: 659.6170\n",
      "Epoch [11/50], Step [364/375], Loss: 188.8369\n",
      "Epoch [11/50], Step [365/375], Loss: 1030.7162\n",
      "Epoch [11/50], Step [366/375], Loss: 439.0904\n",
      "Epoch [11/50], Step [367/375], Loss: 296.8326\n",
      "Epoch [11/50], Step [368/375], Loss: 366.1847\n",
      "Epoch [11/50], Step [369/375], Loss: 292.6876\n",
      "Epoch [11/50], Step [370/375], Loss: 220.9777\n",
      "Epoch [11/50], Step [371/375], Loss: 112.8692\n",
      "Epoch [11/50], Step [372/375], Loss: 567.0688\n",
      "Epoch [11/50], Step [373/375], Loss: 188.3908\n",
      "Epoch [11/50], Step [374/375], Loss: 146.4394\n",
      "Epoch [11/50], Step [375/375], Loss: 952.3331\n",
      "Epoch [12/50], Step [1/375], Loss: 177.3459\n",
      "Epoch [12/50], Step [2/375], Loss: 562.1230\n",
      "Epoch [12/50], Step [3/375], Loss: 346.9602\n",
      "Epoch [12/50], Step [4/375], Loss: 149.4531\n",
      "Epoch [12/50], Step [5/375], Loss: 1561.2255\n",
      "Epoch [12/50], Step [6/375], Loss: 690.5938\n",
      "Epoch [12/50], Step [7/375], Loss: 550.8929\n",
      "Epoch [12/50], Step [8/375], Loss: 266.3274\n",
      "Epoch [12/50], Step [9/375], Loss: 254.3766\n",
      "Epoch [12/50], Step [10/375], Loss: 128.3017\n",
      "Epoch [12/50], Step [11/375], Loss: 106.4083\n",
      "Epoch [12/50], Step [12/375], Loss: 497.1163\n",
      "Epoch [12/50], Step [13/375], Loss: 677.3624\n",
      "Epoch [12/50], Step [14/375], Loss: 431.4662\n",
      "Epoch [12/50], Step [15/375], Loss: 347.6228\n",
      "Epoch [12/50], Step [16/375], Loss: 241.9618\n",
      "Epoch [12/50], Step [17/375], Loss: 492.8582\n",
      "Epoch [12/50], Step [18/375], Loss: 382.1729\n",
      "Epoch [12/50], Step [19/375], Loss: 402.3634\n",
      "Epoch [12/50], Step [20/375], Loss: 800.7707\n",
      "Epoch [12/50], Step [21/375], Loss: 1418.6638\n",
      "Epoch [12/50], Step [22/375], Loss: 120.1505\n",
      "Epoch [12/50], Step [23/375], Loss: 123.9874\n",
      "Epoch [12/50], Step [24/375], Loss: 826.5626\n",
      "Epoch [12/50], Step [25/375], Loss: 225.5973\n",
      "Epoch [12/50], Step [26/375], Loss: 606.5831\n",
      "Epoch [12/50], Step [27/375], Loss: 260.1364\n",
      "Epoch [12/50], Step [28/375], Loss: 718.2500\n",
      "Epoch [12/50], Step [29/375], Loss: 173.4955\n",
      "Epoch [12/50], Step [30/375], Loss: 544.1335\n",
      "Epoch [12/50], Step [31/375], Loss: 367.8383\n",
      "Epoch [12/50], Step [32/375], Loss: 163.4167\n",
      "Epoch [12/50], Step [33/375], Loss: 250.0724\n",
      "Epoch [12/50], Step [34/375], Loss: 222.7177\n",
      "Epoch [12/50], Step [35/375], Loss: 109.9572\n",
      "Epoch [12/50], Step [36/375], Loss: 139.1845\n",
      "Epoch [12/50], Step [37/375], Loss: 450.3687\n",
      "Epoch [12/50], Step [38/375], Loss: 286.4265\n",
      "Epoch [12/50], Step [39/375], Loss: 232.1906\n",
      "Epoch [12/50], Step [40/375], Loss: 74.9041\n",
      "Epoch [12/50], Step [41/375], Loss: 436.1239\n",
      "Epoch [12/50], Step [42/375], Loss: 186.0224\n",
      "Epoch [12/50], Step [43/375], Loss: 660.0298\n",
      "Epoch [12/50], Step [44/375], Loss: 261.9869\n",
      "Epoch [12/50], Step [45/375], Loss: 174.9139\n",
      "Epoch [12/50], Step [46/375], Loss: 134.4797\n",
      "Epoch [12/50], Step [47/375], Loss: 947.2853\n",
      "Epoch [12/50], Step [48/375], Loss: 191.2664\n",
      "Epoch [12/50], Step [49/375], Loss: 385.3161\n",
      "Epoch [12/50], Step [50/375], Loss: 155.6953\n",
      "Epoch [12/50], Step [51/375], Loss: 543.5517\n",
      "Epoch [12/50], Step [52/375], Loss: 235.6048\n",
      "Epoch [12/50], Step [53/375], Loss: 962.3602\n",
      "Epoch [12/50], Step [54/375], Loss: 135.9394\n",
      "Epoch [12/50], Step [55/375], Loss: 627.1909\n",
      "Epoch [12/50], Step [56/375], Loss: 368.8776\n",
      "Epoch [12/50], Step [57/375], Loss: 249.6791\n",
      "Epoch [12/50], Step [58/375], Loss: 471.1699\n",
      "Epoch [12/50], Step [59/375], Loss: 254.7679\n",
      "Epoch [12/50], Step [60/375], Loss: 375.7270\n",
      "Epoch [12/50], Step [61/375], Loss: 1215.1038\n",
      "Epoch [12/50], Step [62/375], Loss: 318.3860\n",
      "Epoch [12/50], Step [63/375], Loss: 212.3137\n",
      "Epoch [12/50], Step [64/375], Loss: 310.4476\n",
      "Epoch [12/50], Step [65/375], Loss: 131.9704\n",
      "Epoch [12/50], Step [66/375], Loss: 408.5036\n",
      "Epoch [12/50], Step [67/375], Loss: 522.2017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Step [68/375], Loss: 200.9197\n",
      "Epoch [12/50], Step [69/375], Loss: 425.1861\n",
      "Epoch [12/50], Step [70/375], Loss: 139.5243\n",
      "Epoch [12/50], Step [71/375], Loss: 398.5648\n",
      "Epoch [12/50], Step [72/375], Loss: 289.9174\n",
      "Epoch [12/50], Step [73/375], Loss: 98.3680\n",
      "Epoch [12/50], Step [74/375], Loss: 107.0936\n",
      "Epoch [12/50], Step [75/375], Loss: 330.9352\n",
      "Epoch [12/50], Step [76/375], Loss: 138.6563\n",
      "Epoch [12/50], Step [77/375], Loss: 472.1089\n",
      "Epoch [12/50], Step [78/375], Loss: 472.8109\n",
      "Epoch [12/50], Step [79/375], Loss: 667.3838\n",
      "Epoch [12/50], Step [80/375], Loss: 355.8430\n",
      "Epoch [12/50], Step [81/375], Loss: 557.0143\n",
      "Epoch [12/50], Step [82/375], Loss: 246.5100\n",
      "Epoch [12/50], Step [83/375], Loss: 325.2621\n",
      "Epoch [12/50], Step [84/375], Loss: 387.8042\n",
      "Epoch [12/50], Step [85/375], Loss: 120.3964\n",
      "Epoch [12/50], Step [86/375], Loss: 272.1903\n",
      "Epoch [12/50], Step [87/375], Loss: 145.9437\n",
      "Epoch [12/50], Step [88/375], Loss: 230.0422\n",
      "Epoch [12/50], Step [89/375], Loss: 590.8515\n",
      "Epoch [12/50], Step [90/375], Loss: 1507.2097\n",
      "Epoch [12/50], Step [91/375], Loss: 432.9095\n",
      "Epoch [12/50], Step [92/375], Loss: 765.6377\n",
      "Epoch [12/50], Step [93/375], Loss: 1035.4962\n",
      "Epoch [12/50], Step [94/375], Loss: 420.2582\n",
      "Epoch [12/50], Step [95/375], Loss: 326.2545\n",
      "Epoch [12/50], Step [96/375], Loss: 265.7274\n",
      "Epoch [12/50], Step [97/375], Loss: 399.0726\n",
      "Epoch [12/50], Step [98/375], Loss: 821.1615\n",
      "Epoch [12/50], Step [99/375], Loss: 577.0707\n",
      "Epoch [12/50], Step [100/375], Loss: 363.8896\n",
      "Epoch [12/50], Step [101/375], Loss: 274.9677\n",
      "Epoch [12/50], Step [102/375], Loss: 479.9105\n",
      "Epoch [12/50], Step [103/375], Loss: 76.2318\n",
      "Epoch [12/50], Step [104/375], Loss: 136.3607\n",
      "Epoch [12/50], Step [105/375], Loss: 325.5889\n",
      "Epoch [12/50], Step [106/375], Loss: 127.4288\n",
      "Epoch [12/50], Step [107/375], Loss: 432.8788\n",
      "Epoch [12/50], Step [108/375], Loss: 1758.7670\n",
      "Epoch [12/50], Step [109/375], Loss: 344.3247\n",
      "Epoch [12/50], Step [110/375], Loss: 369.3138\n",
      "Epoch [12/50], Step [111/375], Loss: 173.8287\n",
      "Epoch [12/50], Step [112/375], Loss: 435.7778\n",
      "Epoch [12/50], Step [113/375], Loss: 296.5670\n",
      "Epoch [12/50], Step [114/375], Loss: 444.9626\n",
      "Epoch [12/50], Step [115/375], Loss: 620.0128\n",
      "Epoch [12/50], Step [116/375], Loss: 293.8148\n",
      "Epoch [12/50], Step [117/375], Loss: 816.2543\n",
      "Epoch [12/50], Step [118/375], Loss: 859.1566\n",
      "Epoch [12/50], Step [119/375], Loss: 907.5667\n",
      "Epoch [12/50], Step [120/375], Loss: 300.4727\n",
      "Epoch [12/50], Step [121/375], Loss: 81.5269\n",
      "Epoch [12/50], Step [122/375], Loss: 191.2511\n",
      "Epoch [12/50], Step [123/375], Loss: 252.1313\n",
      "Epoch [12/50], Step [124/375], Loss: 953.9698\n",
      "Epoch [12/50], Step [125/375], Loss: 275.1635\n",
      "Epoch [12/50], Step [126/375], Loss: 331.2274\n",
      "Epoch [12/50], Step [127/375], Loss: 660.2719\n",
      "Epoch [12/50], Step [128/375], Loss: 602.9982\n",
      "Epoch [12/50], Step [129/375], Loss: 506.9224\n",
      "Epoch [12/50], Step [130/375], Loss: 496.7361\n",
      "Epoch [12/50], Step [131/375], Loss: 859.2164\n",
      "Epoch [12/50], Step [132/375], Loss: 930.1898\n",
      "Epoch [12/50], Step [133/375], Loss: 406.6176\n",
      "Epoch [12/50], Step [134/375], Loss: 369.5065\n",
      "Epoch [12/50], Step [135/375], Loss: 416.6334\n",
      "Epoch [12/50], Step [136/375], Loss: 477.3620\n",
      "Epoch [12/50], Step [137/375], Loss: 493.9380\n",
      "Epoch [12/50], Step [138/375], Loss: 1061.9384\n",
      "Epoch [12/50], Step [139/375], Loss: 311.4093\n",
      "Epoch [12/50], Step [140/375], Loss: 722.6207\n",
      "Epoch [12/50], Step [141/375], Loss: 667.6584\n",
      "Epoch [12/50], Step [142/375], Loss: 405.8401\n",
      "Epoch [12/50], Step [143/375], Loss: 373.4945\n",
      "Epoch [12/50], Step [144/375], Loss: 782.4602\n",
      "Epoch [12/50], Step [145/375], Loss: 390.8206\n",
      "Epoch [12/50], Step [146/375], Loss: 237.7955\n",
      "Epoch [12/50], Step [147/375], Loss: 718.7657\n",
      "Epoch [12/50], Step [148/375], Loss: 792.6321\n",
      "Epoch [12/50], Step [149/375], Loss: 570.4505\n",
      "Epoch [12/50], Step [150/375], Loss: 67.0281\n",
      "Epoch [12/50], Step [151/375], Loss: 581.4327\n",
      "Epoch [12/50], Step [152/375], Loss: 866.3004\n",
      "Epoch [12/50], Step [153/375], Loss: 683.9871\n",
      "Epoch [12/50], Step [154/375], Loss: 549.3575\n",
      "Epoch [12/50], Step [155/375], Loss: 443.9618\n",
      "Epoch [12/50], Step [156/375], Loss: 1254.6823\n",
      "Epoch [12/50], Step [157/375], Loss: 324.8160\n",
      "Epoch [12/50], Step [158/375], Loss: 728.2979\n",
      "Epoch [12/50], Step [159/375], Loss: 209.6885\n",
      "Epoch [12/50], Step [160/375], Loss: 88.0331\n",
      "Epoch [12/50], Step [161/375], Loss: 275.0055\n",
      "Epoch [12/50], Step [162/375], Loss: 997.8739\n",
      "Epoch [12/50], Step [163/375], Loss: 78.7118\n",
      "Epoch [12/50], Step [164/375], Loss: 28.5737\n",
      "Epoch [12/50], Step [165/375], Loss: 168.8356\n",
      "Epoch [12/50], Step [166/375], Loss: 1045.7924\n",
      "Epoch [12/50], Step [167/375], Loss: 192.9977\n",
      "Epoch [12/50], Step [168/375], Loss: 666.2275\n",
      "Epoch [12/50], Step [169/375], Loss: 198.4751\n",
      "Epoch [12/50], Step [170/375], Loss: 122.9140\n",
      "Epoch [12/50], Step [171/375], Loss: 300.9348\n",
      "Epoch [12/50], Step [172/375], Loss: 1010.7302\n",
      "Epoch [12/50], Step [173/375], Loss: 305.2936\n",
      "Epoch [12/50], Step [174/375], Loss: 470.5799\n",
      "Epoch [12/50], Step [175/375], Loss: 407.0699\n",
      "Epoch [12/50], Step [176/375], Loss: 914.6196\n",
      "Epoch [12/50], Step [177/375], Loss: 189.1310\n",
      "Epoch [12/50], Step [178/375], Loss: 259.4306\n",
      "Epoch [12/50], Step [179/375], Loss: 66.1195\n",
      "Epoch [12/50], Step [180/375], Loss: 241.5933\n",
      "Epoch [12/50], Step [181/375], Loss: 550.5939\n",
      "Epoch [12/50], Step [182/375], Loss: 867.2546\n",
      "Epoch [12/50], Step [183/375], Loss: 298.0892\n",
      "Epoch [12/50], Step [184/375], Loss: 185.2437\n",
      "Epoch [12/50], Step [185/375], Loss: 552.9962\n",
      "Epoch [12/50], Step [186/375], Loss: 292.3516\n",
      "Epoch [12/50], Step [187/375], Loss: 76.0709\n",
      "Epoch [12/50], Step [188/375], Loss: 114.6365\n",
      "Epoch [12/50], Step [189/375], Loss: 367.8759\n",
      "Epoch [12/50], Step [190/375], Loss: 671.0301\n",
      "Epoch [12/50], Step [191/375], Loss: 418.7324\n",
      "Epoch [12/50], Step [192/375], Loss: 328.7982\n",
      "Epoch [12/50], Step [193/375], Loss: 252.6629\n",
      "Epoch [12/50], Step [194/375], Loss: 546.0154\n",
      "Epoch [12/50], Step [195/375], Loss: 177.8481\n",
      "Epoch [12/50], Step [196/375], Loss: 690.4146\n",
      "Epoch [12/50], Step [197/375], Loss: 391.3935\n",
      "Epoch [12/50], Step [198/375], Loss: 712.6487\n",
      "Epoch [12/50], Step [199/375], Loss: 414.2303\n",
      "Epoch [12/50], Step [200/375], Loss: 608.9363\n",
      "Epoch [12/50], Step [201/375], Loss: 926.3690\n",
      "Epoch [12/50], Step [202/375], Loss: 142.0427\n",
      "Epoch [12/50], Step [203/375], Loss: 651.4370\n",
      "Epoch [12/50], Step [204/375], Loss: 308.6630\n",
      "Epoch [12/50], Step [205/375], Loss: 268.8997\n",
      "Epoch [12/50], Step [206/375], Loss: 160.3097\n",
      "Epoch [12/50], Step [207/375], Loss: 975.8643\n",
      "Epoch [12/50], Step [208/375], Loss: 375.7515\n",
      "Epoch [12/50], Step [209/375], Loss: 1500.5353\n",
      "Epoch [12/50], Step [210/375], Loss: 128.2901\n",
      "Epoch [12/50], Step [211/375], Loss: 281.2978\n",
      "Epoch [12/50], Step [212/375], Loss: 473.8027\n",
      "Epoch [12/50], Step [213/375], Loss: 933.4570\n",
      "Epoch [12/50], Step [214/375], Loss: 294.6375\n",
      "Epoch [12/50], Step [215/375], Loss: 532.3884\n",
      "Epoch [12/50], Step [216/375], Loss: 627.7636\n",
      "Epoch [12/50], Step [217/375], Loss: 107.2696\n",
      "Epoch [12/50], Step [218/375], Loss: 745.7048\n",
      "Epoch [12/50], Step [219/375], Loss: 317.0005\n",
      "Epoch [12/50], Step [220/375], Loss: 307.6116\n",
      "Epoch [12/50], Step [221/375], Loss: 272.3890\n",
      "Epoch [12/50], Step [222/375], Loss: 602.5816\n",
      "Epoch [12/50], Step [223/375], Loss: 321.5413\n",
      "Epoch [12/50], Step [224/375], Loss: 450.3342\n",
      "Epoch [12/50], Step [225/375], Loss: 564.4038\n",
      "Epoch [12/50], Step [226/375], Loss: 99.6187\n",
      "Epoch [12/50], Step [227/375], Loss: 133.4664\n",
      "Epoch [12/50], Step [228/375], Loss: 279.1148\n",
      "Epoch [12/50], Step [229/375], Loss: 1268.8480\n",
      "Epoch [12/50], Step [230/375], Loss: 437.8848\n",
      "Epoch [12/50], Step [231/375], Loss: 150.3524\n",
      "Epoch [12/50], Step [232/375], Loss: 556.3737\n",
      "Epoch [12/50], Step [233/375], Loss: 107.0012\n",
      "Epoch [12/50], Step [234/375], Loss: 665.6244\n",
      "Epoch [12/50], Step [235/375], Loss: 425.6285\n",
      "Epoch [12/50], Step [236/375], Loss: 536.3786\n",
      "Epoch [12/50], Step [237/375], Loss: 188.8461\n",
      "Epoch [12/50], Step [238/375], Loss: 213.5771\n",
      "Epoch [12/50], Step [239/375], Loss: 677.1396\n",
      "Epoch [12/50], Step [240/375], Loss: 161.0649\n",
      "Epoch [12/50], Step [241/375], Loss: 288.1692\n",
      "Epoch [12/50], Step [242/375], Loss: 195.3818\n",
      "Epoch [12/50], Step [243/375], Loss: 519.9642\n",
      "Epoch [12/50], Step [244/375], Loss: 177.5141\n",
      "Epoch [12/50], Step [245/375], Loss: 668.2266\n",
      "Epoch [12/50], Step [246/375], Loss: 634.1898\n",
      "Epoch [12/50], Step [247/375], Loss: 383.3408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Step [248/375], Loss: 2212.6958\n",
      "Epoch [12/50], Step [249/375], Loss: 251.2562\n",
      "Epoch [12/50], Step [250/375], Loss: 225.8443\n",
      "Epoch [12/50], Step [251/375], Loss: 137.9374\n",
      "Epoch [12/50], Step [252/375], Loss: 1295.3711\n",
      "Epoch [12/50], Step [253/375], Loss: 482.7984\n",
      "Epoch [12/50], Step [254/375], Loss: 379.4587\n",
      "Epoch [12/50], Step [255/375], Loss: 549.0524\n",
      "Epoch [12/50], Step [256/375], Loss: 718.4647\n",
      "Epoch [12/50], Step [257/375], Loss: 533.2433\n",
      "Epoch [12/50], Step [258/375], Loss: 511.3875\n",
      "Epoch [12/50], Step [259/375], Loss: 999.9382\n",
      "Epoch [12/50], Step [260/375], Loss: 716.3373\n",
      "Epoch [12/50], Step [261/375], Loss: 240.1839\n",
      "Epoch [12/50], Step [262/375], Loss: 596.1140\n",
      "Epoch [12/50], Step [263/375], Loss: 392.7632\n",
      "Epoch [12/50], Step [264/375], Loss: 193.8446\n",
      "Epoch [12/50], Step [265/375], Loss: 407.1417\n",
      "Epoch [12/50], Step [266/375], Loss: 344.7230\n",
      "Epoch [12/50], Step [267/375], Loss: 427.7614\n",
      "Epoch [12/50], Step [268/375], Loss: 152.3355\n",
      "Epoch [12/50], Step [269/375], Loss: 228.8063\n",
      "Epoch [12/50], Step [270/375], Loss: 208.5026\n",
      "Epoch [12/50], Step [271/375], Loss: 284.1525\n",
      "Epoch [12/50], Step [272/375], Loss: 125.1326\n",
      "Epoch [12/50], Step [273/375], Loss: 720.5027\n",
      "Epoch [12/50], Step [274/375], Loss: 876.2424\n",
      "Epoch [12/50], Step [275/375], Loss: 212.9847\n",
      "Epoch [12/50], Step [276/375], Loss: 262.8130\n",
      "Epoch [12/50], Step [277/375], Loss: 305.5035\n",
      "Epoch [12/50], Step [278/375], Loss: 252.4181\n",
      "Epoch [12/50], Step [279/375], Loss: 103.2641\n",
      "Epoch [12/50], Step [280/375], Loss: 585.1307\n",
      "Epoch [12/50], Step [281/375], Loss: 649.7241\n",
      "Epoch [12/50], Step [282/375], Loss: 825.1635\n",
      "Epoch [12/50], Step [283/375], Loss: 394.0142\n",
      "Epoch [12/50], Step [284/375], Loss: 471.1900\n",
      "Epoch [12/50], Step [285/375], Loss: 248.1473\n",
      "Epoch [12/50], Step [286/375], Loss: 439.7809\n",
      "Epoch [12/50], Step [287/375], Loss: 154.0365\n",
      "Epoch [12/50], Step [288/375], Loss: 51.5497\n",
      "Epoch [12/50], Step [289/375], Loss: 282.5117\n",
      "Epoch [12/50], Step [290/375], Loss: 430.7017\n",
      "Epoch [12/50], Step [291/375], Loss: 280.0007\n",
      "Epoch [12/50], Step [292/375], Loss: 664.6713\n",
      "Epoch [12/50], Step [293/375], Loss: 13.2637\n",
      "Epoch [12/50], Step [294/375], Loss: 238.8571\n",
      "Epoch [12/50], Step [295/375], Loss: 586.7658\n",
      "Epoch [12/50], Step [296/375], Loss: 144.7419\n",
      "Epoch [12/50], Step [297/375], Loss: 202.0151\n",
      "Epoch [12/50], Step [298/375], Loss: 1086.5245\n",
      "Epoch [12/50], Step [299/375], Loss: 425.6349\n",
      "Epoch [12/50], Step [300/375], Loss: 495.7673\n",
      "Epoch [12/50], Step [301/375], Loss: 101.4040\n",
      "Epoch [12/50], Step [302/375], Loss: 104.9806\n",
      "Epoch [12/50], Step [303/375], Loss: 308.6205\n",
      "Epoch [12/50], Step [304/375], Loss: 465.5044\n",
      "Epoch [12/50], Step [305/375], Loss: 83.9017\n",
      "Epoch [12/50], Step [306/375], Loss: 174.5891\n",
      "Epoch [12/50], Step [307/375], Loss: 324.3910\n",
      "Epoch [12/50], Step [308/375], Loss: 225.0196\n",
      "Epoch [12/50], Step [309/375], Loss: 213.7939\n",
      "Epoch [12/50], Step [310/375], Loss: 604.8539\n",
      "Epoch [12/50], Step [311/375], Loss: 424.3026\n",
      "Epoch [12/50], Step [312/375], Loss: 306.9163\n",
      "Epoch [12/50], Step [313/375], Loss: 476.1382\n",
      "Epoch [12/50], Step [314/375], Loss: 852.1656\n",
      "Epoch [12/50], Step [315/375], Loss: 263.9619\n",
      "Epoch [12/50], Step [316/375], Loss: 83.4502\n",
      "Epoch [12/50], Step [317/375], Loss: 561.0045\n",
      "Epoch [12/50], Step [318/375], Loss: 550.6790\n",
      "Epoch [12/50], Step [319/375], Loss: 942.7865\n",
      "Epoch [12/50], Step [320/375], Loss: 741.0580\n",
      "Epoch [12/50], Step [321/375], Loss: 614.4264\n",
      "Epoch [12/50], Step [322/375], Loss: 185.5964\n",
      "Epoch [12/50], Step [323/375], Loss: 91.3915\n",
      "Epoch [12/50], Step [324/375], Loss: 44.0780\n",
      "Epoch [12/50], Step [325/375], Loss: 95.7557\n",
      "Epoch [12/50], Step [326/375], Loss: 77.3743\n",
      "Epoch [12/50], Step [327/375], Loss: 319.1944\n",
      "Epoch [12/50], Step [328/375], Loss: 397.6456\n",
      "Epoch [12/50], Step [329/375], Loss: 251.9679\n",
      "Epoch [12/50], Step [330/375], Loss: 409.2850\n",
      "Epoch [12/50], Step [331/375], Loss: 333.2355\n",
      "Epoch [12/50], Step [332/375], Loss: 385.0179\n",
      "Epoch [12/50], Step [333/375], Loss: 999.5693\n",
      "Epoch [12/50], Step [334/375], Loss: 317.9061\n",
      "Epoch [12/50], Step [335/375], Loss: 231.5238\n",
      "Epoch [12/50], Step [336/375], Loss: 488.6529\n",
      "Epoch [12/50], Step [337/375], Loss: 435.5155\n",
      "Epoch [12/50], Step [338/375], Loss: 834.6312\n",
      "Epoch [12/50], Step [339/375], Loss: 143.4814\n",
      "Epoch [12/50], Step [340/375], Loss: 206.8143\n",
      "Epoch [12/50], Step [341/375], Loss: 315.3419\n",
      "Epoch [12/50], Step [342/375], Loss: 284.5974\n",
      "Epoch [12/50], Step [343/375], Loss: 937.5631\n",
      "Epoch [12/50], Step [344/375], Loss: 365.1281\n",
      "Epoch [12/50], Step [345/375], Loss: 311.3782\n",
      "Epoch [12/50], Step [346/375], Loss: 144.6529\n",
      "Epoch [12/50], Step [347/375], Loss: 264.9470\n",
      "Epoch [12/50], Step [348/375], Loss: 250.0183\n",
      "Epoch [12/50], Step [349/375], Loss: 50.8878\n",
      "Epoch [12/50], Step [350/375], Loss: 607.9324\n",
      "Epoch [12/50], Step [351/375], Loss: 407.7614\n",
      "Epoch [12/50], Step [352/375], Loss: 1746.7346\n",
      "Epoch [12/50], Step [353/375], Loss: 790.6793\n",
      "Epoch [12/50], Step [354/375], Loss: 173.5405\n",
      "Epoch [12/50], Step [355/375], Loss: 308.7058\n",
      "Epoch [12/50], Step [356/375], Loss: 557.2014\n",
      "Epoch [12/50], Step [357/375], Loss: 205.2903\n",
      "Epoch [12/50], Step [358/375], Loss: 81.5579\n",
      "Epoch [12/50], Step [359/375], Loss: 104.5650\n",
      "Epoch [12/50], Step [360/375], Loss: 370.4066\n",
      "Epoch [12/50], Step [361/375], Loss: 221.0303\n",
      "Epoch [12/50], Step [362/375], Loss: 339.3466\n",
      "Epoch [12/50], Step [363/375], Loss: 211.7666\n",
      "Epoch [12/50], Step [364/375], Loss: 86.6461\n",
      "Epoch [12/50], Step [365/375], Loss: 518.5157\n",
      "Epoch [12/50], Step [366/375], Loss: 99.4234\n",
      "Epoch [12/50], Step [367/375], Loss: 53.5102\n",
      "Epoch [12/50], Step [368/375], Loss: 351.0890\n",
      "Epoch [12/50], Step [369/375], Loss: 754.7454\n",
      "Epoch [12/50], Step [370/375], Loss: 53.1127\n",
      "Epoch [12/50], Step [371/375], Loss: 287.0299\n",
      "Epoch [12/50], Step [372/375], Loss: 188.7243\n",
      "Epoch [12/50], Step [373/375], Loss: 193.1499\n",
      "Epoch [12/50], Step [374/375], Loss: 289.4781\n",
      "Epoch [12/50], Step [375/375], Loss: 199.8762\n",
      "Epoch [13/50], Step [1/375], Loss: 86.7406\n",
      "Epoch [13/50], Step [2/375], Loss: 253.3373\n",
      "Epoch [13/50], Step [3/375], Loss: 547.1191\n",
      "Epoch [13/50], Step [4/375], Loss: 168.4538\n",
      "Epoch [13/50], Step [5/375], Loss: 509.5039\n",
      "Epoch [13/50], Step [6/375], Loss: 212.6268\n",
      "Epoch [13/50], Step [7/375], Loss: 190.5518\n",
      "Epoch [13/50], Step [8/375], Loss: 261.2310\n",
      "Epoch [13/50], Step [9/375], Loss: 316.3287\n",
      "Epoch [13/50], Step [10/375], Loss: 219.1024\n",
      "Epoch [13/50], Step [11/375], Loss: 992.6956\n",
      "Epoch [13/50], Step [12/375], Loss: 409.3167\n",
      "Epoch [13/50], Step [13/375], Loss: 729.3531\n",
      "Epoch [13/50], Step [14/375], Loss: 103.2814\n",
      "Epoch [13/50], Step [15/375], Loss: 116.6471\n",
      "Epoch [13/50], Step [16/375], Loss: 289.8356\n",
      "Epoch [13/50], Step [17/375], Loss: 202.4725\n",
      "Epoch [13/50], Step [18/375], Loss: 438.1039\n",
      "Epoch [13/50], Step [19/375], Loss: 267.7810\n",
      "Epoch [13/50], Step [20/375], Loss: 253.9209\n",
      "Epoch [13/50], Step [21/375], Loss: 227.3766\n",
      "Epoch [13/50], Step [22/375], Loss: 399.4511\n",
      "Epoch [13/50], Step [23/375], Loss: 178.8782\n",
      "Epoch [13/50], Step [24/375], Loss: 122.3118\n",
      "Epoch [13/50], Step [25/375], Loss: 259.6702\n",
      "Epoch [13/50], Step [26/375], Loss: 183.4822\n",
      "Epoch [13/50], Step [27/375], Loss: 320.5730\n",
      "Epoch [13/50], Step [28/375], Loss: 235.6633\n",
      "Epoch [13/50], Step [29/375], Loss: 1148.9355\n",
      "Epoch [13/50], Step [30/375], Loss: 722.5510\n",
      "Epoch [13/50], Step [31/375], Loss: 217.2446\n",
      "Epoch [13/50], Step [32/375], Loss: 255.7422\n",
      "Epoch [13/50], Step [33/375], Loss: 143.2328\n",
      "Epoch [13/50], Step [34/375], Loss: 602.8475\n",
      "Epoch [13/50], Step [35/375], Loss: 277.2898\n",
      "Epoch [13/50], Step [36/375], Loss: 362.9254\n",
      "Epoch [13/50], Step [37/375], Loss: 470.8142\n",
      "Epoch [13/50], Step [38/375], Loss: 217.9433\n",
      "Epoch [13/50], Step [39/375], Loss: 68.2553\n",
      "Epoch [13/50], Step [40/375], Loss: 155.7027\n",
      "Epoch [13/50], Step [41/375], Loss: 463.8714\n",
      "Epoch [13/50], Step [42/375], Loss: 220.5454\n",
      "Epoch [13/50], Step [43/375], Loss: 186.9567\n",
      "Epoch [13/50], Step [44/375], Loss: 286.8778\n",
      "Epoch [13/50], Step [45/375], Loss: 709.8018\n",
      "Epoch [13/50], Step [46/375], Loss: 341.0023\n",
      "Epoch [13/50], Step [47/375], Loss: 159.1347\n",
      "Epoch [13/50], Step [48/375], Loss: 85.2730\n",
      "Epoch [13/50], Step [49/375], Loss: 181.2851\n",
      "Epoch [13/50], Step [50/375], Loss: 82.9058\n",
      "Epoch [13/50], Step [51/375], Loss: 103.6988\n",
      "Epoch [13/50], Step [52/375], Loss: 296.1606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Step [53/375], Loss: 157.6949\n",
      "Epoch [13/50], Step [54/375], Loss: 255.6636\n",
      "Epoch [13/50], Step [55/375], Loss: 323.8759\n",
      "Epoch [13/50], Step [56/375], Loss: 92.5636\n",
      "Epoch [13/50], Step [57/375], Loss: 780.0212\n",
      "Epoch [13/50], Step [58/375], Loss: 544.6580\n",
      "Epoch [13/50], Step [59/375], Loss: 115.9793\n",
      "Epoch [13/50], Step [60/375], Loss: 538.7410\n",
      "Epoch [13/50], Step [61/375], Loss: 716.5337\n",
      "Epoch [13/50], Step [62/375], Loss: 96.7871\n",
      "Epoch [13/50], Step [63/375], Loss: 121.8744\n",
      "Epoch [13/50], Step [64/375], Loss: 220.1541\n",
      "Epoch [13/50], Step [65/375], Loss: 152.2518\n",
      "Epoch [13/50], Step [66/375], Loss: 602.8260\n",
      "Epoch [13/50], Step [67/375], Loss: 506.8302\n",
      "Epoch [13/50], Step [68/375], Loss: 264.9691\n",
      "Epoch [13/50], Step [69/375], Loss: 137.6016\n",
      "Epoch [13/50], Step [70/375], Loss: 91.7283\n",
      "Epoch [13/50], Step [71/375], Loss: 315.5652\n",
      "Epoch [13/50], Step [72/375], Loss: 153.9299\n",
      "Epoch [13/50], Step [73/375], Loss: 280.8690\n",
      "Epoch [13/50], Step [74/375], Loss: 132.7613\n",
      "Epoch [13/50], Step [75/375], Loss: 96.9657\n",
      "Epoch [13/50], Step [76/375], Loss: 77.7330\n",
      "Epoch [13/50], Step [77/375], Loss: 232.9757\n",
      "Epoch [13/50], Step [78/375], Loss: 324.7360\n",
      "Epoch [13/50], Step [79/375], Loss: 191.6264\n",
      "Epoch [13/50], Step [80/375], Loss: 334.3073\n",
      "Epoch [13/50], Step [81/375], Loss: 265.5607\n",
      "Epoch [13/50], Step [82/375], Loss: 83.0923\n",
      "Epoch [13/50], Step [83/375], Loss: 524.4990\n",
      "Epoch [13/50], Step [84/375], Loss: 47.5748\n",
      "Epoch [13/50], Step [85/375], Loss: 659.8591\n",
      "Epoch [13/50], Step [86/375], Loss: 461.0875\n",
      "Epoch [13/50], Step [87/375], Loss: 310.5220\n",
      "Epoch [13/50], Step [88/375], Loss: 886.0416\n",
      "Epoch [13/50], Step [89/375], Loss: 531.2259\n",
      "Epoch [13/50], Step [90/375], Loss: 125.3739\n",
      "Epoch [13/50], Step [91/375], Loss: 336.3609\n",
      "Epoch [13/50], Step [92/375], Loss: 385.1547\n",
      "Epoch [13/50], Step [93/375], Loss: 1049.0286\n",
      "Epoch [13/50], Step [94/375], Loss: 153.3079\n",
      "Epoch [13/50], Step [95/375], Loss: 140.9608\n",
      "Epoch [13/50], Step [96/375], Loss: 1005.2655\n",
      "Epoch [13/50], Step [97/375], Loss: 121.8802\n",
      "Epoch [13/50], Step [98/375], Loss: 418.6924\n",
      "Epoch [13/50], Step [99/375], Loss: 72.3388\n",
      "Epoch [13/50], Step [100/375], Loss: 372.1732\n",
      "Epoch [13/50], Step [101/375], Loss: 473.6437\n",
      "Epoch [13/50], Step [102/375], Loss: 244.0798\n",
      "Epoch [13/50], Step [103/375], Loss: 145.5463\n",
      "Epoch [13/50], Step [104/375], Loss: 195.1118\n",
      "Epoch [13/50], Step [105/375], Loss: 252.0565\n",
      "Epoch [13/50], Step [106/375], Loss: 218.0273\n",
      "Epoch [13/50], Step [107/375], Loss: 76.5164\n",
      "Epoch [13/50], Step [108/375], Loss: 275.7982\n",
      "Epoch [13/50], Step [109/375], Loss: 61.8246\n",
      "Epoch [13/50], Step [110/375], Loss: 279.9206\n",
      "Epoch [13/50], Step [111/375], Loss: 473.6963\n",
      "Epoch [13/50], Step [112/375], Loss: 679.1473\n",
      "Epoch [13/50], Step [113/375], Loss: 195.8391\n",
      "Epoch [13/50], Step [114/375], Loss: 384.6531\n",
      "Epoch [13/50], Step [115/375], Loss: 378.0703\n",
      "Epoch [13/50], Step [116/375], Loss: 212.6491\n",
      "Epoch [13/50], Step [117/375], Loss: 443.4585\n",
      "Epoch [13/50], Step [118/375], Loss: 109.4520\n",
      "Epoch [13/50], Step [119/375], Loss: 126.2717\n",
      "Epoch [13/50], Step [120/375], Loss: 258.3069\n",
      "Epoch [13/50], Step [121/375], Loss: 410.6467\n",
      "Epoch [13/50], Step [122/375], Loss: 181.9500\n",
      "Epoch [13/50], Step [123/375], Loss: 359.6992\n",
      "Epoch [13/50], Step [124/375], Loss: 294.5617\n",
      "Epoch [13/50], Step [125/375], Loss: 129.1910\n",
      "Epoch [13/50], Step [126/375], Loss: 573.4187\n",
      "Epoch [13/50], Step [127/375], Loss: 294.7081\n",
      "Epoch [13/50], Step [128/375], Loss: 77.4188\n",
      "Epoch [13/50], Step [129/375], Loss: 217.0199\n",
      "Epoch [13/50], Step [130/375], Loss: 253.3729\n",
      "Epoch [13/50], Step [131/375], Loss: 38.7774\n",
      "Epoch [13/50], Step [132/375], Loss: 183.6393\n",
      "Epoch [13/50], Step [133/375], Loss: 938.0978\n",
      "Epoch [13/50], Step [134/375], Loss: 386.3004\n",
      "Epoch [13/50], Step [135/375], Loss: 127.8976\n",
      "Epoch [13/50], Step [136/375], Loss: 421.8769\n",
      "Epoch [13/50], Step [137/375], Loss: 228.1604\n",
      "Epoch [13/50], Step [138/375], Loss: 624.8664\n",
      "Epoch [13/50], Step [139/375], Loss: 486.4274\n",
      "Epoch [13/50], Step [140/375], Loss: 696.7230\n",
      "Epoch [13/50], Step [141/375], Loss: 228.0715\n",
      "Epoch [13/50], Step [142/375], Loss: 849.2097\n",
      "Epoch [13/50], Step [143/375], Loss: 285.0473\n",
      "Epoch [13/50], Step [144/375], Loss: 61.3239\n",
      "Epoch [13/50], Step [145/375], Loss: 197.2472\n",
      "Epoch [13/50], Step [146/375], Loss: 833.0918\n",
      "Epoch [13/50], Step [147/375], Loss: 221.6503\n",
      "Epoch [13/50], Step [148/375], Loss: 68.3972\n",
      "Epoch [13/50], Step [149/375], Loss: 107.9697\n",
      "Epoch [13/50], Step [150/375], Loss: 180.0376\n",
      "Epoch [13/50], Step [151/375], Loss: 289.6141\n",
      "Epoch [13/50], Step [152/375], Loss: 384.0939\n",
      "Epoch [13/50], Step [153/375], Loss: 222.7519\n",
      "Epoch [13/50], Step [154/375], Loss: 120.6149\n",
      "Epoch [13/50], Step [155/375], Loss: 835.2656\n",
      "Epoch [13/50], Step [156/375], Loss: 94.1500\n",
      "Epoch [13/50], Step [157/375], Loss: 224.1808\n",
      "Epoch [13/50], Step [158/375], Loss: 260.7365\n",
      "Epoch [13/50], Step [159/375], Loss: 226.3418\n",
      "Epoch [13/50], Step [160/375], Loss: 219.8084\n",
      "Epoch [13/50], Step [161/375], Loss: 472.6425\n",
      "Epoch [13/50], Step [162/375], Loss: 296.6686\n",
      "Epoch [13/50], Step [163/375], Loss: 240.0266\n",
      "Epoch [13/50], Step [164/375], Loss: 53.3286\n",
      "Epoch [13/50], Step [165/375], Loss: 195.0225\n",
      "Epoch [13/50], Step [166/375], Loss: 846.6178\n",
      "Epoch [13/50], Step [167/375], Loss: 278.0617\n",
      "Epoch [13/50], Step [168/375], Loss: 88.9215\n",
      "Epoch [13/50], Step [169/375], Loss: 339.7256\n",
      "Epoch [13/50], Step [170/375], Loss: 515.4590\n",
      "Epoch [13/50], Step [171/375], Loss: 85.6821\n",
      "Epoch [13/50], Step [172/375], Loss: 648.8724\n",
      "Epoch [13/50], Step [173/375], Loss: 531.2862\n",
      "Epoch [13/50], Step [174/375], Loss: 208.1476\n",
      "Epoch [13/50], Step [175/375], Loss: 132.0305\n",
      "Epoch [13/50], Step [176/375], Loss: 133.8609\n",
      "Epoch [13/50], Step [177/375], Loss: 125.7342\n",
      "Epoch [13/50], Step [178/375], Loss: 153.9934\n",
      "Epoch [13/50], Step [179/375], Loss: 428.8449\n",
      "Epoch [13/50], Step [180/375], Loss: 65.1372\n",
      "Epoch [13/50], Step [181/375], Loss: 125.9748\n",
      "Epoch [13/50], Step [182/375], Loss: 264.4020\n",
      "Epoch [13/50], Step [183/375], Loss: 183.8490\n",
      "Epoch [13/50], Step [184/375], Loss: 206.2124\n",
      "Epoch [13/50], Step [185/375], Loss: 60.8924\n",
      "Epoch [13/50], Step [186/375], Loss: 259.5276\n",
      "Epoch [13/50], Step [187/375], Loss: 273.5227\n",
      "Epoch [13/50], Step [188/375], Loss: 644.8372\n",
      "Epoch [13/50], Step [189/375], Loss: 172.4629\n",
      "Epoch [13/50], Step [190/375], Loss: 333.3016\n",
      "Epoch [13/50], Step [191/375], Loss: 72.3868\n",
      "Epoch [13/50], Step [192/375], Loss: 208.6316\n",
      "Epoch [13/50], Step [193/375], Loss: 160.3303\n",
      "Epoch [13/50], Step [194/375], Loss: 23.0126\n",
      "Epoch [13/50], Step [195/375], Loss: 158.1208\n",
      "Epoch [13/50], Step [196/375], Loss: 68.7617\n",
      "Epoch [13/50], Step [197/375], Loss: 382.9432\n",
      "Epoch [13/50], Step [198/375], Loss: 515.9172\n",
      "Epoch [13/50], Step [199/375], Loss: 179.6452\n",
      "Epoch [13/50], Step [200/375], Loss: 209.5498\n",
      "Epoch [13/50], Step [201/375], Loss: 418.5167\n",
      "Epoch [13/50], Step [202/375], Loss: 226.4590\n",
      "Epoch [13/50], Step [203/375], Loss: 216.1752\n",
      "Epoch [13/50], Step [204/375], Loss: 159.8883\n",
      "Epoch [13/50], Step [205/375], Loss: 152.0662\n",
      "Epoch [13/50], Step [206/375], Loss: 255.6418\n",
      "Epoch [13/50], Step [207/375], Loss: 388.4916\n",
      "Epoch [13/50], Step [208/375], Loss: 235.7401\n",
      "Epoch [13/50], Step [209/375], Loss: 468.3816\n",
      "Epoch [13/50], Step [210/375], Loss: 564.4575\n",
      "Epoch [13/50], Step [211/375], Loss: 314.7220\n",
      "Epoch [13/50], Step [212/375], Loss: 43.6691\n",
      "Epoch [13/50], Step [213/375], Loss: 72.6928\n",
      "Epoch [13/50], Step [214/375], Loss: 251.4112\n",
      "Epoch [13/50], Step [215/375], Loss: 284.9641\n",
      "Epoch [13/50], Step [216/375], Loss: 81.9655\n",
      "Epoch [13/50], Step [217/375], Loss: 272.6186\n",
      "Epoch [13/50], Step [218/375], Loss: 185.0966\n",
      "Epoch [13/50], Step [219/375], Loss: 184.6044\n",
      "Epoch [13/50], Step [220/375], Loss: 235.4279\n",
      "Epoch [13/50], Step [221/375], Loss: 276.0339\n",
      "Epoch [13/50], Step [222/375], Loss: 187.7336\n",
      "Epoch [13/50], Step [223/375], Loss: 190.6196\n",
      "Epoch [13/50], Step [224/375], Loss: 752.3096\n",
      "Epoch [13/50], Step [225/375], Loss: 184.7970\n",
      "Epoch [13/50], Step [226/375], Loss: 384.5073\n",
      "Epoch [13/50], Step [227/375], Loss: 286.3434\n",
      "Epoch [13/50], Step [228/375], Loss: 231.0516\n",
      "Epoch [13/50], Step [229/375], Loss: 939.4984\n",
      "Epoch [13/50], Step [230/375], Loss: 268.4385\n",
      "Epoch [13/50], Step [231/375], Loss: 505.0348\n",
      "Epoch [13/50], Step [232/375], Loss: 226.3395\n",
      "Epoch [13/50], Step [233/375], Loss: 1148.8475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Step [234/375], Loss: 762.3915\n",
      "Epoch [13/50], Step [235/375], Loss: 176.1710\n",
      "Epoch [13/50], Step [236/375], Loss: 423.4558\n",
      "Epoch [13/50], Step [237/375], Loss: 357.9855\n",
      "Epoch [13/50], Step [238/375], Loss: 244.2877\n",
      "Epoch [13/50], Step [239/375], Loss: 494.5774\n",
      "Epoch [13/50], Step [240/375], Loss: 610.6049\n",
      "Epoch [13/50], Step [241/375], Loss: 237.0126\n",
      "Epoch [13/50], Step [242/375], Loss: 125.4881\n",
      "Epoch [13/50], Step [243/375], Loss: 169.7106\n",
      "Epoch [13/50], Step [244/375], Loss: 282.0567\n",
      "Epoch [13/50], Step [245/375], Loss: 44.5871\n",
      "Epoch [13/50], Step [246/375], Loss: 1049.6482\n",
      "Epoch [13/50], Step [247/375], Loss: 752.5154\n",
      "Epoch [13/50], Step [248/375], Loss: 537.3672\n",
      "Epoch [13/50], Step [249/375], Loss: 162.4592\n",
      "Epoch [13/50], Step [250/375], Loss: 142.4459\n",
      "Epoch [13/50], Step [251/375], Loss: 119.9760\n",
      "Epoch [13/50], Step [252/375], Loss: 50.8653\n",
      "Epoch [13/50], Step [253/375], Loss: 155.4188\n",
      "Epoch [13/50], Step [254/375], Loss: 747.0114\n",
      "Epoch [13/50], Step [255/375], Loss: 220.5519\n",
      "Epoch [13/50], Step [256/375], Loss: 229.8471\n",
      "Epoch [13/50], Step [257/375], Loss: 384.7066\n",
      "Epoch [13/50], Step [258/375], Loss: 87.8116\n",
      "Epoch [13/50], Step [259/375], Loss: 420.9776\n",
      "Epoch [13/50], Step [260/375], Loss: 606.4444\n",
      "Epoch [13/50], Step [261/375], Loss: 766.7059\n",
      "Epoch [13/50], Step [262/375], Loss: 449.3208\n",
      "Epoch [13/50], Step [263/375], Loss: 57.3887\n",
      "Epoch [13/50], Step [264/375], Loss: 225.8416\n",
      "Epoch [13/50], Step [265/375], Loss: 88.5895\n",
      "Epoch [13/50], Step [266/375], Loss: 161.0178\n",
      "Epoch [13/50], Step [267/375], Loss: 304.1047\n",
      "Epoch [13/50], Step [268/375], Loss: 198.5699\n",
      "Epoch [13/50], Step [269/375], Loss: 260.9828\n",
      "Epoch [13/50], Step [270/375], Loss: 216.8491\n",
      "Epoch [13/50], Step [271/375], Loss: 338.4769\n",
      "Epoch [13/50], Step [272/375], Loss: 112.4302\n",
      "Epoch [13/50], Step [273/375], Loss: 205.1933\n",
      "Epoch [13/50], Step [274/375], Loss: 104.2564\n",
      "Epoch [13/50], Step [275/375], Loss: 192.5915\n",
      "Epoch [13/50], Step [276/375], Loss: 134.3710\n",
      "Epoch [13/50], Step [277/375], Loss: 258.0169\n",
      "Epoch [13/50], Step [278/375], Loss: 91.4031\n",
      "Epoch [13/50], Step [279/375], Loss: 587.9403\n",
      "Epoch [13/50], Step [280/375], Loss: 85.8645\n",
      "Epoch [13/50], Step [281/375], Loss: 508.0421\n",
      "Epoch [13/50], Step [282/375], Loss: 112.5862\n",
      "Epoch [13/50], Step [283/375], Loss: 285.1062\n",
      "Epoch [13/50], Step [284/375], Loss: 75.1370\n",
      "Epoch [13/50], Step [285/375], Loss: 70.3572\n",
      "Epoch [13/50], Step [286/375], Loss: 62.8008\n",
      "Epoch [13/50], Step [287/375], Loss: 1509.5972\n",
      "Epoch [13/50], Step [288/375], Loss: 306.8756\n",
      "Epoch [13/50], Step [289/375], Loss: 139.8075\n",
      "Epoch [13/50], Step [290/375], Loss: 140.4707\n",
      "Epoch [13/50], Step [291/375], Loss: 196.0335\n",
      "Epoch [13/50], Step [292/375], Loss: 727.6552\n",
      "Epoch [13/50], Step [293/375], Loss: 223.8799\n",
      "Epoch [13/50], Step [294/375], Loss: 46.5001\n",
      "Epoch [13/50], Step [295/375], Loss: 316.4784\n",
      "Epoch [13/50], Step [296/375], Loss: 151.0140\n",
      "Epoch [13/50], Step [297/375], Loss: 853.2384\n",
      "Epoch [13/50], Step [298/375], Loss: 663.5456\n",
      "Epoch [13/50], Step [299/375], Loss: 1132.6445\n",
      "Epoch [13/50], Step [300/375], Loss: 213.0907\n",
      "Epoch [13/50], Step [301/375], Loss: 181.4842\n",
      "Epoch [13/50], Step [302/375], Loss: 386.6565\n",
      "Epoch [13/50], Step [303/375], Loss: 214.3076\n",
      "Epoch [13/50], Step [304/375], Loss: 109.4999\n",
      "Epoch [13/50], Step [305/375], Loss: 640.4705\n",
      "Epoch [13/50], Step [306/375], Loss: 227.6796\n",
      "Epoch [13/50], Step [307/375], Loss: 337.5859\n",
      "Epoch [13/50], Step [308/375], Loss: 358.9381\n",
      "Epoch [13/50], Step [309/375], Loss: 174.0750\n",
      "Epoch [13/50], Step [310/375], Loss: 36.6061\n",
      "Epoch [13/50], Step [311/375], Loss: 36.4816\n",
      "Epoch [13/50], Step [312/375], Loss: 209.5268\n",
      "Epoch [13/50], Step [313/375], Loss: 414.5331\n",
      "Epoch [13/50], Step [314/375], Loss: 292.5392\n",
      "Epoch [13/50], Step [315/375], Loss: 126.1619\n",
      "Epoch [13/50], Step [316/375], Loss: 447.6678\n",
      "Epoch [13/50], Step [317/375], Loss: 277.1615\n",
      "Epoch [13/50], Step [318/375], Loss: 118.7861\n",
      "Epoch [13/50], Step [319/375], Loss: 335.4699\n",
      "Epoch [13/50], Step [320/375], Loss: 109.6049\n",
      "Epoch [13/50], Step [321/375], Loss: 118.4499\n",
      "Epoch [13/50], Step [322/375], Loss: 201.1430\n",
      "Epoch [13/50], Step [323/375], Loss: 462.1666\n",
      "Epoch [13/50], Step [324/375], Loss: 335.0864\n",
      "Epoch [13/50], Step [325/375], Loss: 84.9222\n",
      "Epoch [13/50], Step [326/375], Loss: 343.8815\n",
      "Epoch [13/50], Step [327/375], Loss: 184.8478\n",
      "Epoch [13/50], Step [328/375], Loss: 596.7042\n",
      "Epoch [13/50], Step [329/375], Loss: 90.2144\n",
      "Epoch [13/50], Step [330/375], Loss: 700.4572\n",
      "Epoch [13/50], Step [331/375], Loss: 403.5704\n",
      "Epoch [13/50], Step [332/375], Loss: 306.7470\n",
      "Epoch [13/50], Step [333/375], Loss: 512.9717\n",
      "Epoch [13/50], Step [334/375], Loss: 528.4175\n",
      "Epoch [13/50], Step [335/375], Loss: 190.1292\n",
      "Epoch [13/50], Step [336/375], Loss: 265.3716\n",
      "Epoch [13/50], Step [337/375], Loss: 100.3084\n",
      "Epoch [13/50], Step [338/375], Loss: 581.5851\n",
      "Epoch [13/50], Step [339/375], Loss: 234.0868\n",
      "Epoch [13/50], Step [340/375], Loss: 813.5709\n",
      "Epoch [13/50], Step [341/375], Loss: 313.3345\n",
      "Epoch [13/50], Step [342/375], Loss: 324.3427\n",
      "Epoch [13/50], Step [343/375], Loss: 232.6365\n",
      "Epoch [13/50], Step [344/375], Loss: 355.5419\n",
      "Epoch [13/50], Step [345/375], Loss: 819.9325\n",
      "Epoch [13/50], Step [346/375], Loss: 590.4399\n",
      "Epoch [13/50], Step [347/375], Loss: 216.9839\n",
      "Epoch [13/50], Step [348/375], Loss: 464.4692\n",
      "Epoch [13/50], Step [349/375], Loss: 239.9649\n",
      "Epoch [13/50], Step [350/375], Loss: 207.5024\n",
      "Epoch [13/50], Step [351/375], Loss: 576.6717\n",
      "Epoch [13/50], Step [352/375], Loss: 311.1567\n",
      "Epoch [13/50], Step [353/375], Loss: 494.9785\n",
      "Epoch [13/50], Step [354/375], Loss: 385.9884\n",
      "Epoch [13/50], Step [355/375], Loss: 275.8037\n",
      "Epoch [13/50], Step [356/375], Loss: 669.7141\n",
      "Epoch [13/50], Step [357/375], Loss: 433.1288\n",
      "Epoch [13/50], Step [358/375], Loss: 104.9899\n",
      "Epoch [13/50], Step [359/375], Loss: 393.3527\n",
      "Epoch [13/50], Step [360/375], Loss: 352.4599\n",
      "Epoch [13/50], Step [361/375], Loss: 368.5709\n",
      "Epoch [13/50], Step [362/375], Loss: 390.9267\n",
      "Epoch [13/50], Step [363/375], Loss: 158.0524\n",
      "Epoch [13/50], Step [364/375], Loss: 220.5951\n",
      "Epoch [13/50], Step [365/375], Loss: 232.6088\n",
      "Epoch [13/50], Step [366/375], Loss: 199.4754\n",
      "Epoch [13/50], Step [367/375], Loss: 403.3881\n",
      "Epoch [13/50], Step [368/375], Loss: 208.5972\n",
      "Epoch [13/50], Step [369/375], Loss: 37.5811\n",
      "Epoch [13/50], Step [370/375], Loss: 153.9565\n",
      "Epoch [13/50], Step [371/375], Loss: 421.6854\n",
      "Epoch [13/50], Step [372/375], Loss: 44.9913\n",
      "Epoch [13/50], Step [373/375], Loss: 265.9185\n",
      "Epoch [13/50], Step [374/375], Loss: 173.4284\n",
      "Epoch [13/50], Step [375/375], Loss: 109.8645\n",
      "Epoch [14/50], Step [1/375], Loss: 185.4848\n",
      "Epoch [14/50], Step [2/375], Loss: 416.5003\n",
      "Epoch [14/50], Step [3/375], Loss: 279.2580\n",
      "Epoch [14/50], Step [4/375], Loss: 41.3189\n",
      "Epoch [14/50], Step [5/375], Loss: 138.5526\n",
      "Epoch [14/50], Step [6/375], Loss: 94.3802\n",
      "Epoch [14/50], Step [7/375], Loss: 192.1352\n",
      "Epoch [14/50], Step [8/375], Loss: 424.0531\n",
      "Epoch [14/50], Step [9/375], Loss: 332.8877\n",
      "Epoch [14/50], Step [10/375], Loss: 356.0196\n",
      "Epoch [14/50], Step [11/375], Loss: 605.2730\n",
      "Epoch [14/50], Step [12/375], Loss: 142.2663\n",
      "Epoch [14/50], Step [13/375], Loss: 347.7570\n",
      "Epoch [14/50], Step [14/375], Loss: 150.4455\n",
      "Epoch [14/50], Step [15/375], Loss: 770.5530\n",
      "Epoch [14/50], Step [16/375], Loss: 185.2268\n",
      "Epoch [14/50], Step [17/375], Loss: 947.0555\n",
      "Epoch [14/50], Step [18/375], Loss: 92.8143\n",
      "Epoch [14/50], Step [19/375], Loss: 265.1049\n",
      "Epoch [14/50], Step [20/375], Loss: 596.6165\n",
      "Epoch [14/50], Step [21/375], Loss: 125.1811\n",
      "Epoch [14/50], Step [22/375], Loss: 374.6246\n",
      "Epoch [14/50], Step [23/375], Loss: 124.5926\n",
      "Epoch [14/50], Step [24/375], Loss: 265.9948\n",
      "Epoch [14/50], Step [25/375], Loss: 47.2238\n",
      "Epoch [14/50], Step [26/375], Loss: 85.1173\n",
      "Epoch [14/50], Step [27/375], Loss: 77.3448\n",
      "Epoch [14/50], Step [28/375], Loss: 270.3357\n",
      "Epoch [14/50], Step [29/375], Loss: 53.1181\n",
      "Epoch [14/50], Step [30/375], Loss: 306.8899\n",
      "Epoch [14/50], Step [31/375], Loss: 129.3636\n",
      "Epoch [14/50], Step [32/375], Loss: 136.2557\n",
      "Epoch [14/50], Step [33/375], Loss: 233.0571\n",
      "Epoch [14/50], Step [34/375], Loss: 514.0460\n",
      "Epoch [14/50], Step [35/375], Loss: 384.5315\n",
      "Epoch [14/50], Step [36/375], Loss: 53.7909\n",
      "Epoch [14/50], Step [37/375], Loss: 102.2558\n",
      "Epoch [14/50], Step [38/375], Loss: 179.3658\n",
      "Epoch [14/50], Step [39/375], Loss: 236.6876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Step [40/375], Loss: 315.4699\n",
      "Epoch [14/50], Step [41/375], Loss: 185.8180\n",
      "Epoch [14/50], Step [42/375], Loss: 327.3256\n",
      "Epoch [14/50], Step [43/375], Loss: 431.7007\n",
      "Epoch [14/50], Step [44/375], Loss: 327.7283\n",
      "Epoch [14/50], Step [45/375], Loss: 322.4712\n",
      "Epoch [14/50], Step [46/375], Loss: 82.3944\n",
      "Epoch [14/50], Step [47/375], Loss: 571.8616\n",
      "Epoch [14/50], Step [48/375], Loss: 422.2970\n",
      "Epoch [14/50], Step [49/375], Loss: 75.8247\n",
      "Epoch [14/50], Step [50/375], Loss: 435.7752\n",
      "Epoch [14/50], Step [51/375], Loss: 56.7932\n",
      "Epoch [14/50], Step [52/375], Loss: 104.0981\n",
      "Epoch [14/50], Step [53/375], Loss: 51.0630\n",
      "Epoch [14/50], Step [54/375], Loss: 157.5434\n",
      "Epoch [14/50], Step [55/375], Loss: 415.0804\n",
      "Epoch [14/50], Step [56/375], Loss: 894.1157\n",
      "Epoch [14/50], Step [57/375], Loss: 101.8522\n",
      "Epoch [14/50], Step [58/375], Loss: 414.3881\n",
      "Epoch [14/50], Step [59/375], Loss: 50.9994\n",
      "Epoch [14/50], Step [60/375], Loss: 105.2452\n",
      "Epoch [14/50], Step [61/375], Loss: 478.8547\n",
      "Epoch [14/50], Step [62/375], Loss: 1343.2117\n",
      "Epoch [14/50], Step [63/375], Loss: 651.3176\n",
      "Epoch [14/50], Step [64/375], Loss: 57.0321\n",
      "Epoch [14/50], Step [65/375], Loss: 281.4167\n",
      "Epoch [14/50], Step [66/375], Loss: 345.1137\n",
      "Epoch [14/50], Step [67/375], Loss: 350.2565\n",
      "Epoch [14/50], Step [68/375], Loss: 489.6969\n",
      "Epoch [14/50], Step [69/375], Loss: 246.4744\n",
      "Epoch [14/50], Step [70/375], Loss: 71.2335\n",
      "Epoch [14/50], Step [71/375], Loss: 35.6635\n",
      "Epoch [14/50], Step [72/375], Loss: 234.6936\n",
      "Epoch [14/50], Step [73/375], Loss: 165.5150\n",
      "Epoch [14/50], Step [74/375], Loss: 250.7723\n",
      "Epoch [14/50], Step [75/375], Loss: 191.8642\n",
      "Epoch [14/50], Step [76/375], Loss: 122.3057\n",
      "Epoch [14/50], Step [77/375], Loss: 222.7758\n",
      "Epoch [14/50], Step [78/375], Loss: 109.8502\n",
      "Epoch [14/50], Step [79/375], Loss: 255.4673\n",
      "Epoch [14/50], Step [80/375], Loss: 46.9488\n",
      "Epoch [14/50], Step [81/375], Loss: 103.5569\n",
      "Epoch [14/50], Step [82/375], Loss: 94.2868\n",
      "Epoch [14/50], Step [83/375], Loss: 475.1285\n",
      "Epoch [14/50], Step [84/375], Loss: 330.2316\n",
      "Epoch [14/50], Step [85/375], Loss: 112.4496\n",
      "Epoch [14/50], Step [86/375], Loss: 189.3085\n",
      "Epoch [14/50], Step [87/375], Loss: 432.0226\n",
      "Epoch [14/50], Step [88/375], Loss: 251.5009\n",
      "Epoch [14/50], Step [89/375], Loss: 228.5898\n",
      "Epoch [14/50], Step [90/375], Loss: 95.9328\n",
      "Epoch [14/50], Step [91/375], Loss: 167.3904\n",
      "Epoch [14/50], Step [92/375], Loss: 135.6791\n",
      "Epoch [14/50], Step [93/375], Loss: 150.6744\n",
      "Epoch [14/50], Step [94/375], Loss: 245.2284\n",
      "Epoch [14/50], Step [95/375], Loss: 45.3504\n",
      "Epoch [14/50], Step [96/375], Loss: 248.6583\n",
      "Epoch [14/50], Step [97/375], Loss: 63.0792\n",
      "Epoch [14/50], Step [98/375], Loss: 239.2828\n",
      "Epoch [14/50], Step [99/375], Loss: 297.1469\n",
      "Epoch [14/50], Step [100/375], Loss: 589.9982\n",
      "Epoch [14/50], Step [101/375], Loss: 445.9292\n",
      "Epoch [14/50], Step [102/375], Loss: 171.1071\n",
      "Epoch [14/50], Step [103/375], Loss: 165.0047\n",
      "Epoch [14/50], Step [104/375], Loss: 470.3293\n",
      "Epoch [14/50], Step [105/375], Loss: 465.0060\n",
      "Epoch [14/50], Step [106/375], Loss: 117.6643\n",
      "Epoch [14/50], Step [107/375], Loss: 79.3189\n",
      "Epoch [14/50], Step [108/375], Loss: 97.3307\n",
      "Epoch [14/50], Step [109/375], Loss: 282.6673\n",
      "Epoch [14/50], Step [110/375], Loss: 410.5727\n",
      "Epoch [14/50], Step [111/375], Loss: 235.0276\n",
      "Epoch [14/50], Step [112/375], Loss: 364.3050\n",
      "Epoch [14/50], Step [113/375], Loss: 1075.2246\n",
      "Epoch [14/50], Step [114/375], Loss: 81.6713\n",
      "Epoch [14/50], Step [115/375], Loss: 329.3246\n",
      "Epoch [14/50], Step [116/375], Loss: 255.9058\n",
      "Epoch [14/50], Step [117/375], Loss: 368.3109\n",
      "Epoch [14/50], Step [118/375], Loss: 533.2545\n",
      "Epoch [14/50], Step [119/375], Loss: 94.2556\n",
      "Epoch [14/50], Step [120/375], Loss: 173.6548\n",
      "Epoch [14/50], Step [121/375], Loss: 288.4221\n",
      "Epoch [14/50], Step [122/375], Loss: 804.6122\n",
      "Epoch [14/50], Step [123/375], Loss: 114.8433\n",
      "Epoch [14/50], Step [124/375], Loss: 516.7001\n",
      "Epoch [14/50], Step [125/375], Loss: 128.4736\n",
      "Epoch [14/50], Step [126/375], Loss: 77.2454\n",
      "Epoch [14/50], Step [127/375], Loss: 200.8122\n",
      "Epoch [14/50], Step [128/375], Loss: 392.1697\n",
      "Epoch [14/50], Step [129/375], Loss: 243.9762\n",
      "Epoch [14/50], Step [130/375], Loss: 79.2147\n",
      "Epoch [14/50], Step [131/375], Loss: 139.0487\n",
      "Epoch [14/50], Step [132/375], Loss: 34.6105\n",
      "Epoch [14/50], Step [133/375], Loss: 281.6462\n",
      "Epoch [14/50], Step [134/375], Loss: 138.6442\n",
      "Epoch [14/50], Step [135/375], Loss: 154.4140\n",
      "Epoch [14/50], Step [136/375], Loss: 619.6404\n",
      "Epoch [14/50], Step [137/375], Loss: 135.8215\n",
      "Epoch [14/50], Step [138/375], Loss: 290.6882\n",
      "Epoch [14/50], Step [139/375], Loss: 319.7967\n",
      "Epoch [14/50], Step [140/375], Loss: 270.4286\n",
      "Epoch [14/50], Step [141/375], Loss: 145.3397\n",
      "Epoch [14/50], Step [142/375], Loss: 103.5870\n",
      "Epoch [14/50], Step [143/375], Loss: 310.4127\n",
      "Epoch [14/50], Step [144/375], Loss: 158.6535\n",
      "Epoch [14/50], Step [145/375], Loss: 316.7671\n",
      "Epoch [14/50], Step [146/375], Loss: 392.5488\n",
      "Epoch [14/50], Step [147/375], Loss: 378.3131\n",
      "Epoch [14/50], Step [148/375], Loss: 274.2540\n",
      "Epoch [14/50], Step [149/375], Loss: 626.1436\n",
      "Epoch [14/50], Step [150/375], Loss: 806.9072\n",
      "Epoch [14/50], Step [151/375], Loss: 169.7298\n",
      "Epoch [14/50], Step [152/375], Loss: 360.5729\n",
      "Epoch [14/50], Step [153/375], Loss: 191.5934\n",
      "Epoch [14/50], Step [154/375], Loss: 195.9408\n",
      "Epoch [14/50], Step [155/375], Loss: 376.1706\n",
      "Epoch [14/50], Step [156/375], Loss: 732.7403\n",
      "Epoch [14/50], Step [157/375], Loss: 369.6601\n",
      "Epoch [14/50], Step [158/375], Loss: 1016.1523\n",
      "Epoch [14/50], Step [159/375], Loss: 284.3073\n",
      "Epoch [14/50], Step [160/375], Loss: 886.0391\n",
      "Epoch [14/50], Step [161/375], Loss: 243.2193\n",
      "Epoch [14/50], Step [162/375], Loss: 321.7365\n",
      "Epoch [14/50], Step [163/375], Loss: 291.2631\n",
      "Epoch [14/50], Step [164/375], Loss: 2191.0691\n",
      "Epoch [14/50], Step [165/375], Loss: 1464.4889\n",
      "Epoch [14/50], Step [166/375], Loss: 411.9425\n",
      "Epoch [14/50], Step [167/375], Loss: 1005.9861\n",
      "Epoch [14/50], Step [168/375], Loss: 417.0699\n",
      "Epoch [14/50], Step [169/375], Loss: 1369.0767\n",
      "Epoch [14/50], Step [170/375], Loss: 565.4371\n",
      "Epoch [14/50], Step [171/375], Loss: 920.3583\n",
      "Epoch [14/50], Step [172/375], Loss: 812.1331\n",
      "Epoch [14/50], Step [173/375], Loss: 985.0677\n",
      "Epoch [14/50], Step [174/375], Loss: 108.1271\n",
      "Epoch [14/50], Step [175/375], Loss: 80.6197\n",
      "Epoch [14/50], Step [176/375], Loss: 524.3104\n",
      "Epoch [14/50], Step [177/375], Loss: 426.7650\n",
      "Epoch [14/50], Step [178/375], Loss: 744.7902\n",
      "Epoch [14/50], Step [179/375], Loss: 196.5297\n",
      "Epoch [14/50], Step [180/375], Loss: 365.9882\n",
      "Epoch [14/50], Step [181/375], Loss: 168.2227\n",
      "Epoch [14/50], Step [182/375], Loss: 218.9078\n",
      "Epoch [14/50], Step [183/375], Loss: 157.3361\n",
      "Epoch [14/50], Step [184/375], Loss: 160.0470\n",
      "Epoch [14/50], Step [185/375], Loss: 409.1254\n",
      "Epoch [14/50], Step [186/375], Loss: 619.0093\n",
      "Epoch [14/50], Step [187/375], Loss: 578.6932\n",
      "Epoch [14/50], Step [188/375], Loss: 84.7461\n",
      "Epoch [14/50], Step [189/375], Loss: 139.0542\n",
      "Epoch [14/50], Step [190/375], Loss: 113.3462\n",
      "Epoch [14/50], Step [191/375], Loss: 94.3880\n",
      "Epoch [14/50], Step [192/375], Loss: 377.3389\n",
      "Epoch [14/50], Step [193/375], Loss: 379.8078\n",
      "Epoch [14/50], Step [194/375], Loss: 376.3623\n",
      "Epoch [14/50], Step [195/375], Loss: 443.3878\n",
      "Epoch [14/50], Step [196/375], Loss: 205.3042\n",
      "Epoch [14/50], Step [197/375], Loss: 91.5908\n",
      "Epoch [14/50], Step [198/375], Loss: 155.2207\n",
      "Epoch [14/50], Step [199/375], Loss: 175.0199\n",
      "Epoch [14/50], Step [200/375], Loss: 429.9379\n",
      "Epoch [14/50], Step [201/375], Loss: 183.6657\n",
      "Epoch [14/50], Step [202/375], Loss: 297.0544\n",
      "Epoch [14/50], Step [203/375], Loss: 262.2688\n",
      "Epoch [14/50], Step [204/375], Loss: 312.1860\n",
      "Epoch [14/50], Step [205/375], Loss: 39.0014\n",
      "Epoch [14/50], Step [206/375], Loss: 211.4533\n",
      "Epoch [14/50], Step [207/375], Loss: 386.5038\n",
      "Epoch [14/50], Step [208/375], Loss: 399.2040\n",
      "Epoch [14/50], Step [209/375], Loss: 135.0427\n",
      "Epoch [14/50], Step [210/375], Loss: 437.8293\n",
      "Epoch [14/50], Step [211/375], Loss: 193.7925\n",
      "Epoch [14/50], Step [212/375], Loss: 184.4270\n",
      "Epoch [14/50], Step [213/375], Loss: 376.3988\n",
      "Epoch [14/50], Step [214/375], Loss: 280.9014\n",
      "Epoch [14/50], Step [215/375], Loss: 125.6052\n",
      "Epoch [14/50], Step [216/375], Loss: 75.8648\n",
      "Epoch [14/50], Step [217/375], Loss: 112.0103\n",
      "Epoch [14/50], Step [218/375], Loss: 50.9101\n",
      "Epoch [14/50], Step [219/375], Loss: 64.1205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Step [220/375], Loss: 557.2464\n",
      "Epoch [14/50], Step [221/375], Loss: 496.1539\n",
      "Epoch [14/50], Step [222/375], Loss: 112.7361\n",
      "Epoch [14/50], Step [223/375], Loss: 526.2353\n",
      "Epoch [14/50], Step [224/375], Loss: 497.8064\n",
      "Epoch [14/50], Step [225/375], Loss: 157.2974\n",
      "Epoch [14/50], Step [226/375], Loss: 398.0446\n",
      "Epoch [14/50], Step [227/375], Loss: 378.7180\n",
      "Epoch [14/50], Step [228/375], Loss: 247.5232\n",
      "Epoch [14/50], Step [229/375], Loss: 260.7296\n",
      "Epoch [14/50], Step [230/375], Loss: 536.3635\n",
      "Epoch [14/50], Step [231/375], Loss: 99.1396\n",
      "Epoch [14/50], Step [232/375], Loss: 279.0023\n",
      "Epoch [14/50], Step [233/375], Loss: 684.5213\n",
      "Epoch [14/50], Step [234/375], Loss: 248.7323\n",
      "Epoch [14/50], Step [235/375], Loss: 301.2447\n",
      "Epoch [14/50], Step [236/375], Loss: 112.8796\n",
      "Epoch [14/50], Step [237/375], Loss: 360.8868\n",
      "Epoch [14/50], Step [238/375], Loss: 37.1538\n",
      "Epoch [14/50], Step [239/375], Loss: 402.2240\n",
      "Epoch [14/50], Step [240/375], Loss: 140.9116\n",
      "Epoch [14/50], Step [241/375], Loss: 194.8203\n",
      "Epoch [14/50], Step [242/375], Loss: 218.0886\n",
      "Epoch [14/50], Step [243/375], Loss: 260.8444\n",
      "Epoch [14/50], Step [244/375], Loss: 223.7021\n",
      "Epoch [14/50], Step [245/375], Loss: 321.2442\n",
      "Epoch [14/50], Step [246/375], Loss: 483.3889\n",
      "Epoch [14/50], Step [247/375], Loss: 156.6305\n",
      "Epoch [14/50], Step [248/375], Loss: 150.6003\n",
      "Epoch [14/50], Step [249/375], Loss: 297.2144\n",
      "Epoch [14/50], Step [250/375], Loss: 191.4077\n",
      "Epoch [14/50], Step [251/375], Loss: 254.3831\n",
      "Epoch [14/50], Step [252/375], Loss: 140.1523\n",
      "Epoch [14/50], Step [253/375], Loss: 406.3163\n",
      "Epoch [14/50], Step [254/375], Loss: 850.0453\n",
      "Epoch [14/50], Step [255/375], Loss: 153.0422\n",
      "Epoch [14/50], Step [256/375], Loss: 223.2556\n",
      "Epoch [14/50], Step [257/375], Loss: 164.3133\n",
      "Epoch [14/50], Step [258/375], Loss: 238.4976\n",
      "Epoch [14/50], Step [259/375], Loss: 457.3030\n",
      "Epoch [14/50], Step [260/375], Loss: 231.6687\n",
      "Epoch [14/50], Step [261/375], Loss: 332.6536\n",
      "Epoch [14/50], Step [262/375], Loss: 261.9727\n",
      "Epoch [14/50], Step [263/375], Loss: 83.3660\n",
      "Epoch [14/50], Step [264/375], Loss: 141.3449\n",
      "Epoch [14/50], Step [265/375], Loss: 140.9181\n",
      "Epoch [14/50], Step [266/375], Loss: 369.6319\n",
      "Epoch [14/50], Step [267/375], Loss: 183.5804\n",
      "Epoch [14/50], Step [268/375], Loss: 181.5082\n",
      "Epoch [14/50], Step [269/375], Loss: 384.4948\n",
      "Epoch [14/50], Step [270/375], Loss: 80.7227\n",
      "Epoch [14/50], Step [271/375], Loss: 431.1362\n",
      "Epoch [14/50], Step [272/375], Loss: 89.1729\n",
      "Epoch [14/50], Step [273/375], Loss: 109.9978\n",
      "Epoch [14/50], Step [274/375], Loss: 394.1706\n",
      "Epoch [14/50], Step [275/375], Loss: 822.2658\n",
      "Epoch [14/50], Step [276/375], Loss: 82.7936\n",
      "Epoch [14/50], Step [277/375], Loss: 431.0743\n",
      "Epoch [14/50], Step [278/375], Loss: 178.5705\n",
      "Epoch [14/50], Step [279/375], Loss: 337.5010\n",
      "Epoch [14/50], Step [280/375], Loss: 156.6719\n",
      "Epoch [14/50], Step [281/375], Loss: 35.0119\n",
      "Epoch [14/50], Step [282/375], Loss: 558.7766\n",
      "Epoch [14/50], Step [283/375], Loss: 14.3911\n",
      "Epoch [14/50], Step [284/375], Loss: 116.3707\n",
      "Epoch [14/50], Step [285/375], Loss: 433.9135\n",
      "Epoch [14/50], Step [286/375], Loss: 478.5347\n",
      "Epoch [14/50], Step [287/375], Loss: 116.4553\n",
      "Epoch [14/50], Step [288/375], Loss: 62.8476\n",
      "Epoch [14/50], Step [289/375], Loss: 109.7975\n",
      "Epoch [14/50], Step [290/375], Loss: 145.7875\n",
      "Epoch [14/50], Step [291/375], Loss: 23.9451\n",
      "Epoch [14/50], Step [292/375], Loss: 92.7090\n",
      "Epoch [14/50], Step [293/375], Loss: 227.4435\n",
      "Epoch [14/50], Step [294/375], Loss: 494.5247\n",
      "Epoch [14/50], Step [295/375], Loss: 145.3527\n",
      "Epoch [14/50], Step [296/375], Loss: 162.9405\n",
      "Epoch [14/50], Step [297/375], Loss: 91.5912\n",
      "Epoch [14/50], Step [298/375], Loss: 221.1553\n",
      "Epoch [14/50], Step [299/375], Loss: 485.2458\n",
      "Epoch [14/50], Step [300/375], Loss: 217.3005\n",
      "Epoch [14/50], Step [301/375], Loss: 143.7169\n",
      "Epoch [14/50], Step [302/375], Loss: 123.6816\n",
      "Epoch [14/50], Step [303/375], Loss: 31.5445\n",
      "Epoch [14/50], Step [304/375], Loss: 800.2430\n",
      "Epoch [14/50], Step [305/375], Loss: 91.5624\n",
      "Epoch [14/50], Step [306/375], Loss: 173.3535\n",
      "Epoch [14/50], Step [307/375], Loss: 63.4210\n",
      "Epoch [14/50], Step [308/375], Loss: 572.9725\n",
      "Epoch [14/50], Step [309/375], Loss: 180.0870\n",
      "Epoch [14/50], Step [310/375], Loss: 135.9155\n",
      "Epoch [14/50], Step [311/375], Loss: 497.2945\n",
      "Epoch [14/50], Step [312/375], Loss: 233.3487\n",
      "Epoch [14/50], Step [313/375], Loss: 234.1516\n",
      "Epoch [14/50], Step [314/375], Loss: 126.8413\n",
      "Epoch [14/50], Step [315/375], Loss: 429.3340\n",
      "Epoch [14/50], Step [316/375], Loss: 286.9227\n",
      "Epoch [14/50], Step [317/375], Loss: 175.1540\n",
      "Epoch [14/50], Step [318/375], Loss: 532.5064\n",
      "Epoch [14/50], Step [319/375], Loss: 273.1619\n",
      "Epoch [14/50], Step [320/375], Loss: 273.6375\n",
      "Epoch [14/50], Step [321/375], Loss: 104.9973\n",
      "Epoch [14/50], Step [322/375], Loss: 325.6598\n",
      "Epoch [14/50], Step [323/375], Loss: 101.5630\n",
      "Epoch [14/50], Step [324/375], Loss: 262.6690\n",
      "Epoch [14/50], Step [325/375], Loss: 205.7750\n",
      "Epoch [14/50], Step [326/375], Loss: 64.4637\n",
      "Epoch [14/50], Step [327/375], Loss: 273.8180\n",
      "Epoch [14/50], Step [328/375], Loss: 332.3917\n",
      "Epoch [14/50], Step [329/375], Loss: 289.7036\n",
      "Epoch [14/50], Step [330/375], Loss: 85.5477\n",
      "Epoch [14/50], Step [331/375], Loss: 215.3792\n",
      "Epoch [14/50], Step [332/375], Loss: 66.8515\n",
      "Epoch [14/50], Step [333/375], Loss: 111.3647\n",
      "Epoch [14/50], Step [334/375], Loss: 121.2874\n",
      "Epoch [14/50], Step [335/375], Loss: 87.2733\n",
      "Epoch [14/50], Step [336/375], Loss: 112.1193\n",
      "Epoch [14/50], Step [337/375], Loss: 426.3656\n",
      "Epoch [14/50], Step [338/375], Loss: 331.0566\n",
      "Epoch [14/50], Step [339/375], Loss: 109.3643\n",
      "Epoch [14/50], Step [340/375], Loss: 122.6896\n",
      "Epoch [14/50], Step [341/375], Loss: 36.7357\n",
      "Epoch [14/50], Step [342/375], Loss: 623.1805\n",
      "Epoch [14/50], Step [343/375], Loss: 170.8740\n",
      "Epoch [14/50], Step [344/375], Loss: 198.8759\n",
      "Epoch [14/50], Step [345/375], Loss: 341.9956\n",
      "Epoch [14/50], Step [346/375], Loss: 57.3957\n",
      "Epoch [14/50], Step [347/375], Loss: 416.3817\n",
      "Epoch [14/50], Step [348/375], Loss: 273.5792\n",
      "Epoch [14/50], Step [349/375], Loss: 182.2611\n",
      "Epoch [14/50], Step [350/375], Loss: 585.7349\n",
      "Epoch [14/50], Step [351/375], Loss: 130.6330\n",
      "Epoch [14/50], Step [352/375], Loss: 387.9607\n",
      "Epoch [14/50], Step [353/375], Loss: 81.0688\n",
      "Epoch [14/50], Step [354/375], Loss: 288.7950\n",
      "Epoch [14/50], Step [355/375], Loss: 278.3552\n",
      "Epoch [14/50], Step [356/375], Loss: 219.3765\n",
      "Epoch [14/50], Step [357/375], Loss: 451.3888\n",
      "Epoch [14/50], Step [358/375], Loss: 61.8191\n",
      "Epoch [14/50], Step [359/375], Loss: 230.0151\n",
      "Epoch [14/50], Step [360/375], Loss: 298.2898\n",
      "Epoch [14/50], Step [361/375], Loss: 91.6072\n",
      "Epoch [14/50], Step [362/375], Loss: 406.6274\n",
      "Epoch [14/50], Step [363/375], Loss: 212.0947\n",
      "Epoch [14/50], Step [364/375], Loss: 149.4304\n",
      "Epoch [14/50], Step [365/375], Loss: 196.1072\n",
      "Epoch [14/50], Step [366/375], Loss: 764.4257\n",
      "Epoch [14/50], Step [367/375], Loss: 186.5095\n",
      "Epoch [14/50], Step [368/375], Loss: 302.7409\n",
      "Epoch [14/50], Step [369/375], Loss: 362.8005\n",
      "Epoch [14/50], Step [370/375], Loss: 699.1811\n",
      "Epoch [14/50], Step [371/375], Loss: 264.1769\n",
      "Epoch [14/50], Step [372/375], Loss: 286.5248\n",
      "Epoch [14/50], Step [373/375], Loss: 358.6183\n",
      "Epoch [14/50], Step [374/375], Loss: 105.5241\n",
      "Epoch [14/50], Step [375/375], Loss: 649.8284\n",
      "Epoch [15/50], Step [1/375], Loss: 727.7416\n",
      "Epoch [15/50], Step [2/375], Loss: 778.4110\n",
      "Epoch [15/50], Step [3/375], Loss: 201.7143\n",
      "Epoch [15/50], Step [4/375], Loss: 472.8776\n",
      "Epoch [15/50], Step [5/375], Loss: 474.4675\n",
      "Epoch [15/50], Step [6/375], Loss: 353.0635\n",
      "Epoch [15/50], Step [7/375], Loss: 847.1620\n",
      "Epoch [15/50], Step [8/375], Loss: 317.0616\n",
      "Epoch [15/50], Step [9/375], Loss: 134.0361\n",
      "Epoch [15/50], Step [10/375], Loss: 300.2172\n",
      "Epoch [15/50], Step [11/375], Loss: 817.3214\n",
      "Epoch [15/50], Step [12/375], Loss: 658.9413\n",
      "Epoch [15/50], Step [13/375], Loss: 723.0897\n",
      "Epoch [15/50], Step [14/375], Loss: 477.7012\n",
      "Epoch [15/50], Step [15/375], Loss: 1100.9133\n",
      "Epoch [15/50], Step [16/375], Loss: 454.6605\n",
      "Epoch [15/50], Step [17/375], Loss: 107.0252\n",
      "Epoch [15/50], Step [18/375], Loss: 82.6198\n",
      "Epoch [15/50], Step [19/375], Loss: 537.9384\n",
      "Epoch [15/50], Step [20/375], Loss: 258.1555\n",
      "Epoch [15/50], Step [21/375], Loss: 231.5242\n",
      "Epoch [15/50], Step [22/375], Loss: 109.0496\n",
      "Epoch [15/50], Step [23/375], Loss: 98.1502\n",
      "Epoch [15/50], Step [24/375], Loss: 335.3090\n",
      "Epoch [15/50], Step [25/375], Loss: 844.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Step [26/375], Loss: 165.7413\n",
      "Epoch [15/50], Step [27/375], Loss: 409.9117\n",
      "Epoch [15/50], Step [28/375], Loss: 69.5280\n",
      "Epoch [15/50], Step [29/375], Loss: 374.8301\n",
      "Epoch [15/50], Step [30/375], Loss: 904.0480\n",
      "Epoch [15/50], Step [31/375], Loss: 199.6375\n",
      "Epoch [15/50], Step [32/375], Loss: 406.0502\n",
      "Epoch [15/50], Step [33/375], Loss: 519.3226\n",
      "Epoch [15/50], Step [34/375], Loss: 205.3164\n",
      "Epoch [15/50], Step [35/375], Loss: 160.3833\n",
      "Epoch [15/50], Step [36/375], Loss: 59.9088\n",
      "Epoch [15/50], Step [37/375], Loss: 38.9351\n",
      "Epoch [15/50], Step [38/375], Loss: 922.2147\n",
      "Epoch [15/50], Step [39/375], Loss: 360.6110\n",
      "Epoch [15/50], Step [40/375], Loss: 133.6802\n",
      "Epoch [15/50], Step [41/375], Loss: 111.7647\n",
      "Epoch [15/50], Step [42/375], Loss: 318.2749\n",
      "Epoch [15/50], Step [43/375], Loss: 252.4347\n",
      "Epoch [15/50], Step [44/375], Loss: 125.4986\n",
      "Epoch [15/50], Step [45/375], Loss: 119.2546\n",
      "Epoch [15/50], Step [46/375], Loss: 48.0948\n",
      "Epoch [15/50], Step [47/375], Loss: 66.3065\n",
      "Epoch [15/50], Step [48/375], Loss: 130.5580\n",
      "Epoch [15/50], Step [49/375], Loss: 235.9956\n",
      "Epoch [15/50], Step [50/375], Loss: 323.6577\n",
      "Epoch [15/50], Step [51/375], Loss: 291.8692\n",
      "Epoch [15/50], Step [52/375], Loss: 60.4272\n",
      "Epoch [15/50], Step [53/375], Loss: 166.7619\n",
      "Epoch [15/50], Step [54/375], Loss: 48.3661\n",
      "Epoch [15/50], Step [55/375], Loss: 930.8967\n",
      "Epoch [15/50], Step [56/375], Loss: 716.0120\n",
      "Epoch [15/50], Step [57/375], Loss: 335.5314\n",
      "Epoch [15/50], Step [58/375], Loss: 166.2684\n",
      "Epoch [15/50], Step [59/375], Loss: 256.3974\n",
      "Epoch [15/50], Step [60/375], Loss: 828.2687\n",
      "Epoch [15/50], Step [61/375], Loss: 148.0219\n",
      "Epoch [15/50], Step [62/375], Loss: 171.5240\n",
      "Epoch [15/50], Step [63/375], Loss: 150.4276\n",
      "Epoch [15/50], Step [64/375], Loss: 295.0596\n",
      "Epoch [15/50], Step [65/375], Loss: 386.4084\n",
      "Epoch [15/50], Step [66/375], Loss: 123.7496\n",
      "Epoch [15/50], Step [67/375], Loss: 104.2056\n",
      "Epoch [15/50], Step [68/375], Loss: 271.1993\n",
      "Epoch [15/50], Step [69/375], Loss: 263.5566\n",
      "Epoch [15/50], Step [70/375], Loss: 245.9529\n",
      "Epoch [15/50], Step [71/375], Loss: 93.5194\n",
      "Epoch [15/50], Step [72/375], Loss: 619.0848\n",
      "Epoch [15/50], Step [73/375], Loss: 846.8151\n",
      "Epoch [15/50], Step [74/375], Loss: 709.7012\n",
      "Epoch [15/50], Step [75/375], Loss: 121.8670\n",
      "Epoch [15/50], Step [76/375], Loss: 295.9536\n",
      "Epoch [15/50], Step [77/375], Loss: 508.0087\n",
      "Epoch [15/50], Step [78/375], Loss: 473.7631\n",
      "Epoch [15/50], Step [79/375], Loss: 372.8680\n",
      "Epoch [15/50], Step [80/375], Loss: 287.8583\n",
      "Epoch [15/50], Step [81/375], Loss: 214.8908\n",
      "Epoch [15/50], Step [82/375], Loss: 164.4143\n",
      "Epoch [15/50], Step [83/375], Loss: 259.2840\n",
      "Epoch [15/50], Step [84/375], Loss: 216.2406\n",
      "Epoch [15/50], Step [85/375], Loss: 526.0889\n",
      "Epoch [15/50], Step [86/375], Loss: 352.0854\n",
      "Epoch [15/50], Step [87/375], Loss: 150.0843\n",
      "Epoch [15/50], Step [88/375], Loss: 1102.5031\n",
      "Epoch [15/50], Step [89/375], Loss: 113.0343\n",
      "Epoch [15/50], Step [90/375], Loss: 373.3164\n",
      "Epoch [15/50], Step [91/375], Loss: 300.8744\n",
      "Epoch [15/50], Step [92/375], Loss: 200.9771\n",
      "Epoch [15/50], Step [93/375], Loss: 174.6414\n",
      "Epoch [15/50], Step [94/375], Loss: 514.7360\n",
      "Epoch [15/50], Step [95/375], Loss: 407.7452\n",
      "Epoch [15/50], Step [96/375], Loss: 83.8373\n",
      "Epoch [15/50], Step [97/375], Loss: 157.0619\n",
      "Epoch [15/50], Step [98/375], Loss: 386.7409\n",
      "Epoch [15/50], Step [99/375], Loss: 170.7221\n",
      "Epoch [15/50], Step [100/375], Loss: 173.0300\n",
      "Epoch [15/50], Step [101/375], Loss: 492.0894\n",
      "Epoch [15/50], Step [102/375], Loss: 170.8682\n",
      "Epoch [15/50], Step [103/375], Loss: 255.1315\n",
      "Epoch [15/50], Step [104/375], Loss: 351.6632\n",
      "Epoch [15/50], Step [105/375], Loss: 41.7181\n",
      "Epoch [15/50], Step [106/375], Loss: 433.6105\n",
      "Epoch [15/50], Step [107/375], Loss: 185.8367\n",
      "Epoch [15/50], Step [108/375], Loss: 321.1019\n",
      "Epoch [15/50], Step [109/375], Loss: 229.6779\n",
      "Epoch [15/50], Step [110/375], Loss: 85.2818\n",
      "Epoch [15/50], Step [111/375], Loss: 26.6605\n",
      "Epoch [15/50], Step [112/375], Loss: 295.0673\n",
      "Epoch [15/50], Step [113/375], Loss: 185.9670\n",
      "Epoch [15/50], Step [114/375], Loss: 49.6406\n",
      "Epoch [15/50], Step [115/375], Loss: 338.3664\n",
      "Epoch [15/50], Step [116/375], Loss: 131.0251\n",
      "Epoch [15/50], Step [117/375], Loss: 63.8753\n",
      "Epoch [15/50], Step [118/375], Loss: 51.1233\n",
      "Epoch [15/50], Step [119/375], Loss: 393.5935\n",
      "Epoch [15/50], Step [120/375], Loss: 100.4520\n",
      "Epoch [15/50], Step [121/375], Loss: 192.9949\n",
      "Epoch [15/50], Step [122/375], Loss: 345.4160\n",
      "Epoch [15/50], Step [123/375], Loss: 349.6387\n",
      "Epoch [15/50], Step [124/375], Loss: 384.2368\n",
      "Epoch [15/50], Step [125/375], Loss: 227.5639\n",
      "Epoch [15/50], Step [126/375], Loss: 77.8318\n",
      "Epoch [15/50], Step [127/375], Loss: 264.1502\n",
      "Epoch [15/50], Step [128/375], Loss: 107.0504\n",
      "Epoch [15/50], Step [129/375], Loss: 130.3521\n",
      "Epoch [15/50], Step [130/375], Loss: 1596.4463\n",
      "Epoch [15/50], Step [131/375], Loss: 124.3181\n",
      "Epoch [15/50], Step [132/375], Loss: 96.7362\n",
      "Epoch [15/50], Step [133/375], Loss: 356.7545\n",
      "Epoch [15/50], Step [134/375], Loss: 33.6647\n",
      "Epoch [15/50], Step [135/375], Loss: 220.0574\n",
      "Epoch [15/50], Step [136/375], Loss: 188.9290\n",
      "Epoch [15/50], Step [137/375], Loss: 280.8739\n",
      "Epoch [15/50], Step [138/375], Loss: 184.6407\n",
      "Epoch [15/50], Step [139/375], Loss: 164.0070\n",
      "Epoch [15/50], Step [140/375], Loss: 78.8756\n",
      "Epoch [15/50], Step [141/375], Loss: 71.3516\n",
      "Epoch [15/50], Step [142/375], Loss: 27.9099\n",
      "Epoch [15/50], Step [143/375], Loss: 36.7308\n",
      "Epoch [15/50], Step [144/375], Loss: 125.5574\n",
      "Epoch [15/50], Step [145/375], Loss: 160.4342\n",
      "Epoch [15/50], Step [146/375], Loss: 533.4642\n",
      "Epoch [15/50], Step [147/375], Loss: 33.7835\n",
      "Epoch [15/50], Step [148/375], Loss: 248.1557\n",
      "Epoch [15/50], Step [149/375], Loss: 118.1752\n",
      "Epoch [15/50], Step [150/375], Loss: 48.6681\n",
      "Epoch [15/50], Step [151/375], Loss: 41.5974\n",
      "Epoch [15/50], Step [152/375], Loss: 183.7609\n",
      "Epoch [15/50], Step [153/375], Loss: 828.5800\n",
      "Epoch [15/50], Step [154/375], Loss: 94.0001\n",
      "Epoch [15/50], Step [155/375], Loss: 554.9499\n",
      "Epoch [15/50], Step [156/375], Loss: 317.7036\n",
      "Epoch [15/50], Step [157/375], Loss: 84.5471\n",
      "Epoch [15/50], Step [158/375], Loss: 708.3281\n",
      "Epoch [15/50], Step [159/375], Loss: 62.5123\n",
      "Epoch [15/50], Step [160/375], Loss: 202.1604\n",
      "Epoch [15/50], Step [161/375], Loss: 203.1193\n",
      "Epoch [15/50], Step [162/375], Loss: 254.1266\n",
      "Epoch [15/50], Step [163/375], Loss: 321.5259\n",
      "Epoch [15/50], Step [164/375], Loss: 184.3989\n",
      "Epoch [15/50], Step [165/375], Loss: 378.1848\n",
      "Epoch [15/50], Step [166/375], Loss: 200.1132\n",
      "Epoch [15/50], Step [167/375], Loss: 291.6511\n",
      "Epoch [15/50], Step [168/375], Loss: 235.4577\n",
      "Epoch [15/50], Step [169/375], Loss: 100.0481\n",
      "Epoch [15/50], Step [170/375], Loss: 301.6198\n",
      "Epoch [15/50], Step [171/375], Loss: 327.5391\n",
      "Epoch [15/50], Step [172/375], Loss: 242.9138\n",
      "Epoch [15/50], Step [173/375], Loss: 79.1146\n",
      "Epoch [15/50], Step [174/375], Loss: 310.1999\n",
      "Epoch [15/50], Step [175/375], Loss: 209.5220\n",
      "Epoch [15/50], Step [176/375], Loss: 115.4898\n",
      "Epoch [15/50], Step [177/375], Loss: 266.2560\n",
      "Epoch [15/50], Step [178/375], Loss: 170.1241\n",
      "Epoch [15/50], Step [179/375], Loss: 628.3016\n",
      "Epoch [15/50], Step [180/375], Loss: 134.9086\n",
      "Epoch [15/50], Step [181/375], Loss: 473.1810\n",
      "Epoch [15/50], Step [182/375], Loss: 337.5897\n",
      "Epoch [15/50], Step [183/375], Loss: 91.0075\n",
      "Epoch [15/50], Step [184/375], Loss: 126.9343\n",
      "Epoch [15/50], Step [185/375], Loss: 91.9858\n",
      "Epoch [15/50], Step [186/375], Loss: 362.2403\n",
      "Epoch [15/50], Step [187/375], Loss: 271.6397\n",
      "Epoch [15/50], Step [188/375], Loss: 306.7926\n",
      "Epoch [15/50], Step [189/375], Loss: 304.9476\n",
      "Epoch [15/50], Step [190/375], Loss: 99.3747\n",
      "Epoch [15/50], Step [191/375], Loss: 175.7593\n",
      "Epoch [15/50], Step [192/375], Loss: 242.9687\n",
      "Epoch [15/50], Step [193/375], Loss: 175.8422\n",
      "Epoch [15/50], Step [194/375], Loss: 167.0220\n",
      "Epoch [15/50], Step [195/375], Loss: 55.2221\n",
      "Epoch [15/50], Step [196/375], Loss: 531.5887\n",
      "Epoch [15/50], Step [197/375], Loss: 279.1788\n",
      "Epoch [15/50], Step [198/375], Loss: 503.9691\n",
      "Epoch [15/50], Step [199/375], Loss: 264.5016\n",
      "Epoch [15/50], Step [200/375], Loss: 220.8192\n",
      "Epoch [15/50], Step [201/375], Loss: 17.2357\n",
      "Epoch [15/50], Step [202/375], Loss: 534.1273\n",
      "Epoch [15/50], Step [203/375], Loss: 253.9074\n",
      "Epoch [15/50], Step [204/375], Loss: 392.3543\n",
      "Epoch [15/50], Step [205/375], Loss: 348.8795\n",
      "Epoch [15/50], Step [206/375], Loss: 103.2895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Step [207/375], Loss: 76.4247\n",
      "Epoch [15/50], Step [208/375], Loss: 348.9899\n",
      "Epoch [15/50], Step [209/375], Loss: 598.9782\n",
      "Epoch [15/50], Step [210/375], Loss: 405.2266\n",
      "Epoch [15/50], Step [211/375], Loss: 179.3204\n",
      "Epoch [15/50], Step [212/375], Loss: 112.3684\n",
      "Epoch [15/50], Step [213/375], Loss: 24.6766\n",
      "Epoch [15/50], Step [214/375], Loss: 369.0891\n",
      "Epoch [15/50], Step [215/375], Loss: 247.3272\n",
      "Epoch [15/50], Step [216/375], Loss: 734.5739\n",
      "Epoch [15/50], Step [217/375], Loss: 74.4027\n",
      "Epoch [15/50], Step [218/375], Loss: 153.5484\n",
      "Epoch [15/50], Step [219/375], Loss: 284.8172\n",
      "Epoch [15/50], Step [220/375], Loss: 51.3008\n",
      "Epoch [15/50], Step [221/375], Loss: 450.1137\n",
      "Epoch [15/50], Step [222/375], Loss: 166.9202\n",
      "Epoch [15/50], Step [223/375], Loss: 99.3541\n",
      "Epoch [15/50], Step [224/375], Loss: 287.3753\n",
      "Epoch [15/50], Step [225/375], Loss: 54.3778\n",
      "Epoch [15/50], Step [226/375], Loss: 475.0263\n",
      "Epoch [15/50], Step [227/375], Loss: 138.2787\n",
      "Epoch [15/50], Step [228/375], Loss: 488.7724\n",
      "Epoch [15/50], Step [229/375], Loss: 304.2614\n",
      "Epoch [15/50], Step [230/375], Loss: 223.0045\n",
      "Epoch [15/50], Step [231/375], Loss: 520.7582\n",
      "Epoch [15/50], Step [232/375], Loss: 38.9313\n",
      "Epoch [15/50], Step [233/375], Loss: 148.9402\n",
      "Epoch [15/50], Step [234/375], Loss: 456.1675\n",
      "Epoch [15/50], Step [235/375], Loss: 158.6397\n",
      "Epoch [15/50], Step [236/375], Loss: 214.7314\n",
      "Epoch [15/50], Step [237/375], Loss: 48.0499\n",
      "Epoch [15/50], Step [238/375], Loss: 223.8563\n",
      "Epoch [15/50], Step [239/375], Loss: 519.4570\n",
      "Epoch [15/50], Step [240/375], Loss: 42.1134\n",
      "Epoch [15/50], Step [241/375], Loss: 290.9265\n",
      "Epoch [15/50], Step [242/375], Loss: 417.1831\n",
      "Epoch [15/50], Step [243/375], Loss: 180.4326\n",
      "Epoch [15/50], Step [244/375], Loss: 58.7261\n",
      "Epoch [15/50], Step [245/375], Loss: 225.4786\n",
      "Epoch [15/50], Step [246/375], Loss: 110.9532\n",
      "Epoch [15/50], Step [247/375], Loss: 47.6509\n",
      "Epoch [15/50], Step [248/375], Loss: 267.6725\n",
      "Epoch [15/50], Step [249/375], Loss: 176.0392\n",
      "Epoch [15/50], Step [250/375], Loss: 134.6552\n",
      "Epoch [15/50], Step [251/375], Loss: 66.0304\n",
      "Epoch [15/50], Step [252/375], Loss: 273.9100\n",
      "Epoch [15/50], Step [253/375], Loss: 377.6129\n",
      "Epoch [15/50], Step [254/375], Loss: 570.9685\n",
      "Epoch [15/50], Step [255/375], Loss: 116.0017\n",
      "Epoch [15/50], Step [256/375], Loss: 400.1796\n",
      "Epoch [15/50], Step [257/375], Loss: 437.0578\n",
      "Epoch [15/50], Step [258/375], Loss: 56.0911\n",
      "Epoch [15/50], Step [259/375], Loss: 242.2466\n",
      "Epoch [15/50], Step [260/375], Loss: 138.9657\n",
      "Epoch [15/50], Step [261/375], Loss: 149.5971\n",
      "Epoch [15/50], Step [262/375], Loss: 183.0763\n",
      "Epoch [15/50], Step [263/375], Loss: 102.1680\n",
      "Epoch [15/50], Step [264/375], Loss: 185.3076\n",
      "Epoch [15/50], Step [265/375], Loss: 477.6532\n",
      "Epoch [15/50], Step [266/375], Loss: 48.0023\n",
      "Epoch [15/50], Step [267/375], Loss: 189.2745\n",
      "Epoch [15/50], Step [268/375], Loss: 142.4905\n",
      "Epoch [15/50], Step [269/375], Loss: 41.9262\n",
      "Epoch [15/50], Step [270/375], Loss: 98.2287\n",
      "Epoch [15/50], Step [271/375], Loss: 129.8925\n",
      "Epoch [15/50], Step [272/375], Loss: 85.5463\n",
      "Epoch [15/50], Step [273/375], Loss: 87.7314\n",
      "Epoch [15/50], Step [274/375], Loss: 237.7873\n",
      "Epoch [15/50], Step [275/375], Loss: 65.7402\n",
      "Epoch [15/50], Step [276/375], Loss: 69.7877\n",
      "Epoch [15/50], Step [277/375], Loss: 41.3918\n",
      "Epoch [15/50], Step [278/375], Loss: 408.3209\n",
      "Epoch [15/50], Step [279/375], Loss: 376.9083\n",
      "Epoch [15/50], Step [280/375], Loss: 88.0371\n",
      "Epoch [15/50], Step [281/375], Loss: 534.5822\n",
      "Epoch [15/50], Step [282/375], Loss: 98.7923\n",
      "Epoch [15/50], Step [283/375], Loss: 268.5005\n",
      "Epoch [15/50], Step [284/375], Loss: 78.3750\n",
      "Epoch [15/50], Step [285/375], Loss: 178.4071\n",
      "Epoch [15/50], Step [286/375], Loss: 66.4759\n",
      "Epoch [15/50], Step [287/375], Loss: 164.9847\n",
      "Epoch [15/50], Step [288/375], Loss: 289.5117\n",
      "Epoch [15/50], Step [289/375], Loss: 70.4064\n",
      "Epoch [15/50], Step [290/375], Loss: 194.6203\n",
      "Epoch [15/50], Step [291/375], Loss: 142.3067\n",
      "Epoch [15/50], Step [292/375], Loss: 456.4175\n",
      "Epoch [15/50], Step [293/375], Loss: 311.2240\n",
      "Epoch [15/50], Step [294/375], Loss: 75.8375\n",
      "Epoch [15/50], Step [295/375], Loss: 273.7747\n",
      "Epoch [15/50], Step [296/375], Loss: 35.9452\n",
      "Epoch [15/50], Step [297/375], Loss: 188.2935\n",
      "Epoch [15/50], Step [298/375], Loss: 435.8731\n",
      "Epoch [15/50], Step [299/375], Loss: 120.2694\n",
      "Epoch [15/50], Step [300/375], Loss: 107.3290\n",
      "Epoch [15/50], Step [301/375], Loss: 131.8129\n",
      "Epoch [15/50], Step [302/375], Loss: 159.4637\n",
      "Epoch [15/50], Step [303/375], Loss: 110.6247\n",
      "Epoch [15/50], Step [304/375], Loss: 31.3032\n",
      "Epoch [15/50], Step [305/375], Loss: 135.5268\n",
      "Epoch [15/50], Step [306/375], Loss: 191.2276\n",
      "Epoch [15/50], Step [307/375], Loss: 427.2532\n",
      "Epoch [15/50], Step [308/375], Loss: 202.2985\n",
      "Epoch [15/50], Step [309/375], Loss: 165.6671\n",
      "Epoch [15/50], Step [310/375], Loss: 73.1087\n",
      "Epoch [15/50], Step [311/375], Loss: 103.6706\n",
      "Epoch [15/50], Step [312/375], Loss: 225.3285\n",
      "Epoch [15/50], Step [313/375], Loss: 125.2592\n",
      "Epoch [15/50], Step [314/375], Loss: 302.1941\n",
      "Epoch [15/50], Step [315/375], Loss: 213.3049\n",
      "Epoch [15/50], Step [316/375], Loss: 179.3143\n",
      "Epoch [15/50], Step [317/375], Loss: 102.8965\n",
      "Epoch [15/50], Step [318/375], Loss: 100.8662\n",
      "Epoch [15/50], Step [319/375], Loss: 162.5408\n",
      "Epoch [15/50], Step [320/375], Loss: 86.5466\n",
      "Epoch [15/50], Step [321/375], Loss: 31.4475\n",
      "Epoch [15/50], Step [322/375], Loss: 246.9212\n",
      "Epoch [15/50], Step [323/375], Loss: 207.2884\n",
      "Epoch [15/50], Step [324/375], Loss: 363.0067\n",
      "Epoch [15/50], Step [325/375], Loss: 45.9080\n",
      "Epoch [15/50], Step [326/375], Loss: 185.3026\n",
      "Epoch [15/50], Step [327/375], Loss: 179.3340\n",
      "Epoch [15/50], Step [328/375], Loss: 477.2274\n",
      "Epoch [15/50], Step [329/375], Loss: 81.9408\n",
      "Epoch [15/50], Step [330/375], Loss: 276.9093\n",
      "Epoch [15/50], Step [331/375], Loss: 431.5367\n",
      "Epoch [15/50], Step [332/375], Loss: 272.4192\n",
      "Epoch [15/50], Step [333/375], Loss: 72.3470\n",
      "Epoch [15/50], Step [334/375], Loss: 291.9921\n",
      "Epoch [15/50], Step [335/375], Loss: 31.4787\n",
      "Epoch [15/50], Step [336/375], Loss: 44.2825\n",
      "Epoch [15/50], Step [337/375], Loss: 159.6879\n",
      "Epoch [15/50], Step [338/375], Loss: 184.7851\n",
      "Epoch [15/50], Step [339/375], Loss: 312.1143\n",
      "Epoch [15/50], Step [340/375], Loss: 210.8939\n",
      "Epoch [15/50], Step [341/375], Loss: 147.4313\n",
      "Epoch [15/50], Step [342/375], Loss: 207.5409\n",
      "Epoch [15/50], Step [343/375], Loss: 214.5720\n",
      "Epoch [15/50], Step [344/375], Loss: 86.1612\n",
      "Epoch [15/50], Step [345/375], Loss: 123.8807\n",
      "Epoch [15/50], Step [346/375], Loss: 373.0526\n",
      "Epoch [15/50], Step [347/375], Loss: 258.7373\n",
      "Epoch [15/50], Step [348/375], Loss: 177.3759\n",
      "Epoch [15/50], Step [349/375], Loss: 138.8285\n",
      "Epoch [15/50], Step [350/375], Loss: 168.6526\n",
      "Epoch [15/50], Step [351/375], Loss: 221.7531\n",
      "Epoch [15/50], Step [352/375], Loss: 140.9946\n",
      "Epoch [15/50], Step [353/375], Loss: 96.4198\n",
      "Epoch [15/50], Step [354/375], Loss: 205.4970\n",
      "Epoch [15/50], Step [355/375], Loss: 235.1732\n",
      "Epoch [15/50], Step [356/375], Loss: 119.0800\n",
      "Epoch [15/50], Step [357/375], Loss: 150.8436\n",
      "Epoch [15/50], Step [358/375], Loss: 249.9902\n",
      "Epoch [15/50], Step [359/375], Loss: 49.5840\n",
      "Epoch [15/50], Step [360/375], Loss: 343.3579\n",
      "Epoch [15/50], Step [361/375], Loss: 154.5900\n",
      "Epoch [15/50], Step [362/375], Loss: 99.7750\n",
      "Epoch [15/50], Step [363/375], Loss: 108.2893\n",
      "Epoch [15/50], Step [364/375], Loss: 42.1769\n",
      "Epoch [15/50], Step [365/375], Loss: 93.0606\n",
      "Epoch [15/50], Step [366/375], Loss: 216.2873\n",
      "Epoch [15/50], Step [367/375], Loss: 59.2495\n",
      "Epoch [15/50], Step [368/375], Loss: 191.0668\n",
      "Epoch [15/50], Step [369/375], Loss: 180.5225\n",
      "Epoch [15/50], Step [370/375], Loss: 52.3334\n",
      "Epoch [15/50], Step [371/375], Loss: 131.9875\n",
      "Epoch [15/50], Step [372/375], Loss: 148.7184\n",
      "Epoch [15/50], Step [373/375], Loss: 146.9420\n",
      "Epoch [15/50], Step [374/375], Loss: 100.2627\n",
      "Epoch [15/50], Step [375/375], Loss: 113.1681\n",
      "Epoch [16/50], Step [1/375], Loss: 135.5107\n",
      "Epoch [16/50], Step [2/375], Loss: 127.4181\n",
      "Epoch [16/50], Step [3/375], Loss: 102.5434\n",
      "Epoch [16/50], Step [4/375], Loss: 218.6820\n",
      "Epoch [16/50], Step [5/375], Loss: 236.7722\n",
      "Epoch [16/50], Step [6/375], Loss: 244.9231\n",
      "Epoch [16/50], Step [7/375], Loss: 53.9065\n",
      "Epoch [16/50], Step [8/375], Loss: 372.9829\n",
      "Epoch [16/50], Step [9/375], Loss: 637.2250\n",
      "Epoch [16/50], Step [10/375], Loss: 109.8925\n",
      "Epoch [16/50], Step [11/375], Loss: 291.9256\n",
      "Epoch [16/50], Step [12/375], Loss: 127.2281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [13/375], Loss: 72.5070\n",
      "Epoch [16/50], Step [14/375], Loss: 357.1111\n",
      "Epoch [16/50], Step [15/375], Loss: 215.8154\n",
      "Epoch [16/50], Step [16/375], Loss: 467.8138\n",
      "Epoch [16/50], Step [17/375], Loss: 67.3301\n",
      "Epoch [16/50], Step [18/375], Loss: 121.6131\n",
      "Epoch [16/50], Step [19/375], Loss: 347.2813\n",
      "Epoch [16/50], Step [20/375], Loss: 110.7330\n",
      "Epoch [16/50], Step [21/375], Loss: 102.7017\n",
      "Epoch [16/50], Step [22/375], Loss: 332.4905\n",
      "Epoch [16/50], Step [23/375], Loss: 217.0729\n",
      "Epoch [16/50], Step [24/375], Loss: 140.8647\n",
      "Epoch [16/50], Step [25/375], Loss: 135.8489\n",
      "Epoch [16/50], Step [26/375], Loss: 280.0270\n",
      "Epoch [16/50], Step [27/375], Loss: 201.8060\n",
      "Epoch [16/50], Step [28/375], Loss: 161.6408\n",
      "Epoch [16/50], Step [29/375], Loss: 245.9973\n",
      "Epoch [16/50], Step [30/375], Loss: 237.8291\n",
      "Epoch [16/50], Step [31/375], Loss: 110.2273\n",
      "Epoch [16/50], Step [32/375], Loss: 180.1362\n",
      "Epoch [16/50], Step [33/375], Loss: 90.7573\n",
      "Epoch [16/50], Step [34/375], Loss: 107.4438\n",
      "Epoch [16/50], Step [35/375], Loss: 119.1229\n",
      "Epoch [16/50], Step [36/375], Loss: 112.5223\n",
      "Epoch [16/50], Step [37/375], Loss: 85.1655\n",
      "Epoch [16/50], Step [38/375], Loss: 194.4826\n",
      "Epoch [16/50], Step [39/375], Loss: 217.2007\n",
      "Epoch [16/50], Step [40/375], Loss: 76.2784\n",
      "Epoch [16/50], Step [41/375], Loss: 302.2299\n",
      "Epoch [16/50], Step [42/375], Loss: 144.9600\n",
      "Epoch [16/50], Step [43/375], Loss: 158.7768\n",
      "Epoch [16/50], Step [44/375], Loss: 330.2179\n",
      "Epoch [16/50], Step [45/375], Loss: 32.4913\n",
      "Epoch [16/50], Step [46/375], Loss: 196.0409\n",
      "Epoch [16/50], Step [47/375], Loss: 761.4193\n",
      "Epoch [16/50], Step [48/375], Loss: 105.3944\n",
      "Epoch [16/50], Step [49/375], Loss: 161.9417\n",
      "Epoch [16/50], Step [50/375], Loss: 122.5645\n",
      "Epoch [16/50], Step [51/375], Loss: 126.9732\n",
      "Epoch [16/50], Step [52/375], Loss: 168.8877\n",
      "Epoch [16/50], Step [53/375], Loss: 247.5927\n",
      "Epoch [16/50], Step [54/375], Loss: 102.1038\n",
      "Epoch [16/50], Step [55/375], Loss: 139.6079\n",
      "Epoch [16/50], Step [56/375], Loss: 118.6877\n",
      "Epoch [16/50], Step [57/375], Loss: 92.1829\n",
      "Epoch [16/50], Step [58/375], Loss: 191.6087\n",
      "Epoch [16/50], Step [59/375], Loss: 156.9554\n",
      "Epoch [16/50], Step [60/375], Loss: 112.5165\n",
      "Epoch [16/50], Step [61/375], Loss: 688.2496\n",
      "Epoch [16/50], Step [62/375], Loss: 555.9302\n",
      "Epoch [16/50], Step [63/375], Loss: 83.1919\n",
      "Epoch [16/50], Step [64/375], Loss: 235.0698\n",
      "Epoch [16/50], Step [65/375], Loss: 646.6859\n",
      "Epoch [16/50], Step [66/375], Loss: 32.8489\n",
      "Epoch [16/50], Step [67/375], Loss: 247.6263\n",
      "Epoch [16/50], Step [68/375], Loss: 336.1900\n",
      "Epoch [16/50], Step [69/375], Loss: 138.9603\n",
      "Epoch [16/50], Step [70/375], Loss: 399.6462\n",
      "Epoch [16/50], Step [71/375], Loss: 310.3325\n",
      "Epoch [16/50], Step [72/375], Loss: 305.4832\n",
      "Epoch [16/50], Step [73/375], Loss: 134.4700\n",
      "Epoch [16/50], Step [74/375], Loss: 715.9579\n",
      "Epoch [16/50], Step [75/375], Loss: 299.3429\n",
      "Epoch [16/50], Step [76/375], Loss: 469.6214\n",
      "Epoch [16/50], Step [77/375], Loss: 29.4497\n",
      "Epoch [16/50], Step [78/375], Loss: 258.0212\n",
      "Epoch [16/50], Step [79/375], Loss: 79.5015\n",
      "Epoch [16/50], Step [80/375], Loss: 41.3722\n",
      "Epoch [16/50], Step [81/375], Loss: 211.8164\n",
      "Epoch [16/50], Step [82/375], Loss: 212.7545\n",
      "Epoch [16/50], Step [83/375], Loss: 68.5424\n",
      "Epoch [16/50], Step [84/375], Loss: 283.9158\n",
      "Epoch [16/50], Step [85/375], Loss: 330.5956\n",
      "Epoch [16/50], Step [86/375], Loss: 35.0113\n",
      "Epoch [16/50], Step [87/375], Loss: 80.6667\n",
      "Epoch [16/50], Step [88/375], Loss: 196.8921\n",
      "Epoch [16/50], Step [89/375], Loss: 367.6597\n",
      "Epoch [16/50], Step [90/375], Loss: 379.3833\n",
      "Epoch [16/50], Step [91/375], Loss: 152.2939\n",
      "Epoch [16/50], Step [92/375], Loss: 90.6793\n",
      "Epoch [16/50], Step [93/375], Loss: 82.0568\n",
      "Epoch [16/50], Step [94/375], Loss: 114.7770\n",
      "Epoch [16/50], Step [95/375], Loss: 262.3834\n",
      "Epoch [16/50], Step [96/375], Loss: 191.3113\n",
      "Epoch [16/50], Step [97/375], Loss: 63.8501\n",
      "Epoch [16/50], Step [98/375], Loss: 140.0797\n",
      "Epoch [16/50], Step [99/375], Loss: 101.5116\n",
      "Epoch [16/50], Step [100/375], Loss: 53.4327\n",
      "Epoch [16/50], Step [101/375], Loss: 77.9228\n",
      "Epoch [16/50], Step [102/375], Loss: 137.6048\n",
      "Epoch [16/50], Step [103/375], Loss: 271.6754\n",
      "Epoch [16/50], Step [104/375], Loss: 63.4178\n",
      "Epoch [16/50], Step [105/375], Loss: 179.7202\n",
      "Epoch [16/50], Step [106/375], Loss: 61.1991\n",
      "Epoch [16/50], Step [107/375], Loss: 64.8152\n",
      "Epoch [16/50], Step [108/375], Loss: 625.8422\n",
      "Epoch [16/50], Step [109/375], Loss: 291.5948\n",
      "Epoch [16/50], Step [110/375], Loss: 586.4123\n",
      "Epoch [16/50], Step [111/375], Loss: 119.6211\n",
      "Epoch [16/50], Step [112/375], Loss: 183.6108\n",
      "Epoch [16/50], Step [113/375], Loss: 57.3477\n",
      "Epoch [16/50], Step [114/375], Loss: 223.8838\n",
      "Epoch [16/50], Step [115/375], Loss: 112.5450\n",
      "Epoch [16/50], Step [116/375], Loss: 35.4564\n",
      "Epoch [16/50], Step [117/375], Loss: 84.8789\n",
      "Epoch [16/50], Step [118/375], Loss: 106.2168\n",
      "Epoch [16/50], Step [119/375], Loss: 58.5288\n",
      "Epoch [16/50], Step [120/375], Loss: 79.3549\n",
      "Epoch [16/50], Step [121/375], Loss: 42.4181\n",
      "Epoch [16/50], Step [122/375], Loss: 494.8731\n",
      "Epoch [16/50], Step [123/375], Loss: 170.8357\n",
      "Epoch [16/50], Step [124/375], Loss: 88.9647\n",
      "Epoch [16/50], Step [125/375], Loss: 44.2001\n",
      "Epoch [16/50], Step [126/375], Loss: 216.1914\n",
      "Epoch [16/50], Step [127/375], Loss: 286.6910\n",
      "Epoch [16/50], Step [128/375], Loss: 609.9937\n",
      "Epoch [16/50], Step [129/375], Loss: 193.8732\n",
      "Epoch [16/50], Step [130/375], Loss: 133.4489\n",
      "Epoch [16/50], Step [131/375], Loss: 72.5211\n",
      "Epoch [16/50], Step [132/375], Loss: 105.6053\n",
      "Epoch [16/50], Step [133/375], Loss: 371.7856\n",
      "Epoch [16/50], Step [134/375], Loss: 352.0450\n",
      "Epoch [16/50], Step [135/375], Loss: 72.1566\n",
      "Epoch [16/50], Step [136/375], Loss: 71.0094\n",
      "Epoch [16/50], Step [137/375], Loss: 369.1276\n",
      "Epoch [16/50], Step [138/375], Loss: 136.4243\n",
      "Epoch [16/50], Step [139/375], Loss: 173.2404\n",
      "Epoch [16/50], Step [140/375], Loss: 177.5172\n",
      "Epoch [16/50], Step [141/375], Loss: 93.0771\n",
      "Epoch [16/50], Step [142/375], Loss: 98.1695\n",
      "Epoch [16/50], Step [143/375], Loss: 171.6442\n",
      "Epoch [16/50], Step [144/375], Loss: 220.1915\n",
      "Epoch [16/50], Step [145/375], Loss: 157.4247\n",
      "Epoch [16/50], Step [146/375], Loss: 68.0673\n",
      "Epoch [16/50], Step [147/375], Loss: 47.9915\n",
      "Epoch [16/50], Step [148/375], Loss: 309.8714\n",
      "Epoch [16/50], Step [149/375], Loss: 209.5030\n",
      "Epoch [16/50], Step [150/375], Loss: 357.7217\n",
      "Epoch [16/50], Step [151/375], Loss: 166.7200\n",
      "Epoch [16/50], Step [152/375], Loss: 123.8690\n",
      "Epoch [16/50], Step [153/375], Loss: 85.5436\n",
      "Epoch [16/50], Step [154/375], Loss: 113.7182\n",
      "Epoch [16/50], Step [155/375], Loss: 270.0452\n",
      "Epoch [16/50], Step [156/375], Loss: 103.6328\n",
      "Epoch [16/50], Step [157/375], Loss: 178.7601\n",
      "Epoch [16/50], Step [158/375], Loss: 106.1012\n",
      "Epoch [16/50], Step [159/375], Loss: 273.8515\n",
      "Epoch [16/50], Step [160/375], Loss: 161.5263\n",
      "Epoch [16/50], Step [161/375], Loss: 722.5383\n",
      "Epoch [16/50], Step [162/375], Loss: 122.8976\n",
      "Epoch [16/50], Step [163/375], Loss: 49.7714\n",
      "Epoch [16/50], Step [164/375], Loss: 127.9147\n",
      "Epoch [16/50], Step [165/375], Loss: 565.7011\n",
      "Epoch [16/50], Step [166/375], Loss: 223.6238\n",
      "Epoch [16/50], Step [167/375], Loss: 41.2873\n",
      "Epoch [16/50], Step [168/375], Loss: 48.7133\n",
      "Epoch [16/50], Step [169/375], Loss: 338.6224\n",
      "Epoch [16/50], Step [170/375], Loss: 306.4843\n",
      "Epoch [16/50], Step [171/375], Loss: 296.7993\n",
      "Epoch [16/50], Step [172/375], Loss: 302.0351\n",
      "Epoch [16/50], Step [173/375], Loss: 287.9130\n",
      "Epoch [16/50], Step [174/375], Loss: 64.8127\n",
      "Epoch [16/50], Step [175/375], Loss: 135.9606\n",
      "Epoch [16/50], Step [176/375], Loss: 169.6532\n",
      "Epoch [16/50], Step [177/375], Loss: 294.5492\n",
      "Epoch [16/50], Step [178/375], Loss: 334.2365\n",
      "Epoch [16/50], Step [179/375], Loss: 295.1278\n",
      "Epoch [16/50], Step [180/375], Loss: 64.1526\n",
      "Epoch [16/50], Step [181/375], Loss: 273.8249\n",
      "Epoch [16/50], Step [182/375], Loss: 101.3123\n",
      "Epoch [16/50], Step [183/375], Loss: 296.2505\n",
      "Epoch [16/50], Step [184/375], Loss: 126.9391\n",
      "Epoch [16/50], Step [185/375], Loss: 242.8875\n",
      "Epoch [16/50], Step [186/375], Loss: 85.5366\n",
      "Epoch [16/50], Step [187/375], Loss: 117.8500\n",
      "Epoch [16/50], Step [188/375], Loss: 228.5333\n",
      "Epoch [16/50], Step [189/375], Loss: 240.5395\n",
      "Epoch [16/50], Step [190/375], Loss: 489.6425\n",
      "Epoch [16/50], Step [191/375], Loss: 105.5705\n",
      "Epoch [16/50], Step [192/375], Loss: 166.4033\n",
      "Epoch [16/50], Step [193/375], Loss: 224.1296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [194/375], Loss: 207.2492\n",
      "Epoch [16/50], Step [195/375], Loss: 38.9099\n",
      "Epoch [16/50], Step [196/375], Loss: 437.5999\n",
      "Epoch [16/50], Step [197/375], Loss: 549.2782\n",
      "Epoch [16/50], Step [198/375], Loss: 69.1287\n",
      "Epoch [16/50], Step [199/375], Loss: 156.2271\n",
      "Epoch [16/50], Step [200/375], Loss: 224.3248\n",
      "Epoch [16/50], Step [201/375], Loss: 146.7325\n",
      "Epoch [16/50], Step [202/375], Loss: 185.5416\n",
      "Epoch [16/50], Step [203/375], Loss: 434.6046\n",
      "Epoch [16/50], Step [204/375], Loss: 66.5741\n",
      "Epoch [16/50], Step [205/375], Loss: 39.9835\n",
      "Epoch [16/50], Step [206/375], Loss: 133.6924\n",
      "Epoch [16/50], Step [207/375], Loss: 80.0866\n",
      "Epoch [16/50], Step [208/375], Loss: 233.1087\n",
      "Epoch [16/50], Step [209/375], Loss: 180.2370\n",
      "Epoch [16/50], Step [210/375], Loss: 165.8828\n",
      "Epoch [16/50], Step [211/375], Loss: 121.4469\n",
      "Epoch [16/50], Step [212/375], Loss: 160.0389\n",
      "Epoch [16/50], Step [213/375], Loss: 365.9776\n",
      "Epoch [16/50], Step [214/375], Loss: 228.3731\n",
      "Epoch [16/50], Step [215/375], Loss: 314.2266\n",
      "Epoch [16/50], Step [216/375], Loss: 90.9391\n",
      "Epoch [16/50], Step [217/375], Loss: 265.2893\n",
      "Epoch [16/50], Step [218/375], Loss: 53.1210\n",
      "Epoch [16/50], Step [219/375], Loss: 52.4643\n",
      "Epoch [16/50], Step [220/375], Loss: 152.6039\n",
      "Epoch [16/50], Step [221/375], Loss: 168.0542\n",
      "Epoch [16/50], Step [222/375], Loss: 202.1865\n",
      "Epoch [16/50], Step [223/375], Loss: 150.0001\n",
      "Epoch [16/50], Step [224/375], Loss: 137.8875\n",
      "Epoch [16/50], Step [225/375], Loss: 143.1464\n",
      "Epoch [16/50], Step [226/375], Loss: 108.8586\n",
      "Epoch [16/50], Step [227/375], Loss: 591.3726\n",
      "Epoch [16/50], Step [228/375], Loss: 244.6534\n",
      "Epoch [16/50], Step [229/375], Loss: 125.9611\n",
      "Epoch [16/50], Step [230/375], Loss: 481.3040\n",
      "Epoch [16/50], Step [231/375], Loss: 531.5441\n",
      "Epoch [16/50], Step [232/375], Loss: 215.0287\n",
      "Epoch [16/50], Step [233/375], Loss: 116.1865\n",
      "Epoch [16/50], Step [234/375], Loss: 182.5100\n",
      "Epoch [16/50], Step [235/375], Loss: 153.0881\n",
      "Epoch [16/50], Step [236/375], Loss: 324.3970\n",
      "Epoch [16/50], Step [237/375], Loss: 385.9539\n",
      "Epoch [16/50], Step [238/375], Loss: 85.1583\n",
      "Epoch [16/50], Step [239/375], Loss: 137.9190\n",
      "Epoch [16/50], Step [240/375], Loss: 110.7702\n",
      "Epoch [16/50], Step [241/375], Loss: 602.5551\n",
      "Epoch [16/50], Step [242/375], Loss: 188.9773\n",
      "Epoch [16/50], Step [243/375], Loss: 160.8528\n",
      "Epoch [16/50], Step [244/375], Loss: 201.2666\n",
      "Epoch [16/50], Step [245/375], Loss: 144.5989\n",
      "Epoch [16/50], Step [246/375], Loss: 230.6880\n",
      "Epoch [16/50], Step [247/375], Loss: 157.5903\n",
      "Epoch [16/50], Step [248/375], Loss: 234.3385\n",
      "Epoch [16/50], Step [249/375], Loss: 245.0502\n",
      "Epoch [16/50], Step [250/375], Loss: 19.6701\n",
      "Epoch [16/50], Step [251/375], Loss: 16.4734\n",
      "Epoch [16/50], Step [252/375], Loss: 105.8941\n",
      "Epoch [16/50], Step [253/375], Loss: 502.9834\n",
      "Epoch [16/50], Step [254/375], Loss: 143.0319\n",
      "Epoch [16/50], Step [255/375], Loss: 131.5707\n",
      "Epoch [16/50], Step [256/375], Loss: 68.1178\n",
      "Epoch [16/50], Step [257/375], Loss: 91.3730\n",
      "Epoch [16/50], Step [258/375], Loss: 20.0617\n",
      "Epoch [16/50], Step [259/375], Loss: 48.7715\n",
      "Epoch [16/50], Step [260/375], Loss: 53.5411\n",
      "Epoch [16/50], Step [261/375], Loss: 90.1454\n",
      "Epoch [16/50], Step [262/375], Loss: 99.8160\n",
      "Epoch [16/50], Step [263/375], Loss: 117.1897\n",
      "Epoch [16/50], Step [264/375], Loss: 225.4706\n",
      "Epoch [16/50], Step [265/375], Loss: 237.0221\n",
      "Epoch [16/50], Step [266/375], Loss: 161.3253\n",
      "Epoch [16/50], Step [267/375], Loss: 176.2982\n",
      "Epoch [16/50], Step [268/375], Loss: 91.9176\n",
      "Epoch [16/50], Step [269/375], Loss: 78.8155\n",
      "Epoch [16/50], Step [270/375], Loss: 109.9908\n",
      "Epoch [16/50], Step [271/375], Loss: 89.4478\n",
      "Epoch [16/50], Step [272/375], Loss: 162.7300\n",
      "Epoch [16/50], Step [273/375], Loss: 81.8706\n",
      "Epoch [16/50], Step [274/375], Loss: 107.9178\n",
      "Epoch [16/50], Step [275/375], Loss: 77.0539\n",
      "Epoch [16/50], Step [276/375], Loss: 375.0113\n",
      "Epoch [16/50], Step [277/375], Loss: 19.3634\n",
      "Epoch [16/50], Step [278/375], Loss: 35.6552\n",
      "Epoch [16/50], Step [279/375], Loss: 374.4798\n",
      "Epoch [16/50], Step [280/375], Loss: 338.2852\n",
      "Epoch [16/50], Step [281/375], Loss: 64.7652\n",
      "Epoch [16/50], Step [282/375], Loss: 133.4442\n",
      "Epoch [16/50], Step [283/375], Loss: 82.0816\n",
      "Epoch [16/50], Step [284/375], Loss: 283.5811\n",
      "Epoch [16/50], Step [285/375], Loss: 96.7882\n",
      "Epoch [16/50], Step [286/375], Loss: 66.2553\n",
      "Epoch [16/50], Step [287/375], Loss: 337.3162\n",
      "Epoch [16/50], Step [288/375], Loss: 176.3240\n",
      "Epoch [16/50], Step [289/375], Loss: 69.2806\n",
      "Epoch [16/50], Step [290/375], Loss: 189.4534\n",
      "Epoch [16/50], Step [291/375], Loss: 151.1468\n",
      "Epoch [16/50], Step [292/375], Loss: 255.3942\n",
      "Epoch [16/50], Step [293/375], Loss: 492.7076\n",
      "Epoch [16/50], Step [294/375], Loss: 76.4039\n",
      "Epoch [16/50], Step [295/375], Loss: 108.3268\n",
      "Epoch [16/50], Step [296/375], Loss: 89.5883\n",
      "Epoch [16/50], Step [297/375], Loss: 97.3029\n",
      "Epoch [16/50], Step [298/375], Loss: 377.1999\n",
      "Epoch [16/50], Step [299/375], Loss: 65.4001\n",
      "Epoch [16/50], Step [300/375], Loss: 169.0665\n",
      "Epoch [16/50], Step [301/375], Loss: 191.3284\n",
      "Epoch [16/50], Step [302/375], Loss: 170.7066\n",
      "Epoch [16/50], Step [303/375], Loss: 169.9873\n",
      "Epoch [16/50], Step [304/375], Loss: 53.4898\n",
      "Epoch [16/50], Step [305/375], Loss: 194.5486\n",
      "Epoch [16/50], Step [306/375], Loss: 340.8909\n",
      "Epoch [16/50], Step [307/375], Loss: 287.4717\n",
      "Epoch [16/50], Step [308/375], Loss: 136.9984\n",
      "Epoch [16/50], Step [309/375], Loss: 162.4277\n",
      "Epoch [16/50], Step [310/375], Loss: 36.9947\n",
      "Epoch [16/50], Step [311/375], Loss: 199.2108\n",
      "Epoch [16/50], Step [312/375], Loss: 105.6347\n",
      "Epoch [16/50], Step [313/375], Loss: 129.6693\n",
      "Epoch [16/50], Step [314/375], Loss: 169.4859\n",
      "Epoch [16/50], Step [315/375], Loss: 91.4159\n",
      "Epoch [16/50], Step [316/375], Loss: 76.6206\n",
      "Epoch [16/50], Step [317/375], Loss: 227.3560\n",
      "Epoch [16/50], Step [318/375], Loss: 102.7537\n",
      "Epoch [16/50], Step [319/375], Loss: 295.3546\n",
      "Epoch [16/50], Step [320/375], Loss: 572.0261\n",
      "Epoch [16/50], Step [321/375], Loss: 333.2654\n",
      "Epoch [16/50], Step [322/375], Loss: 250.4644\n",
      "Epoch [16/50], Step [323/375], Loss: 335.2490\n",
      "Epoch [16/50], Step [324/375], Loss: 495.0388\n",
      "Epoch [16/50], Step [325/375], Loss: 569.9534\n",
      "Epoch [16/50], Step [326/375], Loss: 598.6950\n",
      "Epoch [16/50], Step [327/375], Loss: 503.0677\n",
      "Epoch [16/50], Step [328/375], Loss: 124.0910\n",
      "Epoch [16/50], Step [329/375], Loss: 196.2197\n",
      "Epoch [16/50], Step [330/375], Loss: 745.9872\n",
      "Epoch [16/50], Step [331/375], Loss: 97.5173\n",
      "Epoch [16/50], Step [332/375], Loss: 372.2773\n",
      "Epoch [16/50], Step [333/375], Loss: 144.2516\n",
      "Epoch [16/50], Step [334/375], Loss: 406.2591\n",
      "Epoch [16/50], Step [335/375], Loss: 51.2983\n",
      "Epoch [16/50], Step [336/375], Loss: 636.8411\n",
      "Epoch [16/50], Step [337/375], Loss: 141.5182\n",
      "Epoch [16/50], Step [338/375], Loss: 178.0125\n",
      "Epoch [16/50], Step [339/375], Loss: 235.8419\n",
      "Epoch [16/50], Step [340/375], Loss: 746.2361\n",
      "Epoch [16/50], Step [341/375], Loss: 472.6775\n",
      "Epoch [16/50], Step [342/375], Loss: 47.1388\n",
      "Epoch [16/50], Step [343/375], Loss: 255.8895\n",
      "Epoch [16/50], Step [344/375], Loss: 356.1491\n",
      "Epoch [16/50], Step [345/375], Loss: 315.4393\n",
      "Epoch [16/50], Step [346/375], Loss: 495.7068\n",
      "Epoch [16/50], Step [347/375], Loss: 59.2951\n",
      "Epoch [16/50], Step [348/375], Loss: 291.1136\n",
      "Epoch [16/50], Step [349/375], Loss: 141.1233\n",
      "Epoch [16/50], Step [350/375], Loss: 87.1701\n",
      "Epoch [16/50], Step [351/375], Loss: 132.7535\n",
      "Epoch [16/50], Step [352/375], Loss: 65.6476\n",
      "Epoch [16/50], Step [353/375], Loss: 248.7534\n",
      "Epoch [16/50], Step [354/375], Loss: 298.3849\n",
      "Epoch [16/50], Step [355/375], Loss: 69.8876\n",
      "Epoch [16/50], Step [356/375], Loss: 470.7788\n",
      "Epoch [16/50], Step [357/375], Loss: 316.5023\n",
      "Epoch [16/50], Step [358/375], Loss: 95.5457\n",
      "Epoch [16/50], Step [359/375], Loss: 45.7295\n",
      "Epoch [16/50], Step [360/375], Loss: 577.5349\n",
      "Epoch [16/50], Step [361/375], Loss: 188.2677\n",
      "Epoch [16/50], Step [362/375], Loss: 231.5235\n",
      "Epoch [16/50], Step [363/375], Loss: 236.9760\n",
      "Epoch [16/50], Step [364/375], Loss: 379.1813\n",
      "Epoch [16/50], Step [365/375], Loss: 47.8495\n",
      "Epoch [16/50], Step [366/375], Loss: 52.7234\n",
      "Epoch [16/50], Step [367/375], Loss: 492.7995\n",
      "Epoch [16/50], Step [368/375], Loss: 443.4515\n",
      "Epoch [16/50], Step [369/375], Loss: 203.8261\n",
      "Epoch [16/50], Step [370/375], Loss: 48.0451\n",
      "Epoch [16/50], Step [371/375], Loss: 112.3309\n",
      "Epoch [16/50], Step [372/375], Loss: 296.5103\n",
      "Epoch [16/50], Step [373/375], Loss: 378.8426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [374/375], Loss: 388.5097\n",
      "Epoch [16/50], Step [375/375], Loss: 117.4670\n",
      "Epoch [17/50], Step [1/375], Loss: 110.3375\n",
      "Epoch [17/50], Step [2/375], Loss: 459.9700\n",
      "Epoch [17/50], Step [3/375], Loss: 98.0835\n",
      "Epoch [17/50], Step [4/375], Loss: 376.0656\n",
      "Epoch [17/50], Step [5/375], Loss: 104.7746\n",
      "Epoch [17/50], Step [6/375], Loss: 291.5116\n",
      "Epoch [17/50], Step [7/375], Loss: 351.9289\n",
      "Epoch [17/50], Step [8/375], Loss: 310.7917\n",
      "Epoch [17/50], Step [9/375], Loss: 81.7248\n",
      "Epoch [17/50], Step [10/375], Loss: 145.9609\n",
      "Epoch [17/50], Step [11/375], Loss: 209.3775\n",
      "Epoch [17/50], Step [12/375], Loss: 113.9576\n",
      "Epoch [17/50], Step [13/375], Loss: 32.7171\n",
      "Epoch [17/50], Step [14/375], Loss: 320.7916\n",
      "Epoch [17/50], Step [15/375], Loss: 422.8377\n",
      "Epoch [17/50], Step [16/375], Loss: 460.8626\n",
      "Epoch [17/50], Step [17/375], Loss: 40.3168\n",
      "Epoch [17/50], Step [18/375], Loss: 173.9337\n",
      "Epoch [17/50], Step [19/375], Loss: 77.2505\n",
      "Epoch [17/50], Step [20/375], Loss: 72.7750\n",
      "Epoch [17/50], Step [21/375], Loss: 767.3279\n",
      "Epoch [17/50], Step [22/375], Loss: 678.4689\n",
      "Epoch [17/50], Step [23/375], Loss: 146.6301\n",
      "Epoch [17/50], Step [24/375], Loss: 299.4073\n",
      "Epoch [17/50], Step [25/375], Loss: 286.2525\n",
      "Epoch [17/50], Step [26/375], Loss: 304.1018\n",
      "Epoch [17/50], Step [27/375], Loss: 61.6602\n",
      "Epoch [17/50], Step [28/375], Loss: 220.8255\n",
      "Epoch [17/50], Step [29/375], Loss: 70.7964\n",
      "Epoch [17/50], Step [30/375], Loss: 285.6077\n",
      "Epoch [17/50], Step [31/375], Loss: 479.4874\n",
      "Epoch [17/50], Step [32/375], Loss: 154.8025\n",
      "Epoch [17/50], Step [33/375], Loss: 219.9263\n",
      "Epoch [17/50], Step [34/375], Loss: 127.8655\n",
      "Epoch [17/50], Step [35/375], Loss: 334.9415\n",
      "Epoch [17/50], Step [36/375], Loss: 158.2137\n",
      "Epoch [17/50], Step [37/375], Loss: 259.5387\n",
      "Epoch [17/50], Step [38/375], Loss: 102.5228\n",
      "Epoch [17/50], Step [39/375], Loss: 107.4897\n",
      "Epoch [17/50], Step [40/375], Loss: 108.2067\n",
      "Epoch [17/50], Step [41/375], Loss: 166.6018\n",
      "Epoch [17/50], Step [42/375], Loss: 142.0457\n",
      "Epoch [17/50], Step [43/375], Loss: 50.8699\n",
      "Epoch [17/50], Step [44/375], Loss: 524.7126\n",
      "Epoch [17/50], Step [45/375], Loss: 447.2567\n",
      "Epoch [17/50], Step [46/375], Loss: 289.9626\n",
      "Epoch [17/50], Step [47/375], Loss: 261.4805\n",
      "Epoch [17/50], Step [48/375], Loss: 842.3331\n",
      "Epoch [17/50], Step [49/375], Loss: 54.7447\n",
      "Epoch [17/50], Step [50/375], Loss: 77.7783\n",
      "Epoch [17/50], Step [51/375], Loss: 109.8466\n",
      "Epoch [17/50], Step [52/375], Loss: 133.6687\n",
      "Epoch [17/50], Step [53/375], Loss: 256.1153\n",
      "Epoch [17/50], Step [54/375], Loss: 138.8553\n",
      "Epoch [17/50], Step [55/375], Loss: 213.6990\n",
      "Epoch [17/50], Step [56/375], Loss: 388.7292\n",
      "Epoch [17/50], Step [57/375], Loss: 165.1860\n",
      "Epoch [17/50], Step [58/375], Loss: 841.8786\n",
      "Epoch [17/50], Step [59/375], Loss: 139.2654\n",
      "Epoch [17/50], Step [60/375], Loss: 267.3813\n",
      "Epoch [17/50], Step [61/375], Loss: 415.6397\n",
      "Epoch [17/50], Step [62/375], Loss: 481.3090\n",
      "Epoch [17/50], Step [63/375], Loss: 128.5800\n",
      "Epoch [17/50], Step [64/375], Loss: 128.0435\n",
      "Epoch [17/50], Step [65/375], Loss: 98.7198\n",
      "Epoch [17/50], Step [66/375], Loss: 78.1712\n",
      "Epoch [17/50], Step [67/375], Loss: 295.0915\n",
      "Epoch [17/50], Step [68/375], Loss: 129.4737\n",
      "Epoch [17/50], Step [69/375], Loss: 88.8667\n",
      "Epoch [17/50], Step [70/375], Loss: 230.8171\n",
      "Epoch [17/50], Step [71/375], Loss: 494.3157\n",
      "Epoch [17/50], Step [72/375], Loss: 303.4252\n",
      "Epoch [17/50], Step [73/375], Loss: 295.5434\n",
      "Epoch [17/50], Step [74/375], Loss: 76.0212\n",
      "Epoch [17/50], Step [75/375], Loss: 39.3142\n",
      "Epoch [17/50], Step [76/375], Loss: 229.3795\n",
      "Epoch [17/50], Step [77/375], Loss: 322.9024\n",
      "Epoch [17/50], Step [78/375], Loss: 156.0627\n",
      "Epoch [17/50], Step [79/375], Loss: 260.7230\n",
      "Epoch [17/50], Step [80/375], Loss: 327.3050\n",
      "Epoch [17/50], Step [81/375], Loss: 473.3753\n",
      "Epoch [17/50], Step [82/375], Loss: 301.1252\n",
      "Epoch [17/50], Step [83/375], Loss: 194.9359\n",
      "Epoch [17/50], Step [84/375], Loss: 498.3018\n",
      "Epoch [17/50], Step [85/375], Loss: 308.5405\n",
      "Epoch [17/50], Step [86/375], Loss: 287.4842\n",
      "Epoch [17/50], Step [87/375], Loss: 235.4695\n",
      "Epoch [17/50], Step [88/375], Loss: 228.8531\n",
      "Epoch [17/50], Step [89/375], Loss: 87.5386\n",
      "Epoch [17/50], Step [90/375], Loss: 66.1336\n",
      "Epoch [17/50], Step [91/375], Loss: 176.4721\n",
      "Epoch [17/50], Step [92/375], Loss: 108.0979\n",
      "Epoch [17/50], Step [93/375], Loss: 103.1485\n",
      "Epoch [17/50], Step [94/375], Loss: 259.3313\n",
      "Epoch [17/50], Step [95/375], Loss: 99.6571\n",
      "Epoch [17/50], Step [96/375], Loss: 124.3284\n",
      "Epoch [17/50], Step [97/375], Loss: 343.4408\n",
      "Epoch [17/50], Step [98/375], Loss: 162.9636\n",
      "Epoch [17/50], Step [99/375], Loss: 194.1994\n",
      "Epoch [17/50], Step [100/375], Loss: 638.7800\n",
      "Epoch [17/50], Step [101/375], Loss: 338.0274\n",
      "Epoch [17/50], Step [102/375], Loss: 74.8690\n",
      "Epoch [17/50], Step [103/375], Loss: 142.5200\n",
      "Epoch [17/50], Step [104/375], Loss: 102.3417\n",
      "Epoch [17/50], Step [105/375], Loss: 156.9435\n",
      "Epoch [17/50], Step [106/375], Loss: 296.1394\n",
      "Epoch [17/50], Step [107/375], Loss: 250.4564\n",
      "Epoch [17/50], Step [108/375], Loss: 298.5449\n",
      "Epoch [17/50], Step [109/375], Loss: 369.3288\n",
      "Epoch [17/50], Step [110/375], Loss: 107.2707\n",
      "Epoch [17/50], Step [111/375], Loss: 219.4941\n",
      "Epoch [17/50], Step [112/375], Loss: 136.1397\n",
      "Epoch [17/50], Step [113/375], Loss: 103.0698\n",
      "Epoch [17/50], Step [114/375], Loss: 216.2385\n",
      "Epoch [17/50], Step [115/375], Loss: 179.4785\n",
      "Epoch [17/50], Step [116/375], Loss: 225.9192\n",
      "Epoch [17/50], Step [117/375], Loss: 66.9833\n",
      "Epoch [17/50], Step [118/375], Loss: 107.6776\n",
      "Epoch [17/50], Step [119/375], Loss: 81.7352\n",
      "Epoch [17/50], Step [120/375], Loss: 135.1046\n",
      "Epoch [17/50], Step [121/375], Loss: 95.2605\n",
      "Epoch [17/50], Step [122/375], Loss: 324.4874\n",
      "Epoch [17/50], Step [123/375], Loss: 250.0683\n",
      "Epoch [17/50], Step [124/375], Loss: 202.8054\n",
      "Epoch [17/50], Step [125/375], Loss: 246.4513\n",
      "Epoch [17/50], Step [126/375], Loss: 72.7813\n",
      "Epoch [17/50], Step [127/375], Loss: 45.3839\n",
      "Epoch [17/50], Step [128/375], Loss: 330.9454\n",
      "Epoch [17/50], Step [129/375], Loss: 79.1562\n",
      "Epoch [17/50], Step [130/375], Loss: 348.8625\n",
      "Epoch [17/50], Step [131/375], Loss: 197.5731\n",
      "Epoch [17/50], Step [132/375], Loss: 309.8528\n",
      "Epoch [17/50], Step [133/375], Loss: 308.2738\n",
      "Epoch [17/50], Step [134/375], Loss: 34.9627\n",
      "Epoch [17/50], Step [135/375], Loss: 151.0708\n",
      "Epoch [17/50], Step [136/375], Loss: 207.1342\n",
      "Epoch [17/50], Step [137/375], Loss: 39.6197\n",
      "Epoch [17/50], Step [138/375], Loss: 162.0313\n",
      "Epoch [17/50], Step [139/375], Loss: 131.3839\n",
      "Epoch [17/50], Step [140/375], Loss: 82.5417\n",
      "Epoch [17/50], Step [141/375], Loss: 76.3343\n",
      "Epoch [17/50], Step [142/375], Loss: 71.0640\n",
      "Epoch [17/50], Step [143/375], Loss: 255.3654\n",
      "Epoch [17/50], Step [144/375], Loss: 351.8488\n",
      "Epoch [17/50], Step [145/375], Loss: 227.9084\n",
      "Epoch [17/50], Step [146/375], Loss: 152.3632\n",
      "Epoch [17/50], Step [147/375], Loss: 91.7865\n",
      "Epoch [17/50], Step [148/375], Loss: 87.1964\n",
      "Epoch [17/50], Step [149/375], Loss: 195.4691\n",
      "Epoch [17/50], Step [150/375], Loss: 234.9892\n",
      "Epoch [17/50], Step [151/375], Loss: 265.5486\n",
      "Epoch [17/50], Step [152/375], Loss: 232.5023\n",
      "Epoch [17/50], Step [153/375], Loss: 79.8167\n",
      "Epoch [17/50], Step [154/375], Loss: 42.1153\n",
      "Epoch [17/50], Step [155/375], Loss: 199.2100\n",
      "Epoch [17/50], Step [156/375], Loss: 68.8309\n",
      "Epoch [17/50], Step [157/375], Loss: 109.4124\n",
      "Epoch [17/50], Step [158/375], Loss: 421.6779\n",
      "Epoch [17/50], Step [159/375], Loss: 161.7100\n",
      "Epoch [17/50], Step [160/375], Loss: 57.1318\n",
      "Epoch [17/50], Step [161/375], Loss: 223.1551\n",
      "Epoch [17/50], Step [162/375], Loss: 525.4975\n",
      "Epoch [17/50], Step [163/375], Loss: 54.5825\n",
      "Epoch [17/50], Step [164/375], Loss: 183.7718\n",
      "Epoch [17/50], Step [165/375], Loss: 294.2591\n",
      "Epoch [17/50], Step [166/375], Loss: 304.6352\n",
      "Epoch [17/50], Step [167/375], Loss: 60.8805\n",
      "Epoch [17/50], Step [168/375], Loss: 220.2978\n",
      "Epoch [17/50], Step [169/375], Loss: 427.9810\n",
      "Epoch [17/50], Step [170/375], Loss: 32.3360\n",
      "Epoch [17/50], Step [171/375], Loss: 31.1474\n",
      "Epoch [17/50], Step [172/375], Loss: 337.2131\n",
      "Epoch [17/50], Step [173/375], Loss: 141.7417\n",
      "Epoch [17/50], Step [174/375], Loss: 310.4688\n",
      "Epoch [17/50], Step [175/375], Loss: 294.1403\n",
      "Epoch [17/50], Step [176/375], Loss: 120.4413\n",
      "Epoch [17/50], Step [177/375], Loss: 205.6024\n",
      "Epoch [17/50], Step [178/375], Loss: 549.7109\n",
      "Epoch [17/50], Step [179/375], Loss: 258.8475\n",
      "Epoch [17/50], Step [180/375], Loss: 66.9429\n",
      "Epoch [17/50], Step [181/375], Loss: 110.5821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Step [182/375], Loss: 547.7386\n",
      "Epoch [17/50], Step [183/375], Loss: 218.1219\n",
      "Epoch [17/50], Step [184/375], Loss: 504.1496\n",
      "Epoch [17/50], Step [185/375], Loss: 168.0435\n",
      "Epoch [17/50], Step [186/375], Loss: 436.8374\n",
      "Epoch [17/50], Step [187/375], Loss: 303.4905\n",
      "Epoch [17/50], Step [188/375], Loss: 72.2755\n",
      "Epoch [17/50], Step [189/375], Loss: 47.0391\n",
      "Epoch [17/50], Step [190/375], Loss: 11.4283\n",
      "Epoch [17/50], Step [191/375], Loss: 196.1006\n",
      "Epoch [17/50], Step [192/375], Loss: 201.0301\n",
      "Epoch [17/50], Step [193/375], Loss: 62.9450\n",
      "Epoch [17/50], Step [194/375], Loss: 316.1454\n",
      "Epoch [17/50], Step [195/375], Loss: 66.8998\n",
      "Epoch [17/50], Step [196/375], Loss: 235.5663\n",
      "Epoch [17/50], Step [197/375], Loss: 142.8767\n",
      "Epoch [17/50], Step [198/375], Loss: 292.8739\n",
      "Epoch [17/50], Step [199/375], Loss: 11.9528\n",
      "Epoch [17/50], Step [200/375], Loss: 200.4954\n",
      "Epoch [17/50], Step [201/375], Loss: 146.2336\n",
      "Epoch [17/50], Step [202/375], Loss: 202.7770\n",
      "Epoch [17/50], Step [203/375], Loss: 250.2767\n",
      "Epoch [17/50], Step [204/375], Loss: 146.7531\n",
      "Epoch [17/50], Step [205/375], Loss: 201.4788\n",
      "Epoch [17/50], Step [206/375], Loss: 244.1875\n",
      "Epoch [17/50], Step [207/375], Loss: 267.2994\n",
      "Epoch [17/50], Step [208/375], Loss: 201.5151\n",
      "Epoch [17/50], Step [209/375], Loss: 221.2926\n",
      "Epoch [17/50], Step [210/375], Loss: 528.2286\n",
      "Epoch [17/50], Step [211/375], Loss: 830.9883\n",
      "Epoch [17/50], Step [212/375], Loss: 94.2353\n",
      "Epoch [17/50], Step [213/375], Loss: 18.3006\n",
      "Epoch [17/50], Step [214/375], Loss: 337.8193\n",
      "Epoch [17/50], Step [215/375], Loss: 636.6614\n",
      "Epoch [17/50], Step [216/375], Loss: 210.3474\n",
      "Epoch [17/50], Step [217/375], Loss: 504.6106\n",
      "Epoch [17/50], Step [218/375], Loss: 55.0029\n",
      "Epoch [17/50], Step [219/375], Loss: 139.6481\n",
      "Epoch [17/50], Step [220/375], Loss: 228.0735\n",
      "Epoch [17/50], Step [221/375], Loss: 275.7650\n",
      "Epoch [17/50], Step [222/375], Loss: 366.0545\n",
      "Epoch [17/50], Step [223/375], Loss: 649.7482\n",
      "Epoch [17/50], Step [224/375], Loss: 84.7484\n",
      "Epoch [17/50], Step [225/375], Loss: 59.9210\n",
      "Epoch [17/50], Step [226/375], Loss: 116.7061\n",
      "Epoch [17/50], Step [227/375], Loss: 346.4022\n",
      "Epoch [17/50], Step [228/375], Loss: 743.0240\n",
      "Epoch [17/50], Step [229/375], Loss: 812.6910\n",
      "Epoch [17/50], Step [230/375], Loss: 132.5290\n",
      "Epoch [17/50], Step [231/375], Loss: 219.0623\n",
      "Epoch [17/50], Step [232/375], Loss: 25.2826\n",
      "Epoch [17/50], Step [233/375], Loss: 209.2315\n",
      "Epoch [17/50], Step [234/375], Loss: 189.5700\n",
      "Epoch [17/50], Step [235/375], Loss: 907.6437\n",
      "Epoch [17/50], Step [236/375], Loss: 244.4853\n",
      "Epoch [17/50], Step [237/375], Loss: 211.0469\n",
      "Epoch [17/50], Step [238/375], Loss: 230.5391\n",
      "Epoch [17/50], Step [239/375], Loss: 424.8038\n",
      "Epoch [17/50], Step [240/375], Loss: 265.3456\n",
      "Epoch [17/50], Step [241/375], Loss: 154.3944\n",
      "Epoch [17/50], Step [242/375], Loss: 97.8504\n",
      "Epoch [17/50], Step [243/375], Loss: 254.2467\n",
      "Epoch [17/50], Step [244/375], Loss: 138.7802\n",
      "Epoch [17/50], Step [245/375], Loss: 180.1112\n",
      "Epoch [17/50], Step [246/375], Loss: 39.2561\n",
      "Epoch [17/50], Step [247/375], Loss: 77.1008\n",
      "Epoch [17/50], Step [248/375], Loss: 65.7950\n",
      "Epoch [17/50], Step [249/375], Loss: 52.0308\n",
      "Epoch [17/50], Step [250/375], Loss: 81.2606\n",
      "Epoch [17/50], Step [251/375], Loss: 494.7846\n",
      "Epoch [17/50], Step [252/375], Loss: 28.9018\n",
      "Epoch [17/50], Step [253/375], Loss: 424.3742\n",
      "Epoch [17/50], Step [254/375], Loss: 306.9712\n",
      "Epoch [17/50], Step [255/375], Loss: 215.6623\n",
      "Epoch [17/50], Step [256/375], Loss: 166.5741\n",
      "Epoch [17/50], Step [257/375], Loss: 57.9527\n",
      "Epoch [17/50], Step [258/375], Loss: 206.0070\n",
      "Epoch [17/50], Step [259/375], Loss: 181.8465\n",
      "Epoch [17/50], Step [260/375], Loss: 139.7754\n",
      "Epoch [17/50], Step [261/375], Loss: 513.0215\n",
      "Epoch [17/50], Step [262/375], Loss: 358.7389\n",
      "Epoch [17/50], Step [263/375], Loss: 168.2356\n",
      "Epoch [17/50], Step [264/375], Loss: 256.3324\n",
      "Epoch [17/50], Step [265/375], Loss: 141.3970\n",
      "Epoch [17/50], Step [266/375], Loss: 123.7351\n",
      "Epoch [17/50], Step [267/375], Loss: 67.3955\n",
      "Epoch [17/50], Step [268/375], Loss: 256.8037\n",
      "Epoch [17/50], Step [269/375], Loss: 171.7222\n",
      "Epoch [17/50], Step [270/375], Loss: 188.0488\n",
      "Epoch [17/50], Step [271/375], Loss: 735.4257\n",
      "Epoch [17/50], Step [272/375], Loss: 89.3679\n",
      "Epoch [17/50], Step [273/375], Loss: 46.8891\n",
      "Epoch [17/50], Step [274/375], Loss: 148.1803\n",
      "Epoch [17/50], Step [275/375], Loss: 262.9934\n",
      "Epoch [17/50], Step [276/375], Loss: 491.3403\n",
      "Epoch [17/50], Step [277/375], Loss: 65.4466\n",
      "Epoch [17/50], Step [278/375], Loss: 137.0309\n",
      "Epoch [17/50], Step [279/375], Loss: 255.7998\n",
      "Epoch [17/50], Step [280/375], Loss: 90.4235\n",
      "Epoch [17/50], Step [281/375], Loss: 49.6483\n",
      "Epoch [17/50], Step [282/375], Loss: 161.4388\n",
      "Epoch [17/50], Step [283/375], Loss: 41.5583\n",
      "Epoch [17/50], Step [284/375], Loss: 229.1403\n",
      "Epoch [17/50], Step [285/375], Loss: 35.2621\n",
      "Epoch [17/50], Step [286/375], Loss: 505.2999\n",
      "Epoch [17/50], Step [287/375], Loss: 518.8361\n",
      "Epoch [17/50], Step [288/375], Loss: 254.0371\n",
      "Epoch [17/50], Step [289/375], Loss: 187.8224\n",
      "Epoch [17/50], Step [290/375], Loss: 48.7295\n",
      "Epoch [17/50], Step [291/375], Loss: 465.8242\n",
      "Epoch [17/50], Step [292/375], Loss: 137.7021\n",
      "Epoch [17/50], Step [293/375], Loss: 194.1856\n",
      "Epoch [17/50], Step [294/375], Loss: 137.0656\n",
      "Epoch [17/50], Step [295/375], Loss: 307.1769\n",
      "Epoch [17/50], Step [296/375], Loss: 119.5558\n",
      "Epoch [17/50], Step [297/375], Loss: 587.3581\n",
      "Epoch [17/50], Step [298/375], Loss: 92.3908\n",
      "Epoch [17/50], Step [299/375], Loss: 277.6307\n",
      "Epoch [17/50], Step [300/375], Loss: 333.7665\n",
      "Epoch [17/50], Step [301/375], Loss: 130.0182\n",
      "Epoch [17/50], Step [302/375], Loss: 428.0924\n",
      "Epoch [17/50], Step [303/375], Loss: 290.0784\n",
      "Epoch [17/50], Step [304/375], Loss: 44.5596\n",
      "Epoch [17/50], Step [305/375], Loss: 107.7972\n",
      "Epoch [17/50], Step [306/375], Loss: 123.4650\n",
      "Epoch [17/50], Step [307/375], Loss: 186.2551\n",
      "Epoch [17/50], Step [308/375], Loss: 141.5275\n",
      "Epoch [17/50], Step [309/375], Loss: 197.3422\n",
      "Epoch [17/50], Step [310/375], Loss: 68.9907\n",
      "Epoch [17/50], Step [311/375], Loss: 363.0005\n",
      "Epoch [17/50], Step [312/375], Loss: 209.0515\n",
      "Epoch [17/50], Step [313/375], Loss: 460.3187\n",
      "Epoch [17/50], Step [314/375], Loss: 100.3458\n",
      "Epoch [17/50], Step [315/375], Loss: 14.3690\n",
      "Epoch [17/50], Step [316/375], Loss: 177.0295\n",
      "Epoch [17/50], Step [317/375], Loss: 98.2242\n",
      "Epoch [17/50], Step [318/375], Loss: 68.0486\n",
      "Epoch [17/50], Step [319/375], Loss: 560.2804\n",
      "Epoch [17/50], Step [320/375], Loss: 178.0618\n",
      "Epoch [17/50], Step [321/375], Loss: 329.9443\n",
      "Epoch [17/50], Step [322/375], Loss: 430.4001\n",
      "Epoch [17/50], Step [323/375], Loss: 317.3363\n",
      "Epoch [17/50], Step [324/375], Loss: 145.3721\n",
      "Epoch [17/50], Step [325/375], Loss: 249.2120\n",
      "Epoch [17/50], Step [326/375], Loss: 66.5161\n",
      "Epoch [17/50], Step [327/375], Loss: 252.4923\n",
      "Epoch [17/50], Step [328/375], Loss: 199.3202\n",
      "Epoch [17/50], Step [329/375], Loss: 338.4946\n",
      "Epoch [17/50], Step [330/375], Loss: 328.1537\n",
      "Epoch [17/50], Step [331/375], Loss: 415.0100\n",
      "Epoch [17/50], Step [332/375], Loss: 29.4083\n",
      "Epoch [17/50], Step [333/375], Loss: 86.1919\n",
      "Epoch [17/50], Step [334/375], Loss: 255.1232\n",
      "Epoch [17/50], Step [335/375], Loss: 111.8712\n",
      "Epoch [17/50], Step [336/375], Loss: 242.9605\n",
      "Epoch [17/50], Step [337/375], Loss: 154.5999\n",
      "Epoch [17/50], Step [338/375], Loss: 154.6998\n",
      "Epoch [17/50], Step [339/375], Loss: 339.6906\n",
      "Epoch [17/50], Step [340/375], Loss: 63.3362\n",
      "Epoch [17/50], Step [341/375], Loss: 190.4969\n",
      "Epoch [17/50], Step [342/375], Loss: 277.9938\n",
      "Epoch [17/50], Step [343/375], Loss: 261.3135\n",
      "Epoch [17/50], Step [344/375], Loss: 403.0793\n",
      "Epoch [17/50], Step [345/375], Loss: 81.2405\n",
      "Epoch [17/50], Step [346/375], Loss: 104.2517\n",
      "Epoch [17/50], Step [347/375], Loss: 133.8967\n",
      "Epoch [17/50], Step [348/375], Loss: 265.5396\n",
      "Epoch [17/50], Step [349/375], Loss: 318.0792\n",
      "Epoch [17/50], Step [350/375], Loss: 192.6920\n",
      "Epoch [17/50], Step [351/375], Loss: 464.6993\n",
      "Epoch [17/50], Step [352/375], Loss: 49.3204\n",
      "Epoch [17/50], Step [353/375], Loss: 212.7016\n",
      "Epoch [17/50], Step [354/375], Loss: 140.9222\n",
      "Epoch [17/50], Step [355/375], Loss: 349.4988\n",
      "Epoch [17/50], Step [356/375], Loss: 169.1242\n",
      "Epoch [17/50], Step [357/375], Loss: 354.2366\n",
      "Epoch [17/50], Step [358/375], Loss: 84.5609\n",
      "Epoch [17/50], Step [359/375], Loss: 45.0012\n",
      "Epoch [17/50], Step [360/375], Loss: 78.7782\n",
      "Epoch [17/50], Step [361/375], Loss: 66.6737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Step [362/375], Loss: 179.3779\n",
      "Epoch [17/50], Step [363/375], Loss: 115.7663\n",
      "Epoch [17/50], Step [364/375], Loss: 58.1471\n",
      "Epoch [17/50], Step [365/375], Loss: 354.4698\n",
      "Epoch [17/50], Step [366/375], Loss: 32.8666\n",
      "Epoch [17/50], Step [367/375], Loss: 99.9027\n",
      "Epoch [17/50], Step [368/375], Loss: 206.7615\n",
      "Epoch [17/50], Step [369/375], Loss: 20.9771\n",
      "Epoch [17/50], Step [370/375], Loss: 164.2601\n",
      "Epoch [17/50], Step [371/375], Loss: 549.6475\n",
      "Epoch [17/50], Step [372/375], Loss: 159.2721\n",
      "Epoch [17/50], Step [373/375], Loss: 175.5558\n",
      "Epoch [17/50], Step [374/375], Loss: 70.5604\n",
      "Epoch [17/50], Step [375/375], Loss: 197.6777\n",
      "Epoch [18/50], Step [1/375], Loss: 202.1149\n",
      "Epoch [18/50], Step [2/375], Loss: 368.1602\n",
      "Epoch [18/50], Step [3/375], Loss: 45.4008\n",
      "Epoch [18/50], Step [4/375], Loss: 73.1926\n",
      "Epoch [18/50], Step [5/375], Loss: 172.0770\n",
      "Epoch [18/50], Step [6/375], Loss: 60.0371\n",
      "Epoch [18/50], Step [7/375], Loss: 50.1274\n",
      "Epoch [18/50], Step [8/375], Loss: 230.2970\n",
      "Epoch [18/50], Step [9/375], Loss: 138.3831\n",
      "Epoch [18/50], Step [10/375], Loss: 345.6894\n",
      "Epoch [18/50], Step [11/375], Loss: 128.7278\n",
      "Epoch [18/50], Step [12/375], Loss: 243.7157\n",
      "Epoch [18/50], Step [13/375], Loss: 397.3116\n",
      "Epoch [18/50], Step [14/375], Loss: 203.3967\n",
      "Epoch [18/50], Step [15/375], Loss: 153.4497\n",
      "Epoch [18/50], Step [16/375], Loss: 232.4177\n",
      "Epoch [18/50], Step [17/375], Loss: 184.3685\n",
      "Epoch [18/50], Step [18/375], Loss: 332.2029\n",
      "Epoch [18/50], Step [19/375], Loss: 238.7408\n",
      "Epoch [18/50], Step [20/375], Loss: 250.9714\n",
      "Epoch [18/50], Step [21/375], Loss: 181.3419\n",
      "Epoch [18/50], Step [22/375], Loss: 423.4885\n",
      "Epoch [18/50], Step [23/375], Loss: 224.7814\n",
      "Epoch [18/50], Step [24/375], Loss: 255.8614\n",
      "Epoch [18/50], Step [25/375], Loss: 196.6480\n",
      "Epoch [18/50], Step [26/375], Loss: 133.6464\n",
      "Epoch [18/50], Step [27/375], Loss: 114.0905\n",
      "Epoch [18/50], Step [28/375], Loss: 953.7123\n",
      "Epoch [18/50], Step [29/375], Loss: 227.3382\n",
      "Epoch [18/50], Step [30/375], Loss: 128.3354\n",
      "Epoch [18/50], Step [31/375], Loss: 140.6404\n",
      "Epoch [18/50], Step [32/375], Loss: 271.7119\n",
      "Epoch [18/50], Step [33/375], Loss: 157.4849\n",
      "Epoch [18/50], Step [34/375], Loss: 430.1581\n",
      "Epoch [18/50], Step [35/375], Loss: 69.6651\n",
      "Epoch [18/50], Step [36/375], Loss: 577.7358\n",
      "Epoch [18/50], Step [37/375], Loss: 273.6266\n",
      "Epoch [18/50], Step [38/375], Loss: 91.7944\n",
      "Epoch [18/50], Step [39/375], Loss: 203.8334\n",
      "Epoch [18/50], Step [40/375], Loss: 160.3025\n",
      "Epoch [18/50], Step [41/375], Loss: 52.3274\n",
      "Epoch [18/50], Step [42/375], Loss: 212.2999\n",
      "Epoch [18/50], Step [43/375], Loss: 99.9584\n",
      "Epoch [18/50], Step [44/375], Loss: 184.9361\n",
      "Epoch [18/50], Step [45/375], Loss: 165.4844\n",
      "Epoch [18/50], Step [46/375], Loss: 154.7122\n",
      "Epoch [18/50], Step [47/375], Loss: 21.7673\n",
      "Epoch [18/50], Step [48/375], Loss: 91.9462\n",
      "Epoch [18/50], Step [49/375], Loss: 250.2367\n",
      "Epoch [18/50], Step [50/375], Loss: 177.3491\n",
      "Epoch [18/50], Step [51/375], Loss: 197.8400\n",
      "Epoch [18/50], Step [52/375], Loss: 65.6009\n",
      "Epoch [18/50], Step [53/375], Loss: 248.7774\n",
      "Epoch [18/50], Step [54/375], Loss: 271.9613\n",
      "Epoch [18/50], Step [55/375], Loss: 212.9988\n",
      "Epoch [18/50], Step [56/375], Loss: 580.0242\n",
      "Epoch [18/50], Step [57/375], Loss: 350.1483\n",
      "Epoch [18/50], Step [58/375], Loss: 126.3563\n",
      "Epoch [18/50], Step [59/375], Loss: 417.3696\n",
      "Epoch [18/50], Step [60/375], Loss: 511.9145\n",
      "Epoch [18/50], Step [61/375], Loss: 456.5720\n",
      "Epoch [18/50], Step [62/375], Loss: 84.0624\n",
      "Epoch [18/50], Step [63/375], Loss: 149.3662\n",
      "Epoch [18/50], Step [64/375], Loss: 101.2681\n",
      "Epoch [18/50], Step [65/375], Loss: 446.6951\n",
      "Epoch [18/50], Step [66/375], Loss: 213.7253\n",
      "Epoch [18/50], Step [67/375], Loss: 297.8939\n",
      "Epoch [18/50], Step [68/375], Loss: 91.1967\n",
      "Epoch [18/50], Step [69/375], Loss: 346.5981\n",
      "Epoch [18/50], Step [70/375], Loss: 213.7292\n",
      "Epoch [18/50], Step [71/375], Loss: 36.4881\n",
      "Epoch [18/50], Step [72/375], Loss: 344.8190\n",
      "Epoch [18/50], Step [73/375], Loss: 283.9772\n",
      "Epoch [18/50], Step [74/375], Loss: 160.2688\n",
      "Epoch [18/50], Step [75/375], Loss: 91.7778\n",
      "Epoch [18/50], Step [76/375], Loss: 255.1765\n",
      "Epoch [18/50], Step [77/375], Loss: 31.7908\n",
      "Epoch [18/50], Step [78/375], Loss: 223.4809\n",
      "Epoch [18/50], Step [79/375], Loss: 214.3307\n",
      "Epoch [18/50], Step [80/375], Loss: 338.7001\n",
      "Epoch [18/50], Step [81/375], Loss: 165.3690\n",
      "Epoch [18/50], Step [82/375], Loss: 154.9733\n",
      "Epoch [18/50], Step [83/375], Loss: 598.2230\n",
      "Epoch [18/50], Step [84/375], Loss: 259.0425\n",
      "Epoch [18/50], Step [85/375], Loss: 210.6875\n",
      "Epoch [18/50], Step [86/375], Loss: 321.6071\n",
      "Epoch [18/50], Step [87/375], Loss: 552.4760\n",
      "Epoch [18/50], Step [88/375], Loss: 70.9427\n",
      "Epoch [18/50], Step [89/375], Loss: 607.5668\n",
      "Epoch [18/50], Step [90/375], Loss: 163.9162\n",
      "Epoch [18/50], Step [91/375], Loss: 83.1928\n",
      "Epoch [18/50], Step [92/375], Loss: 377.6140\n",
      "Epoch [18/50], Step [93/375], Loss: 216.3548\n",
      "Epoch [18/50], Step [94/375], Loss: 147.7171\n",
      "Epoch [18/50], Step [95/375], Loss: 274.4612\n",
      "Epoch [18/50], Step [96/375], Loss: 147.2074\n",
      "Epoch [18/50], Step [97/375], Loss: 365.5989\n",
      "Epoch [18/50], Step [98/375], Loss: 95.4474\n",
      "Epoch [18/50], Step [99/375], Loss: 218.3487\n",
      "Epoch [18/50], Step [100/375], Loss: 237.8596\n",
      "Epoch [18/50], Step [101/375], Loss: 27.3386\n",
      "Epoch [18/50], Step [102/375], Loss: 113.4482\n",
      "Epoch [18/50], Step [103/375], Loss: 280.3239\n",
      "Epoch [18/50], Step [104/375], Loss: 138.6193\n",
      "Epoch [18/50], Step [105/375], Loss: 335.5237\n",
      "Epoch [18/50], Step [106/375], Loss: 199.3762\n",
      "Epoch [18/50], Step [107/375], Loss: 213.7402\n",
      "Epoch [18/50], Step [108/375], Loss: 238.1644\n",
      "Epoch [18/50], Step [109/375], Loss: 404.4988\n",
      "Epoch [18/50], Step [110/375], Loss: 219.3840\n",
      "Epoch [18/50], Step [111/375], Loss: 124.7908\n",
      "Epoch [18/50], Step [112/375], Loss: 195.1166\n",
      "Epoch [18/50], Step [113/375], Loss: 105.9758\n",
      "Epoch [18/50], Step [114/375], Loss: 246.0484\n",
      "Epoch [18/50], Step [115/375], Loss: 103.3131\n",
      "Epoch [18/50], Step [116/375], Loss: 41.4841\n",
      "Epoch [18/50], Step [117/375], Loss: 98.5482\n",
      "Epoch [18/50], Step [118/375], Loss: 167.4343\n",
      "Epoch [18/50], Step [119/375], Loss: 54.6382\n",
      "Epoch [18/50], Step [120/375], Loss: 151.2757\n",
      "Epoch [18/50], Step [121/375], Loss: 159.7911\n",
      "Epoch [18/50], Step [122/375], Loss: 276.7746\n",
      "Epoch [18/50], Step [123/375], Loss: 84.6004\n",
      "Epoch [18/50], Step [124/375], Loss: 218.7185\n",
      "Epoch [18/50], Step [125/375], Loss: 241.8952\n",
      "Epoch [18/50], Step [126/375], Loss: 563.2319\n",
      "Epoch [18/50], Step [127/375], Loss: 195.9340\n",
      "Epoch [18/50], Step [128/375], Loss: 355.3566\n",
      "Epoch [18/50], Step [129/375], Loss: 126.8590\n",
      "Epoch [18/50], Step [130/375], Loss: 94.1296\n",
      "Epoch [18/50], Step [131/375], Loss: 343.4110\n",
      "Epoch [18/50], Step [132/375], Loss: 436.6923\n",
      "Epoch [18/50], Step [133/375], Loss: 164.9055\n",
      "Epoch [18/50], Step [134/375], Loss: 186.6227\n",
      "Epoch [18/50], Step [135/375], Loss: 247.4638\n",
      "Epoch [18/50], Step [136/375], Loss: 346.3476\n",
      "Epoch [18/50], Step [137/375], Loss: 660.3851\n",
      "Epoch [18/50], Step [138/375], Loss: 146.9406\n",
      "Epoch [18/50], Step [139/375], Loss: 111.7204\n",
      "Epoch [18/50], Step [140/375], Loss: 326.3107\n",
      "Epoch [18/50], Step [141/375], Loss: 99.6595\n",
      "Epoch [18/50], Step [142/375], Loss: 86.5614\n",
      "Epoch [18/50], Step [143/375], Loss: 99.2103\n",
      "Epoch [18/50], Step [144/375], Loss: 80.0874\n",
      "Epoch [18/50], Step [145/375], Loss: 70.1285\n",
      "Epoch [18/50], Step [146/375], Loss: 472.5718\n",
      "Epoch [18/50], Step [147/375], Loss: 264.6537\n",
      "Epoch [18/50], Step [148/375], Loss: 115.6328\n",
      "Epoch [18/50], Step [149/375], Loss: 295.0892\n",
      "Epoch [18/50], Step [150/375], Loss: 492.5532\n",
      "Epoch [18/50], Step [151/375], Loss: 374.6053\n",
      "Epoch [18/50], Step [152/375], Loss: 295.1466\n",
      "Epoch [18/50], Step [153/375], Loss: 213.6689\n",
      "Epoch [18/50], Step [154/375], Loss: 188.5166\n",
      "Epoch [18/50], Step [155/375], Loss: 368.2186\n",
      "Epoch [18/50], Step [156/375], Loss: 53.4739\n",
      "Epoch [18/50], Step [157/375], Loss: 399.5847\n",
      "Epoch [18/50], Step [158/375], Loss: 192.8902\n",
      "Epoch [18/50], Step [159/375], Loss: 56.0292\n",
      "Epoch [18/50], Step [160/375], Loss: 284.8487\n",
      "Epoch [18/50], Step [161/375], Loss: 103.1758\n",
      "Epoch [18/50], Step [162/375], Loss: 162.2038\n",
      "Epoch [18/50], Step [163/375], Loss: 149.4350\n",
      "Epoch [18/50], Step [164/375], Loss: 111.1089\n",
      "Epoch [18/50], Step [165/375], Loss: 70.2353\n",
      "Epoch [18/50], Step [166/375], Loss: 129.0180\n",
      "Epoch [18/50], Step [167/375], Loss: 49.1743\n",
      "Epoch [18/50], Step [168/375], Loss: 259.5662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Step [169/375], Loss: 249.0486\n",
      "Epoch [18/50], Step [170/375], Loss: 107.5592\n",
      "Epoch [18/50], Step [171/375], Loss: 32.3893\n",
      "Epoch [18/50], Step [172/375], Loss: 114.4946\n",
      "Epoch [18/50], Step [173/375], Loss: 400.6667\n",
      "Epoch [18/50], Step [174/375], Loss: 247.3735\n",
      "Epoch [18/50], Step [175/375], Loss: 188.7217\n",
      "Epoch [18/50], Step [176/375], Loss: 101.7774\n",
      "Epoch [18/50], Step [177/375], Loss: 381.6096\n",
      "Epoch [18/50], Step [178/375], Loss: 476.7270\n",
      "Epoch [18/50], Step [179/375], Loss: 78.6057\n",
      "Epoch [18/50], Step [180/375], Loss: 168.0424\n",
      "Epoch [18/50], Step [181/375], Loss: 797.6481\n",
      "Epoch [18/50], Step [182/375], Loss: 289.7454\n",
      "Epoch [18/50], Step [183/375], Loss: 232.2190\n",
      "Epoch [18/50], Step [184/375], Loss: 134.3753\n",
      "Epoch [18/50], Step [185/375], Loss: 192.3408\n",
      "Epoch [18/50], Step [186/375], Loss: 138.5565\n",
      "Epoch [18/50], Step [187/375], Loss: 397.0414\n",
      "Epoch [18/50], Step [188/375], Loss: 115.4954\n",
      "Epoch [18/50], Step [189/375], Loss: 133.4500\n",
      "Epoch [18/50], Step [190/375], Loss: 85.0932\n",
      "Epoch [18/50], Step [191/375], Loss: 61.8666\n",
      "Epoch [18/50], Step [192/375], Loss: 73.5333\n",
      "Epoch [18/50], Step [193/375], Loss: 459.8356\n",
      "Epoch [18/50], Step [194/375], Loss: 13.4902\n",
      "Epoch [18/50], Step [195/375], Loss: 56.7281\n",
      "Epoch [18/50], Step [196/375], Loss: 231.2078\n",
      "Epoch [18/50], Step [197/375], Loss: 94.4360\n",
      "Epoch [18/50], Step [198/375], Loss: 125.5249\n",
      "Epoch [18/50], Step [199/375], Loss: 291.1601\n",
      "Epoch [18/50], Step [200/375], Loss: 138.7301\n",
      "Epoch [18/50], Step [201/375], Loss: 278.7909\n",
      "Epoch [18/50], Step [202/375], Loss: 144.8849\n",
      "Epoch [18/50], Step [203/375], Loss: 235.8542\n",
      "Epoch [18/50], Step [204/375], Loss: 78.9518\n",
      "Epoch [18/50], Step [205/375], Loss: 505.4794\n",
      "Epoch [18/50], Step [206/375], Loss: 302.8253\n",
      "Epoch [18/50], Step [207/375], Loss: 105.0781\n",
      "Epoch [18/50], Step [208/375], Loss: 73.7089\n",
      "Epoch [18/50], Step [209/375], Loss: 545.9230\n",
      "Epoch [18/50], Step [210/375], Loss: 294.6217\n",
      "Epoch [18/50], Step [211/375], Loss: 250.9522\n",
      "Epoch [18/50], Step [212/375], Loss: 656.8990\n",
      "Epoch [18/50], Step [213/375], Loss: 142.9258\n",
      "Epoch [18/50], Step [214/375], Loss: 137.8314\n",
      "Epoch [18/50], Step [215/375], Loss: 448.8228\n",
      "Epoch [18/50], Step [216/375], Loss: 59.5379\n",
      "Epoch [18/50], Step [217/375], Loss: 111.9103\n",
      "Epoch [18/50], Step [218/375], Loss: 109.3350\n",
      "Epoch [18/50], Step [219/375], Loss: 462.3797\n",
      "Epoch [18/50], Step [220/375], Loss: 151.4306\n",
      "Epoch [18/50], Step [221/375], Loss: 23.8559\n",
      "Epoch [18/50], Step [222/375], Loss: 453.5242\n",
      "Epoch [18/50], Step [223/375], Loss: 74.0423\n",
      "Epoch [18/50], Step [224/375], Loss: 674.3207\n",
      "Epoch [18/50], Step [225/375], Loss: 81.9477\n",
      "Epoch [18/50], Step [226/375], Loss: 185.1638\n",
      "Epoch [18/50], Step [227/375], Loss: 502.5525\n",
      "Epoch [18/50], Step [228/375], Loss: 107.2437\n",
      "Epoch [18/50], Step [229/375], Loss: 104.4462\n",
      "Epoch [18/50], Step [230/375], Loss: 147.2585\n",
      "Epoch [18/50], Step [231/375], Loss: 218.3983\n",
      "Epoch [18/50], Step [232/375], Loss: 156.5721\n",
      "Epoch [18/50], Step [233/375], Loss: 69.9320\n",
      "Epoch [18/50], Step [234/375], Loss: 218.3319\n",
      "Epoch [18/50], Step [235/375], Loss: 66.8379\n",
      "Epoch [18/50], Step [236/375], Loss: 70.7719\n",
      "Epoch [18/50], Step [237/375], Loss: 140.7454\n",
      "Epoch [18/50], Step [238/375], Loss: 60.1508\n",
      "Epoch [18/50], Step [239/375], Loss: 84.1743\n",
      "Epoch [18/50], Step [240/375], Loss: 146.9479\n",
      "Epoch [18/50], Step [241/375], Loss: 259.5282\n",
      "Epoch [18/50], Step [242/375], Loss: 92.7522\n",
      "Epoch [18/50], Step [243/375], Loss: 76.8533\n",
      "Epoch [18/50], Step [244/375], Loss: 432.6489\n",
      "Epoch [18/50], Step [245/375], Loss: 153.8512\n",
      "Epoch [18/50], Step [246/375], Loss: 31.3947\n",
      "Epoch [18/50], Step [247/375], Loss: 249.3783\n",
      "Epoch [18/50], Step [248/375], Loss: 106.1186\n",
      "Epoch [18/50], Step [249/375], Loss: 187.2634\n",
      "Epoch [18/50], Step [250/375], Loss: 100.2471\n",
      "Epoch [18/50], Step [251/375], Loss: 93.9422\n",
      "Epoch [18/50], Step [252/375], Loss: 101.1295\n",
      "Epoch [18/50], Step [253/375], Loss: 54.7524\n",
      "Epoch [18/50], Step [254/375], Loss: 19.7561\n",
      "Epoch [18/50], Step [255/375], Loss: 587.5964\n",
      "Epoch [18/50], Step [256/375], Loss: 456.3714\n",
      "Epoch [18/50], Step [257/375], Loss: 256.1746\n",
      "Epoch [18/50], Step [258/375], Loss: 82.3462\n",
      "Epoch [18/50], Step [259/375], Loss: 94.2542\n",
      "Epoch [18/50], Step [260/375], Loss: 542.7277\n",
      "Epoch [18/50], Step [261/375], Loss: 403.6839\n",
      "Epoch [18/50], Step [262/375], Loss: 155.8295\n",
      "Epoch [18/50], Step [263/375], Loss: 479.5290\n",
      "Epoch [18/50], Step [264/375], Loss: 392.5480\n",
      "Epoch [18/50], Step [265/375], Loss: 467.2128\n",
      "Epoch [18/50], Step [266/375], Loss: 494.0417\n",
      "Epoch [18/50], Step [267/375], Loss: 71.6134\n",
      "Epoch [18/50], Step [268/375], Loss: 673.6262\n",
      "Epoch [18/50], Step [269/375], Loss: 82.9659\n",
      "Epoch [18/50], Step [270/375], Loss: 73.6102\n",
      "Epoch [18/50], Step [271/375], Loss: 186.8828\n",
      "Epoch [18/50], Step [272/375], Loss: 107.4604\n",
      "Epoch [18/50], Step [273/375], Loss: 842.6563\n",
      "Epoch [18/50], Step [274/375], Loss: 310.3306\n",
      "Epoch [18/50], Step [275/375], Loss: 216.9231\n",
      "Epoch [18/50], Step [276/375], Loss: 223.6969\n",
      "Epoch [18/50], Step [277/375], Loss: 151.1237\n",
      "Epoch [18/50], Step [278/375], Loss: 304.9055\n",
      "Epoch [18/50], Step [279/375], Loss: 114.2956\n",
      "Epoch [18/50], Step [280/375], Loss: 111.9663\n",
      "Epoch [18/50], Step [281/375], Loss: 289.4055\n",
      "Epoch [18/50], Step [282/375], Loss: 53.6368\n",
      "Epoch [18/50], Step [283/375], Loss: 84.6434\n",
      "Epoch [18/50], Step [284/375], Loss: 150.1609\n",
      "Epoch [18/50], Step [285/375], Loss: 170.9825\n",
      "Epoch [18/50], Step [286/375], Loss: 162.1863\n",
      "Epoch [18/50], Step [287/375], Loss: 106.7323\n",
      "Epoch [18/50], Step [288/375], Loss: 13.9418\n",
      "Epoch [18/50], Step [289/375], Loss: 139.9034\n",
      "Epoch [18/50], Step [290/375], Loss: 255.4408\n",
      "Epoch [18/50], Step [291/375], Loss: 166.6962\n",
      "Epoch [18/50], Step [292/375], Loss: 148.3679\n",
      "Epoch [18/50], Step [293/375], Loss: 109.2510\n",
      "Epoch [18/50], Step [294/375], Loss: 535.8154\n",
      "Epoch [18/50], Step [295/375], Loss: 500.1327\n",
      "Epoch [18/50], Step [296/375], Loss: 36.7882\n",
      "Epoch [18/50], Step [297/375], Loss: 47.1396\n",
      "Epoch [18/50], Step [298/375], Loss: 27.3037\n",
      "Epoch [18/50], Step [299/375], Loss: 84.0619\n",
      "Epoch [18/50], Step [300/375], Loss: 173.2659\n",
      "Epoch [18/50], Step [301/375], Loss: 313.1051\n",
      "Epoch [18/50], Step [302/375], Loss: 25.2918\n",
      "Epoch [18/50], Step [303/375], Loss: 254.6907\n",
      "Epoch [18/50], Step [304/375], Loss: 380.6861\n",
      "Epoch [18/50], Step [305/375], Loss: 234.7912\n",
      "Epoch [18/50], Step [306/375], Loss: 176.6307\n",
      "Epoch [18/50], Step [307/375], Loss: 53.0381\n",
      "Epoch [18/50], Step [308/375], Loss: 425.1833\n",
      "Epoch [18/50], Step [309/375], Loss: 47.0547\n",
      "Epoch [18/50], Step [310/375], Loss: 79.5653\n",
      "Epoch [18/50], Step [311/375], Loss: 289.5095\n",
      "Epoch [18/50], Step [312/375], Loss: 69.5271\n",
      "Epoch [18/50], Step [313/375], Loss: 128.4928\n",
      "Epoch [18/50], Step [314/375], Loss: 158.7435\n",
      "Epoch [18/50], Step [315/375], Loss: 285.8028\n",
      "Epoch [18/50], Step [316/375], Loss: 57.6893\n",
      "Epoch [18/50], Step [317/375], Loss: 89.5246\n",
      "Epoch [18/50], Step [318/375], Loss: 242.8174\n",
      "Epoch [18/50], Step [319/375], Loss: 109.6015\n",
      "Epoch [18/50], Step [320/375], Loss: 98.0308\n",
      "Epoch [18/50], Step [321/375], Loss: 184.6391\n",
      "Epoch [18/50], Step [322/375], Loss: 189.1761\n",
      "Epoch [18/50], Step [323/375], Loss: 146.0082\n",
      "Epoch [18/50], Step [324/375], Loss: 20.0234\n",
      "Epoch [18/50], Step [325/375], Loss: 84.2801\n",
      "Epoch [18/50], Step [326/375], Loss: 249.1412\n",
      "Epoch [18/50], Step [327/375], Loss: 158.1954\n",
      "Epoch [18/50], Step [328/375], Loss: 453.8543\n",
      "Epoch [18/50], Step [329/375], Loss: 459.6601\n",
      "Epoch [18/50], Step [330/375], Loss: 111.2595\n",
      "Epoch [18/50], Step [331/375], Loss: 84.7736\n",
      "Epoch [18/50], Step [332/375], Loss: 185.5490\n",
      "Epoch [18/50], Step [333/375], Loss: 114.8604\n",
      "Epoch [18/50], Step [334/375], Loss: 179.7080\n",
      "Epoch [18/50], Step [335/375], Loss: 154.9267\n",
      "Epoch [18/50], Step [336/375], Loss: 117.5856\n",
      "Epoch [18/50], Step [337/375], Loss: 366.8435\n",
      "Epoch [18/50], Step [338/375], Loss: 394.3449\n",
      "Epoch [18/50], Step [339/375], Loss: 40.4780\n",
      "Epoch [18/50], Step [340/375], Loss: 150.2871\n",
      "Epoch [18/50], Step [341/375], Loss: 59.0734\n",
      "Epoch [18/50], Step [342/375], Loss: 76.8265\n",
      "Epoch [18/50], Step [343/375], Loss: 105.6152\n",
      "Epoch [18/50], Step [344/375], Loss: 553.7038\n",
      "Epoch [18/50], Step [345/375], Loss: 63.1877\n",
      "Epoch [18/50], Step [346/375], Loss: 344.4243\n",
      "Epoch [18/50], Step [347/375], Loss: 56.2409\n",
      "Epoch [18/50], Step [348/375], Loss: 242.9363\n",
      "Epoch [18/50], Step [349/375], Loss: 118.7689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Step [350/375], Loss: 192.7866\n",
      "Epoch [18/50], Step [351/375], Loss: 186.3765\n",
      "Epoch [18/50], Step [352/375], Loss: 119.4531\n",
      "Epoch [18/50], Step [353/375], Loss: 367.7194\n",
      "Epoch [18/50], Step [354/375], Loss: 294.3039\n",
      "Epoch [18/50], Step [355/375], Loss: 117.0368\n",
      "Epoch [18/50], Step [356/375], Loss: 158.2458\n",
      "Epoch [18/50], Step [357/375], Loss: 131.8857\n",
      "Epoch [18/50], Step [358/375], Loss: 53.4808\n",
      "Epoch [18/50], Step [359/375], Loss: 203.0634\n",
      "Epoch [18/50], Step [360/375], Loss: 118.2471\n",
      "Epoch [18/50], Step [361/375], Loss: 468.8347\n",
      "Epoch [18/50], Step [362/375], Loss: 130.4420\n",
      "Epoch [18/50], Step [363/375], Loss: 263.1672\n",
      "Epoch [18/50], Step [364/375], Loss: 43.7009\n",
      "Epoch [18/50], Step [365/375], Loss: 100.5210\n",
      "Epoch [18/50], Step [366/375], Loss: 41.2214\n",
      "Epoch [18/50], Step [367/375], Loss: 440.7792\n",
      "Epoch [18/50], Step [368/375], Loss: 405.5782\n",
      "Epoch [18/50], Step [369/375], Loss: 115.0056\n",
      "Epoch [18/50], Step [370/375], Loss: 188.0464\n",
      "Epoch [18/50], Step [371/375], Loss: 131.3721\n",
      "Epoch [18/50], Step [372/375], Loss: 200.1008\n",
      "Epoch [18/50], Step [373/375], Loss: 243.5356\n",
      "Epoch [18/50], Step [374/375], Loss: 249.4245\n",
      "Epoch [18/50], Step [375/375], Loss: 427.7169\n",
      "Epoch [19/50], Step [1/375], Loss: 99.6999\n",
      "Epoch [19/50], Step [2/375], Loss: 90.9119\n",
      "Epoch [19/50], Step [3/375], Loss: 41.8480\n",
      "Epoch [19/50], Step [4/375], Loss: 193.4966\n",
      "Epoch [19/50], Step [5/375], Loss: 544.5068\n",
      "Epoch [19/50], Step [6/375], Loss: 190.8791\n",
      "Epoch [19/50], Step [7/375], Loss: 176.9111\n",
      "Epoch [19/50], Step [8/375], Loss: 45.4799\n",
      "Epoch [19/50], Step [9/375], Loss: 160.0705\n",
      "Epoch [19/50], Step [10/375], Loss: 154.1801\n",
      "Epoch [19/50], Step [11/375], Loss: 82.5873\n",
      "Epoch [19/50], Step [12/375], Loss: 442.0104\n",
      "Epoch [19/50], Step [13/375], Loss: 50.3760\n",
      "Epoch [19/50], Step [14/375], Loss: 133.4007\n",
      "Epoch [19/50], Step [15/375], Loss: 274.6610\n",
      "Epoch [19/50], Step [16/375], Loss: 171.5951\n",
      "Epoch [19/50], Step [17/375], Loss: 135.4387\n",
      "Epoch [19/50], Step [18/375], Loss: 682.5999\n",
      "Epoch [19/50], Step [19/375], Loss: 119.7567\n",
      "Epoch [19/50], Step [20/375], Loss: 83.2753\n",
      "Epoch [19/50], Step [21/375], Loss: 52.4144\n",
      "Epoch [19/50], Step [22/375], Loss: 241.7115\n",
      "Epoch [19/50], Step [23/375], Loss: 136.5693\n",
      "Epoch [19/50], Step [24/375], Loss: 296.4279\n",
      "Epoch [19/50], Step [25/375], Loss: 166.8351\n",
      "Epoch [19/50], Step [26/375], Loss: 400.6904\n",
      "Epoch [19/50], Step [27/375], Loss: 99.2766\n",
      "Epoch [19/50], Step [28/375], Loss: 114.0046\n",
      "Epoch [19/50], Step [29/375], Loss: 141.7599\n",
      "Epoch [19/50], Step [30/375], Loss: 149.2212\n",
      "Epoch [19/50], Step [31/375], Loss: 712.9112\n",
      "Epoch [19/50], Step [32/375], Loss: 360.4836\n",
      "Epoch [19/50], Step [33/375], Loss: 391.2242\n",
      "Epoch [19/50], Step [34/375], Loss: 574.3564\n",
      "Epoch [19/50], Step [35/375], Loss: 211.4439\n",
      "Epoch [19/50], Step [36/375], Loss: 65.1866\n",
      "Epoch [19/50], Step [37/375], Loss: 135.7141\n",
      "Epoch [19/50], Step [38/375], Loss: 65.8811\n",
      "Epoch [19/50], Step [39/375], Loss: 168.8055\n",
      "Epoch [19/50], Step [40/375], Loss: 68.0313\n",
      "Epoch [19/50], Step [41/375], Loss: 579.5366\n",
      "Epoch [19/50], Step [42/375], Loss: 117.4341\n",
      "Epoch [19/50], Step [43/375], Loss: 209.4906\n",
      "Epoch [19/50], Step [44/375], Loss: 166.2793\n",
      "Epoch [19/50], Step [45/375], Loss: 114.2593\n",
      "Epoch [19/50], Step [46/375], Loss: 96.9507\n",
      "Epoch [19/50], Step [47/375], Loss: 254.6586\n",
      "Epoch [19/50], Step [48/375], Loss: 42.3731\n",
      "Epoch [19/50], Step [49/375], Loss: 219.9351\n",
      "Epoch [19/50], Step [50/375], Loss: 246.0651\n",
      "Epoch [19/50], Step [51/375], Loss: 179.3108\n",
      "Epoch [19/50], Step [52/375], Loss: 298.9170\n",
      "Epoch [19/50], Step [53/375], Loss: 141.8512\n",
      "Epoch [19/50], Step [54/375], Loss: 221.3586\n",
      "Epoch [19/50], Step [55/375], Loss: 428.5641\n",
      "Epoch [19/50], Step [56/375], Loss: 153.2148\n",
      "Epoch [19/50], Step [57/375], Loss: 120.8528\n",
      "Epoch [19/50], Step [58/375], Loss: 405.0674\n",
      "Epoch [19/50], Step [59/375], Loss: 99.4305\n",
      "Epoch [19/50], Step [60/375], Loss: 221.2545\n",
      "Epoch [19/50], Step [61/375], Loss: 111.5005\n",
      "Epoch [19/50], Step [62/375], Loss: 377.4293\n",
      "Epoch [19/50], Step [63/375], Loss: 158.2006\n",
      "Epoch [19/50], Step [64/375], Loss: 236.5664\n",
      "Epoch [19/50], Step [65/375], Loss: 306.1987\n",
      "Epoch [19/50], Step [66/375], Loss: 303.2073\n",
      "Epoch [19/50], Step [67/375], Loss: 65.7734\n",
      "Epoch [19/50], Step [68/375], Loss: 276.5665\n",
      "Epoch [19/50], Step [69/375], Loss: 73.2038\n",
      "Epoch [19/50], Step [70/375], Loss: 167.9900\n",
      "Epoch [19/50], Step [71/375], Loss: 273.5941\n",
      "Epoch [19/50], Step [72/375], Loss: 240.0733\n",
      "Epoch [19/50], Step [73/375], Loss: 17.3275\n",
      "Epoch [19/50], Step [74/375], Loss: 63.3471\n",
      "Epoch [19/50], Step [75/375], Loss: 74.8035\n",
      "Epoch [19/50], Step [76/375], Loss: 341.8310\n",
      "Epoch [19/50], Step [77/375], Loss: 93.8917\n",
      "Epoch [19/50], Step [78/375], Loss: 68.0841\n",
      "Epoch [19/50], Step [79/375], Loss: 162.5817\n",
      "Epoch [19/50], Step [80/375], Loss: 89.2836\n",
      "Epoch [19/50], Step [81/375], Loss: 349.9084\n",
      "Epoch [19/50], Step [82/375], Loss: 56.3860\n",
      "Epoch [19/50], Step [83/375], Loss: 311.1346\n",
      "Epoch [19/50], Step [84/375], Loss: 141.8579\n",
      "Epoch [19/50], Step [85/375], Loss: 319.8223\n",
      "Epoch [19/50], Step [86/375], Loss: 303.7875\n",
      "Epoch [19/50], Step [87/375], Loss: 48.6522\n",
      "Epoch [19/50], Step [88/375], Loss: 135.0053\n",
      "Epoch [19/50], Step [89/375], Loss: 155.5861\n",
      "Epoch [19/50], Step [90/375], Loss: 251.5469\n",
      "Epoch [19/50], Step [91/375], Loss: 222.2041\n",
      "Epoch [19/50], Step [92/375], Loss: 95.8042\n",
      "Epoch [19/50], Step [93/375], Loss: 30.8689\n",
      "Epoch [19/50], Step [94/375], Loss: 71.8031\n",
      "Epoch [19/50], Step [95/375], Loss: 47.7356\n",
      "Epoch [19/50], Step [96/375], Loss: 152.3623\n",
      "Epoch [19/50], Step [97/375], Loss: 161.4261\n",
      "Epoch [19/50], Step [98/375], Loss: 56.2136\n",
      "Epoch [19/50], Step [99/375], Loss: 319.0374\n",
      "Epoch [19/50], Step [100/375], Loss: 35.7949\n",
      "Epoch [19/50], Step [101/375], Loss: 149.6425\n",
      "Epoch [19/50], Step [102/375], Loss: 112.6457\n",
      "Epoch [19/50], Step [103/375], Loss: 253.6287\n",
      "Epoch [19/50], Step [104/375], Loss: 133.8253\n",
      "Epoch [19/50], Step [105/375], Loss: 170.2010\n",
      "Epoch [19/50], Step [106/375], Loss: 195.7612\n",
      "Epoch [19/50], Step [107/375], Loss: 131.1493\n",
      "Epoch [19/50], Step [108/375], Loss: 124.4869\n",
      "Epoch [19/50], Step [109/375], Loss: 111.4752\n",
      "Epoch [19/50], Step [110/375], Loss: 44.3644\n",
      "Epoch [19/50], Step [111/375], Loss: 108.3962\n",
      "Epoch [19/50], Step [112/375], Loss: 190.9429\n",
      "Epoch [19/50], Step [113/375], Loss: 89.1378\n",
      "Epoch [19/50], Step [114/375], Loss: 186.7756\n",
      "Epoch [19/50], Step [115/375], Loss: 70.9410\n",
      "Epoch [19/50], Step [116/375], Loss: 409.9340\n",
      "Epoch [19/50], Step [117/375], Loss: 221.2812\n",
      "Epoch [19/50], Step [118/375], Loss: 87.0988\n",
      "Epoch [19/50], Step [119/375], Loss: 46.2651\n",
      "Epoch [19/50], Step [120/375], Loss: 186.6590\n",
      "Epoch [19/50], Step [121/375], Loss: 225.3987\n",
      "Epoch [19/50], Step [122/375], Loss: 223.1666\n",
      "Epoch [19/50], Step [123/375], Loss: 135.6808\n",
      "Epoch [19/50], Step [124/375], Loss: 67.3063\n",
      "Epoch [19/50], Step [125/375], Loss: 438.1608\n",
      "Epoch [19/50], Step [126/375], Loss: 91.1238\n",
      "Epoch [19/50], Step [127/375], Loss: 508.7881\n",
      "Epoch [19/50], Step [128/375], Loss: 145.2643\n",
      "Epoch [19/50], Step [129/375], Loss: 72.6638\n",
      "Epoch [19/50], Step [130/375], Loss: 76.4780\n",
      "Epoch [19/50], Step [131/375], Loss: 81.2102\n",
      "Epoch [19/50], Step [132/375], Loss: 75.3805\n",
      "Epoch [19/50], Step [133/375], Loss: 358.3226\n",
      "Epoch [19/50], Step [134/375], Loss: 57.9731\n",
      "Epoch [19/50], Step [135/375], Loss: 33.7374\n",
      "Epoch [19/50], Step [136/375], Loss: 258.3998\n",
      "Epoch [19/50], Step [137/375], Loss: 86.6287\n",
      "Epoch [19/50], Step [138/375], Loss: 118.1511\n",
      "Epoch [19/50], Step [139/375], Loss: 539.4666\n",
      "Epoch [19/50], Step [140/375], Loss: 112.8360\n",
      "Epoch [19/50], Step [141/375], Loss: 25.2124\n",
      "Epoch [19/50], Step [142/375], Loss: 167.1266\n",
      "Epoch [19/50], Step [143/375], Loss: 94.4813\n",
      "Epoch [19/50], Step [144/375], Loss: 50.5622\n",
      "Epoch [19/50], Step [145/375], Loss: 179.8027\n",
      "Epoch [19/50], Step [146/375], Loss: 261.8733\n",
      "Epoch [19/50], Step [147/375], Loss: 57.6858\n",
      "Epoch [19/50], Step [148/375], Loss: 75.5428\n",
      "Epoch [19/50], Step [149/375], Loss: 179.5454\n",
      "Epoch [19/50], Step [150/375], Loss: 61.6809\n",
      "Epoch [19/50], Step [151/375], Loss: 39.7629\n",
      "Epoch [19/50], Step [152/375], Loss: 125.1928\n",
      "Epoch [19/50], Step [153/375], Loss: 125.9550\n",
      "Epoch [19/50], Step [154/375], Loss: 575.5142\n",
      "Epoch [19/50], Step [155/375], Loss: 89.4190\n",
      "Epoch [19/50], Step [156/375], Loss: 312.8307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Step [157/375], Loss: 129.1019\n",
      "Epoch [19/50], Step [158/375], Loss: 210.2683\n",
      "Epoch [19/50], Step [159/375], Loss: 259.0897\n",
      "Epoch [19/50], Step [160/375], Loss: 159.3069\n",
      "Epoch [19/50], Step [161/375], Loss: 160.3635\n",
      "Epoch [19/50], Step [162/375], Loss: 80.1006\n",
      "Epoch [19/50], Step [163/375], Loss: 229.6117\n",
      "Epoch [19/50], Step [164/375], Loss: 314.9562\n",
      "Epoch [19/50], Step [165/375], Loss: 40.8498\n",
      "Epoch [19/50], Step [166/375], Loss: 220.5826\n",
      "Epoch [19/50], Step [167/375], Loss: 96.1412\n",
      "Epoch [19/50], Step [168/375], Loss: 237.5428\n",
      "Epoch [19/50], Step [169/375], Loss: 57.4976\n",
      "Epoch [19/50], Step [170/375], Loss: 148.9354\n",
      "Epoch [19/50], Step [171/375], Loss: 418.5139\n",
      "Epoch [19/50], Step [172/375], Loss: 163.3081\n",
      "Epoch [19/50], Step [173/375], Loss: 336.9171\n",
      "Epoch [19/50], Step [174/375], Loss: 89.1687\n",
      "Epoch [19/50], Step [175/375], Loss: 586.7887\n",
      "Epoch [19/50], Step [176/375], Loss: 124.9120\n",
      "Epoch [19/50], Step [177/375], Loss: 432.0661\n",
      "Epoch [19/50], Step [178/375], Loss: 381.7877\n",
      "Epoch [19/50], Step [179/375], Loss: 219.6701\n",
      "Epoch [19/50], Step [180/375], Loss: 132.7336\n",
      "Epoch [19/50], Step [181/375], Loss: 113.6551\n",
      "Epoch [19/50], Step [182/375], Loss: 140.0775\n",
      "Epoch [19/50], Step [183/375], Loss: 150.8412\n",
      "Epoch [19/50], Step [184/375], Loss: 13.7177\n",
      "Epoch [19/50], Step [185/375], Loss: 204.7649\n",
      "Epoch [19/50], Step [186/375], Loss: 174.8049\n",
      "Epoch [19/50], Step [187/375], Loss: 314.7136\n",
      "Epoch [19/50], Step [188/375], Loss: 621.7866\n",
      "Epoch [19/50], Step [189/375], Loss: 109.2473\n",
      "Epoch [19/50], Step [190/375], Loss: 178.0073\n",
      "Epoch [19/50], Step [191/375], Loss: 44.4729\n",
      "Epoch [19/50], Step [192/375], Loss: 474.8441\n",
      "Epoch [19/50], Step [193/375], Loss: 93.6526\n",
      "Epoch [19/50], Step [194/375], Loss: 54.1530\n",
      "Epoch [19/50], Step [195/375], Loss: 105.9989\n",
      "Epoch [19/50], Step [196/375], Loss: 109.2192\n",
      "Epoch [19/50], Step [197/375], Loss: 107.0960\n",
      "Epoch [19/50], Step [198/375], Loss: 248.2504\n",
      "Epoch [19/50], Step [199/375], Loss: 241.9250\n",
      "Epoch [19/50], Step [200/375], Loss: 335.5475\n",
      "Epoch [19/50], Step [201/375], Loss: 107.1377\n",
      "Epoch [19/50], Step [202/375], Loss: 160.0159\n",
      "Epoch [19/50], Step [203/375], Loss: 197.7989\n",
      "Epoch [19/50], Step [204/375], Loss: 100.5324\n",
      "Epoch [19/50], Step [205/375], Loss: 122.2118\n",
      "Epoch [19/50], Step [206/375], Loss: 301.6432\n",
      "Epoch [19/50], Step [207/375], Loss: 182.7547\n",
      "Epoch [19/50], Step [208/375], Loss: 640.1877\n",
      "Epoch [19/50], Step [209/375], Loss: 192.3335\n",
      "Epoch [19/50], Step [210/375], Loss: 204.7822\n",
      "Epoch [19/50], Step [211/375], Loss: 335.6119\n",
      "Epoch [19/50], Step [212/375], Loss: 468.1299\n",
      "Epoch [19/50], Step [213/375], Loss: 104.7320\n",
      "Epoch [19/50], Step [214/375], Loss: 132.4442\n",
      "Epoch [19/50], Step [215/375], Loss: 113.6618\n",
      "Epoch [19/50], Step [216/375], Loss: 43.3362\n",
      "Epoch [19/50], Step [217/375], Loss: 123.3171\n",
      "Epoch [19/50], Step [218/375], Loss: 348.2144\n",
      "Epoch [19/50], Step [219/375], Loss: 84.3882\n",
      "Epoch [19/50], Step [220/375], Loss: 87.1694\n",
      "Epoch [19/50], Step [221/375], Loss: 285.5206\n",
      "Epoch [19/50], Step [222/375], Loss: 311.1302\n",
      "Epoch [19/50], Step [223/375], Loss: 116.0992\n",
      "Epoch [19/50], Step [224/375], Loss: 238.0430\n",
      "Epoch [19/50], Step [225/375], Loss: 45.5873\n",
      "Epoch [19/50], Step [226/375], Loss: 151.7378\n",
      "Epoch [19/50], Step [227/375], Loss: 172.6252\n",
      "Epoch [19/50], Step [228/375], Loss: 457.6880\n",
      "Epoch [19/50], Step [229/375], Loss: 70.0610\n",
      "Epoch [19/50], Step [230/375], Loss: 365.3297\n",
      "Epoch [19/50], Step [231/375], Loss: 181.7588\n",
      "Epoch [19/50], Step [232/375], Loss: 250.9230\n",
      "Epoch [19/50], Step [233/375], Loss: 242.3326\n",
      "Epoch [19/50], Step [234/375], Loss: 39.3519\n",
      "Epoch [19/50], Step [235/375], Loss: 209.0979\n",
      "Epoch [19/50], Step [236/375], Loss: 110.9240\n",
      "Epoch [19/50], Step [237/375], Loss: 207.5642\n",
      "Epoch [19/50], Step [238/375], Loss: 40.2520\n",
      "Epoch [19/50], Step [239/375], Loss: 120.6190\n",
      "Epoch [19/50], Step [240/375], Loss: 46.0791\n",
      "Epoch [19/50], Step [241/375], Loss: 112.4779\n",
      "Epoch [19/50], Step [242/375], Loss: 441.1028\n",
      "Epoch [19/50], Step [243/375], Loss: 470.4583\n",
      "Epoch [19/50], Step [244/375], Loss: 140.1399\n",
      "Epoch [19/50], Step [245/375], Loss: 96.5105\n",
      "Epoch [19/50], Step [246/375], Loss: 236.8923\n",
      "Epoch [19/50], Step [247/375], Loss: 469.9680\n",
      "Epoch [19/50], Step [248/375], Loss: 942.2786\n",
      "Epoch [19/50], Step [249/375], Loss: 61.1874\n",
      "Epoch [19/50], Step [250/375], Loss: 194.7902\n",
      "Epoch [19/50], Step [251/375], Loss: 396.6832\n",
      "Epoch [19/50], Step [252/375], Loss: 237.1685\n",
      "Epoch [19/50], Step [253/375], Loss: 808.4044\n",
      "Epoch [19/50], Step [254/375], Loss: 468.2060\n",
      "Epoch [19/50], Step [255/375], Loss: 492.3047\n",
      "Epoch [19/50], Step [256/375], Loss: 100.0308\n",
      "Epoch [19/50], Step [257/375], Loss: 104.8544\n",
      "Epoch [19/50], Step [258/375], Loss: 438.5058\n",
      "Epoch [19/50], Step [259/375], Loss: 62.7018\n",
      "Epoch [19/50], Step [260/375], Loss: 145.0442\n",
      "Epoch [19/50], Step [261/375], Loss: 487.5058\n",
      "Epoch [19/50], Step [262/375], Loss: 442.0575\n",
      "Epoch [19/50], Step [263/375], Loss: 234.9428\n",
      "Epoch [19/50], Step [264/375], Loss: 134.6342\n",
      "Epoch [19/50], Step [265/375], Loss: 117.7044\n",
      "Epoch [19/50], Step [266/375], Loss: 340.5192\n",
      "Epoch [19/50], Step [267/375], Loss: 338.8800\n",
      "Epoch [19/50], Step [268/375], Loss: 400.2362\n",
      "Epoch [19/50], Step [269/375], Loss: 442.1923\n",
      "Epoch [19/50], Step [270/375], Loss: 338.5945\n",
      "Epoch [19/50], Step [271/375], Loss: 72.8906\n",
      "Epoch [19/50], Step [272/375], Loss: 219.3935\n",
      "Epoch [19/50], Step [273/375], Loss: 162.6978\n",
      "Epoch [19/50], Step [274/375], Loss: 474.2874\n",
      "Epoch [19/50], Step [275/375], Loss: 556.5701\n",
      "Epoch [19/50], Step [276/375], Loss: 608.3638\n",
      "Epoch [19/50], Step [277/375], Loss: 198.3245\n",
      "Epoch [19/50], Step [278/375], Loss: 98.5002\n",
      "Epoch [19/50], Step [279/375], Loss: 294.3595\n",
      "Epoch [19/50], Step [280/375], Loss: 156.0957\n",
      "Epoch [19/50], Step [281/375], Loss: 141.9008\n",
      "Epoch [19/50], Step [282/375], Loss: 198.7000\n",
      "Epoch [19/50], Step [283/375], Loss: 208.2112\n",
      "Epoch [19/50], Step [284/375], Loss: 371.1606\n",
      "Epoch [19/50], Step [285/375], Loss: 99.5720\n",
      "Epoch [19/50], Step [286/375], Loss: 120.0307\n",
      "Epoch [19/50], Step [287/375], Loss: 79.9335\n",
      "Epoch [19/50], Step [288/375], Loss: 238.1792\n",
      "Epoch [19/50], Step [289/375], Loss: 229.7822\n",
      "Epoch [19/50], Step [290/375], Loss: 82.1182\n",
      "Epoch [19/50], Step [291/375], Loss: 229.9782\n",
      "Epoch [19/50], Step [292/375], Loss: 176.1247\n",
      "Epoch [19/50], Step [293/375], Loss: 31.5352\n",
      "Epoch [19/50], Step [294/375], Loss: 445.0336\n",
      "Epoch [19/50], Step [295/375], Loss: 124.6024\n",
      "Epoch [19/50], Step [296/375], Loss: 41.2129\n",
      "Epoch [19/50], Step [297/375], Loss: 96.5259\n",
      "Epoch [19/50], Step [298/375], Loss: 260.9874\n",
      "Epoch [19/50], Step [299/375], Loss: 246.0099\n",
      "Epoch [19/50], Step [300/375], Loss: 97.8133\n",
      "Epoch [19/50], Step [301/375], Loss: 80.6361\n",
      "Epoch [19/50], Step [302/375], Loss: 158.9250\n",
      "Epoch [19/50], Step [303/375], Loss: 231.3987\n",
      "Epoch [19/50], Step [304/375], Loss: 353.7538\n",
      "Epoch [19/50], Step [305/375], Loss: 92.3921\n",
      "Epoch [19/50], Step [306/375], Loss: 152.5845\n",
      "Epoch [19/50], Step [307/375], Loss: 37.0910\n",
      "Epoch [19/50], Step [308/375], Loss: 123.9328\n",
      "Epoch [19/50], Step [309/375], Loss: 98.8214\n",
      "Epoch [19/50], Step [310/375], Loss: 75.4527\n",
      "Epoch [19/50], Step [311/375], Loss: 94.6536\n",
      "Epoch [19/50], Step [312/375], Loss: 239.9052\n",
      "Epoch [19/50], Step [313/375], Loss: 123.8943\n",
      "Epoch [19/50], Step [314/375], Loss: 511.4600\n",
      "Epoch [19/50], Step [315/375], Loss: 275.8506\n",
      "Epoch [19/50], Step [316/375], Loss: 57.7661\n",
      "Epoch [19/50], Step [317/375], Loss: 187.4247\n",
      "Epoch [19/50], Step [318/375], Loss: 68.0300\n",
      "Epoch [19/50], Step [319/375], Loss: 100.3050\n",
      "Epoch [19/50], Step [320/375], Loss: 155.4410\n",
      "Epoch [19/50], Step [321/375], Loss: 182.6232\n",
      "Epoch [19/50], Step [322/375], Loss: 99.1493\n",
      "Epoch [19/50], Step [323/375], Loss: 59.0273\n",
      "Epoch [19/50], Step [324/375], Loss: 131.7376\n",
      "Epoch [19/50], Step [325/375], Loss: 237.0383\n",
      "Epoch [19/50], Step [326/375], Loss: 98.9279\n",
      "Epoch [19/50], Step [327/375], Loss: 222.4926\n",
      "Epoch [19/50], Step [328/375], Loss: 114.6936\n",
      "Epoch [19/50], Step [329/375], Loss: 178.5760\n",
      "Epoch [19/50], Step [330/375], Loss: 133.3313\n",
      "Epoch [19/50], Step [331/375], Loss: 31.8719\n",
      "Epoch [19/50], Step [332/375], Loss: 239.2040\n",
      "Epoch [19/50], Step [333/375], Loss: 170.0063\n",
      "Epoch [19/50], Step [334/375], Loss: 159.4660\n",
      "Epoch [19/50], Step [335/375], Loss: 267.1233\n",
      "Epoch [19/50], Step [336/375], Loss: 155.3608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Step [337/375], Loss: 58.7956\n",
      "Epoch [19/50], Step [338/375], Loss: 17.6785\n",
      "Epoch [19/50], Step [339/375], Loss: 142.1848\n",
      "Epoch [19/50], Step [340/375], Loss: 216.5814\n",
      "Epoch [19/50], Step [341/375], Loss: 728.6064\n",
      "Epoch [19/50], Step [342/375], Loss: 162.8519\n",
      "Epoch [19/50], Step [343/375], Loss: 141.1270\n",
      "Epoch [19/50], Step [344/375], Loss: 316.8925\n",
      "Epoch [19/50], Step [345/375], Loss: 269.0276\n",
      "Epoch [19/50], Step [346/375], Loss: 149.8856\n",
      "Epoch [19/50], Step [347/375], Loss: 163.5600\n",
      "Epoch [19/50], Step [348/375], Loss: 145.4756\n",
      "Epoch [19/50], Step [349/375], Loss: 224.0555\n",
      "Epoch [19/50], Step [350/375], Loss: 118.0933\n",
      "Epoch [19/50], Step [351/375], Loss: 27.0484\n",
      "Epoch [19/50], Step [352/375], Loss: 658.9689\n",
      "Epoch [19/50], Step [353/375], Loss: 97.9224\n",
      "Epoch [19/50], Step [354/375], Loss: 368.6955\n",
      "Epoch [19/50], Step [355/375], Loss: 141.0322\n",
      "Epoch [19/50], Step [356/375], Loss: 107.9864\n",
      "Epoch [19/50], Step [357/375], Loss: 123.2555\n",
      "Epoch [19/50], Step [358/375], Loss: 67.7824\n",
      "Epoch [19/50], Step [359/375], Loss: 123.9715\n",
      "Epoch [19/50], Step [360/375], Loss: 80.6974\n",
      "Epoch [19/50], Step [361/375], Loss: 203.5760\n",
      "Epoch [19/50], Step [362/375], Loss: 113.0284\n",
      "Epoch [19/50], Step [363/375], Loss: 86.0907\n",
      "Epoch [19/50], Step [364/375], Loss: 173.4556\n",
      "Epoch [19/50], Step [365/375], Loss: 129.8551\n",
      "Epoch [19/50], Step [366/375], Loss: 161.0160\n",
      "Epoch [19/50], Step [367/375], Loss: 49.1768\n",
      "Epoch [19/50], Step [368/375], Loss: 217.5185\n",
      "Epoch [19/50], Step [369/375], Loss: 301.6380\n",
      "Epoch [19/50], Step [370/375], Loss: 166.0524\n",
      "Epoch [19/50], Step [371/375], Loss: 68.1259\n",
      "Epoch [19/50], Step [372/375], Loss: 63.4508\n",
      "Epoch [19/50], Step [373/375], Loss: 63.7646\n",
      "Epoch [19/50], Step [374/375], Loss: 67.2139\n",
      "Epoch [19/50], Step [375/375], Loss: 162.5259\n",
      "Epoch [20/50], Step [1/375], Loss: 366.1714\n",
      "Epoch [20/50], Step [2/375], Loss: 313.2782\n",
      "Epoch [20/50], Step [3/375], Loss: 114.1778\n",
      "Epoch [20/50], Step [4/375], Loss: 311.3387\n",
      "Epoch [20/50], Step [5/375], Loss: 525.5110\n",
      "Epoch [20/50], Step [6/375], Loss: 106.2622\n",
      "Epoch [20/50], Step [7/375], Loss: 226.9809\n",
      "Epoch [20/50], Step [8/375], Loss: 134.3109\n",
      "Epoch [20/50], Step [9/375], Loss: 44.0988\n",
      "Epoch [20/50], Step [10/375], Loss: 346.1138\n",
      "Epoch [20/50], Step [11/375], Loss: 116.3644\n",
      "Epoch [20/50], Step [12/375], Loss: 163.3251\n",
      "Epoch [20/50], Step [13/375], Loss: 399.1422\n",
      "Epoch [20/50], Step [14/375], Loss: 45.4142\n",
      "Epoch [20/50], Step [15/375], Loss: 500.2233\n",
      "Epoch [20/50], Step [16/375], Loss: 232.8246\n",
      "Epoch [20/50], Step [17/375], Loss: 371.6261\n",
      "Epoch [20/50], Step [18/375], Loss: 140.8538\n",
      "Epoch [20/50], Step [19/375], Loss: 361.4378\n",
      "Epoch [20/50], Step [20/375], Loss: 37.3427\n",
      "Epoch [20/50], Step [21/375], Loss: 228.1085\n",
      "Epoch [20/50], Step [22/375], Loss: 326.3155\n",
      "Epoch [20/50], Step [23/375], Loss: 111.6519\n",
      "Epoch [20/50], Step [24/375], Loss: 140.1601\n",
      "Epoch [20/50], Step [25/375], Loss: 225.9862\n",
      "Epoch [20/50], Step [26/375], Loss: 552.4747\n",
      "Epoch [20/50], Step [27/375], Loss: 250.9059\n",
      "Epoch [20/50], Step [28/375], Loss: 199.2357\n",
      "Epoch [20/50], Step [29/375], Loss: 84.7560\n",
      "Epoch [20/50], Step [30/375], Loss: 314.7988\n",
      "Epoch [20/50], Step [31/375], Loss: 104.2132\n",
      "Epoch [20/50], Step [32/375], Loss: 222.5182\n",
      "Epoch [20/50], Step [33/375], Loss: 20.9318\n",
      "Epoch [20/50], Step [34/375], Loss: 273.4562\n",
      "Epoch [20/50], Step [35/375], Loss: 435.7372\n",
      "Epoch [20/50], Step [36/375], Loss: 51.3308\n",
      "Epoch [20/50], Step [37/375], Loss: 243.2337\n",
      "Epoch [20/50], Step [38/375], Loss: 34.1245\n",
      "Epoch [20/50], Step [39/375], Loss: 33.5766\n",
      "Epoch [20/50], Step [40/375], Loss: 236.6377\n",
      "Epoch [20/50], Step [41/375], Loss: 26.7191\n",
      "Epoch [20/50], Step [42/375], Loss: 394.9512\n",
      "Epoch [20/50], Step [43/375], Loss: 44.0493\n",
      "Epoch [20/50], Step [44/375], Loss: 143.5751\n",
      "Epoch [20/50], Step [45/375], Loss: 148.1332\n",
      "Epoch [20/50], Step [46/375], Loss: 495.8517\n",
      "Epoch [20/50], Step [47/375], Loss: 178.7465\n",
      "Epoch [20/50], Step [48/375], Loss: 348.5968\n",
      "Epoch [20/50], Step [49/375], Loss: 135.2479\n",
      "Epoch [20/50], Step [50/375], Loss: 57.4812\n",
      "Epoch [20/50], Step [51/375], Loss: 283.7629\n",
      "Epoch [20/50], Step [52/375], Loss: 635.3422\n",
      "Epoch [20/50], Step [53/375], Loss: 218.0640\n",
      "Epoch [20/50], Step [54/375], Loss: 167.9650\n",
      "Epoch [20/50], Step [55/375], Loss: 66.0187\n",
      "Epoch [20/50], Step [56/375], Loss: 36.4395\n",
      "Epoch [20/50], Step [57/375], Loss: 286.1349\n",
      "Epoch [20/50], Step [58/375], Loss: 152.0435\n",
      "Epoch [20/50], Step [59/375], Loss: 196.0208\n",
      "Epoch [20/50], Step [60/375], Loss: 391.7526\n",
      "Epoch [20/50], Step [61/375], Loss: 217.9839\n",
      "Epoch [20/50], Step [62/375], Loss: 107.6576\n",
      "Epoch [20/50], Step [63/375], Loss: 146.9063\n",
      "Epoch [20/50], Step [64/375], Loss: 272.2079\n",
      "Epoch [20/50], Step [65/375], Loss: 33.6298\n",
      "Epoch [20/50], Step [66/375], Loss: 74.0915\n",
      "Epoch [20/50], Step [67/375], Loss: 910.7039\n",
      "Epoch [20/50], Step [68/375], Loss: 592.4840\n",
      "Epoch [20/50], Step [69/375], Loss: 58.9728\n",
      "Epoch [20/50], Step [70/375], Loss: 139.7734\n",
      "Epoch [20/50], Step [71/375], Loss: 129.9060\n",
      "Epoch [20/50], Step [72/375], Loss: 176.8056\n",
      "Epoch [20/50], Step [73/375], Loss: 90.0725\n",
      "Epoch [20/50], Step [74/375], Loss: 50.7190\n",
      "Epoch [20/50], Step [75/375], Loss: 469.3570\n",
      "Epoch [20/50], Step [76/375], Loss: 236.5167\n",
      "Epoch [20/50], Step [77/375], Loss: 132.1558\n",
      "Epoch [20/50], Step [78/375], Loss: 159.6058\n",
      "Epoch [20/50], Step [79/375], Loss: 356.3091\n",
      "Epoch [20/50], Step [80/375], Loss: 160.5571\n",
      "Epoch [20/50], Step [81/375], Loss: 253.9664\n",
      "Epoch [20/50], Step [82/375], Loss: 299.2496\n",
      "Epoch [20/50], Step [83/375], Loss: 395.6428\n",
      "Epoch [20/50], Step [84/375], Loss: 146.8267\n",
      "Epoch [20/50], Step [85/375], Loss: 48.8913\n",
      "Epoch [20/50], Step [86/375], Loss: 193.8448\n",
      "Epoch [20/50], Step [87/375], Loss: 336.9444\n",
      "Epoch [20/50], Step [88/375], Loss: 285.3687\n",
      "Epoch [20/50], Step [89/375], Loss: 349.6256\n",
      "Epoch [20/50], Step [90/375], Loss: 314.7907\n",
      "Epoch [20/50], Step [91/375], Loss: 84.1667\n",
      "Epoch [20/50], Step [92/375], Loss: 70.5145\n",
      "Epoch [20/50], Step [93/375], Loss: 38.4715\n",
      "Epoch [20/50], Step [94/375], Loss: 285.8827\n",
      "Epoch [20/50], Step [95/375], Loss: 489.4595\n",
      "Epoch [20/50], Step [96/375], Loss: 365.8968\n",
      "Epoch [20/50], Step [97/375], Loss: 172.4284\n",
      "Epoch [20/50], Step [98/375], Loss: 27.6968\n",
      "Epoch [20/50], Step [99/375], Loss: 293.7275\n",
      "Epoch [20/50], Step [100/375], Loss: 65.0883\n",
      "Epoch [20/50], Step [101/375], Loss: 126.8940\n",
      "Epoch [20/50], Step [102/375], Loss: 211.2439\n",
      "Epoch [20/50], Step [103/375], Loss: 34.7251\n",
      "Epoch [20/50], Step [104/375], Loss: 59.4738\n",
      "Epoch [20/50], Step [105/375], Loss: 142.4241\n",
      "Epoch [20/50], Step [106/375], Loss: 27.4767\n",
      "Epoch [20/50], Step [107/375], Loss: 112.2413\n",
      "Epoch [20/50], Step [108/375], Loss: 57.9034\n",
      "Epoch [20/50], Step [109/375], Loss: 154.5927\n",
      "Epoch [20/50], Step [110/375], Loss: 279.3258\n",
      "Epoch [20/50], Step [111/375], Loss: 227.7003\n",
      "Epoch [20/50], Step [112/375], Loss: 147.0566\n",
      "Epoch [20/50], Step [113/375], Loss: 416.9466\n",
      "Epoch [20/50], Step [114/375], Loss: 22.2800\n",
      "Epoch [20/50], Step [115/375], Loss: 100.4982\n",
      "Epoch [20/50], Step [116/375], Loss: 183.3838\n",
      "Epoch [20/50], Step [117/375], Loss: 301.0047\n",
      "Epoch [20/50], Step [118/375], Loss: 71.1799\n",
      "Epoch [20/50], Step [119/375], Loss: 110.5693\n",
      "Epoch [20/50], Step [120/375], Loss: 228.4919\n",
      "Epoch [20/50], Step [121/375], Loss: 1021.6863\n",
      "Epoch [20/50], Step [122/375], Loss: 356.7180\n",
      "Epoch [20/50], Step [123/375], Loss: 448.4102\n",
      "Epoch [20/50], Step [124/375], Loss: 350.0773\n",
      "Epoch [20/50], Step [125/375], Loss: 350.5460\n",
      "Epoch [20/50], Step [126/375], Loss: 254.8761\n",
      "Epoch [20/50], Step [127/375], Loss: 232.0794\n",
      "Epoch [20/50], Step [128/375], Loss: 388.7677\n",
      "Epoch [20/50], Step [129/375], Loss: 230.8663\n",
      "Epoch [20/50], Step [130/375], Loss: 502.9643\n",
      "Epoch [20/50], Step [131/375], Loss: 367.6349\n",
      "Epoch [20/50], Step [132/375], Loss: 216.2302\n",
      "Epoch [20/50], Step [133/375], Loss: 316.2277\n",
      "Epoch [20/50], Step [134/375], Loss: 254.5132\n",
      "Epoch [20/50], Step [135/375], Loss: 507.7887\n",
      "Epoch [20/50], Step [136/375], Loss: 350.7448\n",
      "Epoch [20/50], Step [137/375], Loss: 274.5796\n",
      "Epoch [20/50], Step [138/375], Loss: 267.0065\n",
      "Epoch [20/50], Step [139/375], Loss: 543.4685\n",
      "Epoch [20/50], Step [140/375], Loss: 98.9572\n",
      "Epoch [20/50], Step [141/375], Loss: 51.4595\n",
      "Epoch [20/50], Step [142/375], Loss: 249.2663\n",
      "Epoch [20/50], Step [143/375], Loss: 107.3923\n",
      "Epoch [20/50], Step [144/375], Loss: 150.0417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Step [145/375], Loss: 192.1428\n",
      "Epoch [20/50], Step [146/375], Loss: 705.6003\n",
      "Epoch [20/50], Step [147/375], Loss: 77.4071\n",
      "Epoch [20/50], Step [148/375], Loss: 41.3133\n",
      "Epoch [20/50], Step [149/375], Loss: 163.5903\n",
      "Epoch [20/50], Step [150/375], Loss: 199.6785\n",
      "Epoch [20/50], Step [151/375], Loss: 179.1439\n",
      "Epoch [20/50], Step [152/375], Loss: 81.4574\n",
      "Epoch [20/50], Step [153/375], Loss: 108.0773\n",
      "Epoch [20/50], Step [154/375], Loss: 146.9574\n",
      "Epoch [20/50], Step [155/375], Loss: 90.8368\n",
      "Epoch [20/50], Step [156/375], Loss: 60.0402\n",
      "Epoch [20/50], Step [157/375], Loss: 84.8998\n",
      "Epoch [20/50], Step [158/375], Loss: 85.2680\n",
      "Epoch [20/50], Step [159/375], Loss: 29.4550\n",
      "Epoch [20/50], Step [160/375], Loss: 122.9722\n",
      "Epoch [20/50], Step [161/375], Loss: 67.3295\n",
      "Epoch [20/50], Step [162/375], Loss: 140.4646\n",
      "Epoch [20/50], Step [163/375], Loss: 219.2854\n",
      "Epoch [20/50], Step [164/375], Loss: 231.7207\n",
      "Epoch [20/50], Step [165/375], Loss: 121.4518\n",
      "Epoch [20/50], Step [166/375], Loss: 44.3115\n",
      "Epoch [20/50], Step [167/375], Loss: 154.2397\n",
      "Epoch [20/50], Step [168/375], Loss: 140.0938\n",
      "Epoch [20/50], Step [169/375], Loss: 447.0824\n",
      "Epoch [20/50], Step [170/375], Loss: 103.0069\n",
      "Epoch [20/50], Step [171/375], Loss: 174.7301\n",
      "Epoch [20/50], Step [172/375], Loss: 147.4252\n",
      "Epoch [20/50], Step [173/375], Loss: 86.9348\n",
      "Epoch [20/50], Step [174/375], Loss: 396.5560\n",
      "Epoch [20/50], Step [175/375], Loss: 144.3557\n",
      "Epoch [20/50], Step [176/375], Loss: 78.6197\n",
      "Epoch [20/50], Step [177/375], Loss: 206.6774\n",
      "Epoch [20/50], Step [178/375], Loss: 240.3822\n",
      "Epoch [20/50], Step [179/375], Loss: 63.8182\n",
      "Epoch [20/50], Step [180/375], Loss: 196.5500\n",
      "Epoch [20/50], Step [181/375], Loss: 222.8181\n",
      "Epoch [20/50], Step [182/375], Loss: 173.9853\n",
      "Epoch [20/50], Step [183/375], Loss: 39.9077\n",
      "Epoch [20/50], Step [184/375], Loss: 212.2948\n",
      "Epoch [20/50], Step [185/375], Loss: 110.3326\n",
      "Epoch [20/50], Step [186/375], Loss: 128.8330\n",
      "Epoch [20/50], Step [187/375], Loss: 309.3699\n",
      "Epoch [20/50], Step [188/375], Loss: 248.2400\n",
      "Epoch [20/50], Step [189/375], Loss: 378.2351\n",
      "Epoch [20/50], Step [190/375], Loss: 74.6688\n",
      "Epoch [20/50], Step [191/375], Loss: 354.9363\n",
      "Epoch [20/50], Step [192/375], Loss: 110.9534\n",
      "Epoch [20/50], Step [193/375], Loss: 156.5889\n",
      "Epoch [20/50], Step [194/375], Loss: 107.4048\n",
      "Epoch [20/50], Step [195/375], Loss: 35.5598\n",
      "Epoch [20/50], Step [196/375], Loss: 361.6675\n",
      "Epoch [20/50], Step [197/375], Loss: 241.3861\n",
      "Epoch [20/50], Step [198/375], Loss: 196.4766\n",
      "Epoch [20/50], Step [199/375], Loss: 163.4866\n",
      "Epoch [20/50], Step [200/375], Loss: 376.8071\n",
      "Epoch [20/50], Step [201/375], Loss: 142.0700\n",
      "Epoch [20/50], Step [202/375], Loss: 119.0194\n",
      "Epoch [20/50], Step [203/375], Loss: 107.1419\n",
      "Epoch [20/50], Step [204/375], Loss: 145.4356\n",
      "Epoch [20/50], Step [205/375], Loss: 191.3755\n",
      "Epoch [20/50], Step [206/375], Loss: 288.7346\n",
      "Epoch [20/50], Step [207/375], Loss: 79.0027\n",
      "Epoch [20/50], Step [208/375], Loss: 135.3049\n",
      "Epoch [20/50], Step [209/375], Loss: 202.4923\n",
      "Epoch [20/50], Step [210/375], Loss: 80.2718\n",
      "Epoch [20/50], Step [211/375], Loss: 123.7330\n",
      "Epoch [20/50], Step [212/375], Loss: 389.3119\n",
      "Epoch [20/50], Step [213/375], Loss: 143.2745\n",
      "Epoch [20/50], Step [214/375], Loss: 94.6333\n",
      "Epoch [20/50], Step [215/375], Loss: 205.4082\n",
      "Epoch [20/50], Step [216/375], Loss: 141.7449\n",
      "Epoch [20/50], Step [217/375], Loss: 114.7540\n",
      "Epoch [20/50], Step [218/375], Loss: 235.8436\n",
      "Epoch [20/50], Step [219/375], Loss: 353.8129\n",
      "Epoch [20/50], Step [220/375], Loss: 199.5988\n",
      "Epoch [20/50], Step [221/375], Loss: 156.0600\n",
      "Epoch [20/50], Step [222/375], Loss: 81.1991\n",
      "Epoch [20/50], Step [223/375], Loss: 92.3727\n",
      "Epoch [20/50], Step [224/375], Loss: 74.2600\n",
      "Epoch [20/50], Step [225/375], Loss: 199.8553\n",
      "Epoch [20/50], Step [226/375], Loss: 60.1110\n",
      "Epoch [20/50], Step [227/375], Loss: 599.5231\n",
      "Epoch [20/50], Step [228/375], Loss: 458.6694\n",
      "Epoch [20/50], Step [229/375], Loss: 199.1223\n",
      "Epoch [20/50], Step [230/375], Loss: 225.4126\n",
      "Epoch [20/50], Step [231/375], Loss: 298.7567\n",
      "Epoch [20/50], Step [232/375], Loss: 605.0539\n",
      "Epoch [20/50], Step [233/375], Loss: 100.8901\n",
      "Epoch [20/50], Step [234/375], Loss: 341.8797\n",
      "Epoch [20/50], Step [235/375], Loss: 181.2969\n",
      "Epoch [20/50], Step [236/375], Loss: 174.7410\n",
      "Epoch [20/50], Step [237/375], Loss: 58.1898\n",
      "Epoch [20/50], Step [238/375], Loss: 161.8416\n",
      "Epoch [20/50], Step [239/375], Loss: 195.0298\n",
      "Epoch [20/50], Step [240/375], Loss: 221.3023\n",
      "Epoch [20/50], Step [241/375], Loss: 67.1961\n",
      "Epoch [20/50], Step [242/375], Loss: 158.8629\n",
      "Epoch [20/50], Step [243/375], Loss: 72.1568\n",
      "Epoch [20/50], Step [244/375], Loss: 100.3922\n",
      "Epoch [20/50], Step [245/375], Loss: 21.4831\n",
      "Epoch [20/50], Step [246/375], Loss: 238.4431\n",
      "Epoch [20/50], Step [247/375], Loss: 76.2748\n",
      "Epoch [20/50], Step [248/375], Loss: 251.2642\n",
      "Epoch [20/50], Step [249/375], Loss: 522.5567\n",
      "Epoch [20/50], Step [250/375], Loss: 309.6234\n",
      "Epoch [20/50], Step [251/375], Loss: 264.7375\n",
      "Epoch [20/50], Step [252/375], Loss: 45.7785\n",
      "Epoch [20/50], Step [253/375], Loss: 143.5965\n",
      "Epoch [20/50], Step [254/375], Loss: 134.3728\n",
      "Epoch [20/50], Step [255/375], Loss: 111.9552\n",
      "Epoch [20/50], Step [256/375], Loss: 98.1317\n",
      "Epoch [20/50], Step [257/375], Loss: 119.4824\n",
      "Epoch [20/50], Step [258/375], Loss: 230.2747\n",
      "Epoch [20/50], Step [259/375], Loss: 93.0035\n",
      "Epoch [20/50], Step [260/375], Loss: 34.5233\n",
      "Epoch [20/50], Step [261/375], Loss: 470.5382\n",
      "Epoch [20/50], Step [262/375], Loss: 226.9493\n",
      "Epoch [20/50], Step [263/375], Loss: 166.1507\n",
      "Epoch [20/50], Step [264/375], Loss: 233.3584\n",
      "Epoch [20/50], Step [265/375], Loss: 53.8803\n",
      "Epoch [20/50], Step [266/375], Loss: 272.5320\n",
      "Epoch [20/50], Step [267/375], Loss: 369.1454\n",
      "Epoch [20/50], Step [268/375], Loss: 324.2188\n",
      "Epoch [20/50], Step [269/375], Loss: 387.8920\n",
      "Epoch [20/50], Step [270/375], Loss: 103.6918\n",
      "Epoch [20/50], Step [271/375], Loss: 122.3213\n",
      "Epoch [20/50], Step [272/375], Loss: 211.1464\n",
      "Epoch [20/50], Step [273/375], Loss: 146.7197\n",
      "Epoch [20/50], Step [274/375], Loss: 82.7446\n",
      "Epoch [20/50], Step [275/375], Loss: 158.6028\n",
      "Epoch [20/50], Step [276/375], Loss: 63.7405\n",
      "Epoch [20/50], Step [277/375], Loss: 251.3842\n",
      "Epoch [20/50], Step [278/375], Loss: 351.0562\n",
      "Epoch [20/50], Step [279/375], Loss: 183.8160\n",
      "Epoch [20/50], Step [280/375], Loss: 161.6183\n",
      "Epoch [20/50], Step [281/375], Loss: 95.8391\n",
      "Epoch [20/50], Step [282/375], Loss: 219.6066\n",
      "Epoch [20/50], Step [283/375], Loss: 285.8639\n",
      "Epoch [20/50], Step [284/375], Loss: 49.8051\n",
      "Epoch [20/50], Step [285/375], Loss: 232.5335\n",
      "Epoch [20/50], Step [286/375], Loss: 78.8675\n",
      "Epoch [20/50], Step [287/375], Loss: 240.6201\n",
      "Epoch [20/50], Step [288/375], Loss: 69.9397\n",
      "Epoch [20/50], Step [289/375], Loss: 263.8516\n",
      "Epoch [20/50], Step [290/375], Loss: 417.3320\n",
      "Epoch [20/50], Step [291/375], Loss: 185.5744\n",
      "Epoch [20/50], Step [292/375], Loss: 43.3046\n",
      "Epoch [20/50], Step [293/375], Loss: 263.7688\n",
      "Epoch [20/50], Step [294/375], Loss: 76.9021\n",
      "Epoch [20/50], Step [295/375], Loss: 100.4907\n",
      "Epoch [20/50], Step [296/375], Loss: 94.2778\n",
      "Epoch [20/50], Step [297/375], Loss: 119.6456\n",
      "Epoch [20/50], Step [298/375], Loss: 79.2483\n",
      "Epoch [20/50], Step [299/375], Loss: 192.6171\n",
      "Epoch [20/50], Step [300/375], Loss: 171.2345\n",
      "Epoch [20/50], Step [301/375], Loss: 262.0186\n",
      "Epoch [20/50], Step [302/375], Loss: 419.2715\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/rect1052.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9899b54ac15a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtotal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlenv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlenv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-037ce68df291>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# image = self.images[idx]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/rect'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#PIL and torch expect difft orders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_coords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlenv/lib/python3.6/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlenv/lib/python3.6/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                                (plugin, kind))\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlenv/lib/python3.6/site-packages/skimage/io/_plugins/pil_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, dtype, img_num, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/rect1052.png'"
     ]
    }
   ],
   "source": [
    "losses_list = []\n",
    "print('Training model now...')\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i_batch, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i_batch+1) % 1 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1,\n",
    "                                                                      num_epochs,\n",
    "                                                                      i_batch+1,\n",
    "                                                                      total_step,\n",
    "                                                                      loss.item()))\n",
    "            losses_list.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display # to display images\n",
    "def imshow_coord(img, a_label):\n",
    "    img = torchvision.transforms.ToPILImage()(img)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw = draw_crosspointer(a_label, draw, 'green', 'white', length=8)\n",
    "    display(img)\n",
    "    \n",
    "def draw_crosspointer(xy, draw, fillcolor_X='green', fillcolor='white', length=2):\n",
    "    a,b = tuple(xy)\n",
    "    draw.line((a-length, b+length, a+length, b-length), fill=fillcolor_X)\n",
    "    draw.line((a-length, b-length, a+length, b+length), fill=fillcolor_X)\n",
    "    draw.point((a,b))\n",
    "    return draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ready!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/ogg;base64,T2dnUwACAAAAAAAAAABZvAkxAAAAAEfCFT0BHgF2b3JiaXMAAAAAAUSsAAAAAAAAgDgBAAAAAAC4AU9nZ1MAAAAAAAAAAAAAWbwJMQEAAAAAJwutDln///////////////+BA3ZvcmJpcy0AAABYaXBoLk9yZyBsaWJWb3JiaXMgSSAyMDEwMTEwMSAoU2NoYXVmZW51Z2dldCkBAAAAGAAAAENvbW1lbnQ9UHJvY2Vzc2VkIGJ5IFNvWAEFdm9yYmlzIkJDVgEAQAAAJHMYKkalcxaEEBpCUBnjHELOa+wZQkwRghwyTFvLJXOQIaSgQohbKIHQkFUAAEAAAIdBeBSEikEIIYQlPViSgyc9CCGEiDl4FIRpQQghhBBCCCGEEEIIIYRFOWiSgydBCB2E4zA4DIPlOPgchEU5WBCDJ0HoIIQPQriag6w5CCGEJDVIUIMGOegchMIsKIqCxDC4FoQENSiMguQwyNSDC0KImoNJNfgahGdBeBaEaUEIIYQkQUiQgwZByBiERkFYkoMGObgUhMtBqBqEKjkIH4QgNGQVAJAAAKCiKIqiKAoQGrIKAMgAABBAURTHcRzJkRzJsRwLCA1ZBQAAAQAIAACgSIqkSI7kSJIkWZIlWZIlWZLmiaosy7Isy7IsyzIQGrIKAEgAAFBRDEVxFAcIDVkFAGQAAAigOIqlWIqlaIrniI4IhIasAgCAAAAEAAAQNENTPEeURM9UVde2bdu2bdu2bdu2bdu2bVuWZRkIDVkFAEAAABDSaWapBogwAxkGQkNWAQAIAACAEYowxIDQkFUAAEAAAIAYSg6iCa0535zjoFkOmkqxOR2cSLV5kpuKuTnnnHPOyeacMc4555yinFkMmgmtOeecxKBZCpoJrTnnnCexedCaKq0555xxzulgnBHGOeecJq15kJqNtTnnnAWtaY6aS7E555xIuXlSm0u1Oeecc84555xzzjnnnOrF6RycE84555yovbmWm9DFOeecT8bp3pwQzjnnnHPOOeecc84555wgNGQVAAAEAEAQho1h3CkI0udoIEYRYhoy6UH36DAJGoOcQurR6GiklDoIJZVxUkonCA1ZBQAAAgBACCGFFFJIIYUUUkghhRRiiCGGGHLKKaeggkoqqaiijDLLLLPMMssss8w67KyzDjsMMcQQQyutxFJTbTXWWGvuOeeag7RWWmuttVJKKaWUUgpCQ1YBACAAAARCBhlkkFFIIYUUYogpp5xyCiqogNCQVQAAIACAAAAAAE/yHNERHdERHdERHdERHdHxHM8RJVESJVESLdMyNdNTRVV1ZdeWdVm3fVvYhV33fd33fd34dWFYlmVZlmVZlmVZlmVZlmVZliA0ZBUAAAIAACCEEEJIIYUUUkgpxhhzzDnoJJQQCA1ZBQAAAgAIAAAAcBRHcRzJkRxJsiRL0iTN0ixP8zRPEz1RFEXTNFXRFV1RN21RNmXTNV1TNl1VVm1Xlm1btnXbl2Xb933f933f933f933f931dB0JDVgEAEgAAOpIjKZIiKZLjOI4kSUBoyCoAQAYAQAAAiuIojuM4kiRJkiVpkmd5lqiZmumZniqqQGjIKgAAEABAAAAAAAAAiqZ4iql4iqh4juiIkmiZlqipmivKpuy6ruu6ruu6ruu6ruu6ruu6ruu6ruu6ruu6ruu6ruu6ruu6rguEhqwCACQAAHQkR3IkR1IkRVIkR3KA0JBVAIAMAIAAABzDMSRFcizL0jRP8zRPEz3REz3TU0VXdIHQkFUAACAAgAAAAAAAAAzJsBTL0RxNEiXVUi1VUy3VUkXVU1VVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVU3TNE0TCA1ZCQAAAQDQWnPMrZeOQeisl8gopKDXTjnmpNfMKIKc5xAxY5jHUjFDDMaWQYSUBUJDVgQAUQAAgDHIMcQccs5J6iRFzjkqHaXGOUepo9RRSrGmWjtKpbZUa+Oco9RRyiilWkurHaVUa6qxAACAAAcAgAALodCQFQFAFAAAgQxSCimFlGLOKeeQUso55hxiijmnnGPOOSidlMo5J52TEimlnGPOKeeclM5J5pyT0kkoAAAgwAEAIMBCKDRkRQAQJwDgcBxNkzRNFCVNE0VPFF3XE0XVlTTNNDVRVFVNFE3VVFVZFk1VliVNM01NFFVTE0VVFVVTlk1VtWXPNG3ZVFXdFlXVtmVb9n1XlnXdM03ZFlXVtk1VtXVXlnVdtm3dlzTNNDVRVFVNFFXXVFXbNlXVtjVRdF1RVWVZVFVZdl1Z11VX1n1NFFXVU03ZFVVVllXZ1WVVlnVfdFXdVl3Z11VZ1n3b1oVf1n3CqKq6bsqurquyrPuyLvu67euUSdNMUxNFVdVEUVVNV7VtU3VtWxNF1xVV1ZZFU3VlVZZ9X3Vl2ddE0XVFVZVlUVVlWZVlXXdlV7dFVdVtVXZ933RdXZd1XVhmW/eF03V1XZVl31dlWfdlXcfWdd/3TNO2TdfVddNVdd/WdeWZbdv4RVXVdVWWhV+VZd/XheF5bt0XnlFVdd2UXV9XZVkXbl832r5uPK9tY9s+sq8jDEe+sCxd2za6vk2Ydd3oG0PhN4Y007Rt01V13XRdX5d13WjrulBUVV1XZdn3VVf2fVv3heH2fd8YVdf3VVkWhtWWnWH3faXuC5VVtoXf1nXnmG1dWH7j6Py+MnR1W2jrurHMvq48u3F0hj4CAAAGHAAAAkwoA4WGrAgA4gQAGIScQ0xBiBSDEEJIKYSQUsQYhMw5KRlzUkIpqYVSUosYg5A5JiVzTkoooaVQSkuhhNZCKbGFUlpsrdWaWos1hNJaKKW1UEqLqaUaW2s1RoxByJyTkjknpZTSWiiltcw5Kp2DlDoIKaWUWiwpxVg5JyWDjkoHIaWSSkwlpRhDKrGVlGIsKcXYWmy5xZhzKKXFkkpsJaVYW0w5thhzjhiDkDknJXNOSiiltVJSa5VzUjoIKWUOSiopxVhKSjFzTkoHIaUOQkolpRhTSrGFUmIrKdVYSmqxxZhzSzHWUFKLJaUYS0oxthhzbrHl1kFoLaQSYyglxhZjrq21GkMpsZWUYiwp1RZjrb3FmHMoJcaSSo0lpVhbjbnGGHNOseWaWqy5xdhrbbn1mnPQqbVaU0y5thhzjrkFWXPuvYPQWiilxVBKjK21WluMOYdSYisp1VhKirXFmHNrsfZQSowlpVhLSjW2GGuONfaaWqu1xZhrarHmmnPvMebYU2s1txhrTrHlWnPuvebWYwEAAAMOAAABJpSBQkNWAgBRAAAEIUoxBqFBiDHnpDQIMeaclIox5yCkUjHmHIRSMucglJJS5hyEUlIKpaSSUmuhlFJSaq0AAIACBwCAABs0JRYHKDRkJQCQCgBgcBzL8jxRNFXZdizJ80TRNFXVth3L8jxRNE1VtW3L80TRNFXVdXXd8jxRNFVVdV1d90RRNVXVdWVZ9z1RNFVVdV1Z9n3TVFXVdWVZtoVfNFVXdV1ZlmXfWF3VdWVZtnVbGFbVdV1Zlm1bN4Zb13Xd94VhOTq3buu67/vC8TvHAADwBAcAoAIbVkc4KRoLLDRkJQCQAQBAGIOQQUghgxBSSCGlEFJKCQAAGHAAAAgwoQwUGrISAIgCAAAIkVJKKY2UUkoppZFSSimllBJCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCAUA+E84APg/2KApsThAoSErAYBwAADAGKWYcgw6CSk1jDkGoZSUUmqtYYwxCKWk1FpLlXMQSkmptdhirJyDUFJKrcUaYwchpdZarLHWmjsIKaUWa6w52BxKaS3GWHPOvfeQUmsx1lpz772X1mKsNefcgxDCtBRjrrn24HvvKbZaa809+CCEULHVWnPwQQghhIsx99yD8D0IIVyMOecehPDBB2EAAHeDAwBEgo0zrCSdFY4GFxqyEgAICQAgEGKKMeecgxBCCJFSjDnnHIQQQiglUoox55yDDkIIJWSMOecchBBCKKWUjDHnnIMQQgmllJI55xyEEEIopZRSMueggxBCCaWUUkrnHIQQQgillFJK6aCDEEIJpZRSSikhhBBCCaWUUkopJYQQQgmllFJKKaWEEEoopZRSSimllBBCKaWUUkoppZQSQiillFJKKaWUkkIppZRSSimllFJSKKWUUkoppZRSSgmllFJKKaWUlFJJBQAAHDgAAAQYQScZVRZhowkXHoBCQ1YCAEAAABTEVlOJnUHMMWepIQgxqKlCSimGMUPKIKYpUwohhSFziiECocVWS8UAAAAQBAAICAkAMEBQMAMADA4QPgdBJ0BwtAEACEJkhkg0LASHB5UAETEVACQmKOQCQIXFRdrFBXQZ4IIu7joQQhCCEMTiAApIwMEJNzzxhifc4ASdolIHAQAAAABwAAAPAADHBRAR0RxGhsYGR4fHB0hIAAAAAADIAMAHAMAhAkRENIeRobHB0eHxARISAAAAAAAAAAAABAQEAAAAAAACAAAABARPZ2dTAABAewAAAAAAAFm8CTECAAAAbA8upjABAXOPp6WtppseHB4gISUvMDCnb2BYX1t5ISUlLy41rHdgWV1fXaIuLTKkemheWV0ACj5m3PwsXzYKSilY4yNAM6YsaDEYAABRzfirL1g/PAG6D4935/LnQjucAzA83oQBngs6zkGKOcB2v/oPjt9tJ4YCA+SgHOJztY+O+HcnAX8nhCUK8EsAMAaDuOfuCU4EGLv6C9CDwXsrALt/EsCuBPdJJQA+lrzc0rcLRy+i7QCIME06x2IKBgDuXd7xV+HUTDrk1QUf3mQjIu9ZqJO/PJoFLUkhyTvDTx+ZoogDGMS7edh/E2v4ao58fx8fC3FChnk9OIvUMTx8CDe8Xqv0oF/nGvcKCHPfl75/wQSYrC/93NUGs4iQReOvK7InR7d+qncBPdsbUqGaeh7RR2+iXuVJAD6GvF39t+O4QAqAZGamCWOIhgFgNzYc0X3L6xYB0JCOHdOjgddHhqWX4en8gio3aex3XBnvMstAkIuJwQExsXrDlfrk0UBGazzYGmI+kF4OR+khqSBWf0LvZSlcWWVxWE6QAjDLVNYP1DaIc8U40fJagWwno+Wyd9V6/0BE2lJvIk4gVnXoh3ZKvl56xTljRE/FFcM4rBsbymFNdoIME1Zx+NOCOxYAPoa8Xf3X4JQFxDcGkPbMSAgzSgwAcPt+/1+szo3OkVB0cwEA4/BOQcSn1T715bY4k4yFmYnHx90QSeVoxfkjAdRazDSVPcqpaTn7HqFINV5vxgqjuyO4q7T9+qz6Nm7lYGByqPpVpE+T6gBIpn1MkmxrjxA0GTySAo+PYLmNXmFWaPU+7dN6eJV8V9dc10vJhJiA7wS8w8MQuQBPV+XqYyBh4JwAPoa83uLXMeoLgA0AOM/MNM5OmzIAAAAA5xkBuOK/3+zwvh/XJZ9ryMB7OyYxuP2EzU/RdlO7cwJIUVrtvbb2MQm2hKohk0ImvDKxCxPUnSXR2T87nBNiKfFJFKK7zIpq4mGk7L4jTs7JnDQ7cZrSmISJ0iEg0RQJ6fPPjE0VXqHfQi9k5DVuh9U9B7M7dinyLJnOvwlQ7xJwTeCxhi/grmyEh5kgyiBse1LeAgA+ltze01dqYEjIDSAA1GjQMzNUlMRAA0rVcD4DAAD8T9B75LwqQCiQbtuaFRAtNzM5uKmH3uJI5uEj9t0BK9zZrt0j151w1soRUgvJpralhEgqeFua0hHe28cecbGITovwBHv5rmEyHwX/ScgvfLdo/tE6HKAP+1ipyAhdPK+8NNdU/EK6d+uXNbEiZuktCtOANGrzJIpJb3RddKyP8i0zVOS8cwAANoY8b+lr3JhELAAyMBNAeulFSVSgBAAqdegNoJ7qb1QQ3AHpzrBNivVJ9OSM7YeDERlwAdQJcn3NNqhoH9x+ivuWYNw0s1lxa+ObODneFKJlOBjoxEBfEFwrb4h8b0tXLx7hp9UW0ecWSRxnkhfRCJeIUiE7zaaSZ9REbhMvAziqFXGdWQAHA/SHvXkVgkgWM6lrHe8JQmOFtgB8QqpJNkiBAADM3yi6/UOiafmtc0KjOckQS+wW2wB8QqsBb65RAwDAp9fEJ8dWoyx9VNyNNLC63HUAdELPFk64NgIA5DedLyn+kbHweCGhqesddIt2H7kAjEgPuYKla0pgEAAAYUSdiN6KLlBsZfHwel0cmPHMmQCERgpJQUQakgSiAABC7NheVyvrMyaJq9o+NVtoEOJ90wCMRH5cdGx7G6AbcAAAq+WmxXkjqjRl8vy+YyEL49Xv7XvSFzAAjERILXe65/SAVcdmh80GAEyi9B3KrlL6jnv0210pbf621rr/3nbT+X+Aoe+vyAAsy+QlXeztt+oAmT0Ox3EKAJivjjUEqRzmL6f54Yd6dBQvPKt96dGo/y5q83kiDnREUSaBA13+ywsbvhf+lAj5utPX2wEA6+9+5By3fENpLd+WWNlx+DUg62E2P+b3BWYa6T0GsJT9iqn8+vVbqs0W+/8ezSeTCgAAMgDijikJFAEA+GCU02cAANjPF+kBAAAAEoD5VQASzxvzDAAAAKDfD+zTBQDVWmvfH+4aQQWAGGM8zNn3aE0AAACo1pKl7pFjVAAAgNZaa59VdQDMZ/b3tdaaABCW/rv31neOOGL1L54t1nu3guPjN988eVxrBQDOIQGc/EzvtbHLoygCAIC2vHwOwAIeD14pvoRd8roy/9E9ok0FPSTT+dMBAEABAAAoAAAADnw+AQAA+3k6KcBABZIgmwMAAAAAgK+zAQA/ARQAAFBhCgAAAADApK5WBAAAAIAA9tnVLusBAABgerWdATA/nFAJAMAGAAAAAGhAGgCAZZcMAD4pPoOr1HlN/EeX7mLjBTUxHQACkAHgf1ftAgoAAICD4x4AANg9ARUiAAAAAIB+9QMAAODUQ4ApAADgS4YAAAAAALxPIABCIWT5Hr2rANiuw5QAADQOAACzJCbQgpJIAB4ZPrNXKeuS/aCfJ2VcGFICAAAFAAAgw9/OFgCAgyIBAIDPCUAwAAAAAABXzwCAzwCCVQsAAICkQQEAAAAAzswAABtsvOnsq/pAAwAAgCtj1gENNMAmU3Y+Gb4EVynzSjxR90kZD2ymAwCADAD/omoBCgAAgIMbAADAfQkEQjAAAAAA/HgBAADgGhW4AgAAzAIAAAAAQOUFIBAsItxNeFYByA7dIAAAoLzC4x1MTEDBXPUvIgKgCv4YPrNXKWcrQXTn1BsXYjoAACgAAAAFAADAwQMAANgSgkAAAAAAANeZEgD4CLgAAEAWAAAAAABaEhWASCok+X/toA8AAIBpffMcgHbBswAAIHKcBS5pAFMJQAEWCb5kLlLWhYDlfSfvAjOgNgAAyADwuiKQoP92mgCAg0gAACDKREQADAAAHA6HhO0cAFDa+/mnyRFCCF+o0XtXABDwpAAAUABwcSdkN/HI3y0zp/59y1prGtftVpL46P//3/97FAOMGdhLpm0QILH4UhpuSMA7A2EIVOGDPop99+KttmS5CQAbDQAAAJD2fySwKjsDbEEsVWMAVOEjp2LXjwH4vcAgAOAEeN1Jgdu84S5fyebADwLV34lJEE8YAFTfI6L/GgNwnoACAOgAIFlw8N3XQ6Et2J9+7d759YVG8LPWLABM37q/t40BmFJAKQBAb0BpR+ihPL5qohpKtod7cLrZC1Lq0VFiBQ9Wi21q2GOPAFRRFsvn+7vPaaGbuta3FgA4wvSpy9LsfBLamrYNJeWnxfaNE5MKp+lfcfdssAQ007yN3xMDMAIbBQArAADABQhnBufv/FGA99euF8O8zcCJWHGx3nvXFDOEzNCEWjefHOqUHRr5PQeg5HONtcrHr9+i5KPb7PMPsJ2kpAIAkAAgikpAEQAAxMH8aiQAAPTNPekZAAACQQZwMxJI3Nw5EgAAAMC0E3NVAA1ak2rv/5JDYQsAWmvts8auOSoAAADEuNNu5tdaaw0AAACA+NI1xuge6q7HEWOMUaFBfvaxQ1/tcsFObzX8Vfbw8ru7t9/+dvqudwEAVHH6CHgBkTrXLwgRAIA7sR8TdFeGAGOArQI+OT6tLpAAcP+Rl1C3UuHHaJqnAwCAAgAAUAQAAA5ckwAAoG9KUIGKFCBJYiQAAAAAgPnnFwDgjwS2AgAAmj4AAAAAAO66TJ8PAAAAgGDLzfC87ckEAADgw8knJRIAgqOtBQCAQwAAAAgEgHcAAID9idM+gM1zA14pPsOrlHVNfNGVkzJWkBPTAQBAAQAAKAAAAA4mbicAAOh6ElSIAAAAAACuMyUAUBaACgAAzZqpAAAAAAA7fwAEiyOm5y/XBwAAgPOxIwBCbUgLAACHAAA8FQjA4AGfAF4pvoRXaeua+EM3j00SkekAAKAAAAAUAAAAB7cDAADoAggwBAAAAACwPU4A4BdgCgAAZssCAAAAAEBqFQAQUiT6fFMPAACA3WtvFQDi59FaAADABKBhFMAJPhnehjep65L9oe5jJSHJdAAAkAHgbNUCFAEAgIMvAACAAiICAAAAAPi6DQAAcPmsAlMAAPBCiwAAAAAAWAQAAtK+8FKDNugAYG693hAAgAUAE/3KGhzQS6NMCfgE/hg+sjfJayv+0J2ThY9JMB0AABQAAJDA36YFADg4TwAAYCuAQAQAAAAA8HU2AOAHgKlGAAAAoCUAAAAAAJRVASwWR7DP/d/pAACwwKnL51lMgCEiU4UOAhoqgp//QQI+Gd7aN2lzI34QzzEuyXQAAFAAAACKAADAwQAAADwFRAQAAAAAENULAKAsgCsAAIh/AgAAAADgTAVAQMDxH69PAwAAABfqCjwAZFccKQIAAJDQqF3TSCBAgQUDzgAWCd7mLlLPRmj072EsMLtBbQAAUAAAAIoAAMDBPQAA4AmEILIYAabVarXgegUA+AJcAAAgVikAAABQ1PlbEbPzr7Dijf98d+H556/8bv+YumNGibnpRAAAQEJYfLC5iNkSxmyaual9rzXEsQQAyK0EPPwxPFyB3NxclPNAn/tUsAWnAmAE+FsNMGnSIHBfaWQATLRJkwxgBBjAxKQKACpBAwBM34rfr40BuB2QCgBQA5awgPwer/rUaEnRsmbwaV/zjI1t8ff+SPp1nq/J+HwqZFfcJ/YB6AIAFMC809qGuczOvKPR/uScr+LT9vbI+OtO0tzuna/iZFF5dSIOZF2Og4O4fMsQCARC/hS2Wg7wHU8FAAAm3/e3NpI8M6219tZMRGPUai1o50hHg2XzXQA6CV42tATqB+ACSVDz7HZ/7DJ6w23vf+3333j1ap7nZ+KHph4gA0Dj6AMA0AD6M6ghgZ0/V5OAwHxfZXIAAAAAkAHQtwckwH53EgAYUIsc5pctfpjV3KcAEGNU9+hA1FyCAACA19cEAHpu7X1rbKwxApCTzjtijAAAADh4tHVzpEE1s9j/a601Th7XrJ7pvQtgs9VVDQIA4HZHAOwb/qdzmMAQAD45nvNC8rl2oujrj5621ayfDgAAMgCM4FDtJADQAPwKqEAGcgYAmU8NAABABSqQAWAOSIAeCQAAACj+ZQAAQPlVAP5hAAAAwBsAwGkA8PUXAGAe7SoAAAAARIXSXwCAPxqJRAUAqBQhI62+Vr8VNwAA+ArAjQHgdgAAPjleBlaBsoOKSFw/X0/aHh7L0wEAQAaAB8fXDQCgAXgFRgJ6cgCQmPo+AACwQAUAAACA6f+2DwAAKG8AuFEAAACgAwD4AeB1dqsA0D9OAAAAAILAhmy0baJPaQAeABL4qgCgnsdkATxeOV6zW4GyQFskHt+3Z9neHkFKAAAgPXYqAEAngEkwkEGXAEi2OgAAAGAAAAAAmEPzEvCuAQAAgBoAAJoAUKoAlPAdUwEAAADAxpbJB+Y7ygsSAAAA5qEoFABg7igAXjlecxeBdkBaONafZ8HTtsdHTAcAABkALhw9LQCgE8AJADJQAgC53wAAADAAAAAAAMqfDQAAgN8IwFIGAAAA7wIAIAAwVQEoMFYAAAAAABKxcB5S/3MPLAA+KV6zV4G6gGsI69/Tk6aHMh0AAKTH+2sAgAQwBYwEKAGA3FUBAADBAAAAALDlvxf4mQAAAAATAAD9AAhZAQDspwAAAIAFrJWiVjTzyG0AAAB5agQCwANMgEIxDgBPZ2dTAADA/wAAAAAAAFm8CTEDAAAAEn2hajBYWmpdXFtgZHBkcYEbIyQpLSt0Z2hjY2lkX15ubnZ1hZ+WJSclJScoKS4xLzbBk6Q+KV6zN4GygGkklr/bk6bHMh0AAGQAeHCothIAkAAqAJCBEgDIewMAgAADAAAAALDz3RMAAKBbADiMAQAAAFQBgGYBwAEAYCgAAAAAgBPs4vPy254AqIAOHhlec3eBeoBICOvf8aTpNNMBAEB6PJMAAAngDAAyUAIAWQUAgAiAAQAAgC06FQDfCgAAAE0BAOICgAQFAGingAMAAAAEG6i0/LK1DAAAAE6HAHQToAPArKQB/hheBh4C5QYhUbz49qTpUZkOAAAyADSOpzoAQAKoARKgBEDSBwCAiGAAAABA8TsHAACAuwKwpAIAAADXAAC0D0BuAgBANwAAAABgg4gE5parb30FL5GY2skJl9zQOx361DChVDugCjoaAP4IXnN3gXpASohr3lZNj2Y6AABID9MCAABwACRAAiAxCQAgAgAAAACY/p+0AYsbAAAAuBkAAAegsirgpdSnAAAAAICQ0N70+YOvAwAA0BSAMbYtGtEBKQEd1QkfAP4IPgauAmUHISEO/WC6mekAACADwOL46R4AsADUIEiABEAiAAAEAAAAAADM4Q0BAAAoBMDPHwAAAJgWAKBUQXlRAYD2gkBAkVIFAMAqJB3xl9vGB/BCgJwLD4ACHvk9MneBtoBJFNc6BVvTIzMdAAAkjz4rAYAF4EAyEUEAAAAAAFB/JwFxGgAAAHAAAHwAgAwIx6O5q3cAAHUtDQAaJIFZ240RXM0iAZB4k3xbFgOAAEDdhALuA7743fNXgbyAiH9cc6cwPTDTAQBAeuwUAMACcIERyQiAAAAAAMC2/3QAPVsAAAAKAQCoB4ANJrYST/DwtQAAAPwCFIDjNZuAQecmz0BOHSiSfLNkTFcAAABKdo8eam40AJ7oXQbuAmUHKuGc+sZ0M9MBAEDy+LoFAFgAFgQZGREMAAAAbPxuAKQAAACgpgAAeAMAIWCw5FvlDwAgCYDt5HE8tD9NXYhPCNCVlUFsWo47XdI8m7QsDlzCPSY2AYD7MZwfsAne6D2yN4G6ACTEIQ+mk5kOAADSQzUAgA0AF5IphAQAAAAAbKWqBLxhAAAAYGYAgPoBkAgho096uXQAAAD4CxQA/FFLZHvEaL11DFcTAADOLjIe8cTZmyJcN6qYabap6hNhsXepxGifI4MRYEjhTQUA3tg9cnfp+zUO51AH05jpAAAgeVwnAAABYEZBIQAGAAAApvjZAIRTAAAAoCwAgF8AsAHs0rWiDwGAstIAWNFPRtZPtDrk4S2zKW7Xhofx2xexkK9pBS51yUwcDfECMPIlsSrhCr7Y3TN3qfOahHPoE9MDMx0AAKTHdQYAIAAMNBRFAAMAAADX/nsBZ1QAAAAoFQAAByBkgw2Tz9G/MwAAAE+gACANVDLt8tV7S5q3Y/3dbjjkfF3Iwl2WAACIAmfuBwoJDjQHSFTWK2wlnACq4S4Yp9cDVshdh9+lP1fK5ZBTWNNpNvXb337r1kRd1+eVb69MkDxMDQAQAGaYjtECAAAgHP1M6kjEj7e+DzhDBgUAALAAAGG0b/c/PLhfUEopAgAImjueAFa9LULm0OfPwzDWBX0DkysU0r8ApdBZiWDCXjQASj6OA2ebcDYOeBzPw0xn4DQJROF30ftl55/VoOZvJQAEAAAAvVWhU6V8TcEDLOE3Bb39GODgb0ABBAB8AVuWbbwYKvmLDRbbdnWLoLuzFQBE2/lAvfbckSDoAJsAANqyey7KfU5b8FbacnvyhjxCg7YxOQBEU1KQ9brrT2pQ0gErAKDTe9fem9eZamw/mxQGW6LsM7v7SDrX3GYeADRb6vXb7lVZB3B1jU0kAHAkYm1yLv8QyEau/X1z9mtXSCw+lWvX9XaxwuYqABxfKBO1gxN2Tj6D9PyMlysA1yvMJYAAgKoPRWtlH6GxGgEATAMXogbXqxMaGV4CS7Ld/Pn/O6MU7D+/N+FWAADXjwQAAHEIAACQVQBkAKDfBAaQBuiPCRYAwO0BAAAAAAKbFzldzwbgMcYIwJsAAIAAgMb46Wg0AAAAeAAeY9xptwAAAADg+wKS6Po73r71n/IHD8wuACokoC7V1RgAAF4p3nksNaXr/yfF2KjpaYXbNAD23xN3DwAAIKZBAAAAABQAAIABpAF0AtIAYE8AAAAAAAD4/JK/YzsBAMALAAAAQAEAgBIAQI6pAAAAAJWkA7d6vQAAAEABAEBYkawEFwAAALg9UABeGd7VWWo2ROQnaf0WCl1TJVcAAP/+FwUAgAB1AAAgAwBztQ0ApAFyJCANANEDCDAAAACg6FPhsAAAAAAoAAAAAA4LAGzWGQEAAADO/7cAYB1BdK3r4rQADfC8AQAAAADg1kgJkUqABD4ZXtWtlHy08A/K6xY6eywBAAAAAFAHAAAyANBvBgMmAAMwAYAbAAAAAACYuIGqAAAAFAAAAADpAwDOvhUAAADAFwAAG1TIlU/oQyYYjq8XAAAAyJgAAAAAAGwNSnBqACSABv4IXpSLpGFU/z9JH/cmOLcsAQAAAABQCAAAMgCwvwADQRqwASANAC8BAAAAAIBrD7juAQAACgAAAIBwAgBzFQBAAACoNQUAIBJhsvLIreXYCAUAAABfhwAAAGA/bqoERRWgAR4J3tW75DSK/7/wOGQ10wDw8ex3kwAAAFAEAAAZAOh/gwrEBGAGTAAggAAAAABAh/nl32J6AwAApgAAAAAgAODMRQigAAAU0KzCNU/rAgAA+AoAAIBdMU4JakAAYEKbisTkIxaOfQLQAP7Yne2H5Gy0yE/Sb4TOeqdpANhq51cHAACgBeB9WgAZAHAbDKsTAGiAAQAAAOAl0P9xHdsJAAAA4OliQAAAAOBMHAAAUABXX/oBAAAAIgAAQAGARxpVoAP40LydAD/mywLwAEz+yF2Uu5Q0mH+fhN+Q9U4rAIB//5oAAIAEgJ+qAMgAgBMAq1UQYAAAAODJh1qNBQAAAADAz2sgBQAAgPBBADAlg/tP/jLgtwEKmq7xowAmuZpgN+ADAAAAfAQmIEADGr7IXYKH5Gyw0C/8RqjZf5oGgK+pfjQBAAABAH6aFkAGAEwBA0EKUCEYAAAAoBHecBOgKgAAAADvh0AAAAAAfcx4pn4AAID6bgSABA75egUBzDlWaQYAoCx0YAN9Aui+6F3Uu6Q8k9AHfm0htY8lAAAAAEACwE8FgAwAqCAFTgEEAqCqAgAAAEBRBtcDAAAAmOkn0AEAAKBtgEJIXXsIOBAAQLjrbDeIDc1FAAAAp5YAeGQAAACznAxodZUdRgIiPAKA7p4EAABgvhIMAN7o3a2b1CxJ8AOfYxNSu3mnAdDv078DAAAgAeCnAkAGAJxWcVgWAAAAgNNLuEurFHNGAgCAA7heIAAAAMBOeeUrAwAAALcHIH9GtgAAALrJrZvnBLQKAEyu4fEhlIgF8GkrWQBAD8QJAAD8TvhKnthd7F1ybjT0C68idO0XeksAAAAAIADATzOADAA4n0AAAA+APQOABqAPAAAAgMkL2wUAAB3AzylwAQAA4JaDXbYBAAAHQJxuV6UEAFwMgAOAY4Hs5iPGKoB4q14AAIDPhgAARKcBKABzxG4BALD6yQAAwBsFAJ7YXcIkJXkFP/CaQtd2C980AHS13hwAAIB3BQAAwE8AZADAksYRDwDADICtgT6AAAA4TcWJ9raG7QAAn4MAAAAARsGn/QQcAAAAvKC+eHQAAAAAgLk2lKWn6wAAAAAECAAk99fAs0AS8EtCAIDk8S8A98AOAn7YXQIjOdX6/0n9LEJqfQztNAB8Tf1DCQAAxPs1AAANfgLECR6RAMAmAFABYgAASgA2AAAF5VBHGjr0HACA4wAAAAC/QA96gQIqDgEAAACgQH8BBQCAahb45CmDAAAAwAN0AAAAmN9YBhMkgBrAWQMUAzBcm7D551x3egf4HQHLbCruCQBeyJ2tJinz8Peg/r7u5L3kEgAAAAAkvwMAgAXvgNgJMwDUC3GAOQAAwDOD6wEAexcAAA5AkXQonz+UloYihuoMc2oZQAaEUbI4+ezXOayzQwAAAACA/c4mXC1YIgEATk+Wf5s92SjA7AMUdgdgl/UuZsVXIjsAYAyJEY9RAPZ8CVZigMx/DvFBpL5eCgxabgEAAO+vFmQDAD4JQIgO6wI2uJ2zWvIoVnoN+XVSZV/35jeNPb73w6+P4zi+VflTAAAA0UKD9wSQTtDmBADMAHCKpgEjAAC1T23277R1RwmUAAC4EkIIy31WKREqSUYHQAEAAHxn7WXejVLq4jiO4ziO41gCtvy5FgAAgAEAAFObBT/YGSe4ygAAgMgXASCQrxuAzHkfVwD+cQDwK8xuAM4SwLIzUwIkXyhr4qc9nvubhiSx9xHgHADAAQAx8neg9OzKxSMACCp0+CoAFF0oE8W3CNe5JgKSGs/dWQAOAAAHAJbkV4GbEH6o+RwAuJXg8M0AHF2VKyc3bCr/s9gYQC0AJAAgPzuB+QAEt3Q4wn9hPr1GAOD2AhRfpT2nPux2rkwIBtxPCTgAkACAJFmsQgVpF7hhAwDRhQB7EQD8XCgVxbcJuzF/aAgCH+4IwAQAgAMAa7efwCzUCJwoBKD1XXSwVwH8XgA5bN8hbN5PAh0DOAUAcABAfq5AdQGaBCXAjetHQON1TwBg318AFFsoE8VpdXm8JCSN+n5tAiYADQCM1D8Fv8oD8t8AoHW1mgLFHwDjOxIcWSiRZLXMRXE7oSTQdydAAgbQJmZR9K5aZ3XO1XtcBfxvqa4uyauMomLudTUJFFWqzWoCWJcTAQubtWSw8NXVpkv9IdktfV/6alYtffkx9ubCcs5h5s1Netnsjk0AAExdaASX2N5acOhRnfcTAAw2aQDX+8xRY+cadx3Olz3TiB4rzMGbN5TrSHkKM04ANFnVu7HLCpb6p0wAAEvwt/9oAADGXA0DwNj+pMC9Bgb4bK3eFwCyERKFlya0/gPth6QE8CQAGvmd7Jxk2fynjXatW4x8YgvLnh63b3/qzslh++PNj7ADAICYNAAxkUwA6GrBBO8xJ4DpAAAToMcUwGgBsAkwkO4xbu88AwAq/JzDx5z9+I/W5msmx30cx44xRuXegkZrrf3rGh0AwKlrAXS25uUAAABuEkCMMf7LMYQCSgAA1XFExXiVH6M1AQDAkkwADzjdsY7juPIFW1cvdCwANQAAAJ9NAPhqJAAAAMDKASA3FAAAALLWevwaAABIz7+n044FAF45ngkqSXVMBJRqb2QjmTkAnoqXr3/muZsAABATDUC1F0wAeKYG0hjFlQBIA7gBZsCeIHEASOBJAAwABAIA4A41ku0Vl88CAADMkQEA8qcAAECptQD4upoAoAAAAPFGBQCA6fbzWxYAAKBuKUAdBQCBrgBOSTM+ASzA8wYAUo+HAmQpDQAAmH9eAeO6ShVQHsBZAj4pnkkpSdAJgW7pN3M9xCmuAABxvUUAAIgZAFHtJhMAvmqYwssKAKCaAGAjabEAcMguEgAAGwAgqAAAiFCxz1MAAID8ewcA0sMAAIBSGwCbrKsepU4aAABwHG8zEdTFbAGAxFKE5Py6vX0K1d1RAKDcCwEArCOk+WCjVF9fbLuLK7CU6gHQ3QnbFoaKwQjB5GgFXAAAgGHbLAAoVhzEOwDJfAUAT2dnUwAAwFkBAAAAAABZvAkxBAAAAB4x9VwalYCPjJq5r5qrs6vHx9DVMjMyNOLhzdvT19keKZ5JLxGxiYCypj32jswW8gD4ab55/5/evwcAgHkDgKlBGoCnGpjgPiMAkGICgK5AHyAgGAAKRQmzdif381AAAICZCABAPhIAAKCZaQCoI6YWoAQAgAnE+wNgxGf4GojqISG/dQCAsQEAwEhRQONn7SmoK73n66Y/H/r11PNd1goLYACYiRqoAeDO02hL/kgAbFW1Bv4YnngjMXT6/zvjcU4ee4d8CN4SAAAAAJgtAD8E0gD02YA0OjMAkGIGwCWYAKATAwAAAACTu11KABDSBgAwZgoAALAYAwDfPQEAAAAcoKUZAACAKAoAAJC9ZqyPP052SxTqAgAAgAG3DAAATQAAwB8VoAEAQHsA8MMxAADgc7IAHhmeUZIE07/fSb98jdkeogK6AgDE10cAAGLuGoBPgTQAP93DBMfxOwGAagOgX4JmAwA7AwgAAJChucUCAADwRQEAXJsDAAByHgIAY60GAAAALHQNTywKgSBFp6D2AADA0uB9jxePBubSAzSaAZ1TAdjLWRgAXGI0AAAAAHivCbwQgV5hEwCA+c4CoILnJADeCB5JIVH9/B+5Puyt6xjdOAC+Jiff/2OnEQAA4lcBwHeABQBpAK4zMMHmhxIA2AFwAcABsA8A7CYAcwNAAAAQUKielpmtiQIAADQEBABRBQA6DFAAAABcswVABasUAACAOqqMFRToULoVAKD3XuACiFUUAGCxIQHw+IZ6PgAArwEKXg4wuAAGwJh2AN4InjgsUbX/h/x61N1qDd1YAQBcbwIAhPcZAG4ANRowAUBV2GyeXwAAG4C+EfgVADgFQAAAAKxV2hcHCgAAjA4AQBAF8N8KGAAAwAHO1QIle7Q/WhQAABCoeRqDkgEAiGciAIAFqJhlPrzmKQmXJfROYM9gATACgPcNAAyg2LIAAOCq1QW+FAgAALLAdK5MfybYDtScaeNMGQDe2J05IElISQh8/Kp7U40qUvkA2Crnz69x3R0A5EIngAcTAJ4BC6hSHwCCGyDpOpLflgCIBCCCAQBQij7x2/4k3g4AAKCL0BUADw0Ax4HaAFC0OU5bhap4IIRA7+fw+kba+GTxAiD2aCR2XOBDjm2CVMbphRz2w16jXUmPAQCckAsdJwnk0RMehUzbWQKg8rZYcNujJ24GAGBuy0H2l0GQIAMS6/usCpCP96AGoOreNfN/D47iuBgTAL74nTgtUb3/Ax6/rXtLxhxx0wBwVZTnfxUAAHxKAPCOCQDPBCxAJwBrYdED9EjBCCqQggE4AhRIcr7dKQFAsxEAqGoRBwCg5ikA9b32tLUGMVZr6yf+f4eKmN8s6q+11AYAAMByHqAun2C4CqvJfNjJF/UdTsfqKpQY4EXLZjPMCQB/R12zKltiWFh1qCZfp+M7YU8foG83B4Dqt+ZkdptJygcFAEggyabVkaFzSAC+6J1JI5mY/v3O4/f1iXUNPTqvAAD59Q4A8HsKwDdgAWACgCpAGv2+HQDADIC5wAwAjjQACAYAYFC3ygAAANijAQBoaABYCwilAABAQUsFwAt3G+gxAAAA0OOMqQIAQLUk3wZBIJBYspP7351/T3RAMO+OawDeu7gtD60AtEIPk4m9P64sQOZ7NA4AFA7fXQDMvzdq118XGFMD3uhdCCZF9P4P/Gn9br8fFKYB4Kbq+9ffAQDwNgNwDtIAXCcwwZy+B4APwLzZAKiBpgWABgAOKgAcVBVi0k9JKADAp+oCAHUVAADwdwgAtdMQBOgRwAUAD3n9zxMXAH9qFUTJWQHKg1aiKvbS2VoAAADIrXVHpcRf1wH6tw0cwTIA5cTw8FcBEgAAZFdLMZlkMEFPRK9Vtn2pnUJePwbUYpGK5eS9FCDBezYDnuidOChJ9fzPeH32x2+/Ruy0AgC43gAA8BqAA1ADYAJAH7DAi2sBWAegO8oEsAm4AkYEAwAgOZrnxgsAAG6ytQBKABRAjGt0aShOiwDge4mIQl/CNhw3KFEBEAX1s/CkoQXUzVum4gUxAIjwgnPb9gfoWD7FgXNGLQCggeFjUjC6MnBpKgAO6NDnX81zvgOW899Z9onWUV5hjZclADIn3mA6ALYrPVeH1qHpcOxzAHknRgF+2J14KlFj/oN+Wd6ta/oosQIAuO4OAPBmAGpABg2YAVDCBFt/lQBIcQBk1wC8rb4HVlsCUDfABgAAYMWcbI9WFAAAlr8DAEhFAOjgXwkAAAAwrRWAm6SpR0DFAQAAYuy/KoAL7wimAFoDAHy7JALZCGFjJDXbLf2fc+DSNLBHDYB30UI5ZwPARAcAAAAY/bKvi0sAALMWgP88xQIAgCyzGZYBSP3MmWlrAACeyF0UW5Lq9P49hL3W1jOobdJDLHgmbp5fsdVOAgDtMwBbwgTrpQYwA7BH6voAaAA4NQFmADS0ADig6oEBIPUHB57cdj3mTwRAAABFAW/MJFUAkspaaOBUDwEcl4rrxCzjBABASV51tAOwzfwBAAAcJmHgKqUAoKI/nlnMEl1Y7RH5UB0hjHovZRsXOIp9tNRZvtYxAPBaAALwv6xCeQB42QkAMIAy40pdPyrAyq2+P8gCGJ+A2NcBHpuU4X/kDKoVykRF+koAnqidyJxkRPj5LcT4+bmba8+Fo1cAgPh6BwDktKZw9E0FgA2g1a3+n77VBA0oAQCIVdFrJg0AAO/c6uthEMpd6QXCTdP06l//ylBclW0nAJk+p9OUy7rc1f512QBFzMH57Izb9tW3hzkxj5ZBlFlg6H+AxyGmNRX57wsA9qd3X2O+x68CAABQYbsWVDmEUqCovncAeKTw/kP0ggVgcvvqd7GUe2ibRmAzdR0v+F5g9JhciqAEKn++WIu7cU4klvFAzBEW88f9Kp6YrVwoOYR/oET8+Gz7rWtXDj50gKuYuPmerSYAIHs9wTy+VwDNBiDm1d9agCeAOAXoXJKogjOge+d7APhyU/Ofy2IRAEBQELV+NkXhWXDKI377tod9P0RA4FAAABqcc/GZmLKQtlcTgqjj4NGBCvt7Vodta6jlZBQ5F5emGDOQIxB9grWoCdzPxlln8FVNYP0HJ82++sGBAQQADAacFEWnGgDCE++7EZLfrgDwIrAS8ZvMy8mBlbPRL3F8HQSIseyoYqBM6zzBxEf8ITwkJgCWiE1qRloT/G0jhl+/OTx59187jtffu/vr4xin5fNp+gQAlB5O6DUDcAAJ5gYAbAAs2HZQDPR3mst+0y7t5uNfkr/FXqUdIqLI161J+0nvXU+8oPpfNf4VERPCuXQrAAAAAAHpNk1LY4yYTe1OyCbMjIHF2kzPZI2yClcmDKR1EQy6KfcaY7c3Hah6wDm9sv4bDAZHcQIBnpxZr6IdSMieWhjlgnGu2gQAXpryYCdExOfaJwH999Og9EJszIxpQV9b8CP/+R0mJowe4fdPxQ1NY6FFCgAsUe/CGn37+wB1HbD7BwKzo4gGACg7e9QWNtoDsuM7o+XE3s/0m8b51WvmxvPucWrpbTxT7zBA3fk8BP0tA/QDwi3zh1mSkQAAznDajH5LJ45YHkTdzYHH4C+H9Qap9Qad71MfAjxXId+iu1V9wN5Y2P2tOXK1ovtPCwCgfZzae+znRErmv9N//Rd44x8h4pOQOwThqFEBJF9VqquuuxlFwCxZbhsuYsH1vfwJQAMA3kjTIRJMMyVznd8PN73NbRVapbklXaGkgh+7AVoJTnBQUrL0/zZTQw9GKWm1HejbY6Qpkf/CtBIAjB5wDwDUB0DioAUAiM0CwAV2qADgLUz7xVrTd6TjG699431DEED9AAA8AAAqvKzLlQ/5jU3qq79BQQEAqg5XS4XNzDTii+cieTkPAsj14isawZTF6zIcbtTJofhl9D3syBb21Qkcce1XSv/1LeHBzzem8Z9D+QPkYD/BXgZILzXMqQAJCWhNbkGPwZpKcXkQBDKJ8rBW/WXZf14w26M+hVv9qoABAIDKofb7jUwjRn7Ul93cXH23zLse2VVVTzaaYp73tgBeCR5hVmKy9D9MqdfCbqRc1aYB4Mmx/1cAAOAbAQAVPwaEhSlA9PmxPXk7DzTfioHcNNcJAG4AjTFHJYC1AmqFAJRzS5SK06z/CQDgWqOdfSi4SlS1DipOZtWg4Bm353rq8ZIWApRAWhK+/4pf2cnqRwYAAAAgEpKebHuCR61FdHdp0HPVxBIAAEAufTLTguhzwQg+2TMzC1QqjKiZHipc5q3Z3mtpSokb3PmRVTVPObGhJA0AAIAMZWMQPv1RvjSAaaqMMhdNYrJFRkQJMo7nMJjuJdfmvgUD1YN2c066QwBeCZ5pIHGo/B+G1Fe/xb2DuyT5TAPAV7H9bwAAEgCxW4l2AwAg8QUAzMDaq9OdIw7g3wXW1z+rjx8DAMQM4LKOqA8AuBhAfQRUIQAAIFpCm0e6rJ0EAACAiNulp4C4SKAaAABJKYAmvegAAKFlO5K3LAoAqmWGc38f67oPAwAAADQLf0i0pSkIANqliba/6Xf2WM3+LUXg7zF9CwAAgLfoKPsmryMRklHS3RH85agtAJDqu/+0AQCTSwCn/1nbc3OBg395qIiSl1hqj5MAHvmdcUbCUfN/mFKvXrY320CoaAUA+EUXAIAEQNtAAe0CloUDovvpt93cbwIADja5f4GT+q38U+dvWgBAHMA8W/VNAQAI7ALmAFXIAAAEL/KdAgAAIIAD/etv6dCmAvjKMokAAJr2HEoPu7epAgAAAPBvZTnNaO3T5JdfZwQAAFzcY5zWyqUSGwAAAED8hVUwbckdIQCSLFJg/YZlNt7hE5wT/mdnZgDLlHMkzrbvreNTGABW+ATvARVAvOjllzm9koxcmwmajXx8Lg9pG+0n3++WdmJ/Xb5sHTUAHumdcEbimMV/UFKbHp4YRXQCnQaAqxh7CwDA30gNQMAXALABzehfnkzkgaUzkXnX0ZUAAHEAdVIYBQDADxJCABAUgOWdzVQBANDl8u0CFRzPWQDQ/9WwAADcwZD03yeAL1u9GxMrdn31Fu2lIOAAeD3qTxbhi1EAAAAg486HAAAAwJQB3hSkBq4SbR5MbaaMc4zWqkei3wLHhHpMQFAAAFDFXQE+DGVKv4v2W3++5+kxTt+vRPLPdczMuwnd7PqBSo6H425i1fpcGx3efqg3AMACA/7oXVBO0kD6+5VS1wvsDZUIKCEfANdu//X/W5UAgASADWgFwILWB9ABOACn/v1ynLwGABxoGog6dwEAZwBtr5M0qo4BQKmgsOzjJeMQsQAAAEgEqN5rmUVF1BWqSZJ04P4OcHu5NgAAmCzfsV/IU2zzLl4OAABEIR7BNob/ZrakIQoqTgHgJdSwN8Hw9uYuTm6bEwnA5EFPDj+uBgBYGkjQ7DQ7ku1oFQAAgOmrjPL46wEPOChrWRjo6LxmgLDw7cgazwSenfsSi3oem8lNk2r7HE4yCtwZ3uidSUtivsr/31P6ldmeghFLTgNAl/WYGgCABGBTwMG8ADoAgNYDJOAAuxtf/zrmSQDAgQxZJPTtlgAACRtApzo9bWKhQWwbCQAMBgDCVVFir/TTGgCgAECym1BUqfnE/esKUG29AgAAAOnqgBovDQBAua1kbvVgQhBEAQAAgJqJy5ebjZLbUaFyzxGeAAAo0Xu2Z5ftxZiNU24D/GjuawOa9GYT9NmjZ0sAAAAVp4O5O90BABjPzjgEo5+3AAAAADBOeB9w//jldAJABwAclMtZZrAaHzgnAE9nZ1MAAMCtAQAAAAAAWbwJMQUAAACANWSuFdLT1c7LwszL1NTPyc3JvMDHysrBwN7YnTAv4ab8PyjpFwx72yKAFKYB4KksnxcAABIAKeDYmBtAAyBAogZWghlYGxXq18d84OFbBbj+YrITACAOQOQRMc8AgJZaALAPASzQAACQCAAAJShQ+zDhdgUAQKBUEQ82RkB0yTk5ggIQIATh9bT+eAjILgEIlM0KAPiSqsbcZosAtb+KwUQpsutrf9YIAKAAgHOTddqjVQEAAJDRl6FgOOrHLRVw9W007hk8SCgAAKCjoSwBAACgVmAA8FM5XQGAwQEA6EyKq35ByFVkHoV6A/7YnWkgcbT1P0up6wt2B3cRY4lpAPgy+98AAEgAVoAecArQ4IDdXj++71gAwAHpKWbov93tlAUAtrcBAMQDwIqdAQAQDACciRPrzhI6AAAAAFlmtClIo4C26I8rAKBxz3rWpfLTYDpUBAAAnC+pmx6dJr58Mg8RAERpDgAAADBKgErM6uvGG14AAgDHdW9BAAAAyPtA4KsxVxSpjsrM+9iW275qkvZIOgCgAWhpDwgAgDI//2v839ENnH7rAY03K+Rq3dThUjNn5/29leYeo/I4KgG+6J2B8h9M/g9T6vo32ztMRZYkpwHgqeieBAAgthIA20jUCTqADVhxU7+LPNDMkyXazeTUAgCQcAB2d9cDAAhAAqAKgwBU4Q6UHMtOegEAfCCCK9RQm8JnFKjTal4AAOpc7Py7HskFwGf5PDW+3pMi6SkAAOBSgGtv+R5bk44jABSAlk23KPgkQttp++EAAABwwwNg4D24xWx2IGd03ogZl2EyfTpw+MwlO24AAIjGjl8m0B8UVy/0Vs83jDmwYntsVhAfaC+UQ+7xX0HH6401MAeWBgDe2D2ALXFM+R+GeHn9vnc4ylaFFQDgh7MEAOCDpEvAAhuwR0/b3Xft9vnb6SQAgIQNYOuuNX8iSrZh0QxKAACCm3NEBQAA+L8kAr4sBQAAvJm8dJzHOJOYilcEAKChUBo1Ht3HrdQrqJcQwvJqpIAlmBHYznjcsk95wxCQhLu5ynMO4wy+3ogCgEg3e/VkcE9GV+s0oB823200BgAAoDZO9Jfmm8pgaGBOvvZL2DEAAADQe7LHfd1aJyYgJysAFdoDzYM4F2bRqq2JwwsgBb7Y3aEt4djqL6T4/Ptve6egJFhhGgDeT8K0AADE0QrQm8AGcHOmz+uXONhTFuz80+u6AQBiAziyXvhVgQFA56qCy/G93QAAsCrAnSMurgAArvqFlpr1ByB8d6n5EzjP5UsLFQAAykFwCav4b/b2W7YCAADAAjBA10a8+aYUSbrxS+zDmgoZcjVL1loNCADYRsMAABY0kwUAAACBrZzNywAAAOCB1uw/e+VftaSJSACEbx8dSv4fZL8m9Y+EHNvwGfGICP0D3DLzV8EE3thdoCJ5qPb3K6WuP2E3FUygtAIA/B+qAwASAA10kJVAi4YNILruiWsPtnkfldievHsAAM4A+lVkNL+KCABgkq/z/gIAAACAMhv91w4YFJAaeioAAPjYhqksANW/+J5UUK2eD9tPBQAAABAxvqznOQGkVQPYqxl8+l5b6yBZ2Wg/aD4EYBpPR12ycEkttf3xtAAAADi2ALTstQAAELfqR29vkM22SfcRABOcvrG/mJpzd5s1JkDbuvVTKUxOVdQmOgCeuN1hIOHo8Q+E1MvvsHc4KkItOQ0Aqh5bCQAA0hYAWCQCWMAG9N7c61Yf7MxcN+pv891WdgIAYgN0X32a2p9w4ABogQHA9C0CHO1prxIAoEzU6imAB7HKU4Dt+h8zAgD4t9/39bk7QFv/VtucFWBfa16iCAAADdzjWWmXpL1mjqZpKPz3M/JmL7ABAAAAwAA1Y+7Rp0zOdXFbr9s5pjW648DhjwAAAADRMYaHOwAAAMAmrvpn+/J5FWfcA4KsAnfOyyY3GgQQkbncqACeuF1RIHFI+j8MqetP2BsuaJRkD4CnjP2/+qE+AABxgwaARAISmAHdXen8/PNxYOkaeoszUyQA8AD6RS1FAgD+xNxNQlsQDEApegMqrj5fG64AAAAkrX3ENYiI4xqDAbydHlsKAKDaRjvP/2UFoIc+O46WSthNjVICAHgHxZNz3Tkpv9JRAQCAYL9HWyPur209xA3DACrMs75xOUE9WFi1Q4bfr+gZoMEKAEAE5eb6pjWAPX7o22b2b6smIwfgrODBI+YqxkfadHwSAH6YnUBGwmHjfzHF1fX73mQnLDENAF/16BoAgLgADQB5A7oV0RUjDzQZJTjuPgAAJByA2EFfAIAANAAmAEibKQsAgpyUUvLXmntLAABrqO3GEaoAAO47//FvNRMB+LKOdFhCbmPM5sGlcAAAwAPsL5hPA1CAA4B7UtZLkC4CGuTD4DDP9Z7N7NrUiwoAACA/AYCB60fR5k8i6I7xYOc17LvDW38AcAeeOZP9F7Wh2axi8AAAIH4JHgtI/mHfPkURCyKihk97hQrhI8bd8ZCjh1CC+zEB3qhdaShlyOQfSKmXFfcGuSjhTgPAVqy/BgAA3skboPvIcp5+HEgKidW3HTMAeADqYpbmAABAAwB7NA6UAHiVRAEaL52dAAAA0I+Xj1VW2wCQoAkvrIa9avvzIRAUAABUfOajL9NE01EAAIAOZ1eXFqNFDhn/8M0AAACIkzTp1Bn0D+Qx0EwjmuaNzFWAnk8B+aSKu/WetxgJEiJ8w/4WAXx+ddQAD7VWBwAB0KnANP1YapAtUUS+7TIDkO36/lX7YbJlAOgKQ94s+E60TvTnsSzqBwBemN1RRuI48l8Qr16/743n5xLQpgGgK+r9DgAAvJM3QG95nNedSwAAAAAQG4AXqaMNAOBzewAAEAwAokwpxZfihg4BAAAghidmeeuRArgEyCkBAIASmTebim9n/h4jPtQ7vBrawQEXALSTvQoAAICvTgAGdra/HNsx9FtzGQkDQ/esg7tWg6Q6CPmmxzcVUM4wJv/ck7LgwdFKAAAAAJxhGnt03UjWDDPyo18+2DQvAACARn4VAAAAABhACWSPlLMmEfwl9u/aBrBALwicUQWemF1xVsow+G9IqVc97A3l950GgPfNugoAALGTD+g63vDzj+uNAACmARCnWAAAkJwBKLIj259HAoBGMAB0oE0p9yVbrwAAAICbc+c/06P0EAAAAICah6dt56aV9ZUAQEfqek21ZxJHP6WCdXFuszHy/plvXQEAAPDQ7x8AOP89PG+XgcxGUO43rKLpSXtWzyVBEPRMrDUycDDAWoYfD2S1TybtoQQAAAALr2lZAAB6j7d//Wak34T271oNkn/LCniggWzpdjYEeABeiJ1RTlKe9CekuF4+9wb5nVAPgKuc+1f/uU8BQABgEVjQdAAoG2Drs3z84kDr540SdX5imkcAABJmAG7MCKABYE4aIIFgANRRVwDvp01XSRMFAAAABGjNzmGtgnZRbYsGaCQNAFg8XU35ugCUnnxxJGpEPmv/JDoAAKgRLQjyS7J1+b6WCKhKOURp0xL1ipon8/QU+QJAX/sPTbGykVOg8QHVkgQuSDj/DO1a4fRiAQAA8KXCKGn88SsAAPRGp/PevRAUAKChFDoM9IoOPohdUEbiINXf7yGul992cimhTgOAyms/AgAQF0gNAGgNWBIbQITR4sCu+b46Mr47rdYBAJAwAbCzpdtBJgB1lcEAnK9ab8Af3z0bEgCArrr+hgjAx1nqAIoYAADvnwm7NDkNADKXrCNtiedzx0qkAADAgZBS66rf7O+1agNIli7S56GnWTEJAACAZKKAgf7SXA8MAwnStzq7pSiacbspMck0AADA4yRDWysAAAA+poat1dq3B1m+iNzd1zJVNJDvb6I19O6ME1MAfohdgCI5JfPze4jr1+97Uz5iBQD45TYAIDZjBsj+xog4sOl9p2Pu/sFd5wYA2ACUDhwALMFCADcNAgAAFvepFQAAAABASkaSVrqkANSatDjUhDbvlyh/WQEAAGQWrC29CgAA1ZSoxE+aORy3nojXMgBXyEkE4VTp8RSb5ABgEgC/5sG2YWAeKr/1kgAsFSzx9MY6FTEGnaFSycIZAFBzRIGAAMApYhoAAIC7/PoGZQ3666gvNxMAsCN0dAA+iF0IW2Ky8g+I7evXHjutkHoaAJ6I/gYAQFyAcQCwZ4Ctzw8Z8wHp9PRA983r8xoAeICVHUkDAEbDYADQ1BWokLz0LwQAcFxbmyWUwAQA/AzR7jI9AlDU3+ZXbO71+y0UFABoiav2aZdLiAcOAAAAT/r0KgAAAFYBIADUXG8bSCR7UgDcYRpmtApiKr2k9HLFKmAAAICGhwIAiL64/W08uO9cN+dsXmnGbk9YXZh+KR4/0tdN3AAQk9lxCijzkwU+iF1hTmJu7J8grq9fOwW9E3saAFTp/b8AAIB0gdADAHkDdntk3G95gJjvBw7nWUUAADYDiSBtWxMJwDVJAACCATgLk9jgy5t3BABQ3Nm+o7zANQBAzfWlSVznB4BItskslzPZ4cwxdQUAAEBGcY7cXh1n4Eig9NGds9H3DkHh3P6L0GvW6gIJAAA5APD85T74AiLdoj5419uUN+c42f0DWIZkwu1G2QQe7qUDAABgXaUXDgAAAPDo4RwmBPxAtYGKymLOohIAfmg90ICULMVvDHFZfu2a4IpMhQ6ALtbb33KcAgDiFOgBIM4A+8isuz5An34LRN/kyQIAZwBGjEwbADQzAI5TWAhADbGq4MtvR45fogAAADQOl7MoKWINQPEWDl+cr6UA+Kxq74xUjO3L+cQBgEILXGOb5xFkdAAAjRSiO0Z9BnQafJxpKheLmiRwaEXvMsHWwzAnPaFN0mRPQ+TudGvpzcnKaEwAQAdGdYYsEQComh9a0GUnyebCPypP9hG4d1vvSlR0wYlB3CY8AD5oXYAlKeX0jSE2j99bv0FFBElsGpDwLvpPAAAkAKhhgdQAgAaQwAbgTdn54sAycaammXyiJQAQM4C47xkbAIwwEwALDAZAjfqSgnn/YG1XAgBAXBWkmagKyBmORk9hgkYFKIK7KwAAKuu3aJKIAOBr/NJ4el1iYqotpkUAAABHPcvY02YAoEArJlaS2F1R4UAWLf9X4wwlAACA/P3GImiyFJ1PAmJX8LsWY3UBAADYT6gDAOweNuLS+YEm8aPjTlcAmfeCeqIKJAA+aF1AKDlL/BdSDI9fu6FK7BK6gwZdOfYv3741ACABQED3JgDc2T2iD5Bjcob916O4EgCcAdrIRItYmIFJOAAAggHA1otCzKIxurEAAADgQgSWvpoTAICSuYQz//YC+J5xTcRICAtz5zNxGh0AoGwQ+vx81NJnj4eLhKspBGyaXxoFVL0MGl4Hk8VqN3l5lNQ5A5I6yeGlEakmUe7ZB5DRY/h1BWNoUQ8AvVLXU68FAAAwTGYbbjG4BCAodA6ZnRMA/lediUByPrD3byU2/a+9QUUwJbxpoMGWu3cBACCOMgP0OlKZB3Dep2zub0UnACAmAFyGQwugwU7iBABAMACacA4H0tilVwQAAADQeXfs60el4NNcySHc3cWxT9RRHAFAQcLsTb919Sjzdy2PvtEo4f9VmyhO0kPHR+vTKAAAAFaDmVoAvPgtVwuAGtv6q21ZZbIwtQBmmPT+gXAkk2E3XmGgSQEAuQk0ZgCAZpMrAABAfzHzGQ8aHfSk3kso/S0AT2dnUwAAwAkCAAAAAABZvAkxBgAAAEQvJaAXw8fBvLmxvri8sLC0tbfDs7W7s8G2ubseWF2BLXnYoJ/fUgz9r50KnJzgDgR8dX394j89AwASAAZYoIkFCDeAuXMWDqS82YHIP2oAgG0NAGjRANg5AFBrYGAAgP8pRc1O/TEUAAAAJSqAS6wUXOGe/SRoR10BAHD1uaZBDADx8/Ha8LPMeNS6dHUABQ0gAABAN72X4mhzgb7jFLwrML74JWJC5WxoGRemU3LYTwFTpPapuj47Af4XAgAAAJiA6iiTlRXvGT50d7RvVAAAEniP9hdY7iC4S1eWawDeR104S1I+wN9QYtP/rjGyYgltCQAAAEDs/gYgw9Z9YEkwGOORAHAGYG6pyQsAPE2NYAAABGUtAQAA4Dkm7bC5AUjLvZuxDrMk437fkC8DAOCBKijNyeq8qqFaJbrD/rwfgHsYxALCs2WVlfhkteITqgAAADAQo0AJ2Pv3+gh0yOmnxjtpy/WKK5lqqZP+6BKoMKyBDFPArOX4jw3HMegVAACogiVo7lXHCAAAz6TaWlJza6ATAu86Z8cOu+S7foakoH4WpwMA/jddkSIlz8XP7yk21++7YQsreRAJKubn/kc+JgEAcUaTAIITgM06x1M4gK8J2JjL0QkASNgAkOZt0YkO4A3AFksAAMAAAKr7MQzKWqd/by0FAAAAPunEiDJeawA4MTc5vngTgBizlt5RPueSLKOt2goAAJSSuuRl9ziX7mWBa1WjlvzxFHCY3CzvaMQIAAA4EwBgj6ZGHkoI+c4kO9UWIzfFun5wRZC+buzcMQEA4N+Kfl8MAAAAADAxEbl77G83DP5HnUlFshntDSk19KHNrI0VTEOtwRXdfwEAADIAJJpwAhBqTgoHEBLm8zMBACAmAPY5aN4MgD0aBgNwztm8ILxKWi8AAADVFIiP3AAQxabzKHtQJQ4aEZ7Jc0nyIfkUmqBJByCUIlr5SOiVzyNoUi7EedDl3l9tu7AAAADkL903o7HT7YCSt7Ml9+Z2/Fh9L9q1zdDwo3dNEzDAKB0AfG/zyf2Jj5kgdUEAMkG1PHaE0Ki86n9kPB5gGroL/jddECHVJvH9PaWG3203VYKqMA00uDL7TgAAYrcnAN1j9l04QPdA51aCAMAJABNS86f6AKAXBgMQym8L4Pzn5SgAAACIKuK+DYDDvxQzpT5zmK6OZ28dBYASivLFw+3mrpboKrWYaIK309y1FQAAAEAjAOA6jr1OvAtwmWdaxQzTiJi7henWHJE3mEsCB0dY+Od/BinDBbgH6MBAAMA+d/41aAfXRje8IOhUT4e18z7KC/n0M/gFoAH+N92RLTkl/g9CjI+PzVBF5iS6AgD8cM8AgNiEEwD95Hg4gAvwuQYAICYAlEEKLJ0AqCIYAADJdaiVAgAAAIB4OvI8OADVmdhUqZj0f1TFrEABAIBIpJd/yUya6dHHvhIAB0RcM0xYKFCu/VJjkDAkAHePewsYJkaeN4cWNJg+jvGnNaWf2qhk5BQDtrI7Ua4yMwE+69urAAAc51ccogzANO7UXIHTZgdGmlc0AmIbXQL+N90JXlrK7C+U2L5+2/TCuiJZJaeBBU/Z3gAAAKlHZ4AwZXjhAEY2dGTTCYAzAHMEAhs6ARAyGABUD52i9pqTo5QAAIByOcz47lopQK9XNhlHEOqG8N9wJgUeAXVAI8G4PcKLS8pVJW+PBGBmj9VUAQAA0AUA2TSnFvANx8VTD7GFPK17qumTzKj/edLH+Bhkz0ffU9Bc6jsAgOXHOjtzcVsBAIhGq/+6DOoz+aU4GkMiyAnja42vbQagmfAA3jddECcl5er8lmLT/2ozB1c/4RUA4OedBAAgDcsMwKGPdAA3IQMdAAAkTABIJH8iAPAkBgMAsHjpjgIAAAAQgRdiN8ECYMMN6ZmalCUeGdPKAQCgPMZWe0OMiX029gRAPIbVuESWiBUJB+ITmTdsTgaA5Lr7VloGfGZjRMOgbPGql2lR6Fdu7I17ksxHAjMwPl3OGQqHIAC+udComg0Aeq7yT2cVeY8WtFMSB8dXDYoFb+P2CACNB74nXUhLis3R+7cUrf/QmOzICTYNq8FWFC+TAADEDCcAVj9dar0cCwA4AWDpaDrVAPR8gWAAWoHKDi1El6QCAAAATncPXHWSd3S0QAvo0NEgTrmbdH7fugTBtSPp0egcdjEAAABIKjLFgsJ+3V/REpexZrO4/mvxa/7BmH6AmQo8omY4tqSDCW528a5xiHMDABmw9hOvX6Hy8wsE4gfNyUFr/RMAV/xdjKZj3u+eHjX9AQJbsMCf+EqlfdcAnhddSFWyvYDu31LE+KvNMS6hHa1BFyN+1fdVAABiLxMAEWuCA7imA/U2CQDEBgB5hF9FMKCgog0KSGs2dpMaAAAAAIC7xFnHkQEAph66HPuPYmzbY7UAAJSAUG2kLC9lGQGw03g9R2Wo8MzpjRW2dIm63Q/ExAOBUTpFPvvoFZwBAEDWH3UgGkAN6FEACQAAxIk3e6UIfqkpFCakvRn5t7FASuN1tz1nkqPggQJwuwGeF10IS0qW8xNKjPWVujHYERLcNByOgGufqwQAAG/CGSAcqTlAH1GDIwEANlkFAwMIfYm7o/hMzn3UAAAA8GZrqmbfAABl7tnqkvfoLQR3F6D6u2ddAQAAAIsF6InZymUIwr9ra6KLBsA2MSm6TYNZLXEPn/ePZAl7H37l1ACPHgAa4MBy4AVUOtB6cN/07yQvKQAAQFlYM8dzcFJVxqWjfv61iekJZIaZOeYOGAcCBL733AlFatrQG1O0/rPtG7IzEjrbHnCV9d79brMEAOAjOAPggAPInREbJeUMAA6/zQAAEABgvu4CcLYzu6zPAgAAAAB9vsWe4wgAIDqHTnzawxc5vgAAQFlxAFAAKNizTiEy8xPbAMfNXrlXdaqcgogqC2FWGTa56nI5NYU5rLg7bXgAQAHl2f5CQhqAS3/Gf1X4+u8IAAAAkPJBMbql2ieN+V9zdOjvPYsNVFa+uBr6nJ8KAH73XMhAqs39G1KM8WM3sBOLDxqozPmNu9kBAAg9nAGoiXAA5gQ3BgDADWBtgDwYDFAk8TxCwZnMA026AgAAAADjVkytswEAVikjVZNmx/8daADKAYUGzK5q5Qcmn/HPmiRYmMOPPCvHJUm2dRVm3TasJRAYveNhYv6cCjBeGNwqCwAkjDMC3+oJ7d+XhgAAAIB2n7hFXf2rLk3eIgsaU5aKPFBZufQ5RaNjAADAeFUslgAdywR+B11JVWo+yhNKjMsvTagihCQ6DcMR8OT9VQAAgGeZAbre1GEDGAU0bgCQHd6kbgAAwYCCR2KB0p3VFAAAAKBuR+rcCgAw1SYSzBNAEehdJVltGs/UpbvAXcXr+pULGQEAABQMAwCJtl0uWNlf0/5P/FDNLdtZxP00kJNbvGrm9a+RjAAAqNsv4Jc7AWD/v4e/r0PsESQADcAMFB67SAAAiBxab2tkR37LgUQHyPUgNPgCfAKIOAx+51w4W6q5EM9fIYb+982wHWaOsOCJzl/9AxUAwM84AbC6ntsB5P2ayWtODQCICQDoDH+RkQ3o6AhoAQg/flXpy2LMvN4NAAAAANBz2MO+LwJ0hTIs8+CaJov/rQbeAaiCckI3aU+7e7peBRzzZZtT2MCIxt6iQ5KluSy5IH4+XyO2yhmeiwdyGAUtbnHxhmGCB3K8TcID01EBwNUyXQAAPPyX2558EsoKRqR5uVFRCWq6E/CVjBiiNEu967sedt2vRgF+B12QKoCm7Pf+LcW4fu5mY79pIICKY88BAIgZTgCo7X04ADWwAABOAGgGZgKAdA+CASpB67Qg8ukeVQMAAKBa+1LPae4AgItn6cqn/05xCm+oREW6tcr2kGT/dmlSqpS2sJPPVsx87CoAAACaDCZkxeCNYC4q+MdFOt9wOfK6RuWotdaXoPpnGxh4m8PK8XtjHaF+HDi+GwLCzYHBaQtA2/qdnr/ds1MEe8PnB0kBEDAbAF73XEhFshmh+XuIq+W3tmfxT3FHdIOrmPt/fFQJAIhZJgC2Vqt3A/RckICEJoA6AFBFMECVpYYC/q7XyRzqAAAAAPSkEitujgNUKF1SSxISSGu5eXHXKqGJsyYpAIAfwgdh9UBax8fmdPrUbWogwlrDKXF6XDY84gAMMAnHr404D+Dhfzf7qxaHMQCQtLdCPIs0LJd2f1D+eThdAACAwjPzxw+WKnhuTvaYM9qgmaqtH9AAkABe95w5VYrM0Pw9xeb6RX6nuGlYDS7X+GEAALMA3QDIE4DW4z1O9gA6LcytAYCkAYBzJNjBbgBVBAM0lVZxBbz+OHYBAKBUJDldTaOaAACEKpt/2QsAlIT4dlIlleUsKwFXOgAAQN1yjbuM71/islMVQEutnB8AAAD4VlT6e0cWwKxfugIlV8mHpePn+L5buo3eNSvuUMpWrzeBwVcAfNIpdlTDOtaq/a4Mg3X9lvGfBw+jQ7isCz4ATyUAXudcOVUAlcP/jSHGj5exCuKldEfLgC6P+//jTVsDAHK3Z0AHbjocgARuEADgBAAYcYCBBDoYAFUEAwp5fK6Cn/3ML6+fAAAAAFCUPg1i7AlAV8IsVSr6uP8Li9C0AQAO0KXApgkAsPzSKnFw4Ke3P7HgkQY7PMUSADDHkX5uOWE49LC+aQAtki605zCwkBJLMyPPWQuVxsaWkQ8eAERBgFkjAECtFeDtu8gXOaABFnRQQAA+11zJQIod7QMhdbnAwE4qOQ1tA7Ys+q0BAMwC1AKgTAHscm2ttSQAcAIAXNFikxqgigxEtMkOAJpte6UAANCdP6MKRCIAtBh36emf6PL+elqClygAihZIbL38UtoI8t+uAPxW0EwgAQAARokhEgnwUd53Hxc6sfUdM1/RXZxFKtnlHcCCYbr6YxcUWj0iBwAgab6ixEfYnkyKbS1FAAAk/qaZBGatqkLhesv79gHcZ1hkBVMxlIHKteOGTtu+9AQAHtec1VCyzOFPKLG5PjXNCjpN8g8iYI3+wTR7AUAAQACdTgB1iBjWAbgFSACApAGAjVFFMIDsXvN3pe5e5p9tigMAACoAhDZVBABQOf7JxsUTAOo3FyOpEM/FauEl5aLgPQh0wMOjslGiF2//MRlfL89boWpy3An3JmyIIiZzukNG6K9yrDXDxw7QSHWaeUXnFXGVALjMDw3d/r/dJ10Pp4vFngjmQ5qBDDb6dcMFGmQEAsAsRx0ex1yIUABOw2P8VuJyfbR9LGRVeFYP8BTPvn5rlQDA6+QJoIPoPRxATAVIAAAnAMBsA5SoUUUAUM2HMYIiSdjVdJalAAAAAHEbqn/Nrh1Ag+jsizdTUcIs5iLqCA5AQ0GTlGWkBgCBxNuNndo93LKX/l4ih3sbM9cGAL0R2SNlbX12yeTiXmXH+E6RPpT7WxhDGtN/buRhAUNHwAPZvBTNpNYAY4iF6YNxZ7v6FJRUIoE3XYLWQAdAAf7GXMmsAJQ23xtCXK6PlkaRz1XsNIQMUFGbCgAgO3kGCML9sAFcxasETgCALweABW0GwARIoBOCAZrWk6EFrHwtKQAAAMA9uzmPnB0AtKlRH60KgMIV0HMeAMDNQH8NY+9vgYugKNrTjo5GQavJanvuBBIAAABODDkCqGAnNMl7C3zFVkg9RpJghByHoQevOSWchDlb3AoAAP4eHD4FcNhSAPaH859gKNFc1AXAAKO0zDIlyKNgAYEFQANPZ2dTAADAZQIAAAAAAFm8CTEHAAAAhz27XBe6v7G3t8C6ure5t7Wtsriqqq60s6qjq97GXJWsAJSG3/wtxdX60pgHWlV0DAuumHz/+G2rAwBvAWsBgAbYJDADNsSkTQcwqk4N+0wAAJwAQN2RGwAaVQSArtzYUgGvO+oZtwYAAACaL0+So0YDqBKgak34RAAAmP/uXzR+AQC8hUnnXP2FeVRDG6oAgANFW84cAYAKyM1dXH0kLAvKRs5s+AeFvBixmseKEeHAp92fqXt10gEAJkYbmDAG4On+u7ctzkFogNk5NS2Qp7jTATpAAt62XBVLADTbR/s9xFX30eaWwK0Gp7GFSLhy904AAPAZiAQADQCBGQB6Ow/g+WSqBCcAAARpAPTRH7X0RgIwBQBHDQOALvm3bxT4ecfRSwEAQC7zhXJvkgqgDnjwJYgBAODKao71LgkA4DBOtNPPYGJrCiAKAAAojzfI7doy4kUEHPAuUKiP/ENSj/EEAAAAzUH09I06uvauDgDTXdyOLvN+iKDA75u97YCGArgBAKDmBp2H7LM0stiZK7Mm4xQAPrfccqpEe4kfSHHV/QrbBPKjFHYiNVCe7xu3+wAAXvcnANBzaQPYogQkDQB6hB8RDNDEboLFwNZfXtkWAQDAAUApX1Pbl7UBAKgsWedzBQeoiM7XDNtnKv4nOrGDM9JnyJD6HGt7XHXJWT1bFhDg8UIKtPWsBtwsAJAHXdvmgDsB9eXt32I+1GQADzQAsIDXtZQO1+onrnA0cQDKpvEbO8Ci77fGXLBiA9EBeImkxDkB3rY8rEBCc+HOb2Lb/ZbEEkpMw+qALfP8vwAA/A4aABITAAZH2wDU9wBGGgB0za8RgSihp+l2oVjTPykkAAAKqN70vAAAICXXhlgGAKBh4h9CB3CAlJDwvpMKTxIBAIDMBBNtmm68SCT6M062B4Pf2Qa2MaNbP6YHvHfYEE6BLdy74VQZBGh8b7zR70MAC9ACAO8NxoDRI5VlFkBWn/viGIp9fW9DlLsKBVLFRvFdyaDfe5yv/QcAvrbcLZvfbJ8nhnjpPzVBRRZXo2ebgMecd33TDgBAXgC1BJBnAFo/hwP4MP0jOBoAAKQB4OgrAk3XAJgAwAgYAOJ56Dx7BOaKrNuYjgAApYA21WsTcW50BwB2axV0ugEAvP7PekEcJs66JQrWowIAAN6v2xf+vy5eXQGActBC4pdWx2OiVfWjI4D9EzAvu4Qko24fOxo09Kg05tUBATO9/xMNwRCOdADoo41mxhaNxDMliNqj8QUAvpZc1YxEMnlCiMv6m6EQVTzWgi2u/fs3bwEAyhToBlAmAMh6dhzATflqHfrlPhsAIGYA0DERwIIFqggGWK0zkVOVWpwW5zEFAQBAQS0vBhWJvZ8AAGibX/ybAADslqyTVVtS8gUXAAAAAKpq2uPsYYgXvR8aABDkXNzl8ETjDh5nGD+FYEyMScTf8/EW72p31ExMkgmo+bk7Ag6NCeiGE+kIAAA9ADWAGbdqmYTMcuJ3p1C7O2AeHj0GFZN42EoAvqac1EAAJPs/VmKzfmoaRWoKd4RI6OLoV9PsEwDgTwEHgAAAFJgBmD13zPMB9AInxxYAwAkAcAQJaljAZAHgAMGASFv/45XDS8X0748CAACAc8N/JUrRJJQACtAkpAAARI/xeNNnCgLEwewhVhFbk1xBuygFgFCgeqvpEaagG1zj9ubAsoMCKMxYLYItoz9JhFUZuOz6fZLTodRnkuHwvLPdGvxjmFcAgLHiLOE4AdixzYMUoGABgQ4AnqZclawAKMf/jSG2/cNYyCX8R7rAtcX4K+d9AIBcAHMCgAZAJ2YALbreuvVT3xcAwA0A3CPBEVjABAByBsGALpKaMzTwWtN7kQAAAADT3TTcQZRyhQLwSPwGAAAV7/K3OHcO26o24wUAIIALVW2saVbfaVbqJhKBKhMAAGYS/h70SZG88jlbepK/+qlmCB6KFy52PoX1B6tNuFQ5AT3RIwApXE9tq1L3CmA1SvM2AAAAIOc1CxRgAaABnpbclawAZNJn/gpx9bp2Y0WOqsJpRCFBl2PPAQDMAugE8A9AGyEDABDwrRAAwLYEAJBghgVMAMAFggHxZeUzIsRdS8WKBABMjSVHGtTLqQIAQO/cx7dWRAEQAGjpyAR1VwAwFAUAAHhoVlUIt4M6DQSAwnjwrqtlVQAAgM0j735nM52FiBvP5ASeJTHi298JZ29tpxUSqgYAJqYEAD9XL/cJiQ8FAAA4CdafCS7d0TkDYEEA8IYBvoZcSJtXmtf9e4nN59r0jCpIrQpPnlqgcuOtv9sGAAEASMzA9REgnAJgxcrWq1dFAQA8ALCdAAASNgAztBIAAAAg3mSV+ErgNOnR44sAADigFbuLuweJFDDxWfHmT1XBAQDF43+c/rC5xPTmACAiioIiDndNIjgUAADi6wjw3lRXitYLAACACjEnhu+B3roCcfGJUG5EQJt9qGbJYvkdYOnpDwEAAGDygSFHAczjlsDLawEkkOTU0wK+hpx5jlfk3xtbtMdHdHtUQYOEfxranLCjvqkKAOBPAUcAxKYV5asKAIAoJPQCEgYYAOiRfppFgfvaC6UAAHjM/swvzJpAP94RiFEBAPFrBaECK/S+Wp13AQAAkuhVfS3xpYQC7B9EAe6IOv4O9T3Dd9e7O1MBaD/YZiQDAFDW6ejrX2PuQfeuAAAAWU6/RUwbyjQA3Rnueu4CP8g2GQQAABBsDLS9vzrlibIWUOqZbKoUAADABAA+dpwCm19k3xtSDNfDXBFSFXcECRtjT+/sGQD4C2AOgOAMYOeFVoxjAYATAOQ2ASQAdt7NXQAgGGCPJM+FCNV2vfQ/V0EAAQBiDxqOT8RxSgGAmtVjF12aLrq1AEAFAVwp1Ne6MZemEQdoODewDo+3i4sIKCPwzRNatxYzKCG/ggHG+BHkUOd7vANkbDY39op/ujRWCwAAphX45Xq7sspdgKVtzCnGACiwSTW4vp3FAzAFDQAdvnZcSF4AaMbnDS3G5dHUCbH0rApPHxYo1pum6lMAYKZAdwCEUwAcuqNb/dy9AYAbANAkbANAAQBA0cXgXvDGaDrFAAAABaW9Xt4GvAQBAFBZxCR21PSGlgIAgDQBNB47xgwtBHFwrQWq0Q22i/+KNGrUB8qEYIK93ua8vlFoirmInKrpkf7D5Knq8S4AAEDd//cGdsuGMwQgagAAAAA3fXNUwZ+hrfhP80YAAAA+duyWyivsbf/WYvPxSBqqCKEamia0SOg4vxIAoMzA8wIQTgBYY3sPgAD5zACAEwBATUIHSAsDAABrJan7AOG7OgoJALha5eoi2ns8AQAarO/TmwAAUH5pHqR2mRAVACgKKADU1mIao53qoTd3BZ5XPakSAACsmDUuwooTJ5e7B0pAyZgFQMl3PtkU08VgEHUGZLV1XFtG3M9HJUDFVNKOXAHwA06JAAAYr1et91MBAAAQPnYcVVsAyPA/oEVbXimhQ3wSf9RzguvI/dWvtwFAZs4AZPag4vP0OQAAYgNAxzYJ2w2A2QGAOSAYkIccux1d8bvaOXe6IwBABAEAqsL3vpyYM7FyCgAAANCBgLacVd6U61B4dMHvapfCgZKmqZaSE8Wsh8SEkSyOdxfbYVEe/3bSzjPTMLkhpoi+wMe73QvRpoO6KcaL25dCCGm/hCCQgbCfvw5CCZ0/ORUAAABYuptgyYAJRB2AGp523JWAVwyv81uK7ccjtApOq3HTkBZ0Oe9UAAClDk4AkGtCwH8PAAASZgCYd4NYRQA4fn1NKQn0e3svBQAAALy2Jlm7NUVRs4AIAIAAEt8SfJdMFBcAABIpe3yFZYuuQwTK7Am8np2EgcPdxFhUN0qtjc70d2kbNAuiHlHRTA8OWmsAwPObn0FtGAZnoBkAAGBPA/PeqvD9jckO9CkeSFn17fvtjALZARQAnnZceJVXxeP8VmLzuYYeFFyqoq0AAFfPACAXwNYBaCYAbDopBPxnAACQMAPAMM8kOGALgBQAGAAAOfNsNwIAANXoNOf9B0EKMQAAFacZN5uao6tQCgAAAAAY2VmoBGC5rQCkJswT5R4IIYcyvPy8BbMcFs1O+FMnJQZXpc6gTQGlgy0rUi5PCriVvaziw8A20DMBknvqE0x9BQt8+kAAABrjJCkAgLerQQUeZqwqx63if0CL8bGkPB1yCf00vLjA43B2AAByE04A5LKzVpcAADaBAPQMVBEMsJtZYoGaR+9JAQAAwBWMLanw7bGHNwEFQEpLLEedQQEomjGRBAiAhPCmbpWwG40iTx+SeZ3AlIGTjbenB6rupLjUFp+rINiAJ43nD5OcIS2O75wJAAMJrRilVjUJoBQLNmcAALL5Ov/9ftsGAMAGxD8VqADQ0ZvFDRAAbKPDDwp+ZpwV8qO5O7+PGPweeskWoqN1wBbx/P0bSgBgejgDODYzlw8HsYpVwO6nmkZXivzNke/uAADVcKAE5dw5fCNbYe2Ri75u7E3U9xU1oAnI4D1ClrLVojMzeTx4TzpYhJ7KIKAKQQFQDVdaFvBbbavoqP/8gyxn4wQNZDEf2Cz9/0uJyyTAtTP/2VEAAAFgne+Vok4byAplqsJt6ZvlK0WJl6C5chQNSBzSULxlAFLzUWZOtQF+Zuwc/LqB3zDC+kfoueCihO9i1wYorqs4+9EAYMzABkBwCoDIjdT2NS8A4ASAIPCraAH/sbVrGhRZ5P9WSYwCALgolClp/EbauC12ADzrvX0EOaIffoCiFIACAEDqLFHz7JwRLJSsZwKmwrnHANCsdn19H2utQQqA+1DpYy4By4lwxAAAQ5I/G4wSLECpNoCZ8lUopjwMHdLLqZr1uNoDefhX9No6RAfHiocEYeUc/KmcAB5mrCrPH3JXfhth/aP1LCFbpfPJ5QEd6813qwIA9CbYHMDWC5QNAGDVAABgqwAYYOprKqpA+NP4fWk0ACgUAKCwbJseaQWm/W55KYiCiOLqAA4SY3dNZw9hUqz5EBF/XamwAfwezuS+DW4569CB1LT+S1LFVtanjiFWdyo6ALh1N/7+1m4u+rpF8rRfALK7LhQQaSb/eU1vijMEAKg5Nvw6/TAIYNoLwMMDHmasCuB19ieMaK8PUy7UMfHxiITOePaOngFAKeEEoE4JG8CWAUgawAIH0AAAYEkHAAAAA7IyjYWIz7tGuQMAkKIaAQComMzAKEGBCqrxiQ4GAAAtoeoDAAAi4AAAAChFAwAA3IIQsAje6OHbnITp0/t3SIBCdvVXPPKLv9WCgQIIJU21RCK472xRnPz8kmAHx3zaBPfbb29hAAQAnZjMfwAUAH5mbDz8hkLntx24XKFnb5I3TeICylFPBQBQwnAC6JYNG8D8ACQNQIADaAAA8JA+EgBABOzSo+3+VImi/1dIAAC4FldUbnQUAOAu165eHQCAtUFYBADARQB3IEQAAFjOAQ4AboOwVueEUgIAAMptPDZeob5BpwJrzYYSqLjZOsFlF0lsY+gBe3rNaO3qaNVrjxb97Xf4T5CARuuHkGSAAfDAA5gEYLprgUoGAE9nZ1MAAEC/AgAAAAAAWbwJMQgAAACSLJyBIK+3KCouvbu0vLCgopq5ur7BIiMfIiUqLi6wrrq2tLuvHmasKscX9ti/z7Dl01TBUr18HsOIwObTd75sCQCyCc4A3TZxwND1AiUAwAmAsYzZqIKBAWm4Kc2m0IkhX5+LokAHLwRAC6tl1jHSCQD1Na6HOYQQVu0LogKUAwBgFq23Abe1rGaOWIe5P7nyo+xLIEvU5/XOTXOVTToinT96kHeE6Xt4vYXZzj8O3t/PAGBQim09AQEAAOC1ALSAAQDG659TS9kOAshzxwELdIDWADZmrCSWopZuOPxePzVAueLe/PLd6++9vH79+vimXz6p1tYAoPRwAoDOEVrPOQAAmwDQ3TPgVQQDrA0xz9nW9Zy8/Xu0SQgBtGvRC6g36rbF5iDRe0IF1wYICACAi3NWmvaUjWR4Z8wlkRXwrB5sGGBvm/Uz9wp3d72zmLmefVgpPolmSShPQ59sY6AA5gKAmd5bLV4DC9AEAHc0bDp+CAgYqgetoOxpYDoPsNR9rYGJNQyzkPcVJsw+6uI68QHCPegAbHQAAPAAP8JFypt6xeYvtXrUmYQ4GsEiJ/UlXxbUQMr6OrXjd5mI3uhwoAGAr48vIMc9xlbJ6/9pso8n0ugXA2cfNwP8dxvkQoraevX5nAlfCWv7a0/4FsBGFwUAwLn3kJr1N4DooR1ynea1ts9S8NpTIT8BOmac+YwAksnH/fuOy2+L1jgfVM2nv+d4441Xr+b58HnPdQNAWYA6AVQnANux7tMBCKgmAQCwGkAAACkQDLBr+VhuZ39Sbb1l+Y/jOI6co4IUi9IkakBxOgAQ56ylay8AoFqDelNt0+4dFUAB9ewCAESPexz5a69Lf3uJUwVJ5XbqSoE1MQpFNfPT1n1KbSUAfInhaN9Q/1UNUwOtndbrJQSgfNfft59BeFFNAIC//P6PHrZw8X99AALgATAMHmYsJPHVhuZvMxlgNchGCd0SAAAAoAJgC7CgeQcgnAD0WOYpVgCAAACAIA3ABrRsAQBVBBUAAFZRCABAVAFg7goKcLqnmRYA1wgA8I0la34XAHBTQSIFAAAAAFSCR8cy/wIAqrm6/GHHsD8CuOzjCfcxPrV0/QABKQlCPB818dukTTYBIwtL1vQ6ywKgtO/3ApvUAV0q0MADAIAuF6FrKc5XBgMAABQrvA2AzOn6HCUDD7B4QN8Fcq86y35mnHnuHaj9a8bmcw0Z+e3Ta8Gqr9v3vQDQZQYdAMoMoJMeDgB4XQAAkDQAGzVIEAAwQZ2wADJwpD2LpAWwYrsVoQJEnKJdwLjVSKlLuhQAQFw0BVJQAEpLpEmyL6IgDoACgItyTv+lcCyiBQBoacv3Q5s9Wo/AEhkHrs3IJoNFDvDpK4SYGfrJj2pzdxJ/jxOHASMDPwMAcAcRsGDhryoBThv3TOnIN6QsnTTR9KlPksS5AJ5mXAn8cykfHBF/e4XaCIVUiUu1OmGL3DvPrgQAZQEUAPwJwNaDLrUBACBMABANuyobULkipxERnXmWr8fZoQABxaGM5xgFCVVuAICav2X3XUOiVKGliAooAOB3cCPYQtw6vDsqbI3tTIDXghkKBo02w2ngm4cjHP4iBgQ1AgBpYIcBWWHMtfF/pewfabG+QlE5ZzoIAPgT4TmfuAO45JSwePqcrgZov1B1USm2bFGmBF6BnOJZmjx/CgAAfmYcSfIbUp6wA5crdCN7M/XSoYFi3jcmdxIAZF0mAKsDNkAzCZAUNAirgDZtwbsIsvxp8HwMBaAKVRwAENPH+LJAA0DHbuVUUw6jngs4YK2tpQBHRlhwD4Bu08zRwjhOt2N+sgjasunA7qzBztip1FcEABLw0guASYEBHO3Rt4jc/t4LDADw1TdSYPnaeez/OVbkDtseOMJk3sKAiPsZLgtswPN5U+nBUAD+olEeAgCeZtwJ5a9S3thi8+uKrhSclUuKvXZp0K7+PdXWAKD0MgFsEDADsAUgaQABTAAKACIoAT3F+JlAMd83E12H0AHwUgcA0CXpqQIAuMNE6uoDAIepAAAAbxXcCBxgG1O62ikZE92UvD5N7gwkwT+PhxQA+2p1Nm898DecCHXhcmKXFkoAWN8MAAH4Jh1bJYKbqTurgrEgYE3gARQAmpiRVGQNfmZcSP5TRp9YYlgfYYfKdiUmH2sDOnPvnFYBAMYCO1sAZNKAOQjYAG7KM4CgmgD6BAkwEAzot9rmPxav9NyrJldwAERoiktY7yJB4HYEAK+0NWNDFwBoDTFjPXULAGiIHU9aYGXy3iVNWdUrFJBJfqtoGY6KItIQE9IynP5Sv6pzYQxW8LIAKK/+7KMRicAwwYQF4I+2QCKRoMHDQKaHlQYAfmacCfwJAd8wIlyvsPJQCfIutAXKeX/xuhcA5AICAOTqAkBrQFBNAF0CALAqEFPXMdQVunhLdqcAV5pEVy9v1LDRFTziAIDnqIYaDQCwW/DuyhzVnhkZiL9WHB8iD+C2AkBQlyovthOrst8oS5RiPO/dAAAAh/tW61szRSM24P8Ru0RqSCg9wUXorwBYtgBlIQEDMFrwFIBRAB5m7Bz9hUDj9xagGhO6x0PC5tWfqy0lAMgFrAbQzIBlHTgAYyEkAFC1gWgB+UoqwcGppS9zzaWgIFAdCOJLxf4XHksgKnCP72LWsxtwASDE8yqp15CmaAEo3E3zEQlSCBrOGzCxV5S477ye2OUt+rBymkrKF51xLyp2uOj6Iv6hFADQ0mMQ3xBCGGhJAHJFSECthKYAqJV5b861npcgPv2FjLhbAkswW3NJnGYEBv9QSg5zuV27Ox0AnmacAfENF/O36VMIdZhEvjQ02Dj8tWsHAMgF0AC8ZgNgALSMoAVE0eBdm0D504qoOoB0KC6o1mkXNOizpbaIBcA9EUdZe7rftItjqpE60DryqHiQfTYVsrb9O5v77aR98cMhnpgCw8ID9KxF0F+Fkf8RS/Dcw6FTefSs8a8HaAAA8PR5tBYRfG+6vT45G5tRSiAw/4uISrsD/NhhaXHlapNMsFnwcR00NzVHU+jIeU8a9ThHvw6yRQEAnmacIfF15QcOv8uhrqXF0GmYdYAingkAgFwALwDoFEDakBwAAWwmAAjWsEQKQLOnvStBtZlEbQEAAETj8lxR7eVOFy1Ygx5HOwEAKPeSKvV8bfNQHUdxSg6bT0iwUgSkwN72Bg3TTs6H90eIUjNOBysdJAp0PySc3Ma7FjcRu8t/8T5hXsi+MjygwIZT7ZEag2UifBqM+RCQgNHPEAEb1j6aYiWQ9M8YCyJyzqnN8yvNJjLqM27TeSwGQJ8wMTZmbCSUUiWPkPxaqkuuiaAw+PiVjjvuuFXXdXHVE7MZAIRNOAFgw0zLUQCA1LCCQHr8SbfW9jXZR3lSPZ79THvH3SEgClBdpF37sLm5gjtCAd84oGk9wHutwssezgJo8+APmsXg6XGa15kd4lRt/sVxFxEqUxptg2JTWnA8IWGAKRlTOCHiEecVQr4v+lKMkN836w875EcjlgGl4EUGxn13stRJ3FakKXHJl3I/WWeEW4lAooG5Y9rkEaA6V6uXUwLUPqoAnrr+8QE0AgA9kagKG8ew0skpsHnQtveMGYlWLaYA1D4qA966/jmBhgCAHmlOS/17XD0skKcqy23PqNFPnIXWvgnUPM4BHNf/AAQCAHjcw5V/QsmZdeMQ3LCL+a1W3DAfpD7FhXrHyvcDaAgASPqlAfc/Y6ZIXBU6e0yOZL99PnhnAIw+KEEiuNleZZ5JuADcBADo0WOkiCF6UcxJybcwVZgC0VNhiwisQGjt8PmVc5kwJoCMsOwCAFQm5eLv5ZjrOsfRG1vmv5neA3IibH2nPB+kPur98P5VPmWCCSAQ0YURAAA9+zCR06ShRJvKH/UzO/2nefznqc1lOB3PSHIHvD5o7/jZ27lM+AyYu2DaFOoJfwoAgH2/Jrg5TgNayXdFkvABr3tjOyt8JsMcADpmHKkqAI/m/sQTYVm1Hf9qz4t9V4+d53l+Ke53igRoyAUkAMIJgA6wATimLixCcJAGAgAAANkmub3rafuSZaSHOWI+juPIx3EeRAHcR0IsjxYAQNGc+tfCKwDwWLGptAnQ6okrANDrlTWotZLpdS2mEkNBFKbIsuqIdZ25DNfKsZzRxMydf2iGs0MDrJ4vTTOQAJAgq9RdyJyOWuAsV8vPVbMAAAAAWV9OnhYTkAAA/mXsnPIOS08YEWqv8RY0kXzHrMHmiB+qvgMAlKZMALSEDcB+H0DCBABIJBsIACZAAkALyLdQISg18+nRHZUCQR1vAFCABM9lHABA+5J8r2gArjEWsDjXat0OsVoEAEBvAJoAfualC+UxcKs+GnoHqA8A0M/jtZn1aqWpXuF76UkhKZRKNlxeMTqQNQ3sJwGqgO1x5Nx3A4C7aIL3uX4GALCzA/YVF0iACDuQ9QQAfmacAPEJzPl9+n3tQs8FXiTWadLQAWuvEgCgTAEPgOAEQB8JGwC/BFgl2UQAUDVBYI//JfRSuPv7WwEAAOJOFtEWBVAAANewpjgAAJRiA3eEjqQSKAVgzfC+hIUQIJYBq6hdSOF0kcBeIA2TkyUq6O2Ij3WEVp4UsrhPuKWh4UYVDbys9/TQAQCgiKIe7Pc9AwggRf0ZalhnAYzDFK7mhm4SMJcSKozIrcQK429iPhA1EqsXnRfjGBQAfmZckfING87vze+xhm7kXEjlS2EDNvr45YsTABB2u3oAnAQ6OgAAWtSSBfTRXow/nfIlSfKeU1CgcKI+AWiUY3KT4s6xbdIBUOBizy+qYdv8mYTb8NpmDyxtj5pwWdAbTgFG+1Sb0PTDGye23esACW5CTSRAytlo9tRSY9fFKACYVFVAo3YLuLb+uIvhUhzxTt5ku7Dsla4qKDGD3wZhK1RFUbeDg/DsrxDK2OTq5Cm5VNjnEAB+Zlwg+oSS81sK6IWeiywuhk7T0gLFMVcBAMgmBg+ABH0CAKBFgFwF0jNvPP8Ooc85SwAAAAC+e1Ftb4bguBcUaM8+FGMBHCsixGlRd0bbtSy1po99IWFkFaDeaX/5mYtKq8AWtrybjLqcS2Wv+HXs2X2aMBMcIH/1SgWUcXYG+G0XooR6nui+lwEUXH9dUxm5JuAOuZbANMxkYakgAbee0RC1URtbGeH6latJpRig/EwAZwAeZqyIfsvlAcUHthTCPgoSep773zdKAFD3nAKgQeuaAQCMkoKAXZKWlyCC+Cbbrih4Ay2BmEhEhL478ZrYaAclgEMJ+MFcU5OE1HCN7MJifb1TVCfq92tN7anZ/jLh2xQ+B4CVYitxVC+As9MAT6r39yIh0KfBMHZBcL0OK4/v1182rJFrbRa9iwLgr9lqQE6INM0tHXrYCeM2+wBFtv1OU7l42sSLypMs2LbzQz2YS2SziXuxEGYKuwAAnmbcIZawWXkgD8Iugb0e2Q06L2emsQMA5Ax69ALCakeUFATimHWDVQRv57/e1Sg4EgUcR6DaIB4KDjG9FeLmy78vm/fi+Mhhmx8faZoixS4InDochzG+V1r29QJjVWO3I6VEYysXAcW5AHS9oc66HS+JqZ4J+nJlyyQ05VxKkZoPHJW6trsht4ribf8QFfJEPuW7+LS39QNi7qUoZeu/trtbvdwPC8llLEJeHsUSAE9nZ1MAAEAfAwAAAAAAWbwJMQkAAAB3ZyM+GLq2uLOws7KhqauvvKevrqinuK+3qrGvrz527AhLqeZv3LqcNCYbEshH5FhQHvu26QoAEE4BRzcgzgBsiNSSAQDQWZYsQEXmqkuWQkdYh32HoAAARC+C6ihVDT3SAMrh9dUm/xnGHC07CArAj8YbV5OTXqerZXWtxu/tuyrz5bwdGMVL872OkH6Imt8SnnRm15o9dgAJZsgNNH17Tefmi1DoJiPk0j53/4fTKo+PrjoAf5M5zVl3HJJLa4iYp44JNUBbKAvmtsjSjsGp9LTZNk5lAB5mHCH7uKUbbA8SrSN0H4cabMZVn9UnACAX0KEXYGYAGusASLAJAAiWZDEQxW1i1RXY7ax7HgIQogrFdbp9KbJdRAAtABAnQE5cUSigbyk0Uu49hsKpQjxTZuJe2pLVeHHKB5GyLxBpLf+OAkTq1apPvPLOLH3LldtXBIuahY5sKfIbPIpbWIECTYvhZjLzmAr56fnJwrq/O6oJx4NjtC8uOj1Sob+oM2nX48qJ5+zW0v5VeVkAfmacIf405yfyEkJm5QLIR63BGt48zXEAgFxAZgLIautJAACdBEkBxLQREFWqliSuYyQKBbRy6FCLMW61uzkTuEkHFXUAgXNvJ8W3YGhVMMxkCSk572iXvWkEmizMp4qsDrdqhQ0G59nrjhhVrxKPqaP4FQ7+DyE1LDQWHwvOmiyngxRyaLXNLnFvN81gjiR1IYSVB/VIryEjuyyEbkZIU/oyy3qv09Ui0yxTpJ17Y9isRCxm5i8kHR5m7AB8y9nzt+RXZp2kTNpLh4zFFs9zf4cSAIR1nABwgAOggH1KAEBwRFQQyCaqyA4xM/NcTSZagIrBFQQivffOaHoqAKAAfgiwNekAAAANpu+y9Ll30OBSt8c5J5Angut9G5KZR3GisS0gv0FwgV6AyMDnzz1yYHToNHRxqRzLEoktB+D0+OAfdPOWaYDVmPezlAgUVpJGwDZZKd0Zchhjit+WmPZ+qJN3xGYeoHCYPAEAfmYcKXqXFPu34VfIYbejZE9DbUEXdU8LABB2kaLdmBsAoDPIFpAesWObachNi10AALB+tjyUwimoX7kVwAawRNY8KDQrizhOXld0Rb/fNAzU4Ve7rDLeWhmFFPAFpfi31yddw8EhLpr1wl0A6fOD5u/mRBQAgPnt+w0Aeoj0alkkuihcG/ziiFWNcZibJCP8UPmjkXNzOwzARlQUy3XBPnEXVTL7+ubEnyHmAHSIAAAeZpwI7ltSjV8zcO2dovwokY8XcUAb/alHAQBKHU4AKBI2AH48AVglaUgAqtAC0jAX/oWAcp/2elvQgCKGpgAAxdMRKQUAoFWlHV+tcjZVBwCedYxG0G9AYJJUkmblbKMAwLU9+UaZFF6r2R35rmkrhEX8KWfpcU3AW6K4TFkBPg/CwgIDAFpoFLoa2bcCwADuuG8O6JYmmCTAd7vAGJEiCENdIq4b+j/KLrUap0LzHa8HAH5m3Kn19pyfViLUPvSo0Im0XWgNOndvqtUzABhTWDYAghMAZnAA/HthAQBwUpBcWABMgAaAFqCHhjHSaQik7/TzXwQgUVGJYwN1RmNFfgAFAKSioCFZAADlGfWICz3VRQAohdNAzODSTwCAYgF6AKAdLnnlbGQGFFESFoxco0Dy6Ltvd5F/QOd0o0Gi4+clp2QcwA4ohCEv/1AjDgWAya2g/HgTwHsArkhCB3qHukycBQAeZuyYkKSlP+22dlmzKaEoqc8GAsr2/ck+AIDpWV0A0LcnAavgFhgDsNTeMUP1kCRxpt4BAAcHAEBKR2I9zspHlOPj1HiohoQ61Fobo3zz+GRF01uSpRZYTawL1HYFnRjm25sTcKi2AIyGgTm/3eridEAL+vvZZgFgXQMA8LEeAEDvAg6/P2ksAO6m6f8ElSQA/L5h3yAoQAGPZsX+cOwDAB6GHHGTGKr/wyM1tjIHZLKZ/W0aSgDghWEa2YZCCwBA0/E5ffbw25EoQAcA2I4J24hrgOxJcfWcP2Bdi0lv6jODzOqbswlt5U45KXT8efC1QrAo0RDB1D3Nz7uPcDS5QbWcmumTo2nVzImfTsJDiMP3GTc56CZnqS7yK+RVu7x8qhJfol1IOl/92vc5hf0vRbxoSWyVES8lMQDjswFnYcEMo74HgEBSCQA+hrxiI8mx/xnYgQMSG/N+nHZuANCGBgDFpJEsCy0AcGYlLVfzY5/PAiB4KcAyT48wnEW0NLokAFCN62v76DpFsKldvnutjUxpKVOlkxoa2ivhp6bouwxzp2TE/LpYPMX2n3Xnvmo7knSStWLwlsw4dlD1OrBD5VDsqH/NwI2FYGdpksBk0pJInizDcKoMhSlubnG2/PYTjQBwt1mJQf4L4KoNAj10Nl5xDAAehpxElVBV/8PbATgAFJcfvbsCAHi9RxfajloMANDD6FFv0lqLPQrgoBoFPHtCL5z5kpO1rjIUpXuUa1jEM0ts466g2syTNNPFoYqzUjOCzDi6kJrXPD6rrPg7RByikcoTR4jtBfZTJ7RM5dqXALJ3ddwGVZXdHonrjLP9TuonmWgNjGHfXEVvnbFur3Y7+acSFZvQ/+mCk9uvSMHFAuZ3jqAMV+lsO7BX5Zx8fA0AHobcYZEU6P9gAzAN6ETH0d8AALzayzQuRscAQDMnz7WVmKUEAPTsGksgiXEsANDefMnLL78FYuuMB2jJFGgEyQBTNhU+zlIOV6eXOVmFkfdra0ksuvCIc0EguuUt9Q7xbZtB5DBuOgpVb+9QUTI2SkNk0GcL3lEmJ8g192uDNAC6VVbhfnmpuXw4UezFNfeZWK+yIQ5tmPorWs/PWtR3vzXX+jIuNbXEP4JV9w6jcCXgdVbga85EQRQYDAAehtxxkqSYn983AAdAi+MH530AgJoaaow8iqAEgFINixj8bEsa71SgAABvHUopRfRDL72XZ+1zeBVk1u+qrXxx69LHI3whZDTXivXm/bamgoQcxav679Rejof4a+hHz4qYC7PB3OLSfDZWqtCkFQs0d1WJtcE2+U75uS1ygav/MXWnxVf7rRP2hI+LJuy8epkm7ch0k/DNtyBjAczAKUsCKpFrrBlfAB6GPGCS5MhvGABMAwm6HHN1AIAkZ0wTIyWACgDa+vmngWuW3AoJAGR9mRLAgoAgrltgCuAO8vFeYqLFTBoue2s65GFHssuS1RoVTR6quRwZyi8dcS8TyZ4EIhZPzasSo9S/qXdX1dcroToPv2twLNsVAfzVYsFHH6ID4uEQnH4BPkdWBITkiuFwPWk7uTwmAJaJcXXNScAhOokQ+MblsJ3lYAcNGE14AIdAVfNscB4+hpxYl1wl/8FWcGqFA2DL7fNX2wAgM71oImVHAABc/dSmM/lXo/IAoBCoKOQqdZC4H7+gFk3pTVr1QgB7YEnnavx5GCJW8S1QalsbhlUJHUaS16eQ7he/3WwRbq/w/8kSn55De8DmLe6rZP/jzXjh59bbv+3e3QO1GI6VKiEMknqRSopk5I96tQwiDZC7byLKHEPDHQIQlRn33hw0FSSUpEwKiqiPDACGaVPSAQAellxgkhQi/f2+DYBpwNZYdU4NAJBpQok6MQOAh7v/RdF5yiwFAFg94aMAJCABhNphd+EcQMeRPL46BFCZx3pW4JyArcAetEJUCHfS3rOjXHiXRQhqA+2q1s3wnqnyfAXoC+qRPF54e32yVilL2jFtMiwx+EdYAxe/l2pr2zFSq86cpAvB3CaJFkUwJ3gaURXxvrBLyRv61DwwK4zLVnUaDDH7oF/AKAA+htxZkuTYf3CgKjiAsDHm+a49A4BMGZcmWqCyAACgXkeS+//v3wAAuASby6EO7x7DTd1j50yigVimj3Il3k2bnDqfOmL5ikh7Wnw/e7Hw+R8b+/NMcq7H0KJ3EtRbIZgBnmNVJBUxEQd/ObpILcfaGywoE1noU1EmBWhmE+xSWUXM9f5LcRcg0hMk5SlJkPh1WwKJ2F4+GU95BDBVS+VhwGMhBKgAAB6GPKGXqNj/cIJgOCAh1nfVOwFAGRmThraxLQCAfqW6+5BlJO9XABdVZpNmtr8BTfJt/XnF1RDzbJFATQ09ttWHxUVArEu5J4CZSpnkr/uJHkFbtz9v+wplUVHoednWLz0lk4VYfGeFM8AwdYgl24WcExqvFWCkkbcL4aslt2ng80OB9BCYdXUqmzjuptldZy9nocvyVYckusxWsmibXTVnivCtRA4l9XPqdQgOpTbBgZ4WPRnwDQA+htwyL6mwfwKoCg6AjnpMnk0CgJ7GC1OCQgAAiqooPX6av0MBoNzLwaVSFgn13IPP7S9mvQlgaHEqL36nyclLlokNX5MeklVmrbu0obQKt9f7cmeib1z3W9m3HNvGor2ADOwWcejXTS93o5pjzAzh1QJ2QYnuBLSX07Il7FPSR8Mo3FapXG+3iVbVuuDStv4mrcaimoNNpUdx82eNitH+zxJ+//G8Cagc9GToVAIAHoY8qZdQUf9/H6ACKwDA620AULwMjR8a6iwAAHD1PQAcCDIFgICJE9kTjdNeevh6oAAD5NzVlF1ZQjA6jzJ8ceqp95dfI/Pp0jGbkonLpOZwOrHlOG4vYVb4kGq/dj6Ce2bfc+7CTvHx3YLf2EwzE0pi5mTYL+anP4LLUgozEhp9GZBqa6wS7Jzu0WLrXtPSzlUVpTboqFwyX1QMv2zZ04bBSUyDkfsQICKmFynLIlhiL7QxxHwAHoZcWJIwwvz7vSlYYBogoZxNBwDomUkJkmNQAQAEH5VolC6hFACguKpfYEFahZXYSFtWhMVaVXhyenufjOCDtZycpQ4m8DeXYqPbVgMyLL+LrfkRQGU96sEhuRoqxDydTyEEWmxlrKZPhffAp9S96M5fRywmaSquDrVICtdhdSwCtI7Djyw8SOItbP/3en9eDmuy9Jb220qFZuCOXFa3IKYNcagSeJYuDQA+hjxpktSw/wEADpBsdv/3Tc8AoITOGJMpCioAAJYV7z49JVTGAQBUnIcUhBPIv9Ur6KX0tcBBcZL8G7Dv+rCW5lZsFQ4V9dxL2+2u9Zlj7X1yXqYqTO6rD69PbF7yi4GQ4acikmZ1G8c5rUeBDhzBNSSn5ihk4tiQdHU6VHM+tGE4OvpYGfHp83abiAdPuF2pkI7icOysVUnBA21h3G/acjcBzeA7wYjOTyeTAnCC0QIedlxZkTBgf7/foBBMAzqwjk0AAD9KXlKPEiwAAHkzRtoabiwAAFOZzUsAIQWRdEQCQgat81Oo8hyDSciVchDByWVgWzCfQmdtsogwVzEaTTu9hvbr08J0F7sM60M+jb68jnyK+Ry3BHu/vKi2fqoaal1n1lXW01iYoAjvPv5hJ5HZFfT8WySDvljtYRlefPwK2unl2u9eFVrL0gh6LkC/e1bxqsQZXKHSYbzE9SgAHoY8sZMY+H/YADigExHefiIBQJI9L6SejCwAAN3ZKNd0+ve2goMA4P8eRspAmkVYgvKDBcHhn0vXEbE7iCTH7hWfe+9oUrEBqHFd/cZKYeQfYmq65KLkLdn36OYEXlMHHOBv2Eji0p1uXUsSb4eijYLalDPGDusrHYFVHNKGSrdcT+Qyg7zqkpWqb7PveUcXi5KURCKgTpL1qpk66c46blGDHZnYCU1QRy66YJcLAE9nZ1MAAECLAwAAAAAAWbwJMQoAAABC9fjvG66wqrOrubqrqLKourOntremtbG2oVBNSE5NWx6G3EWSMLD/sABwYEF0j7NvDQDShNGExnk2AwDUkgQNc+RZlX8AgVh0GhcGQRFbH09VyPtsMLtM13B2LZ4GmnfAwRIRVxzEGtZFINq7nj5JnCoIGS22FsHs3Hhq7reEWNd9GpegrcbgaswsOqgIDuflVRj8X8h3IWd8G+dLaAYku42a+P7KZqKfrb/cRUx4fQBdTjxRB9J/chBViJwkA9fdp7hc4BVWa8rXkBcBAD6GPESR5Og/MKEaHNDLsHv3aSoAQImhjHG2HWQAKGJTSfy7uo+QrQBa3pNWbv+1wve2f/t1wZG0zICVDhdAei6eT92b3XZ11R9HYo+kK73Bu7Ng1YTZPlQm1hN3mHnq77dKbnpMdhr/K/bRTvZ+X9t/iu1ehRXoVjk7Z3CWguhpxX3wRd0YEsWe9lQDMLe6Kip4Hmrm0UcvTYBn8eBvKaoBIPtsq1OgVrjaKu2wrQEAPoY8TZIokH/iAeCAXIh9NWEBQEZ5CZ4SMwBAbxIayIIJywLgcZY7tRRXV3t9XLcn/D7XdUBwZ9kmy7aNmU6tt/whAonLqFg3w8Fc3B9lAVTGzfUxmYFBiknCbkGOY+VB1OPClpM2XfTMYae9qLIOyi1Re6OeHAEoucVqmXDywRIq7sOOjKWYOlF6vOj6mpnFEFoxpuAjNMUH31Zp4xgu99wcm4p01yOtCgA+hjxSkVCi32HA2QHTALaT0QUAgO9lqGhTFzIAAFfXZ0Ys8xcAgEFhixIAJ4ZY8v/pBvoh+LNPChJIY2od9FgG+f0z99ayuMwmiJFZqS/T6rxYuSSW5GaOKswRFkwjD3dotOFCJY1s+1YdEXh7pyIUp8ujxY8dJjMrGicHBrXYyjEHainBsCY6iRhpuJCc2Ihj0EKCAI8eXIUUjw8EcVWCH3fECwZPCHIyY9ch0UBPYtfGAT6G3GOSqOjP0KBqCQ6g8fjVLwYA6L4dPTmXNgIAlLQMUiEn4Z6KU150EzUe6L2GFmTH+WxALkRmOZUYg+9htPwhIiQGSMaSPVQXJWHt8KRv6rA06ZA3wLNI9LmtTaxb5RBhl2n0RSjKo5H2LjFSWUGcYo9xsZ3vZ+7rmrui/VyM3tORKzt3bXYkYtJWdet0IzU7tnezq0QZ5xwot/knAa7j70xckhkqsIPHAh6GPHX8Cyn/wADVMA0god4LAGBkhhmlFAMABE8dKYnnKAEA8ajuAhAE4cQgwhGtBLAZfakdba/VO7W1sg7lloNFRnRKsVEUuAvPeyMLm8ib2k8+WQOtMILJDXUUXKMi5jTRfy1uUa8vxe6LDxqRW5BFCoXaVfBYyK78JRiz22BVquyHxPMPpP0ztpdoZlaY2c4+As8fYu1X+SwEQ447aj7vhpxulwiAGSslr1f5R/IXXsGb9zXXGwAAPoY8fZKo6E8DVcEBLMr6f9xWAIDSY3aTkrEBAHAf5vdo/q7Rios7gSpR1w1zhGCj3PhjaS1NiNbA5crcu4zUs1bBo2dpJ9rzVcoawE35vJbDYZQrthT3C3ujng5U/xb7lxLiiIeOVBOyH2a2K2KoZmkco+EhETXGzWl6srzuCjp6HK0piGyiZzfkxYHqKDIaRvItfdXgeqs8jW+szS4V9x60ur4F/FdptQCWEByRac8lAlCP8x6pHQAAHobcXfor+tsK1FbDATow5/em0QsACvWMbRzBURsAQDx5BS1dp3wLQL8FAKkzI1utSlF69FZzD/pOuoI09ij79rZMG/NdTPdeercp/+qQJVuzFF6JcQFb7EYCOH3+OEz2GkpFJRbc4c1UMC+DkH8j8vysjqHM59iNIZ4LbsvVwsh4viJxwO3IzMAwSnlzRqbssjc17C6AxADl0dfIt3nEzXdg0O+xFUh/UwAAHoY8m/tK4nsAJw8cwAa9P72FEgCUDD1KCVRCAAB3ZaYiYbacDAUI7i0At/CihxuxNBsZdosUF3IcPVOSapXjmOyXu5yEreQeGXVqo76FvBgR12qVX8PE7tOHpGO0aMVpg0XmkK0R84h+EluGir7OK6JyRWyZ9Fs67u1gzAxMAfuIhErrGSt3f0Dpwy2GMAbCbiWAlfoXiNPEyKtCf41lOYKWZ/VHMAMAPobcNvcH+wzg9IED0KRbd98EACXTi1ExOgsAAAixGb2J72NRELxiKwiMD+FZMBocL3mOXIc+0qw6gyMclNdT+Z5WNajG+oR0UqcxR4zXY4HPT/9oPI43kakTnfdhsdxclFJ2K/m0lIHrCln+6/1WBM2bK56ZXjSyx6ogTo7+MD3siHBP67I19ImoGYJiMeYt+o4Img9ODtiHnIOx5JfX5BwfgbWBa+eLeREN9CzR/K0AAD6G3J2XWOq/jUT9GQ6ITujvVTsCAGSaaFOLyjEAQKw0XW21UXH8EwQUwEUTRzUGBeKnna2ngjKGpc+KaCaE86NUN81DJik4Hdy+Jqbu9BbZlkKPchV1dJ4zN8RSIULc1oa/z/FLvaPgt7luaEsgoOHCVGIxDCJ81NfQUhJ80U8DrrJ26vevtUW4lJuKNmZdBAS5ZZqmDOilN1zNb2NLKru38u7D3AYLAD6G3FuSUJZ92oRqcAAJz/fOBQDImJmGemlbAABV/TS/V4w1whBwROkA4OtUGwW8u3Xw17wk2BkcEMfZCsbtfecml9KFIZi4f5dazcD6FK/ywylVBae8ir8k5jFpTKY3WzesR5LgIUv8I2eBeGEzHYHzQnJZOjsILVtfuR89moKNe006bwOvGxI5pccoWkLyW4Pd50ZXdAze5p2i6oGpfxTKxNcaAAY5W7MmCyXXyf/hOBcEdrcQVAwaAD6GPGKSUGCev2+oCqYBNNhpAAAUoxhtOyZlAACv/X298PlXAADp5wwIAEE6QFB5UObdDAjg4VOEnBPXwWRWohGxzDU3+yAqj+hFjKj5Vltsg1bg5mZiXQCdULmVU/H6dgOZ+Tk5yQwB2yzXN1/vJmCJZRAiyd+rM8V1UJCrD3QUR1znjs3i324BcfgVt3cx/AaxJlqOAA4YPlidYoQ8lio6nazX7RAOb17fJGCIaabJlwkAPoZcp/JP2Ce+oVKGA9C43r9TAoDCnpQZYVoAAIDbswnzOBgKFChwwhVB8z7O3ftbGDHWAMwg2UKKlZE522pm2DCzwXMOjGLjVJbKPDK2gwp1I/Jk/BPrmIYxVLa0z0RP4OPBjFB6vohyFt91ynQAqtZUKKj7h9ltlIAq1DAVh2SvpQTforKEvjMSVSegqgoefBhmUexmTCA+YSgyxgd2bv/c9e3sCQAehjyT/wn8OySoBdMAFhx3BQDoJszQSKwgAMjv/meJ7qyhBAAMa+gGgAUAetOozVoAe7Cu7Xai/mmHmOrew2ZRaY63IusUcdTdQOi6oDjyHfUAV1D+zEGyWmP6ts4XhCVK4owb2pqPa8aOb/pQIz7U+JAQ35e1uNyJW02D1QTeoMq29LRV3/y0qpRHaUaP2ShW7f187igGpmmPsouywlaccAZO2298iF3LYPQ9xFYlbBhk3z4MAB6GPFr8gn1vQAUcQCz21RQBAEq6DCMNw2gBQIyK3nT1yKfL3QKiXPWukMmVBy6PQ9whXj8TrmWGHMLOlntHvNUgfyVbZbQ3FaNxT0IeOKqEPpCnPI6E3ZQVPC9mp8s7zKm8PVSOyz31JhGVJ4pVFxtCI6QAmhI/uyIIQpGNvEarD+pfrdrSYOg8hILIOyqcN+/HdgHxx4YGUNV3euwsxWRjZs1A2HCwGQgWEx0YfW+XUooNfqoVAD6W3GuR0DW+I01XCw6QoP+YhgAAmcZzghIFAwAQH+OlgjaTkysQW1GTQ/G9ffCbCuBYmjL2kBbb7g0/W0Q0MagBjV+KWrMnkSMlR9pWAZrNJinAWb1ZYFpb7RR9fBCUk3vmNA7eOae3+uP37d22jVLNWbLfPi1mP9I+Qz9sQ7YYt6QIyF0npNNHtkzUt1yjWa9BJK2woz9/qtyb4J6EgslVAn+3ZBc+hlxSlbCV/kQalQUOMBLcPlu9ACAzMxonqiAAAO7BtOYxp+PfxCYeC3eQeLrBzMfQT605eXPog8k9Z08Oro4qOq7ENqM9XRyDYDwIylLHXX8Ra2YH2MYxU3Qkv9JoDmrgzReWfWxOnb1KemwbjFzCR/r2UpW0jTomDlrBdcxWHuY7IlnMPGKxSkBG52GfCyblsLCHP4pEH/DNAN7RZE6+nLMo7UcSVFpF658OI0r4fEAxsAEAPoY8evlL5NMaVMABgP271xIAZBrjxdCEjgEAUDdX20bioapUhZ6r6YdXqW6e2xVPmqVOFRrcoJw1rAqen/hKisMn0um8Ls6xkj215sNJ6DdbVLeXhgzkZQyvi14mR0C4aYknUdiZQB39NN9stRMhZMGQpx27Gs+SeACyDRjgk+btvp8+dOX4fLyghTpWHG6oRXcqykI/YICudMN+aJilzl1ghrG0R/+61azl9jfkqpgAPoZcpvYXbp/YbE4OHECi+6Ta0QDAK6YYTyENgwAA0KJpunzJTMTXRNylRQD4TMHMnsz6R017QqDVWgZcfQAdEdD4CrR7GsUktPVxn9q8gx9/OIWT4trzrpWUtWJ7Zj4JiRFpoFIz56yRheZgrjHQfTsZt91iuOwdFCXkxOwq/ch5ZRt7wIsX+N1FEagPzTFatU5Oo25h96/30f+Lqx/BnAooyBEHfBT2N8xUk6BdFyWXKCvOBAA+lnwv6duJZ2y+LRSdHgNxPQA2+mbSPAeOAOQUQALC4mRDMQIAADTW89r5q6cQ16O8BAAAfG7PDvSzjQCCPbEu9rOD+nES9iS2nNf87ERh4Ohs/canU4LrzbkIwEviNQva6JlLwTGGXemBwx52r9BMZ4uH+fyADG02ne1sgO7dK9BvCjrW6HsCzCbAe1uGJU3eCQDtmc0PWEqw1c1QOHMnAD6W/O/0X0YFdyoU4egDABIEALjQMQgQYAAAYAwAcAYAaJh7tD3tw3YAJoym+IMIXzEGw26QAABl+lvuAVrU1wVgNCkqAycVbIWTCu4B4O4JPpb87/RfRgV3zBTQ+QMASBtQAyIiggEAQP0WAAAAZwEUHgVkKQDwQcnXjnO96MHP2KFbAHh4nzoX1hXA6HM7OI5xUHVmgHMcuAUA7gQ+lvzvlF8GA8eg+oUfAEAytAgWmAUGAAAA3QGQrQoLI/sKkea1CEK+SQF4VIlBAHdPAFgszwHLdIcAZ+cA7gSKc8J2dE8AIAE+lvzv1F+MgbowyX4AMAHU9gDDAhWowCAYAAAAsJTEqYQAuNUwc7iDb1ArAGjTWQ3ZGAAAvhFuAJiiv2GxsF3ghB9b+ArQdckrvyOtgRs+lvzv9F8yB2E+DUqMyQAAUPV9tBkAAAAAmF/l6bBzE9gKnwEKAFAj7Xy3GQMAjIXXe6DGem/tgQFwSvCVgD4VAADs6miC2YRl2AoGAD6W/O+UX0YD1dOsC4EBkAHAnIihRbBsACQBAAAAAJgHAKdfzlq8bsDcMX0MZAm7GzkOAHVqx/WkAIvC3QxYY4ChKiBp/18qPR0iAOBrAHYZB8zeuVgGABgHCABPZ2dTAARxowMAAAAAAFm8CTELAAAAKDjaKwdQVFdQZJUBPpb8n4N9GR1EfxTMBABSv7FtGwEQAAAAAADU5/YowADAdXcSLQCglUwomC7eTgAAgE+k0pMAAACjBYDJBgC9vCMgBXzQdxUAAHcUbBXAWRU+lvz30F/fOFjT0zrtFAGQ+pZVIwEAAAAAAAAgP0cBAYBP3FTvAkooiI6QnWAclDQmY3k04pgAcEcAALbXpoBdjGyEWwS4+yn8mE7ZQAXcHQB4EQA+lvz3kF/PDVzxaVttACDpNaAiUAQDAwECAAD+JfACYF8ih6jOoEOgc2t1kTQFgAVmSlW6E94SAGNwo5FiyDQnsOo24JtqwwwAWNzD6fzYAPCV8JW4BwA+lvzvZF+sg+e7eNLtA4C00CEBDAwECABqYNkcYGN+/yUjKHEFoC9uIikAZ1QBcMoK0CiuUhRa1IvoINof1bAFgHrbuqYMADAYAM6qYBRnAD6W/HOJH1Bw50mkFLKNZTcN2gQEAwAAAAAgX/3BCeHfjgUAgP/ni/hhBcB1Afi6A+4PB1KQnwUAQK3AIwUAgFhgwgDeeWb6pwDMwcA64GYBukNwdQ/MAIAFspMzJgDueOKOwwA+lvx1jl8yATNl8JZwkGWMZTEDAAAE9c2Ptr77PRINTq23gNprq/FSV6sWjA5F+INKnjr2UodcsoA68N6cRT3ncE7OMmtCPvvCW5PzstSq39QPrlMhkJ33coHk2tDCNYBrIQ7S1OJfP1b/mzQrXEKuhFNIMpnfIZeRQPegX2LGXNeOUNiEBXjEu5eG6tMObhuAl4J6AA4=\" type=\"audio/ogg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('All ready!')\n",
    "# alert when training is done\n",
    "sound_file = '/home/rui/Downloads/newyear.ogg'\n",
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchvision \n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "# get some random training images\n",
    "with torch.no_grad():\n",
    "    dataiter = iter(train_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    outputs = model(images)\n",
    "    \n",
    "    # show images\n",
    "    #imshow_coord(torchvision.utils.make_grid(images), (outputs))\n",
    "\n",
    "\n",
    "    # print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                                  # for j in range(4)))\n",
    " \n",
    "n =1 \n",
    "print(len(labels))\n",
    "print('x,y truth', labels[n])\n",
    "print('x,y guess by net', outputs[n], '\\n')\n",
    "\n",
    "images_copy = copy.deepcopy(images)\n",
    "print('image size: ', images_copy[n].size(), '\\n')\n",
    "print('net output: ')\n",
    "imshow_coord(images_copy[n], outputs[n])\n",
    "print('truth label: ')\n",
    "imshow_coord(images_copy[n], labels[n])\n",
    "\n",
    "#imagePIL = torchvision.transforms.ToPILImage()(images[n])\n",
    "#print('PIL image size', imagePIL.size)\n",
    "#imagePIL.save('test.png')\n",
    "#display(imagePIL)\n",
    "\n",
    "#display(Image.open('./data/rect'+str(n)+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "f = plt.subplot()\n",
    "f.plot(range(len(losses_list)), losses_list)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [30, 5]\n",
    "xposition = np.array(range(num_epochs))  * (total_step) \n",
    "print(xposition)\n",
    "for xc in xposition:\n",
    "    plt.axvline(x=xc, color='k', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#im = Image.open(\"Mew.jpg\")\n",
    "n = 5\n",
    "\n",
    "image = io.imread('./data/rect'+str(n)+'.png')\n",
    "image_tensor = torch.FloatTensor(image).permute(2, 0, 1) #PIL and torch expect difft orders\n",
    "coords = torch.FloatTensor(true_coords[n])\n",
    "with torch.no_grad():\n",
    "    output = model(image_tensor)\n",
    "\n",
    "print(true_coords[n])\n",
    "print(output)\n",
    "x,y = output.numpy().flatten()\n",
    "imshow_coord(image, (x,y))\n",
    "plt.imshow(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = Image.new('RGB', (300,400), 'gray')\n",
    "n = 0\n",
    "#imshow_coord(images[n], outputs[n], labels[n])\n",
    "\n",
    "print(images.size())\n",
    "a = torchvision.utils.make_grid(images)\n",
    "print(a.max(), a.min(), a.size())\n",
    "#a = a / 2 + 0.5     # unnormalize\n",
    "\n",
    "a = a.numpy()\n",
    "a = np.transpose(a,(1,2,0))\n",
    "print(a.shape)\n",
    "print(a.ndim)\n",
    "\n",
    "#ran = a.max() - a.min()\n",
    "#a = (a/ran )\n",
    "\n",
    "plt.imshow(a)\n",
    "#x,y = labels[0].numpy()\n",
    "#plt.scatter(x,y, color='g', marker='x', linewidth='1')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [30, 5]\n",
    "for i in range(len(labels)):\n",
    "    x,y = labels[i].numpy()\n",
    "    plt.scatter(x + i*IMG_X,y, color='g', marker='x', linewidth='1')\n",
    "#plt.imshow(np.transpose(a, (2,0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
