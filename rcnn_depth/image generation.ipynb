{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from skimage import io\n",
    "import math\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "IMG_X, IMG_Y = 200,200 \n",
    "# length and width of blocks (fixed for now)\n",
    "block_l, block_w = 20, 30\n",
    "\n",
    "# img_list = []\n",
    "\n",
    "\n",
    "# Calc rectangle vertices. makeRectangle() credit Sparkler, stackoverflow, feb 17\n",
    "def makeRectangle(l, w, theta, offset=(0, 0)):\n",
    "    c, s = math.cos(theta), math.sin(theta)\n",
    "    rectCoords = [(l/2.0, w/2.0), (l/2.0, -w/2.0), (-l/2.0, -w/2.0), (-l/2.0, w/2.0)]\n",
    "    return [(c*x-s*y+offset[0], s*x+c*y+offset[1]) for (x, y) in rectCoords]\n",
    "\n",
    "\n",
    "# ---- Make depth images ---\n",
    "def make_dataset(dirname, num_images):\n",
    "    true_coords = []\n",
    "    newpath = './' + dirname  \n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "        print(newpath)\n",
    "    for i in range(num_images):\n",
    "        #orient = 0 # degrees\n",
    "        img = Image.new('RGB', (IMG_X, IMG_Y), 'black')\n",
    "\n",
    "        # block_l and _w offset so blocks don't run off edge of image \n",
    "        rand_x = int(np.random.rand() * (IMG_X-2*block_l)) + block_l\n",
    "        rand_y = int(np.random.rand() * (IMG_Y-2*block_w)) + block_w\n",
    "        orient = int(np.random.rand() * 180)  # .random() is range [0.0, 1.0).\n",
    "        orient = math.radians(orient) # math.cos takes radians!\n",
    "\n",
    "        true_coords.append(np.array((rand_x, rand_y, orient)))\n",
    "\n",
    "        rect_vertices = makeRectangle(block_l, block_w, orient, offset=(rand_x,\n",
    "                                                                        rand_y))\n",
    "\n",
    "        idraw = ImageDraw.Draw(img)\n",
    "        idraw.polygon(rect_vertices, fill='white')\n",
    "\n",
    "        # use a truetype font\n",
    "        #font = imagefont.truetype(\"dejavusans.ttf\", 15)\n",
    "        #font = imagefont.truetype(\"arial.ttf\",14)\n",
    "        #idraw.text((10, 25), '('+ str(rand_x) + ', ' + str(rand_y) +')')\n",
    "        img.save(newpath + '/rect'+str(i)+'.png')\n",
    "    return true_coords\n",
    "\n",
    "train_truth = make_dataset('data', 500)\n",
    "print(len(train_truth))\n",
    "test_truth = make_dataset('./data/test', 100)\n",
    "    \n",
    "class RectDepthImgsDataset(Dataset):\n",
    "    \"\"\"Artificially generated depth images dataset\"\"\"\n",
    "\n",
    "    def __init__(self, img_dir, coords, transform=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.true_coords = coords\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        #print('true coord len', len(self.true_coords))\n",
    "        return len(self.true_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # image = self.images[idx]\n",
    "        image = io.imread(self.img_dir + '/rect'+str(idx)+'.png')\n",
    "        image = torch.FloatTensor(image).permute(2, 0, 1) #PIL and torch expect difft orders\n",
    "        coords = torch.FloatTensor(self.true_coords[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # sample = {'image': image, 'grasp': str(coords[0]) + str(coords[1])}\n",
    "        sample = {'image': image, 'grasp': coords}\n",
    "        sample = image, coords\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available? device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "num_epochs = 50 \n",
    "num_classes = 3 # predicting x,y,orientation\n",
    "learning_rate = 0.001\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"CUDA available? device: \", device)\n",
    "\n",
    "# Dataset is depth images of rectangular blocks\n",
    "train_dataset = RectDepthImgsDataset(img_dir='./data', coords=train_truth)\n",
    "\n",
    "# Data loader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_dataset = RectDepthImgsDataset(img_dir='./data/test', coords=test_truth)\n",
    "\n",
    "# Data loader\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):  # CIFAR is 32x32x3, MNIST is 28x28x1)\n",
    "    def __init__(self, IMG_X, IMG_Y):\n",
    "        super(Net, self).__init__()\n",
    "        self._imgx = IMG_X\n",
    "        self._imgy = IMG_Y\n",
    "        _pool = 2\n",
    "        _stride = 5\n",
    "        _outputlayers = 16\n",
    "        \n",
    "        def _calc(val):\n",
    "            layer_size = (val- (_stride-1)) / _pool\n",
    "            return layer_size \n",
    "        \n",
    "        #print(self._imgx)\n",
    "        self._const = _calc(_calc(self._imgx))\n",
    "        self._const *= _calc(_calc(self._imgy))\n",
    "        self._const *= _outputlayers \n",
    "        #print(self._const)\n",
    "        self._const = int(self._const)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, _stride).to(device)\n",
    "        self.pool = nn.MaxPool2d(_pool, _pool).to(device)\n",
    "        self.conv2 = nn.Conv2d(6, _outputlayers, _stride).to(device)\n",
    "        self.fc1 = nn.Linear(self._const, 120).to(device)\n",
    "        self.fc2 = nn.Linear(120, 84).to(device)\n",
    "        self.fc3 = nn.Linear(84, num_classes).to(device)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        x = x.to(device)\n",
    "        x = x.view(-1, 3, IMG_X, IMG_Y)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self._const)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net(IMG_X, IMG_Y)\n",
    "model = model.to(device)\n",
    "\n",
    "# ONLY FOR DEBUGGING (check if code runs at all)\n",
    "#images = iter(train_loader)\n",
    "##outputs = model(images.next()[0])\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model now...\n",
      "100\n",
      "Epoch [10/50], Step [1/100], Loss: 2.3481\n",
      "Epoch [10/50], Step [2/100], Loss: 9.0007\n",
      "Epoch [10/50], Step [3/100], Loss: 1.6362\n",
      "Epoch [10/50], Step [4/100], Loss: 1.6049\n",
      "Epoch [10/50], Step [5/100], Loss: 4.7753\n",
      "Epoch [10/50], Step [6/100], Loss: 4.5424\n",
      "Epoch [10/50], Step [7/100], Loss: 8.5975\n",
      "Epoch [10/50], Step [8/100], Loss: 4.1345\n",
      "Epoch [10/50], Step [9/100], Loss: 1.7500\n",
      "Epoch [10/50], Step [10/100], Loss: 1.5412\n",
      "Epoch [10/50], Step [11/100], Loss: 5.8149\n",
      "Epoch [10/50], Step [12/100], Loss: 19.0537\n",
      "Epoch [10/50], Step [13/100], Loss: 7.6189\n",
      "Epoch [10/50], Step [14/100], Loss: 7.3013\n",
      "Epoch [10/50], Step [15/100], Loss: 1.5891\n",
      "Epoch [10/50], Step [16/100], Loss: 3.0706\n",
      "Epoch [10/50], Step [17/100], Loss: 9.5280\n",
      "Epoch [10/50], Step [18/100], Loss: 4.5801\n",
      "Epoch [10/50], Step [19/100], Loss: 3.3688\n",
      "Epoch [10/50], Step [20/100], Loss: 8.1064\n",
      "Epoch [10/50], Step [21/100], Loss: 3.1719\n",
      "Epoch [10/50], Step [22/100], Loss: 6.8556\n",
      "Epoch [10/50], Step [23/100], Loss: 10.6009\n",
      "Epoch [10/50], Step [24/100], Loss: 4.8233\n",
      "Epoch [10/50], Step [25/100], Loss: 4.8221\n",
      "Epoch [10/50], Step [26/100], Loss: 7.9103\n",
      "Epoch [10/50], Step [27/100], Loss: 10.2822\n",
      "Epoch [10/50], Step [28/100], Loss: 4.0221\n",
      "Epoch [10/50], Step [29/100], Loss: 5.9438\n",
      "Epoch [10/50], Step [30/100], Loss: 5.7804\n",
      "Epoch [10/50], Step [31/100], Loss: 9.5071\n",
      "Epoch [10/50], Step [32/100], Loss: 6.7250\n",
      "Epoch [10/50], Step [33/100], Loss: 3.5527\n",
      "Epoch [10/50], Step [34/100], Loss: 7.4337\n",
      "Epoch [10/50], Step [35/100], Loss: 6.7650\n",
      "Epoch [10/50], Step [36/100], Loss: 7.8117\n",
      "Epoch [10/50], Step [37/100], Loss: 5.3397\n",
      "Epoch [10/50], Step [38/100], Loss: 3.9705\n",
      "Epoch [10/50], Step [39/100], Loss: 8.5717\n",
      "Epoch [10/50], Step [40/100], Loss: 8.4720\n",
      "Epoch [10/50], Step [41/100], Loss: 4.2536\n",
      "Epoch [10/50], Step [42/100], Loss: 5.4416\n",
      "Epoch [10/50], Step [43/100], Loss: 9.0861\n",
      "Epoch [10/50], Step [44/100], Loss: 4.2799\n",
      "Epoch [10/50], Step [45/100], Loss: 2.2375\n",
      "Epoch [10/50], Step [46/100], Loss: 3.7930\n",
      "Epoch [10/50], Step [47/100], Loss: 7.4889\n",
      "Epoch [10/50], Step [48/100], Loss: 4.6706\n",
      "Epoch [10/50], Step [49/100], Loss: 3.1529\n",
      "Epoch [10/50], Step [50/100], Loss: 1.2374\n",
      "Epoch [10/50], Step [51/100], Loss: 7.0380\n",
      "Epoch [10/50], Step [52/100], Loss: 3.4528\n",
      "Epoch [10/50], Step [53/100], Loss: 5.0381\n",
      "Epoch [10/50], Step [54/100], Loss: 2.2913\n",
      "Epoch [10/50], Step [55/100], Loss: 5.7075\n",
      "Epoch [10/50], Step [56/100], Loss: 2.3325\n",
      "Epoch [10/50], Step [57/100], Loss: 4.7071\n",
      "Epoch [10/50], Step [58/100], Loss: 0.7110\n",
      "Epoch [10/50], Step [59/100], Loss: 4.4953\n",
      "Epoch [10/50], Step [60/100], Loss: 3.2230\n",
      "Epoch [10/50], Step [61/100], Loss: 2.5367\n",
      "Epoch [10/50], Step [62/100], Loss: 1.5147\n",
      "Epoch [10/50], Step [63/100], Loss: 6.9737\n",
      "Epoch [10/50], Step [64/100], Loss: 2.1396\n",
      "Epoch [10/50], Step [65/100], Loss: 3.6793\n",
      "Epoch [10/50], Step [66/100], Loss: 11.0616\n",
      "Epoch [10/50], Step [67/100], Loss: 7.9373\n",
      "Epoch [10/50], Step [68/100], Loss: 2.3423\n",
      "Epoch [10/50], Step [69/100], Loss: 6.5323\n",
      "Epoch [10/50], Step [70/100], Loss: 14.8235\n",
      "Epoch [10/50], Step [71/100], Loss: 1.6946\n",
      "Epoch [10/50], Step [72/100], Loss: 6.2588\n",
      "Epoch [10/50], Step [73/100], Loss: 2.9028\n",
      "Epoch [10/50], Step [74/100], Loss: 3.7792\n",
      "Epoch [10/50], Step [75/100], Loss: 2.3906\n",
      "Epoch [10/50], Step [76/100], Loss: 2.4478\n",
      "Epoch [10/50], Step [77/100], Loss: 3.9469\n",
      "Epoch [10/50], Step [78/100], Loss: 3.5895\n",
      "Epoch [10/50], Step [79/100], Loss: 1.6438\n",
      "Epoch [10/50], Step [80/100], Loss: 0.7220\n",
      "Epoch [10/50], Step [81/100], Loss: 4.0495\n",
      "Epoch [10/50], Step [82/100], Loss: 7.4957\n",
      "Epoch [10/50], Step [83/100], Loss: 1.5939\n",
      "Epoch [10/50], Step [84/100], Loss: 2.7254\n",
      "Epoch [10/50], Step [85/100], Loss: 2.1339\n",
      "Epoch [10/50], Step [86/100], Loss: 1.6697\n",
      "Epoch [10/50], Step [87/100], Loss: 12.8389\n",
      "Epoch [10/50], Step [88/100], Loss: 2.2367\n",
      "Epoch [10/50], Step [89/100], Loss: 2.1775\n",
      "Epoch [10/50], Step [90/100], Loss: 1.3608\n",
      "Epoch [10/50], Step [91/100], Loss: 4.2546\n",
      "Epoch [10/50], Step [92/100], Loss: 9.1791\n",
      "Epoch [10/50], Step [93/100], Loss: 2.2795\n",
      "Epoch [10/50], Step [94/100], Loss: 1.8671\n",
      "Epoch [10/50], Step [95/100], Loss: 7.7181\n",
      "Epoch [10/50], Step [96/100], Loss: 3.4241\n",
      "Epoch [10/50], Step [97/100], Loss: 1.8516\n",
      "Epoch [10/50], Step [98/100], Loss: 6.5174\n",
      "Epoch [10/50], Step [99/100], Loss: 1.8391\n",
      "Epoch [10/50], Step [100/100], Loss: 1.5988\n",
      "Epoch [20/50], Step [1/100], Loss: 1.9633\n",
      "Epoch [20/50], Step [2/100], Loss: 11.6499\n",
      "Epoch [20/50], Step [3/100], Loss: 4.6578\n",
      "Epoch [20/50], Step [4/100], Loss: 5.6743\n",
      "Epoch [20/50], Step [5/100], Loss: 3.2400\n",
      "Epoch [20/50], Step [6/100], Loss: 2.6483\n",
      "Epoch [20/50], Step [7/100], Loss: 9.5630\n",
      "Epoch [20/50], Step [8/100], Loss: 8.3867\n",
      "Epoch [20/50], Step [9/100], Loss: 0.9908\n",
      "Epoch [20/50], Step [10/100], Loss: 10.4735\n",
      "Epoch [20/50], Step [11/100], Loss: 4.3152\n",
      "Epoch [20/50], Step [12/100], Loss: 3.0107\n",
      "Epoch [20/50], Step [13/100], Loss: 2.9032\n",
      "Epoch [20/50], Step [14/100], Loss: 2.9375\n",
      "Epoch [20/50], Step [15/100], Loss: 10.0501\n",
      "Epoch [20/50], Step [16/100], Loss: 10.4901\n",
      "Epoch [20/50], Step [17/100], Loss: 3.1697\n",
      "Epoch [20/50], Step [18/100], Loss: 7.6113\n",
      "Epoch [20/50], Step [19/100], Loss: 3.9409\n",
      "Epoch [20/50], Step [20/100], Loss: 5.3321\n",
      "Epoch [20/50], Step [21/100], Loss: 5.4082\n",
      "Epoch [20/50], Step [22/100], Loss: 6.4674\n",
      "Epoch [20/50], Step [23/100], Loss: 9.5955\n",
      "Epoch [20/50], Step [24/100], Loss: 2.9951\n",
      "Epoch [20/50], Step [25/100], Loss: 4.4970\n",
      "Epoch [20/50], Step [26/100], Loss: 2.3505\n",
      "Epoch [20/50], Step [27/100], Loss: 2.9196\n",
      "Epoch [20/50], Step [28/100], Loss: 7.8498\n",
      "Epoch [20/50], Step [29/100], Loss: 2.6826\n",
      "Epoch [20/50], Step [30/100], Loss: 2.9619\n",
      "Epoch [20/50], Step [31/100], Loss: 3.5404\n",
      "Epoch [20/50], Step [32/100], Loss: 0.6836\n",
      "Epoch [20/50], Step [33/100], Loss: 2.4044\n",
      "Epoch [20/50], Step [34/100], Loss: 0.9821\n",
      "Epoch [20/50], Step [35/100], Loss: 4.9927\n",
      "Epoch [20/50], Step [36/100], Loss: 4.7102\n",
      "Epoch [20/50], Step [37/100], Loss: 4.6663\n",
      "Epoch [20/50], Step [38/100], Loss: 3.1659\n",
      "Epoch [20/50], Step [39/100], Loss: 4.6219\n",
      "Epoch [20/50], Step [40/100], Loss: 2.3202\n",
      "Epoch [20/50], Step [41/100], Loss: 3.9758\n",
      "Epoch [20/50], Step [42/100], Loss: 3.1372\n",
      "Epoch [20/50], Step [43/100], Loss: 1.8526\n",
      "Epoch [20/50], Step [44/100], Loss: 1.8885\n",
      "Epoch [20/50], Step [45/100], Loss: 5.0213\n",
      "Epoch [20/50], Step [46/100], Loss: 2.8263\n",
      "Epoch [20/50], Step [47/100], Loss: 3.4784\n",
      "Epoch [20/50], Step [48/100], Loss: 2.5182\n",
      "Epoch [20/50], Step [49/100], Loss: 8.6199\n",
      "Epoch [20/50], Step [50/100], Loss: 6.2929\n",
      "Epoch [20/50], Step [51/100], Loss: 3.6634\n",
      "Epoch [20/50], Step [52/100], Loss: 1.2047\n",
      "Epoch [20/50], Step [53/100], Loss: 2.1633\n",
      "Epoch [20/50], Step [54/100], Loss: 2.0152\n",
      "Epoch [20/50], Step [55/100], Loss: 2.7089\n",
      "Epoch [20/50], Step [56/100], Loss: 1.3189\n",
      "Epoch [20/50], Step [57/100], Loss: 2.6050\n",
      "Epoch [20/50], Step [58/100], Loss: 3.3097\n",
      "Epoch [20/50], Step [59/100], Loss: 1.9994\n",
      "Epoch [20/50], Step [60/100], Loss: 14.3611\n",
      "Epoch [20/50], Step [61/100], Loss: 3.4779\n",
      "Epoch [20/50], Step [62/100], Loss: 5.0953\n",
      "Epoch [20/50], Step [63/100], Loss: 2.7466\n",
      "Epoch [20/50], Step [64/100], Loss: 1.4874\n",
      "Epoch [20/50], Step [65/100], Loss: 3.0201\n",
      "Epoch [20/50], Step [66/100], Loss: 1.9791\n",
      "Epoch [20/50], Step [67/100], Loss: 2.8944\n",
      "Epoch [20/50], Step [68/100], Loss: 4.0862\n",
      "Epoch [20/50], Step [69/100], Loss: 4.5780\n",
      "Epoch [20/50], Step [70/100], Loss: 1.6477\n",
      "Epoch [20/50], Step [71/100], Loss: 4.2694\n",
      "Epoch [20/50], Step [72/100], Loss: 3.3618\n",
      "Epoch [20/50], Step [73/100], Loss: 3.7477\n",
      "Epoch [20/50], Step [74/100], Loss: 5.3459\n",
      "Epoch [20/50], Step [75/100], Loss: 1.8417\n",
      "Epoch [20/50], Step [76/100], Loss: 0.9351\n",
      "Epoch [20/50], Step [77/100], Loss: 1.8768\n",
      "Epoch [20/50], Step [78/100], Loss: 2.3749\n",
      "Epoch [20/50], Step [79/100], Loss: 3.9837\n",
      "Epoch [20/50], Step [80/100], Loss: 2.8830\n",
      "Epoch [20/50], Step [81/100], Loss: 4.5799\n",
      "Epoch [20/50], Step [82/100], Loss: 2.7381\n",
      "Epoch [20/50], Step [83/100], Loss: 4.6025\n",
      "Epoch [20/50], Step [84/100], Loss: 0.9513\n",
      "Epoch [20/50], Step [85/100], Loss: 5.8685\n",
      "Epoch [20/50], Step [86/100], Loss: 2.9150\n",
      "Epoch [20/50], Step [87/100], Loss: 3.0375\n",
      "Epoch [20/50], Step [88/100], Loss: 4.5889\n",
      "Epoch [20/50], Step [89/100], Loss: 2.6624\n",
      "Epoch [20/50], Step [90/100], Loss: 3.1315\n",
      "Epoch [20/50], Step [91/100], Loss: 2.3445\n",
      "Epoch [20/50], Step [92/100], Loss: 2.4199\n",
      "Epoch [20/50], Step [93/100], Loss: 3.3848\n",
      "Epoch [20/50], Step [94/100], Loss: 2.0059\n",
      "Epoch [20/50], Step [95/100], Loss: 5.2884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Step [96/100], Loss: 2.3943\n",
      "Epoch [20/50], Step [97/100], Loss: 13.0939\n",
      "Epoch [20/50], Step [98/100], Loss: 3.4412\n",
      "Epoch [20/50], Step [99/100], Loss: 8.0817\n",
      "Epoch [20/50], Step [100/100], Loss: 3.4886\n",
      "Epoch [30/50], Step [1/100], Loss: 4.0768\n",
      "Epoch [30/50], Step [2/100], Loss: 1.9172\n",
      "Epoch [30/50], Step [3/100], Loss: 0.8485\n",
      "Epoch [30/50], Step [4/100], Loss: 2.9886\n",
      "Epoch [30/50], Step [5/100], Loss: 3.1148\n",
      "Epoch [30/50], Step [6/100], Loss: 0.9427\n",
      "Epoch [30/50], Step [7/100], Loss: 1.2085\n",
      "Epoch [30/50], Step [8/100], Loss: 2.8824\n",
      "Epoch [30/50], Step [9/100], Loss: 2.1958\n",
      "Epoch [30/50], Step [10/100], Loss: 1.7573\n",
      "Epoch [30/50], Step [11/100], Loss: 3.4557\n",
      "Epoch [30/50], Step [12/100], Loss: 5.0022\n",
      "Epoch [30/50], Step [13/100], Loss: 1.7518\n",
      "Epoch [30/50], Step [14/100], Loss: 1.0585\n",
      "Epoch [30/50], Step [15/100], Loss: 1.1517\n",
      "Epoch [30/50], Step [16/100], Loss: 1.6982\n",
      "Epoch [30/50], Step [17/100], Loss: 3.1661\n",
      "Epoch [30/50], Step [18/100], Loss: 3.5809\n",
      "Epoch [30/50], Step [19/100], Loss: 1.2535\n",
      "Epoch [30/50], Step [20/100], Loss: 0.9344\n",
      "Epoch [30/50], Step [21/100], Loss: 3.4518\n",
      "Epoch [30/50], Step [22/100], Loss: 1.8993\n",
      "Epoch [30/50], Step [23/100], Loss: 1.0127\n",
      "Epoch [30/50], Step [24/100], Loss: 2.1636\n",
      "Epoch [30/50], Step [25/100], Loss: 1.5750\n",
      "Epoch [30/50], Step [26/100], Loss: 3.3932\n",
      "Epoch [30/50], Step [27/100], Loss: 1.0521\n",
      "Epoch [30/50], Step [28/100], Loss: 2.8909\n",
      "Epoch [30/50], Step [29/100], Loss: 3.0000\n",
      "Epoch [30/50], Step [30/100], Loss: 2.2749\n",
      "Epoch [30/50], Step [31/100], Loss: 0.8202\n",
      "Epoch [30/50], Step [32/100], Loss: 2.3599\n",
      "Epoch [30/50], Step [33/100], Loss: 2.6213\n",
      "Epoch [30/50], Step [34/100], Loss: 1.5799\n",
      "Epoch [30/50], Step [35/100], Loss: 1.5835\n",
      "Epoch [30/50], Step [36/100], Loss: 4.0089\n",
      "Epoch [30/50], Step [37/100], Loss: 2.1384\n",
      "Epoch [30/50], Step [38/100], Loss: 1.6854\n",
      "Epoch [30/50], Step [39/100], Loss: 2.5905\n",
      "Epoch [30/50], Step [40/100], Loss: 1.0010\n",
      "Epoch [30/50], Step [41/100], Loss: 3.3841\n",
      "Epoch [30/50], Step [42/100], Loss: 2.2208\n",
      "Epoch [30/50], Step [43/100], Loss: 2.2484\n",
      "Epoch [30/50], Step [44/100], Loss: 1.4575\n",
      "Epoch [30/50], Step [45/100], Loss: 0.9320\n",
      "Epoch [30/50], Step [46/100], Loss: 6.5216\n",
      "Epoch [30/50], Step [47/100], Loss: 2.2213\n",
      "Epoch [30/50], Step [48/100], Loss: 0.7254\n",
      "Epoch [30/50], Step [49/100], Loss: 1.0059\n",
      "Epoch [30/50], Step [50/100], Loss: 0.7264\n",
      "Epoch [30/50], Step [51/100], Loss: 2.3903\n",
      "Epoch [30/50], Step [52/100], Loss: 1.1992\n",
      "Epoch [30/50], Step [53/100], Loss: 1.5659\n",
      "Epoch [30/50], Step [54/100], Loss: 1.6772\n",
      "Epoch [30/50], Step [55/100], Loss: 2.2554\n",
      "Epoch [30/50], Step [56/100], Loss: 1.1810\n",
      "Epoch [30/50], Step [57/100], Loss: 2.5486\n",
      "Epoch [30/50], Step [58/100], Loss: 2.4835\n",
      "Epoch [30/50], Step [59/100], Loss: 2.6367\n",
      "Epoch [30/50], Step [60/100], Loss: 1.0002\n",
      "Epoch [30/50], Step [61/100], Loss: 0.8909\n",
      "Epoch [30/50], Step [62/100], Loss: 0.8095\n",
      "Epoch [30/50], Step [63/100], Loss: 1.7916\n",
      "Epoch [30/50], Step [64/100], Loss: 3.0445\n",
      "Epoch [30/50], Step [65/100], Loss: 1.3341\n",
      "Epoch [30/50], Step [66/100], Loss: 0.8456\n",
      "Epoch [30/50], Step [67/100], Loss: 0.7434\n",
      "Epoch [30/50], Step [68/100], Loss: 1.9589\n",
      "Epoch [30/50], Step [69/100], Loss: 4.1461\n",
      "Epoch [30/50], Step [70/100], Loss: 0.8850\n",
      "Epoch [30/50], Step [71/100], Loss: 1.1044\n",
      "Epoch [30/50], Step [72/100], Loss: 1.8721\n",
      "Epoch [30/50], Step [73/100], Loss: 1.0461\n",
      "Epoch [30/50], Step [74/100], Loss: 1.4742\n",
      "Epoch [30/50], Step [75/100], Loss: 1.1287\n",
      "Epoch [30/50], Step [76/100], Loss: 1.3404\n",
      "Epoch [30/50], Step [77/100], Loss: 2.2981\n",
      "Epoch [30/50], Step [78/100], Loss: 2.3747\n",
      "Epoch [30/50], Step [79/100], Loss: 1.4566\n",
      "Epoch [30/50], Step [80/100], Loss: 3.2893\n",
      "Epoch [30/50], Step [81/100], Loss: 2.1943\n",
      "Epoch [30/50], Step [82/100], Loss: 1.4389\n",
      "Epoch [30/50], Step [83/100], Loss: 6.0778\n",
      "Epoch [30/50], Step [84/100], Loss: 2.0957\n",
      "Epoch [30/50], Step [85/100], Loss: 2.3930\n",
      "Epoch [30/50], Step [86/100], Loss: 1.8229\n",
      "Epoch [30/50], Step [87/100], Loss: 3.7483\n",
      "Epoch [30/50], Step [88/100], Loss: 2.2119\n",
      "Epoch [30/50], Step [89/100], Loss: 4.2255\n",
      "Epoch [30/50], Step [90/100], Loss: 4.9341\n",
      "Epoch [30/50], Step [91/100], Loss: 2.8191\n",
      "Epoch [30/50], Step [92/100], Loss: 3.2344\n",
      "Epoch [30/50], Step [93/100], Loss: 2.2148\n",
      "Epoch [30/50], Step [94/100], Loss: 5.0391\n",
      "Epoch [30/50], Step [95/100], Loss: 5.1565\n",
      "Epoch [30/50], Step [96/100], Loss: 1.5672\n",
      "Epoch [30/50], Step [97/100], Loss: 2.6784\n",
      "Epoch [30/50], Step [98/100], Loss: 2.0371\n",
      "Epoch [30/50], Step [99/100], Loss: 5.9394\n",
      "Epoch [30/50], Step [100/100], Loss: 2.9250\n",
      "Epoch [40/50], Step [1/100], Loss: 11.2769\n",
      "Epoch [40/50], Step [2/100], Loss: 3.8737\n",
      "Epoch [40/50], Step [3/100], Loss: 4.3133\n",
      "Epoch [40/50], Step [4/100], Loss: 1.8507\n",
      "Epoch [40/50], Step [5/100], Loss: 5.5413\n",
      "Epoch [40/50], Step [6/100], Loss: 3.9646\n",
      "Epoch [40/50], Step [7/100], Loss: 1.8334\n",
      "Epoch [40/50], Step [8/100], Loss: 7.0113\n",
      "Epoch [40/50], Step [9/100], Loss: 6.2234\n",
      "Epoch [40/50], Step [10/100], Loss: 2.5988\n",
      "Epoch [40/50], Step [11/100], Loss: 1.5684\n",
      "Epoch [40/50], Step [12/100], Loss: 2.5776\n",
      "Epoch [40/50], Step [13/100], Loss: 2.6918\n",
      "Epoch [40/50], Step [14/100], Loss: 4.7689\n",
      "Epoch [40/50], Step [15/100], Loss: 2.3839\n",
      "Epoch [40/50], Step [16/100], Loss: 1.7719\n",
      "Epoch [40/50], Step [17/100], Loss: 2.1378\n",
      "Epoch [40/50], Step [18/100], Loss: 1.3287\n",
      "Epoch [40/50], Step [19/100], Loss: 4.8320\n",
      "Epoch [40/50], Step [20/100], Loss: 2.0542\n",
      "Epoch [40/50], Step [21/100], Loss: 1.4399\n",
      "Epoch [40/50], Step [22/100], Loss: 2.4293\n",
      "Epoch [40/50], Step [23/100], Loss: 3.1194\n",
      "Epoch [40/50], Step [24/100], Loss: 3.7105\n",
      "Epoch [40/50], Step [25/100], Loss: 3.3884\n",
      "Epoch [40/50], Step [26/100], Loss: 1.4297\n",
      "Epoch [40/50], Step [27/100], Loss: 6.2215\n",
      "Epoch [40/50], Step [28/100], Loss: 4.7463\n",
      "Epoch [40/50], Step [29/100], Loss: 3.3791\n",
      "Epoch [40/50], Step [30/100], Loss: 6.8207\n",
      "Epoch [40/50], Step [31/100], Loss: 1.9952\n",
      "Epoch [40/50], Step [32/100], Loss: 2.3871\n",
      "Epoch [40/50], Step [33/100], Loss: 2.6471\n",
      "Epoch [40/50], Step [34/100], Loss: 1.7163\n",
      "Epoch [40/50], Step [35/100], Loss: 2.1698\n",
      "Epoch [40/50], Step [36/100], Loss: 2.2694\n",
      "Epoch [40/50], Step [37/100], Loss: 2.0545\n",
      "Epoch [40/50], Step [38/100], Loss: 1.6528\n",
      "Epoch [40/50], Step [39/100], Loss: 2.3845\n",
      "Epoch [40/50], Step [40/100], Loss: 0.4358\n",
      "Epoch [40/50], Step [41/100], Loss: 2.6008\n",
      "Epoch [40/50], Step [42/100], Loss: 1.2135\n",
      "Epoch [40/50], Step [43/100], Loss: 4.4663\n",
      "Epoch [40/50], Step [44/100], Loss: 3.1528\n",
      "Epoch [40/50], Step [45/100], Loss: 2.3079\n",
      "Epoch [40/50], Step [46/100], Loss: 2.8966\n",
      "Epoch [40/50], Step [47/100], Loss: 3.9998\n",
      "Epoch [40/50], Step [48/100], Loss: 1.6347\n",
      "Epoch [40/50], Step [49/100], Loss: 1.5117\n",
      "Epoch [40/50], Step [50/100], Loss: 1.8208\n",
      "Epoch [40/50], Step [51/100], Loss: 2.4965\n",
      "Epoch [40/50], Step [52/100], Loss: 1.3451\n",
      "Epoch [40/50], Step [53/100], Loss: 2.0642\n",
      "Epoch [40/50], Step [54/100], Loss: 4.0347\n",
      "Epoch [40/50], Step [55/100], Loss: 1.4773\n",
      "Epoch [40/50], Step [56/100], Loss: 0.5399\n",
      "Epoch [40/50], Step [57/100], Loss: 3.9314\n",
      "Epoch [40/50], Step [58/100], Loss: 1.2447\n",
      "Epoch [40/50], Step [59/100], Loss: 1.5137\n",
      "Epoch [40/50], Step [60/100], Loss: 0.5361\n",
      "Epoch [40/50], Step [61/100], Loss: 1.8115\n",
      "Epoch [40/50], Step [62/100], Loss: 1.0379\n",
      "Epoch [40/50], Step [63/100], Loss: 1.2817\n",
      "Epoch [40/50], Step [64/100], Loss: 2.4682\n",
      "Epoch [40/50], Step [65/100], Loss: 0.6927\n",
      "Epoch [40/50], Step [66/100], Loss: 0.9664\n",
      "Epoch [40/50], Step [67/100], Loss: 2.7856\n",
      "Epoch [40/50], Step [68/100], Loss: 0.9347\n",
      "Epoch [40/50], Step [69/100], Loss: 0.9099\n",
      "Epoch [40/50], Step [70/100], Loss: 0.9577\n",
      "Epoch [40/50], Step [71/100], Loss: 3.2516\n",
      "Epoch [40/50], Step [72/100], Loss: 1.4907\n",
      "Epoch [40/50], Step [73/100], Loss: 1.4292\n",
      "Epoch [40/50], Step [74/100], Loss: 1.7758\n",
      "Epoch [40/50], Step [75/100], Loss: 2.0371\n",
      "Epoch [40/50], Step [76/100], Loss: 2.1573\n",
      "Epoch [40/50], Step [77/100], Loss: 1.4858\n",
      "Epoch [40/50], Step [78/100], Loss: 0.6103\n",
      "Epoch [40/50], Step [79/100], Loss: 4.9980\n",
      "Epoch [40/50], Step [80/100], Loss: 1.8908\n",
      "Epoch [40/50], Step [81/100], Loss: 1.4691\n",
      "Epoch [40/50], Step [82/100], Loss: 4.2042\n",
      "Epoch [40/50], Step [83/100], Loss: 1.5845\n",
      "Epoch [40/50], Step [84/100], Loss: 1.4104\n",
      "Epoch [40/50], Step [85/100], Loss: 1.3794\n",
      "Epoch [40/50], Step [86/100], Loss: 1.8064\n",
      "Epoch [40/50], Step [87/100], Loss: 1.1819\n",
      "Epoch [40/50], Step [88/100], Loss: 0.6800\n",
      "Epoch [40/50], Step [89/100], Loss: 0.9782\n",
      "Epoch [40/50], Step [90/100], Loss: 0.8871\n",
      "Epoch [40/50], Step [91/100], Loss: 1.1481\n",
      "Epoch [40/50], Step [92/100], Loss: 0.7973\n",
      "Epoch [40/50], Step [93/100], Loss: 0.7334\n",
      "Epoch [40/50], Step [94/100], Loss: 1.4059\n",
      "Epoch [40/50], Step [95/100], Loss: 1.6627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Step [96/100], Loss: 0.3928\n",
      "Epoch [40/50], Step [97/100], Loss: 1.0164\n",
      "Epoch [40/50], Step [98/100], Loss: 1.8940\n",
      "Epoch [40/50], Step [99/100], Loss: 0.8397\n",
      "Epoch [40/50], Step [100/100], Loss: 2.5379\n",
      "Epoch [50/50], Step [1/100], Loss: 2.0032\n",
      "Epoch [50/50], Step [2/100], Loss: 2.8212\n",
      "Epoch [50/50], Step [3/100], Loss: 0.9271\n",
      "Epoch [50/50], Step [4/100], Loss: 2.2694\n",
      "Epoch [50/50], Step [5/100], Loss: 0.6949\n",
      "Epoch [50/50], Step [6/100], Loss: 2.2219\n",
      "Epoch [50/50], Step [7/100], Loss: 3.1904\n",
      "Epoch [50/50], Step [8/100], Loss: 1.1502\n",
      "Epoch [50/50], Step [9/100], Loss: 3.3825\n",
      "Epoch [50/50], Step [10/100], Loss: 2.8470\n",
      "Epoch [50/50], Step [11/100], Loss: 1.1017\n",
      "Epoch [50/50], Step [12/100], Loss: 4.5316\n",
      "Epoch [50/50], Step [13/100], Loss: 1.1689\n",
      "Epoch [50/50], Step [14/100], Loss: 3.6239\n",
      "Epoch [50/50], Step [15/100], Loss: 2.3700\n",
      "Epoch [50/50], Step [16/100], Loss: 3.5008\n",
      "Epoch [50/50], Step [17/100], Loss: 0.8969\n",
      "Epoch [50/50], Step [18/100], Loss: 2.7310\n",
      "Epoch [50/50], Step [19/100], Loss: 1.3720\n",
      "Epoch [50/50], Step [20/100], Loss: 2.7820\n",
      "Epoch [50/50], Step [21/100], Loss: 2.4490\n",
      "Epoch [50/50], Step [22/100], Loss: 1.7139\n",
      "Epoch [50/50], Step [23/100], Loss: 1.2859\n",
      "Epoch [50/50], Step [24/100], Loss: 3.0190\n",
      "Epoch [50/50], Step [25/100], Loss: 1.2140\n",
      "Epoch [50/50], Step [26/100], Loss: 2.1749\n",
      "Epoch [50/50], Step [27/100], Loss: 1.0150\n",
      "Epoch [50/50], Step [28/100], Loss: 3.4463\n",
      "Epoch [50/50], Step [29/100], Loss: 1.6165\n",
      "Epoch [50/50], Step [30/100], Loss: 4.0251\n",
      "Epoch [50/50], Step [31/100], Loss: 1.3691\n",
      "Epoch [50/50], Step [32/100], Loss: 2.6663\n",
      "Epoch [50/50], Step [33/100], Loss: 0.5351\n",
      "Epoch [50/50], Step [34/100], Loss: 0.8478\n",
      "Epoch [50/50], Step [35/100], Loss: 2.7475\n",
      "Epoch [50/50], Step [36/100], Loss: 1.4239\n",
      "Epoch [50/50], Step [37/100], Loss: 1.0948\n",
      "Epoch [50/50], Step [38/100], Loss: 0.8199\n",
      "Epoch [50/50], Step [39/100], Loss: 1.5585\n",
      "Epoch [50/50], Step [40/100], Loss: 1.2093\n",
      "Epoch [50/50], Step [41/100], Loss: 1.1312\n",
      "Epoch [50/50], Step [42/100], Loss: 1.6378\n",
      "Epoch [50/50], Step [43/100], Loss: 2.2450\n",
      "Epoch [50/50], Step [44/100], Loss: 2.4340\n",
      "Epoch [50/50], Step [45/100], Loss: 0.5507\n",
      "Epoch [50/50], Step [46/100], Loss: 3.1260\n",
      "Epoch [50/50], Step [47/100], Loss: 0.7913\n",
      "Epoch [50/50], Step [48/100], Loss: 1.8418\n",
      "Epoch [50/50], Step [49/100], Loss: 3.2613\n",
      "Epoch [50/50], Step [50/100], Loss: 2.1037\n",
      "Epoch [50/50], Step [51/100], Loss: 2.0054\n",
      "Epoch [50/50], Step [52/100], Loss: 1.2122\n",
      "Epoch [50/50], Step [53/100], Loss: 5.6059\n",
      "Epoch [50/50], Step [54/100], Loss: 1.9663\n",
      "Epoch [50/50], Step [55/100], Loss: 1.0500\n",
      "Epoch [50/50], Step [56/100], Loss: 0.5913\n",
      "Epoch [50/50], Step [57/100], Loss: 5.1654\n",
      "Epoch [50/50], Step [58/100], Loss: 5.1748\n",
      "Epoch [50/50], Step [59/100], Loss: 1.4338\n",
      "Epoch [50/50], Step [60/100], Loss: 3.2472\n",
      "Epoch [50/50], Step [61/100], Loss: 3.6692\n",
      "Epoch [50/50], Step [62/100], Loss: 2.1969\n",
      "Epoch [50/50], Step [63/100], Loss: 1.0658\n",
      "Epoch [50/50], Step [64/100], Loss: 3.3455\n",
      "Epoch [50/50], Step [65/100], Loss: 1.6961\n",
      "Epoch [50/50], Step [66/100], Loss: 5.3582\n",
      "Epoch [50/50], Step [67/100], Loss: 2.2213\n",
      "Epoch [50/50], Step [68/100], Loss: 0.9918\n",
      "Epoch [50/50], Step [69/100], Loss: 1.1493\n",
      "Epoch [50/50], Step [70/100], Loss: 3.8606\n",
      "Epoch [50/50], Step [71/100], Loss: 2.3977\n",
      "Epoch [50/50], Step [72/100], Loss: 2.1275\n",
      "Epoch [50/50], Step [73/100], Loss: 2.4052\n",
      "Epoch [50/50], Step [74/100], Loss: 0.9466\n",
      "Epoch [50/50], Step [75/100], Loss: 2.2278\n",
      "Epoch [50/50], Step [76/100], Loss: 3.7552\n",
      "Epoch [50/50], Step [77/100], Loss: 2.3080\n",
      "Epoch [50/50], Step [78/100], Loss: 2.1092\n",
      "Epoch [50/50], Step [79/100], Loss: 1.7695\n",
      "Epoch [50/50], Step [80/100], Loss: 1.8763\n",
      "Epoch [50/50], Step [81/100], Loss: 2.5870\n",
      "Epoch [50/50], Step [82/100], Loss: 2.9042\n",
      "Epoch [50/50], Step [83/100], Loss: 2.0860\n",
      "Epoch [50/50], Step [84/100], Loss: 2.2159\n",
      "Epoch [50/50], Step [85/100], Loss: 2.3622\n",
      "Epoch [50/50], Step [86/100], Loss: 1.5258\n",
      "Epoch [50/50], Step [87/100], Loss: 1.6027\n",
      "Epoch [50/50], Step [88/100], Loss: 2.7040\n",
      "Epoch [50/50], Step [89/100], Loss: 1.2897\n",
      "Epoch [50/50], Step [90/100], Loss: 1.3891\n",
      "Epoch [50/50], Step [91/100], Loss: 0.6350\n",
      "Epoch [50/50], Step [92/100], Loss: 1.9770\n",
      "Epoch [50/50], Step [93/100], Loss: 3.0703\n",
      "Epoch [50/50], Step [94/100], Loss: 0.4555\n",
      "Epoch [50/50], Step [95/100], Loss: 1.5109\n",
      "Epoch [50/50], Step [96/100], Loss: 0.5502\n",
      "Epoch [50/50], Step [97/100], Loss: 0.6836\n",
      "Epoch [50/50], Step [98/100], Loss: 2.5155\n",
      "Epoch [50/50], Step [99/100], Loss: 2.3486\n",
      "Epoch [50/50], Step [100/100], Loss: 0.9413\n"
     ]
    }
   ],
   "source": [
    "losses_list = []\n",
    "ct = 0\n",
    "print('Training model now...')\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i_batch, (images, labels) in enumerate(train_loader):\n",
    "        #print(ct)\n",
    "        ct+=1\n",
    "        #print(i_batch)\n",
    "        if ct == 2:\n",
    "            print(len(train_loader))\n",
    "        #ct += 1\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images).to(device)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #if (i_batch+1) % 1 == 0:\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1,\n",
    "                                                                      num_epochs,\n",
    "                                                                      i_batch+1,\n",
    "                                                                      total_step,\n",
    "                                                                      loss.item()))\n",
    "        losses_list.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "100\n",
      "20\n",
      "20\n",
      "i_batch 0\n",
      "i_batch 1\n",
      "i_batch 2\n",
      "i_batch 3\n",
      "i_batch 4\n",
      "i_batch 5\n",
      "i_batch 6\n",
      "i_batch 7\n",
      "i_batch 8\n",
      "i_batch 9\n",
      "i_batch 10\n",
      "i_batch 11\n",
      "i_batch 12\n",
      "i_batch 13\n",
      "i_batch 14\n",
      "i_batch 15\n",
      "i_batch 16\n",
      "i_batch 17\n",
      "i_batch 18\n",
      "i_batch 19\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "model.to(device).eval()  \n",
    "# eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "\n",
    "# evaluation: MSE loss of center predictions\n",
    "# evaluation: MSE loss of degree predictions\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "print(len(test_loader))\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))\n",
    "print(len(test_loader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_err = 0\n",
    "    n_total = 0\n",
    "    for i_batch, (images, labels) in enumerate(test_loader):\n",
    "    #for i_batch, (images, labels) in enumerate(train_loader):\n",
    "        print('i_batch', i_batch)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images).to(device)\n",
    "        diff = outputs - labels\n",
    "        diff = torch.sum(diff, 0) #column sum\n",
    "        total_err += diff\n",
    "        #loss = criterion(outputs, labels)\n",
    "        #print(loss)\n",
    "        #x, y, orient = outputs.squeeze() # remove extra dim, so not nested list of list\n",
    "        #true_x, true_y, true_orient = labels.squeeze()\n",
    "        #xy_err +=criterion( torch.Tensor([x,y]), torch.Tensor([true_x, true_y]))\n",
    "        #orient_err += criterion(orient, true_orient)\n",
    "        #print(n_total)\n",
    "        #n_total += 1\n",
    "        #_, predicted = torch.max(outputs.data, 1)\n",
    "        #total += labels.size(0)\n",
    "        #correct += (predicted == labels).sum().item()\n",
    "print(n_total * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAABGklEQVR4nO3cQQ6CMBRFUWrc/5br1ATFWHj8pD1nAcLg5oc3cdsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP7XWqt+Be7wzP20hlZ2WVgy4t1IWBrip8f9j9TlCgrCYgUjYfXeL38PJuNiESEsIoRFRE1YhuH0XCwiBsMyDDnmYhEhLCKERURZWIbh3FwsIsbDMgw54GIRISwihEVEZViG4cRcLCJOhWUY8o2LRYSwiBAWEcVhGYazcrGIOBuWYchHwX+b2VPhOoJhyYhTfIADAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKt7AWxnFVRZqpGpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=200x200 at 0x7FDC14E51A20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([114.3512,  78.8904,  43.3447], device='cuda:0')\n",
      "tensor([1.1435, 0.7889, 0.4334], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n_total = len(test_loader.dataset)\n",
    "\n",
    "print(n_total)\n",
    "from IPython.display import display # to display images\n",
    "\n",
    "import torchvision\n",
    "img = torchvision.transforms.ToPILImage()(images[0].cpu())\n",
    "display(img)\n",
    "\n",
    "avg_err = total_err / n_total \n",
    "print(total_err)\n",
    "print(avg_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display # to display images\n",
    "#font = ImageFont.truetype(\"Arial.ttf\",14) # OSError: cannot open resource\n",
    "font = ImageFont.truetype(\"/usr/share/fonts/dejavu/DejaVuSans.ttf\",14)\n",
    "def imshow_coord(img, a_label):\n",
    "    img = torchvision.transforms.ToPILImage()(img)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    #draw.text((10, 25), '(' + np.array2string(np.around(a_label.numpy()), separator=', ') + ')')\n",
    "    x,y,orient = a_label\n",
    "    rect_vertices = makeRectangle(5, 15, orient, offset=(x,y))\n",
    "    draw.polygon(rect_vertices, fill='red')\n",
    "    draw = draw_crosspointer(a_label, draw, 'green', 'white', length=8)\n",
    "    display(img)\n",
    "    \n",
    "def draw_crosspointer(xy, draw, fillcolor_X='green', fillcolor='white', length=2):\n",
    "    a,b, orient = tuple(xy)\n",
    "    draw.line((a-length, b+length, a+length, b-length), fill=fillcolor_X)\n",
    "    draw.line((a-length, b-length, a+length, b+length), fill=fillcolor_X)\n",
    "    draw.point((a,b))\n",
    "    return draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torchvision \n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "# get some random training images\n",
    "with torch.no_grad():\n",
    "    dataiter = iter(train_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    outputs = model(images)\n",
    "    \n",
    "    # show images\n",
    "    #imshow_coord(torchvision.utils.make_grid(images), (outputs))\n",
    "\n",
    "\n",
    "    # print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                                  # for j in range(4)))\n",
    "        \n",
    "    loss = criterion(outputs.to(device), labels.to(device))\n",
    " \n",
    "n =0 \n",
    "#print(len(labels))\n",
    "print('x,y truth', labels[n])\n",
    "print('x,y guess by net', outputs[n])\n",
    "\n",
    "images_copy = copy.deepcopy(images)\n",
    "print('image size: ', images_copy[n].size())\n",
    "print(loss)\n",
    "print('net output: ')\n",
    "imshow_coord(images_copy[n], outputs[n])\n",
    "print('truth label: ')\n",
    "imshow_coord(images_copy[n], labels[n])\n",
    "\n",
    "#imagePIL = torchvision.transforms.ToPILImage()(images[n])\n",
    "#print('PIL image size', imagePIL.size)\n",
    "#imagePIL.save('test.png')\n",
    "#display(imagePIL)\n",
    "\n",
    "#display(Image.open('./data/rect'+str(n)+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#im = Image.open(\"Mew.jpg\")\n",
    "n = 12\n",
    "n = np.random.rand()*len(images)\n",
    "n = int(n)\n",
    "\n",
    "image = io.imread('./data/rect'+str(n)+'.png')\n",
    "image_tensor = torch.FloatTensor(image).permute(2, 0, 1) #PIL and torch expect difft orders\n",
    "coords = torch.FloatTensor(true_coords[n])\n",
    "with torch.no_grad():\n",
    "    output = model(image_tensor)\n",
    "\n",
    "print(true_coords[n])\n",
    "print(output)\n",
    "x,y,orient = output.cpu().numpy().flatten()\n",
    "imshow_coord(image, (x,y, orient))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#img = Image.new('RGB', (300,400), 'gray')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "n = 0\n",
    "#imshow_coord(images[n], outputs[n], labels[n])\n",
    "\n",
    "print(images.size())\n",
    "a = torchvision.utils.make_grid(images)\n",
    "print(a.max(), a.min(), a.size())\n",
    "#a = a / 2 + 0.5     # unnormalize\n",
    "\n",
    "a = a.cpu().numpy()\n",
    "a = np.transpose(a,(1,2,0))\n",
    "print(a.shape)\n",
    "print(a.ndim)\n",
    "\n",
    "#ran = a.max() - a.min()\n",
    "#a = (a/ran )\n",
    "\n",
    "fig,ax = plt.subplots(1)\n",
    "# Display the image\n",
    "ax.imshow(a)\n",
    "#x,y = labels[0].numpy()\n",
    "#plt.scatter(x,y, color='g', marker='x', linewidth='1')\n",
    "labels = labels.cpu()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [30,5]\n",
    "import matplotlib.patches as patches\n",
    "for i in range(len(labels)):\n",
    "    x,y, orient = labels[i].numpy()\n",
    "\n",
    "# class matplotlib.patches.Rectangle(xy, width, height, angle=0.0, **kwargs)[source]\n",
    "\n",
    "    rect = patches.Rectangle((x + i*IMG_X, y), 1,20,angle=orient, fill=True, color='orange')\n",
    "    ax.add_patch(rect)\n",
    "    ax.scatter(x + i*IMG_X, y, color='r', marker='x', linewidth='1')\n",
    "#plt.imshow(np.transpose(a, (2,0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "f = plt.subplot()\n",
    "f.plot(range(len(losses_list)), losses_list)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [30, 5]\n",
    "xposition = np.array(range(num_epoch))  * (total_step)\n",
    "#print(xposition)\n",
    "for xc in xposition:\n",
    "    #plt.axvline(x=xc, color='k', linestyle='--')\n",
    "    pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = plt.subplot()\n",
    "trunc = 100\n",
    "g.plot(range(trunc), losses_list[-trunc:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't run the following cell (takes long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = [10,20,50,70,100,150] \n",
    "num_classes = 3 # predicting x,y,orientation\n",
    "batch_size = 5 \n",
    "learning_rates = [0.001, 0.005, 0.01, 0.1]\n",
    "\n",
    "meta_losses_list = []\n",
    "for i in range(len(num_epochs)):\n",
    "    num_epoch = num_epochs[i]\n",
    "    learning_rate = learning_rates[0]\n",
    "    losses_list = []\n",
    "    print('Training model now... with: %d num_epoch and %d learning rate' % (num_epoch, learning_rate))\n",
    "    \n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epoch):\n",
    "        for i_batch, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            # magnify orientation loss\n",
    "            outputs[2] *= 10\n",
    "            labels[2] *= 10\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i_batch+1) % 1 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1,\n",
    "                                                                          num_epochs,\n",
    "                                                                          i_batch+1,\n",
    "                                                                          total_step,\n",
    "                                                                          loss.item()))\n",
    "                losses_list.append(loss.item())\n",
    "    meta_losses_list.append(losses_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots()\n",
    "trunc = 100\n",
    "for l in meta_losses_list:\n",
    "    plt.plot(range(len(l[-trunc:])), l[-trunc:])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
